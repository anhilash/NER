<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06181810B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06181810</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6181810</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference family-id="22427965" extended-family-id="3907157">
      <document-id>
        <country>US</country>
        <doc-number>09127029</doc-number>
        <kind>A</kind>
        <date>19980730</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1998US-09127029</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>4041205</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>12702998</doc-number>
        <kind>A</kind>
        <date>19980730</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1998US-09127029</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>A61B   8/06        20060101AFI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>8</main-group>
        <subgroup>06</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G01S   7/52        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>01</class>
        <subclass>S</subclass>
        <main-group>7</main-group>
        <subgroup>52</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>G01S  15/89        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>01</class>
        <subclass>S</subclass>
        <main-group>15</main-group>
        <subgroup>89</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>G06T   1/00        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>1</main-group>
        <subgroup>00</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="5">
        <text>G06T   5/10        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>10</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="6">
        <text>G06T   7/00        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>7</main-group>
        <subgroup>00</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>382128000</text>
        <class>382</class>
        <subclass>128000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>382134000</text>
        <class>382</class>
        <subclass>134000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>382260000</text>
        <class>382</class>
        <subclass>260000</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>600437000</text>
        <class>600</class>
        <subclass>437000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G01S-007/52S2F</text>
        <section>G</section>
        <class>01</class>
        <subclass>S</subclass>
        <main-group>007</main-group>
        <subgroup>52S2F</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>G06T-005/10</text>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>10</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-005/10</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>10</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150217</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G01S-007/52036</classification-symbol>
        <section>G</section>
        <class>01</class>
        <subclass>S</subclass>
        <main-group>7</main-group>
        <subgroup>52036</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150217</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-005/002</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>002</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150127</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2207/20056</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2207</main-group>
        <subgroup>20056</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150127</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2207/20182</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2207</main-group>
        <subgroup>20182</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150127</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>28</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>4</number-of-drawing-sheets>
      <number-of-figures>4</number-of-figures>
      <image-key data-format="questel">US6181810</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Method and apparatus for spatial and temporal filtering of intravascular ultrasonic image data</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>LIPSCHUTZ DAVID</text>
          <document-id>
            <country>US</country>
            <doc-number>5224483</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5224483</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>OLSTAD BJORN, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5476096</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5476096</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>SONI BOBBY, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5520185</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5520185</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>SUORSA VEIJO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5522392</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5522392</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>TEO TAT-JIN</text>
          <document-id>
            <country>US</country>
            <doc-number>5876343</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5876343</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>TEO TAT-JIN, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5885218</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5885218</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="7">
          <text>EVANS STEVEN J, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5417215</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5417215</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="8">
          <text>HEWLETT PACKARD CO</text>
          <document-id>
            <country>EP</country>
            <doc-number>0571084</doc-number>
            <kind>A2</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-571084</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>SciMed Life Systems, Inc.</orgname>
            <address>
              <address-1>Maple Grove, MN, US</address-1>
              <city>Maple Grove</city>
              <state>MN</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>BOSTON SCIENTIFIC SCIMED</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Zhang, Xiangmin</name>
            <address>
              <address-1>Sunnyvale, CA, US</address-1>
              <city>Sunnyvale</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Teo, Tat-Jin</name>
            <address>
              <address-1>Sunnyvale, CA, US</address-1>
              <city>Sunnyvale</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Townsend and Townsend and Crew LLP</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Black, Thomas G.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A method and an apparatus are provided for combining spatial and temporal filtering for blood speckle reduction in high frequency ultrasound images wherein a sequence of image frames is processed to produce a binary mask.
      <br/>
      In this mask, a first value is assigned to regions of identified blood speckles and a second value is assigned to regions of the remainder.
      <br/>
      The images are then modulated with the mask, i.e., by applying different filtering techniques to assigned blood regions and assigned nonblood (i.e., tissue) regions, the filtering techniques having been selected to optimize images for the type of feature to be highlighted based on differences in frequency sensitivity between blood and tissue.
      <br/>
      The images are preferably in polar coordinate format.
      <br/>
      The degree of blood speckle suppression can be determined based on the actual values of the pixels at the same spatial location in given frames.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">This invention relates to intravascular ultrasonic imaging, particularly to data processing techniques for improving image perception.</p>
    <p num="2">
      With the increasing frequency (above 40 MHz) ultrasonic signals, blood speckles appear more prominently in ultrasonic intravascular images.
      <br/>
      The speckles are sufficiently bright to lower the contrast between blood and tissue, making it harder for physicians to determine the true boundaries based on a single frame images.
    </p>
    <p num="3">
      Most blood speckle reduction algorithms use either spatial or temporal information only, which is insufficient to determine the characteristic.
      <br/>
      See, for example, B. Olstad, "Noise reduction in ultrasound images using multiple linear regression in a temporal context", SPIE, vol. 1451, pp.269-281, 1991; Olstad, et al., "Analysis and measurement of temporal tissue variations", U.S. Pat. No. 5476096, 1995; and Karaman, et al., "An adaptive speckle suppression filter for medical ultrasonic imaging", IEEE Trans.
      <br/>
      Med. Imag., vol.14, pp.283-292, 1995.
    </p>
    <p num="4">
      Some algorithms have attempted to combine spatial and temporal filtering.
      <br/>
      However, they are so complex and cumbersome that processing cannot be realized in real-time with known technology.
      <br/>
      See, for example, Evans, et al., "Biased Motion-Adaptive Temporal Filtering for Speckle Reduction in Echocardiography", IEEE Trans.
      <br/>
      Med. Imag., vol.15, pp.39-50, 1996.
    </p>
    <p num="5">
      Tissue tends to be static over short periods of time.
      <br/>
      Blood cells move rapidly so blood speckles are randomly scattered.
      <br/>
      However, due to the fast cardiac motion and speckling nature of the high frequency ultrasound signals, it is difficult to differential blood and tissue without the consideration of additional information, such as spatial properties.
      <br/>
      What is needed is a near real-time technique for suppression of spurious dynamic artifacts.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="6">
      According to the invention, a method and an apparatus are provided for combining spatial and temporal filtering for blood speckle reduction in high frequency ultrasound images wherein a sequence of image frames is processed to produce a binary mask, preferably a two-dimensional binary mask.
      <br/>
      In this mask, a first value is assigned to regions of identified blood speckles and a second value is assigned to regions of the remainder.
      <br/>
      The images are then modulated with the mask, applying different filtering techniques to assigned blood regions and assigned nonblood (i.e., tissue) regions, the filtering techniques having been selected to optimize images for the type of feature to be highlighted.
      <br/>
      The preferred filtering technique is a spectral analysis of transformed data so that the energy content of features changing at higher frequencies can be weighed against features changing at lower frequencies.
      <br/>
      The images are preferably in polar coordinate format.
      <br/>
      The degree of blood speckle suppression can be determined based on the actual values of the pixels at the same spatial location in given frames.
    </p>
    <p num="7">
      In a specific embodiment, the process of generating the mask involves obtaining a vector in each frame for the given frames at the same spatial location to produce a two-dimensional matrix, with the matrix then being transformed to the frequency domain to determine its characteristics.
      <br/>
      A binary label is derived and given to the pixel that is located at the center of the vector in the current frame, indicating whether it is blood speckle.
      <br/>
      Assuming the blood clutter and tissue are not isolated, a morphologic operator is applied to the first mask and then isolated labels are removed.
    </p>
    <p num="8">
      Once the mask is generated, different operations are performed on the original input frames.
      <br/>
      This is done on a pixel-by-pixel basis.
      <br/>
      For a pixel which is labeled as tissue, an average with the previous output value is used.
      <br/>
      For a pixel which is labeled as blood speckle, a minimum value is derived from values of this pixel in the given image frames.
    </p>
    <p num="9">
      The invention will be better understood by reference to the following detailed description in conjunction with the accompanying drawings.
      <br/>
      BRIEF DESCRIPTION OF THE DRAWINGS
      <br/>
      FIG. 1 is a block diagram of an apparatus according to the invention.
      <br/>
      FIG. 2A is a flow chart of a first part of the process according to the invention.
      <br/>
      FIG. 2B is a flow chart of a second part of the process according to the invention.
      <br/>
      FIG. 3 is a spectral diagram of a fast Fourier transform of image data.
    </p>
    <heading>DESCRIPTION OF SPECIFIC EMBODIMENTS</heading>
    <p num="10">
      In order to efficiently combine spatial and temporal filtering, patterns should be identified in regions of interest generated by both the dimensions of time and of space.
      <br/>
      For example, a vector is obtained along the  THETA  dimension from each image frame within a certain time window, the so called  THETA -Time filtering window.
      <br/>
      It has been discovered that, in the  THETA  dimension, neighboring pixels have similar intensities in tissue, while they may appear to be more scattered in the blood area.
      <br/>
      Tissue regions and blood regions have been observed to exhibit spectral sensitivity in the both time dimension and the angle ( THETA ) dimension, albeit differently.
      <br/>
      Blood exhibits greater reflectivity with higher frequency.
      <br/>
      These characteristics are useful for distinguishing blood and tissue in imaging.
    </p>
    <p num="11">
      In the present invention, a specified number of consecutive frames is made available for digital analysis.
      <br/>
      FIG. 1 is a block diagram of an apparatus 10 according to the invention that illustrates an implementation.
      <br/>
      In this example, input is a sliding window 12 comprising fifteen image frames (F1, . . . , F15) which are processed together to generate one output frame (Fo) 14.
    </p>
    <p num="12">All images are in raw image data format whose pixel values represent the value at every r and  THETA  coordinate.</p>
    <p num="13">Referring to the flow chart of FIG. 2A in connection with FIG. 1, the process to generate a blood speckle reduction frame includes two major steps:</p>
    <p num="14">
      A.
      <br/>
      For each frame generate a binary mask indicating blood regions (value 1) and non-blood regions (value 0) by comparison of an analyzed intensity value at each pixel in relation with previous frames and in relation to a adjacent pixels with a selected threshold intensity value.
    </p>
    <p num="15">B. Apply the mask obtained in Step A to a block of raw (original) frame data (F1-F15) and to the previous output frame (Fo @t-1)) to generate the new output frame (Fo).</p>
    <p num="16">In operation, an input buffer 12 containing the fifteen consecutive frames and the output frame is provided for storage.</p>
    <p num="17">
      In the first major step, each pixel in r and 6 is examined for its characteristic intensity (Step C).
      <br/>
      For each pixel intensity I(r,  THETA ) in the current frame (in this example, the center frame, Frame 8), if the pixel intensity is larger than a preset value T1, it is tentatively considered to be non-blood (tissue), and value 0 is assigned to the corresponding pixel.
      <br/>
      This is an indication that further gray scale analysis will not be required.
      <br/>
      Otherwise, value 1 is assigned as tentatively being blood, and an image intensity matrix M(r,  THETA ) of 15 * 15 is formed (Step D), as hereinafter explained to further refine whether the pixel is of blood or nonblood.
      <br/>
      Specifically, each column of this matrix consists of a block of fifteen neighboring pixels in an angular ( THETA ) direction in the same time frame.
      <br/>
      Each row consists of pixels at the same location in successive time frames.
      <br/>
      Hence, a matrix in space and time is formed.
    </p>
    <p num="18">
      In the example illustrated in FIG. 1, the interim 15x15 matrix is constructed in the form:
      <br/>
      M(r, THETA )=�v1v2 . . . v14 v15�
    </p>
    <p num="19">where</p>
    <p num="20">vt=�I(r, THETA -7) . . . I(r, THETA ) . . . I (r, THETA +7)�T, t=1, 2, . . . , 15</p>
    <p num="21">
      Signal processing operations can then be performed on matrix M(r, THETA ) to discriminate between tissue and blood in the region containing tissue.
      <br/>
      First, a two-dimensional 16 * 16 FFT of the matrix is computed, with zero padding on the last row and last column of the 15 by 15 matrix to 16 by 16 (Step E).
      <br/>
      Then, from the spectral results of the FFT, a spectral analysis is performed wherein a ratio is computed between the total power of high frequency components and the total power of low frequency components (excluding the DC component) (Step F).
      <br/>
      See FIG. 3 for a spectral diagram of the fast Fourier transform.
      <br/>
      While the transition between low frequency components and high frequency components is not precise, it can be selected for example to be at between the third and the fifth harmonic, the ratio of high frequency components to low frequency components tends to be sufficiently higher in a blood region than in a tissue region so that this ratio can be used as a metric.
      <br/>
      If the ratio R is greater than a dimensionless threshold Tr (Step G), the position in the matrix M is set to 1 and identified as blood (Step H).
      <br/>
      If the ratio R is less than the threshold Tr, the position in the matrix M is set to 0 and identified for further processing (Step I).
      <br/>
      The process is repeated for each pixel location +i,j} (Step J).
      <br/>
      Because tissue at a distance from the center of a region reacts more like a blood region in the spectral domain, this method is useful for detecting a tissue ring that encloses a blood pool.
    </p>
    <p num="22">
      Further processing is needed to produce a reliable binary mask separating tissue (nonblood) and blood.
      <br/>
      First, a technique is used to remove pixels tentatively but falsely identified as blood based on a count of blood-designated pixels in the neighborhood.
      <br/>
      This technique is based on the knowledge that blood regions are known to be relatively large and cannot be isolated points.
      <br/>
      Referring to FIG. 2B, for each pixel, the number of neighboring pixels with label as blood is counted (Step K) and if the number is substantially small (Step L), this pixel is labeled as tissue (Step M).
      <br/>
      Otherwise it is labeled as blood (Step N).
      <br/>
      This process is repeated for each pixel +i,j} (Step O).
    </p>
    <p num="23">
      Second, each radial direction is scanned for maximum intensity of the tissue point (rm or MITP) in this radial direction (Step P).
      <br/>
      Based on the assumption that blood pools are surrounded by tissue, all pixels after, or further away than, the MITP are labeled as tissue (set to zero) (Step Q).
      <br/>
      This is repeated for all coordinates of j, the radial direction (Step R).
      <br/>
      The mask is thus built (Step A).
    </p>
    <p num="24">
      The next steps (comprising Step B) yield the so-called filtered frame, wherein each pixel value in the output is derived from the following: for every point M(r,  THETA ) in M, if its value is 1 (Step S), this point is characterized as blood and needs to be suppressed.
      <br/>
      For example, the corresponding point in the output is set to the minimum value of I(r,  THETA ) in all frames or subset of frames (e.g., 5 frames) (Step T).
      <br/>
      Otherwise, for a tissue point, where the value is 0, an average of the original intensity value and the intensity of the same point in the previous output frame can be used as the output value (Step U).
      <br/>
      These assignments or calculations are carried out for every pixel location +i,j}. (Step V).
    </p>
    <p num="25">
      This invention has numerous advantages.
      <br/>
      This approach can enhance the edge between lumen (blood) and vessel wall (tissue), providing a clearer border definition in an intravascular ultrasonic imaging system.
      <br/>
      This spatial and temporal analysis of the interior of a vascular region using signal processing techniques enhances the identifiable image distinction between blood and tissue.
      <br/>
      This approach is more efficient in that it combines a time dimension with only one spatial dimension, and so it need not involve higher dimensional analysis.
    </p>
    <p num="26">
      The invention has been explained with reference to specific embodiments.
      <br/>
      Other embodiments will be evident to those of ordinary skill in the art.
      <br/>
      It is therefore not intended that this invention be limited, except as indicated by the appended claims.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A method for combined spatial and temporal real-time filtering of ultrasonic image data in a contained zone in order to identify non-blood (tissue) and blood comprising:</claim-text>
      <claim-text>(a) generating a binary two-dimensional mask indicating both blood regions and non-blood regions in a center frame in time of a sequence of consecutive frames within a certain time window, each such frame comprising intensity data in at least two spatial dimensions, the step of generating a binary two-dimensional mask comprising:</claim-text>
      <claim-text>- (i) transforming a two-dimensional array of intensity data for the sequence of consecutive frames into a two-dimensional frequency domain, the two-dimensional array comprising a spatial dimension and a temporal dimension;</claim-text>
      <claim-text>and - (ii) analyzing the resulting two-dimensional frequency transform to denominate certain pixels as blood regions;</claim-text>
      <claim-text>and (b) filtering the center frame by applying said binary mask to a two-dimensional block of frame data including unprocessed frame data for the center frame and adjacent frames in sequence, and processed frame data of a prior output frame, in order to obtain a new output frame.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The method according to claim 1 wherein said analyzing step comprises comparing the power of high-frequency components of the resulting two-dimensional frequency transform with the power of lower frequency components to denominate pixels where the ratio of the high-frequency power to low-frequency power exceeds a predetermined value as blood regions.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The method according to claim 2 wherein said filtering step comprises: suppressing intensity values of blood region pixels;</claim-text>
      <claim-text>and averaging over time and space intensity values of non-blood region pixels.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The method according to claim 2 wherein the low-frequency components include harmonics below and including the third harmonic but do not include the DC component, and the high-frequency components include harmonics above the third harmonic.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The method according to claim 1 wherein said filtering step comprises: suppressing intensity values of blood region pixels;</claim-text>
      <claim-text>and averaging over time and space intensity values of non-blood region pixels.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The method according to claim 5 wherein said filtering step further comprises: identifying points of maximum intensity along radials of non-blood regions;</claim-text>
      <claim-text>and designating points along said radials beyond said points of maximum intensity as non-blood regions.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. The method according to claim 1 wherein said analyzing step is performed for all pixels in said tentative blood regions within non-blood regions.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The method according to claim 1 wherein each such frame comprises intensity data in plane polar coordinates (r,  THETA ) and the two-dimensional array of intensity data for the sequence of consecutive frames comprises a time dimension and the angular dimension  THETA .</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. The method according to claim 1 wherein the step of transforming a two-dimensional array of intensity data comprises performing a fast Fourier transform.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. The method according to claim 1 wherein the step of generating a binary two-dimensional mask further comprises identifying tentative blood and non-blood regions in the center frame before transforming the two-dimensional array of intensity data into the frequency domain.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. The method according to claim 10 wherein the step of identifying tentative blood and non-blood regions in the center frame comprises comparing the intensity of each pixel of the center frame against a predetermined value, identifying such pixel as a non-blood region if its intensity exceeds the predetermined value and identifying it as a blood region otherwise.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. A method for combined spatial and temporal real-time filtering of ultrasonic image data in a contained zone in order to identify non-blood (tissue) and blood comprising: (a) generating a binary mask indicating both blood regions and non-blood regions in a center frame in time of a sequence of consecutive frames within a certain time window, each such frame comprising intensity data in at least two spatial dimensions, the step of generating a binary two-dimensional mask comprising: - (i) comparing the intensity of each pixel of the center frame against a predetermined value, tentatively identifying such pixel as a non-blood region if its intensity exceeds the predetermined value and tentatively identifying it as a blood region otherwise; - (ii) transforming a two-dimensional array of intensity data for the sequence of consecutive frames into a two-dimensional frequency domain, the two-dimensional array comprising a spatial dimension and a temporal dimension;</claim-text>
      <claim-text>and - (iii) comparing high-frequency components of the resulting two-dimensional frequency transform with lower frequency components to denominate pixels with more higher frequency components as blood regions;</claim-text>
      <claim-text>and (b) filtering the center frame by applying said binary mask to a two-dimensional block of frame data including unprocessed frame data for the center frame and adjacent frames in sequence, and processed frame data of a prior output frame, in order to obtain a new output frame, said filtering step comprising: - (i) suppressing intensity values of blood region pixels; - (ii) averaging over time and space intensity values of non-blood region pixels; - (iii) identifying points of maximum intensity along radials of non-blood regions;</claim-text>
      <claim-text>and - (iv) designating points along said radials beyond said points of maximum intensity as non-blood regions.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. An apparatus for combined spatial and temporal real-time filtering of ultrasonic image data of a contained zone in order to identify non-blood (tissue) and blood comprising: (a) a binary two-dimensional mask generator for indicating both blood regions and non-blood regions in a center image frame in time of a sequence of consecutive frames within a certain time window, each such frame comprising intensity data in at least two spatial dimensions;</claim-text>
      <claim-text>and (b) a blood/non-blood filter applying said binary mask on a block of frame data including unprocessed frame data for the center frame and adjacent frames in sequence, and processed frame data for a prior output frame, in order to obtain a center output frame identifying blood regions and non-blood regions; said binary two-dimensional mask generator comprising: - (i) a signal transformer for converting a two-dimensional array of intensity data for the sequence of consecutive frames into a two-dimensional frequency domain, the two-dimensional array comprising a spatial dimension and a temporal dimension; - (ii) means for computing a ratio of the power of higher frequency components to lower frequency components of the resulting two-dimensional frequency transform;</claim-text>
      <claim-text>and - (iii) comparator means for comparing said ratio to a threshold ratio in order to distinguish between blood regions and non-blood regions on a spectral basis in the two-dimensional frequency domain;</claim-text>
      <claim-text>and said blood/non-blood filter comprising: - (i) means for suppressing intensity values of the blood region pixels; - (ii) means for averaging, over time and space, intensity values of non-blood region pixels; - (iii) means for generating from said averaged intensity values of said non-blood region pixels and from said blood region pixels having suppressed intensity values, an output frame identifying blood regions and exhibiting said averaged intensity values of said non-blood region.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. An apparatus for combined spatial and temporal real-time filtering of ultrasonic image data of a contained zone in order to identify non-blood (tissue) and blood comprising: (a) a binary two-dimensional mask generator for indicating both blood regions and non-blood regions in a center image frame in time of a sequence of consecutive frames within a certain time window, each such frame comprising intensity data in at least two spatial dimensions, said generator comprising: - (i) a signal transformer for converting a two-dimensional array of intensity data for the sequence of consecutive frames into a two-dimensional frequency domain, the two-dimensional array comprising a spatial dimension and a temporal dimension;</claim-text>
      <claim-text>and - (ii) an analyzer for denominating certain pixels as blood regions according to the resulting two-dimensional frequency transform;</claim-text>
      <claim-text>and (b) a blood/non-blood filter applying said binary mask on a block of frame data including unprocessed frame data for the center frame and adjacent frames in sequence, and processed frame data for a prior output frame, in order to obtain a center output frame identifying blood regions and non-blood regions.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. The apparatus according to claim 14 wherein said analyzer comprises: means for computing a ratio of the power of higher frequency components to lower frequency components of the resulting two-dimensional frequency transform;</claim-text>
      <claim-text>and comparator means for comparing said ratio to a threshold ratio in order to distinguish between blood regions and non-blood regions on a spectral basis in the two-dimensional frequency domain.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. The apparatus according to claim 14 wherein said blood/non-blood filter comprises: means for suppressing intensity values of the blood region pixels; means for averaging, over time and space, intensity values of non-blood region pixels;</claim-text>
      <claim-text>and means for generating from said averaged intensity values of said non-blood region pixels and from said blood region pixels having suppressed intensity values, an output frame identifying blood regions and exhibiting said averaged intensity values of said non-blood regions.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. The apparatus according to claim 16 wherein said blood/non-blood filter further comprises: means responsive to location and intensity of pixels for locating a point of maximum intensity along each radial of the non-blood regions;</claim-text>
      <claim-text>and means for designating lengths along each said radial beyond each said point of maximum intensity as non-blood regions.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. The apparatus according to claim 14 wherein said analyzer comprises: a ratio-computation module for computing the power of higher frequency components to lower frequency components of the resulting two-dimensional frequency transform;</claim-text>
      <claim-text>and a comparator for comparing said ratio to a threshold ratio in order to distinguish between blood regions and non-blood regions on a spectral basis in the two-dimensional frequency domain.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. The apparatus according to claim 18 wherein the lower frequency components include harmonics below and including the third harmonic but do not include the DC component, and the higher frequency components include harmonics above the third harmonic.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. The apparatus according to claim 14 wherein said blood/non-blood filter comprises: an intensity-suppression module for suppressing intensity values of the blood region pixels; an averaging module for averaging intensity values of non-blood region pixels over time and space;</claim-text>
      <claim-text>and an output-generation module for generating from said averaged intensity values of said non-blood region pixels and from said blood region pixels having suppressed intensity values, an output frame identifying blood regions and exhibiting said averaged intensity values of said non-blood regions.</claim-text>
    </claim>
    <claim num="21">
      <claim-text>21. The apparatus according to claim 20 wherein said blood/non-blood filter further comprises: an intensity-identification module responsive to location and intensity of pixels for locating a point of maximum intensity along each radial of the non-blood regions;</claim-text>
      <claim-text>and a length-designation module for designating lengths along each said radial beyond each said point of maximum intensity as non-blood regions.</claim-text>
    </claim>
    <claim num="22">
      <claim-text>22. The apparatus according to claim 14 wherein each such frame comprises intensity data in plane polar coordinates (r, THETA ) and the two-dimensional array of intensity data for the sequence of consecutive frames comprises a time dimension and the angular dimension  THETA .</claim-text>
    </claim>
    <claim num="23">
      <claim-text>23. The apparatus according to claim 14 wherein the signal transformer for converting a two-dimensional array of intensity data uses a fast Fourier transform.</claim-text>
    </claim>
    <claim num="24">
      <claim-text>24. The apparatus according to claim 14 wherein the generator further comprises an identification unit for making tentative assignments of blood and non-blood regions in the center frame before the signal transformer converts the two-dimensional array of intensity data.</claim-text>
    </claim>
    <claim num="25">
      <claim-text>25. The apparatus according to claim 24 wherein said identification unit makes such tentative assignments of blood and non-blood regions by comparing the intensity of each pixel of the center frame against a predetermined value, assigning such pixel as a non-blood region if its intensity exceeds the predetermined value and assigning such pixel as a blood region otherwise.</claim-text>
    </claim>
    <claim num="26">
      <claim-text>26. An apparatus for combined spatial and temporal real-time filtering of ultrasonic image data of a contained zone in order to identify non-blood (tissue) and blood comprising: (a) a binary two-dimensional mask generator for indicating both blood regions and non-blood regions in a center image frame in time of a sequence of consecutive frames within a certain time window, each such frame comprising intensity data in at least two spatial dimensions;</claim-text>
      <claim-text>and (b) a blood/non-blood filter applying said binary mask on a block of frame data including unprocessed frame data for the center frame and adjacent frames in sequence, and processed frame data for a prior output frame, in order to obtain a center output frame identifying blood regions and non-blood regions; said binary two-dimensional mask generator comprising: - (i) a signal transformer for converting a two-dimensional array of intensity data for the sequence of consecutive frames into a two-dimensional frequency domain, the two-dimensional array comprising a spatial dimension and a temporal dimension; - (ii) a ratio-computation module for computing the power of higher frequency components to lower frequency components of the resulting two-dimensional frequency transform;</claim-text>
      <claim-text>and - (iii) a comparator for comparing said ratio to a threshold ratio in order to distinguish between blood regions and non-blood regions on a spectral basis in the two-dimensional frequency domain;</claim-text>
      <claim-text>and said blood/non-blood filter comprising: - (i) an intensity suppression module for suppressing intensity values of the blood region pixels; - (ii) an averaging module for averaging intensity values of non-blood region pixels over time and space;</claim-text>
      <claim-text>and - (iii) an output-generation module for generating from said averaged intensity values of said non-blood region pixels and from said blood region pixels having suppressed intensity values, an output frame identifying blood regions and exhibiting said averaged intensity values of said non-blood regions.</claim-text>
    </claim>
    <claim num="27">
      <claim-text>27. A method for generating a binary two-dimensional mask for use in combined spatial and temporal real-time filtering of ultrasonic image data in a contained zone in order to identify non-blood (tissue) and blood comprising: (a) transforming a two-dimensional array of intensity data for a sequence of consecutive frames within a certain time window into a two-dimensional frequency domain, wherein each such frame comprises intensity data in at least two spatial dimensions and the two-dimensional array comprises a spatial dimension and a temporal dimension;</claim-text>
      <claim-text>and (b) analyzing the resulting two-dimensional frequency transform to denominate certain pixels as blood regions.</claim-text>
    </claim>
    <claim num="28">
      <claim-text>28. A binary two-dimensional mask generator for use in combined spatial and temporal real-time filtering of ultrasonic image data of a contained zone in order to identify non-blood (tissue) and blood comprising: (a) a signal transformer for converting a two-dimensional array of intensity data for a sequence of consecutive frames within a certain time window into a two-dimensional frequency domain, wherein each such frame comprises intensity data in at least two spatial dimensions and the two-dimensional array comprises a spatial dimension and a temporal dimension;</claim-text>
      <claim-text>and (b) an analyzer for denominating certain pixels as blood regions according to the resulting two-dimensional frequency transform.</claim-text>
    </claim>
  </claims>
</questel-patent-document>