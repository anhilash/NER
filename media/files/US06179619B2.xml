<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06179619B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06179619</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6179619</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference family-id="15198176" extended-family-id="1459024">
      <document-id>
        <country>US</country>
        <doc-number>09214786</doc-number>
        <kind>A</kind>
        <date>19990112</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1998US-09214786</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>1516391</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>JP</country>
        <doc-number>13741897</doc-number>
        <kind>A</kind>
        <date>19970513</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1997JP-0137418</doc-number>
      </priority-claim>
      <priority-claim kind="international" sequence="2">
        <country>WO</country>
        <doc-number>JP9802098</doc-number>
        <kind>A</kind>
        <date>19980512</date>
        <priority-linkage-type>W</priority-linkage-type>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1998WO-JP02098</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G09B   9/05        20060101AFI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>09</class>
        <subclass>B</subclass>
        <main-group>9</main-group>
        <subgroup>05</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>A63G   7/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>63</class>
        <subclass>G</subclass>
        <main-group>7</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>A63G  21/04        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>63</class>
        <subclass>G</subclass>
        <main-group>21</main-group>
        <subgroup>04</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>A63G  31/02        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>63</class>
        <subclass>G</subclass>
        <main-group>31</main-group>
        <subgroup>02</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="5">
        <text>A63G  31/16        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>63</class>
        <subclass>G</subclass>
        <main-group>31</main-group>
        <subgroup>16</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>434069000</text>
        <class>434</class>
        <subclass>069000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>434062000</text>
        <class>434</class>
        <subclass>062000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>434307000R</text>
        <class>434</class>
        <subclass>307000R</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>463030000</text>
        <class>463</class>
        <subclass>030000</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>472060000</text>
        <class>472</class>
        <subclass>060000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>A63G-007/00</text>
        <section>A</section>
        <class>63</class>
        <subclass>G</subclass>
        <main-group>7</main-group>
        <subgroup>00</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>A63G-031/16</text>
        <section>A</section>
        <class>63</class>
        <subclass>G</subclass>
        <main-group>31</main-group>
        <subgroup>16</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>A63G-007/00</classification-symbol>
        <section>A</section>
        <class>63</class>
        <subclass>G</subclass>
        <main-group>7</main-group>
        <subgroup>00</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>A63G-031/16</classification-symbol>
        <section>A</section>
        <class>63</class>
        <subclass>G</subclass>
        <main-group>31</main-group>
        <subgroup>16</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>8</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>4</number-of-drawing-sheets>
      <number-of-figures>4</number-of-figures>
      <image-key data-format="questel">US6179619</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Game machine for moving object</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>GOLENSKI STEPHEN S</text>
          <document-id>
            <country>US</country>
            <doc-number>3991485</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US3991485</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>LEWIS EDGAR B</text>
          <document-id>
            <country>US</country>
            <doc-number>4028725</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4028725</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>SPOONER ARCHER M</text>
          <document-id>
            <country>US</country>
            <doc-number>4315241</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4315241</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>WALDERN JONATHAN D</text>
          <document-id>
            <country>US</country>
            <doc-number>4984179</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4984179</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>LETOVSKY HOWARD, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5006072</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5006072</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>LEWIS RUSSELL F, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5322441</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5322441</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>MURAKAMI KANJI</text>
          <document-id>
            <country>US</country>
            <doc-number>5336132</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5336132</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>BAXTER ANTHONY W, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5403238</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5403238</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="9">
          <text>CARMEIN DAVID E E</text>
          <document-id>
            <country>US</country>
            <doc-number>5490784</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5490784</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="10">
          <text>RITCHEY KURTIS J</text>
          <document-id>
            <country>US</country>
            <doc-number>5495576</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5495576</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="11">
          <text>TRUMBULL DOUGLAS</text>
          <document-id>
            <country>US</country>
            <doc-number>5584697</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5584697</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="12">
          <text>YASUMARU SHINGO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5662523</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5662523</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="13">
          <text>PRATHER JAMES G, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5669821</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5669821</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="14">
          <text>TAKEMOTO TAKATOSHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5707237</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5707237</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="15">
          <text>DOTE SHINGO</text>
          <document-id>
            <country>US</country>
            <doc-number>5716281</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5716281</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="16">
          <text>HODGES LARRY F, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5807114</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5807114</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="17">
          <text>LATYPOV NURAKHMED NURISLAMOVIC</text>
          <document-id>
            <country>US</country>
            <doc-number>5846134</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5846134</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="18">
          <text>MYERS NICOLE J</text>
          <document-id>
            <country>US</country>
            <doc-number>5921780</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5921780</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="19">
          <text>LO PATRICK K, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5954508</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5954508</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="20">
          <text>HUGHES AIRCRAFT CO</text>
          <document-id>
            <country>WO</country>
            <doc-number>9316776</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>WO9316776</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="21">
          <text>BIOCONTROL SYSTEMS INC</text>
          <document-id>
            <country>EP</country>
            <doc-number>0468340</doc-number>
            <kind>A2</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-468340</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="22">
          <text>MATSUSHITA SEIKO KK</text>
          <document-id>
            <country>JP</country>
            <doc-number>S6148786</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP61048786</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="23">
          <text>CANON KK</text>
          <document-id>
            <country>JP</country>
            <doc-number>H0215230</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP02015230</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="24">
          <text>SENYO KIKO KK</text>
          <document-id>
            <country>JP</country>
            <doc-number>H0386187</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP03086187</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="25">
          <text>SEGA ENTERPRISES KK</text>
          <document-id>
            <country>JP</country>
            <doc-number>H06218145</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP06218145</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="1">
          <text>"Virtual Environment Display System" by Fisher et al, ACM 1986 Workshop on Interactive 3D Graphics, pp. 1-11, Oct. 1986.</text>
        </nplcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant app-type="applicant" sequence="1">
          <addressbook lang="en">
            <name>TANAKA SHIGENOBU</name>
          </addressbook>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Tanaka, Shigenobu</name>
            <address>
              <address-1>Kawasaki-shi, Kanagawa, 213-0026, JP</address-1>
              <city>Kawasaki-shi, Kanagawa, 213-0026</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Wenderoth, Lind &amp; Ponack, L.L.P.</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Cheng, Joe H.</name>
      </primary-examiner>
    </examiners>
    <pct-or-regional-filing-data>
      <document-id>
        <country>WO</country>
        <doc-number>JP9802098</doc-number>
        <date>19980512</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1998WO-JP02098</doc-number>
      </document-id>
    </pct-or-regional-filing-data>
    <pct-or-regional-publishing-data>
      <document-id>
        <country>WO</country>
        <doc-number>9851385</doc-number>
        <kind>A1</kind>
        <date>19981119</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>WO9851385</doc-number>
      </document-id>
    </pct-or-regional-publishing-data>
    <lgst-data>
      <lgst-status>LAPSED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A game machine for a moving object having both a position detecting device being operable to detect a position of a person riding on the moving object on a course of movement to obtain position information and a direction detection device being operable to detect a direction of a field of vision of the person to obtain direction information.
      <br/>
      The game machine also has a memory being operable to store visual and auditory information regarding a change in the course of movement and a central processing part being operable to select visual and auditory information corresponding to the position of the person and the direction of the field of vision of the person riding on the moving object based on the position information of the position detection device and the direction information of the direction detection device.
      <br/>
      A speaker and a display are used to output the selected auditory and visual information, respectively.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">This invention relates to a game machine for moving objects, which enables a human operator to experience virtual reality.</p>
    <p num="2">
      In game establishments such as theme parks, a track travelling game machine adapted to move a vehicle along a course of movement such as, for example, a track furnished with curves and undulations, and to enable a human player on the vehicle to experience the sensation of a run at full speed and the sensation of exhilaration has formed a typical popular game machine.
      <br/>
      This game machine has been offered in various types such as keeping the human player in a standing position while in motion and keeping the human player in a position suspended from the track while in motion.
      <br/>
      A game machine of another type is adapted to advance a moving object along a channel of a fluid and enable a human player thereon to enjoy the delightful view of backgrounds and buildings laid out in a vicinity of the channel.
    </p>
    <p num="3">
      Further, in recent years, the game machine of yet another type adapted to move a seat as synchronized with an image and to integrate the image with the experience of the acceleration and deceleration of the speed of the seat enabling the occupant of the seat to experience the simulation of the movement of his seat, has been proposed.
      <br/>
      The game machine of this type is also known in various versions such as solely utilizing the occupancy by a human player, conferring the propensity for a game by combining the movement of a seat with the sensation of shooting, and so on (as disclosed in JP-B-02-15,230, for example).
    </p>
    <p num="4">
      The former version, however, has been at a disadvantage since it quickly ceases to hold lasting interest because of the use of a fixed course of movement which is devoid of visual variations.
      <br/>
      Since an effort to revive the game machine from the boredom by changing the course of movement or altering the peripheral facilities requires a large expense, this version does not easily permit such alterations to be made in short cycles from the viewpoint of business.
    </p>
    <p num="5">
      The latter version indeed permits such alterations to be implemented quickly and inexpensively because it allows the experience in simulation to be differentiated by simply altering the software, namely, the mode of moving the image and the seat.
      <br/>
      It nevertheless has had the problem of producing no sensation of the acceleration and deceleration of speed because it does not produce as high a sensation of acceleration and deceleration of speed as the former version.
      <br/>
      Further, the letter version suffers because the gravity actually sensed by the human player in his body to produce a sensation of discrepancy from the artificially generated gravity does not occur.
      <br/>
      The latter version has been further at a disadvantage in generating the same sensation of discrepancy with respect to the pressure of the wind which the human player experiences while the seat is in motion.
    </p>
    <p num="6">This invention has for an object thereof the provision of a game machine for a moving object, which enables an operator to differentiate his experience in simulation by making an arbitrary selection from the information on various courses of experience of simulation prepared in advance without requiring any alteration in the curves or undulations of the course of movement and also enables the operator to make an experience approximating as closely to reality as possible by properly providing him with an image conformity with his sensation of acceleration and deceleration of speed and the bearing of his body relative to the direction of the movement of the chair.</p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="7">To accomplish the object described above, this invention contemplates a game machine for a moving object, which is provided with position detecting means for detecting the position of a human player occupying the moving object on the course of movement, memory means for storing the visual and auditory information associated with a change in the course of movement, means for selecting the visual and auditory information based on the information emanating from the position detecting means, and means for outputting and displaying the selected visual and auditory information.</p>
    <p num="8">The invention further contemplates a game machine for a moving object, which is provided with position detecting means for detecting the position of a human player occupying the moving object on the course of movement, direction detecting means for detecting the direction of the field of vision of the human player, memory means for storing the visual and auditory information associated with a change in the course of movement, means for selecting the visual and auditory information based on the information emanating from the position detecting means and the direction detecting means, and means for outputting and displaying the selected visual and auditory information.</p>
    <p num="9">The game machine is further provided with input means capable of being operated by the human player.</p>
    <p num="10">
      The game machine for the moving object described above is capable of storing preparatorily in the memory means thereof the visual and auditory information for developing a story in connection with a change in the course of movement.
      <br/>
      It, therefore, allows the story to be readily altered by changing the visual and auditory information.
      <br/>
      The game machine of the version which is provided with the input means is capable of storing a plurality of stories in advance and consequently enabling the human player to make an arbitrary selection from the collection of stories.
      <br/>
      Further, the use of this input means allows the human player to play a game.
    </p>
    <p num="11">
      This game machine detects the position of the human player on the course of movement with the aid of the position detecting means, selects from the memory means mentioned above the visual and auditory information proper for the position of the human player on the course of movement on the basis of the information on position derived from the position detecting means, and transmits the selected visual and auditory information to the output display means.
      <br/>
      When the game machine happens to be additionally provided with the direction detecting means, which is capable of detecting the direction of the human player's field of vision, it selects from the memory means mentioned above the visual and auditory information proper for the position of the human player on the course of movement and the direction of the human player's field of vision on the basis of the information on the direction derived from the direction detecting means and the information on the position derived from the position detecting means and transmits the selected visual and auditory information to the output display means.
      <br/>
      Then, the output display means outputs and displays the image and the sound on the basis of the visual and auditory information to be received from time to time.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="12">
      FIG. 1 is a schematic explanatory diagram illustrating one mode of embodying the game machine according to this invention.
      <br/>
      FIG. 2 is a schematic explanatory diagram illustrating part of the mode of embodying the present invention.
      <br/>
      FIG. 3 is a block diagram illustrating a typical example of the construction of the control unit according to this invention.
      <br/>
      FIG. 4 is a schematic explanatory diagram illustrating the entirety of the game machine shown in FIG. 1.
    </p>
    <heading>DETAILED DESCRIPTION OF THE INVENTION</heading>
    <p num="13">Now, one mode for embodying this invention will be described in detail below with reference to the drawings annexed hereto.</p>
    <p num="14">
      With reference to FIG. 1, 1 denotes an endless track provided with curves and undulations and destined to serve as a course of movement and 2 denotes each of a plurality of objects for detection intended for permitting detection of the position of a human player.
      <br/>
      Particularly, the objects 2 for detection are disposed invariably before and after a position at which the track 1 changes inclination or angle, for example, a point of rise or fall in an undulation or a curve.
      <br/>
      Besides the endless track 1, a waterway and a road may be cited as other examples of the course of movement.
    </p>
    <p num="15">
      Then, 3 denotes a moving object shaped like a ship and adapted to travel along the track 1.
      <br/>
      This moving object 3 is provided thereon with seats 4 capable of enabling respective human players thereon to experience vibration and other sensations to be exerted on their persons.
      <br/>
      The seats 4 are each provided with an input designating device 5 to be operated by the relevant human player, a display 6 for providing the relevant human player with an image, and a speaker 7 for providing the human player with a sound.
      <br/>
      Further, as illustrated in FIG. 3, an image memory part 12, a sound memory part 13, an interface part 14, and an image display control part 15 are connected to a central processing part 11 and, at the same time, control units 10 each having the input designating device 5, a position detecting part 8, and a direction detecting part 9 connected thereto through the medium of the interface part 14 are disposed quantitatively equally to the seats on the moving object.
    </p>
    <p num="16">
      The seat 4 is provided with a built-in bodily-sensation device 16 adapted to impart a stimulation such as vibration to the human player in accordance with the bodily-sensation information transmitted from the central processing part 11.
      <br/>
      By synchronizing the bodily-sensation information with the auditory information, the human player is able to experience a further exalted sensation of realism.
    </p>
    <p num="17">
      The input designating device 5 is an input means that enables a relevant human player to produce various manipulations for enjoying an experience of virtual reality such as a game or selecting the development of a story of the image put up on the display 6.
      <br/>
      When this device 5 is used for a game, for example, a shooting game, the human player is able to produce an operation of shooting at a target by manipulating a stick or a visual sensor adapted to pinpoint a cursor placed on the display 6 at the target and then depressing a button.
    </p>
    <p num="18">
      The display 6 and the speaker 7 are disposed on a helmet 17 which is worn on the human player's head.
      <br/>
      When the human player wears this helmet 17, the display 6 covers his eyes and the speaker 7 muffles his ears, with the result that the human player will be enabled to view an image put up on the display 6 through the medium of the image display control part 15 and hear a sound from the speaker 7.
      <br/>
      This display 6 is capable of showing different images to the opposite eyes of the human player and producing a three-dimensional image.
      <br/>
      The speaker 7 is capable of emitting a stereophonic sound.
      <br/>
      Thus, the helmet 17 enables the human player to appreciate the sensation of realism both visually and auditorially.
    </p>
    <p num="19">
      The image display control part 15 is adapted to synthesize image information, three-dimensional data, game data, etc. and places the result of the synthesis on the display 7.
      <br/>
      The image display control part 15, on electing to show a three-dimensional image, puts up a two-dimensional image to be viewed by the left eye, and a two-dimensional image to be viewed by the right eye respectively, of the human player.
    </p>
    <p num="20">
      The present embodiment contemplates disposing the display 6 and the speaker 7 on the helmet 17.
      <br/>
      This arrangement does not constitute a critical requirement for this invention.
      <br/>
      For example, the display may be in the form of goggles or may be fixed on the seat, and the speaker may be in the form of a headphone or may be fixed on the seat.
    </p>
    <p num="21">
      The position detecting part 8 is provided on the moving object 3 and is adapted to detect the objects 2 for detection laid out along the track 1 and transmit successively the information on the positions of the moving object 3 on the track 1 to the central processing part 11.
      <br/>
      A plurality of position detecting parts 8 may be provided, when necessary, one each for the seats 4 so that the positions of the human players on the track 1 may be respectively detected.
      <br/>
      In this case, the direction detecting part 9 detects the directions of the lines of vision, respectively, of the human players.
      <br/>
      The plurality of position detecting parts 8 may be disposed one each on the rows of seats 4 which perpendicularly intersect the direction of travel of the moving object 3.
      <br/>
      In this case, the direction detecting part 9 satisfactorily functions by detecting the directions of the lines of vision of the human players and the positions of the human players in the rows of seats 4 of the moving object 3.
      <br/>
      As another concrete example of the position detecting part, the global positioning system (GPS) which makes use of an artificial satellite may be utilized.
    </p>
    <p num="22">
      The direction detecting part 9 is disposed on the helmet 17 and is adapted to detect the direction of the line of vision of the human player wearing the helmet 17 and, at the same time, detect the position of the human player on the moving object 3 and transmit the information on the direction of the human player to the central processing part 11.
      <br/>
      As concrete examples of the direction detecting part 9, a device adapted for detecting and positioning the three-dimensional angle of the helmet 17 by properly combining a gyrosensor with an acceleration sensor and a device adapted for magnetically detecting the motion of the helmet 17 by causing the moving object 3 to generate a magnetic field may be utilized.
    </p>
    <p num="23">
      The central processing part 11 is adapted to transmit to the image display control part 15 the visual information and the three-dimensional data corresponding to the position of the human player on the track 1 and the direction of the line of vision of the human player based on the information on position and the information on direction acquired through the medium of the interface part 14, and also to transmit via the sound memory part 13 to the speaker 7 the auditory information corresponding to the visual information as synchronized with the visual information, and further to transmit to the bodily-sensation device 16, the information on the bodily sensation as synchronized with the auditory information.
      <br/>
      The image, three-dimensional data, and bodily-sensation information are stored in the image memory part 12, the auditory information is stored in the sound memory part 13, and the stored matters together constitute the contents which are associated with changes in the course of movement.
    </p>
    <p num="24">
      The memory parts 12 and 13, when necessary for the purpose of permitting the selection of courses of experience, may be adapted to memorize visual information of various developments and store such bodily-sensation information and auditory information as correspond to the visual information.
      <br/>
      Further, by altering the stored information, the game machine is enabled to provide entirely new images and sounds for the human player.
    </p>
    <p num="25">
      As concrete examples of the image memory part 12 and the sound memory part 13, ROM's and RAM's may be used.
      <br/>
      These devices may be suitably adapted for the storage of a program for specifying a procedure for the operation of the central processing part 11 and for the storage of such pieces of information to be processed by the central processing part 11.
      <br/>
      By using additional implements such as a reading device incorporating an optical disk therein as a memory medium and a magnetic memory device, which are not illustrated in the diagram, it is possible to prepare a large volume of visual and auditory information and permit storing in the image recording part 12 and the sound memory part 13 such information as is suitably required in conformity with the story selected by the human player and the position of the moving object 3.
      <br/>
      In this case, the reading device or the magnetic memory device will be precluded from being effected by the weather or vibration when it is installed at a place separated from the control unit 10 and adapted to effect necessary transmission or reception of the information by radio.
      <br/>
      It is allowable to utilize the reading device and the magnetic memory device jointly as a combination visual and auditorial part.
    </p>
    <p num="26">
      The embodiment, as described above, provides for one control unit 10 for each of the human players riding on the moving object 3.
      <br/>
      This invention, nevertheless, does not preclude installing the control unit 10 at a place other than the moving object 3 and further allowing the control unit 10 to exchange necessary information with wireless communication means (not shown) provided on the helmet 17 or the moving object 3.
      <br/>
      Alternatively, one control unit may be so adapted as to provide images and sounds to a plurality of human operators.
    </p>
    <p num="27">Now, the operation of the game machine for the moving object constructed as described above will be described below.</p>
    <p num="28">
      For a start, the image memory part 12 and the sound memory part 13 are caused in advance to store several patterns of stories that concern changes in the course of movement or a plurality of sets of images in the image memory part and a plurality of sets of sounds in the sound memory part having different stories stored in advance.
      <br/>
      As a concrete example of the information for the storage, a story of the environment in which a human player rides on an imaginary means of transportation and travels thereon through an unrealistic space may be cited.
      <br/>
      For this story, it is preferred to project an image of the moving object in motion corresponding to an inclination relative to a horizontal line in conformity with a curve in the course of movement, an image of the moving object plunging into a cloud or ground corresponding to a rise or a fall in the course of movement, and an image of the moving object passing a scene varying quickly or slowly in concert with the acceleration or deceleration of the moving object 3 to and also emit such sounds as those of a specific effect aimed at producing the sensation of speed and those of an impact aimed at producing the sensation of a plunge.
    </p>
    <p num="29">
      The story may further contemplate projecting an image moving faster than the real speed or an image moving slower than the real speed.
      <br/>
      By thus showing a fast moving image to human players that seek an exaggerated thrill and a slow moving image to infant and elderly human players, it is possible for any human player to select the degree of ease of ride (fearfulness) that befits his taste.
    </p>
    <p num="30">
      The human player first puts on the helmet 17 disposed at the seat 4 of his choice on the moving object 3, sits down on the seat 4, and selects a story fitting his taste with the aid of the input designating device 5.
      <br/>
      At this time, since the moving object 3 is still at rest, the direction detecting part 9 detects the position of the relevant human player on the moving object 3 and the direction of the line of vision of the human player and transmits the information on the position and the information on the direction to the central processing part 11 through the medium of the interface part 14.
      <br/>
      Then, the central processing part 11 derives from the chosen story, the visual information and the three-dimensional data corresponding to the direction of the line of vision of the human player based on these pieces of information and forwards them from the image memory part 12 to the image display control part 15, and the image display control part 15 places two two-dimensional images on the display so as to render the three-dimensional image visible.
      <br/>
      When the image to be displayed is accompanied by a sound, the central processing part 11 causes the sound memory part 13 to forward corresponding auditory information to the speaker 7.
    </p>
    <p num="31">
      When the moving object 3 is then begins moving, the position detecting part 8 disposed on the moving object 3 detects the object 2 for detection disposed on the track 1 and forwards the information on position corresponding to the position of the moving object 3 on the course of movement through the medium of the interface part 14 to the central processing part 11.
      <br/>
      Then, the central processing part 11 derives from the chosen story, the visual information corresponding to the position of the human player and the direction of the line of vision of the human player based on the information on the position and the information on the direction emanating from the direction detecting part 9, and forwards the pieces of information from the image memory part 12 to the image display control part 15.
      <br/>
      The central processing part N also reads an auditory information corresponding to the visual information, emits it through the speaker 7, forwards bodily-sensation data to the bodily-sensation device 16 disposed on the seat 4 which exerts a vibration corresponding to the image on the seat 4.
    </p>
    <p num="32">
      Even when multiple human players ride on the same moving object 3, images taking into account the positions of the individual human players on the moving object 3 are put up on the displays 6 assigned to the different human players.
      <br/>
      The different images, therefore, are displayed even when the human players have selected the same story and are keeping the lines of their vision in the same direction.
      <br/>
      Accordingly, the individual human players are able to view the images that are synchronized with their own actual experienced sensations of acceleration and deceleration and zero gravity and are consequently allowed to experience an unrealistic world in a state approximating closely to reality.
      <br/>
      Such human players are able not only to acquire a realistic experience of viewing a human player seated next to them, but also to acquire more realistically such an unrealistic experience of viewing a famous character seated next to themselves.
    </p>
    <p num="33">
      This invention, as described in detail above, contemplates providing a human player with the chance of experiencing a novel simulation by altering visual and auditory information and, therefore, enables the human player to acquire a constantly new experience of riding on a new means of transportation even when he actually repeats the ride on the same moving object.
      <br/>
      Thus, the invention is capable of securing a great number of repeat users.
      <br/>
      Further, since the renewal of the visual and auditory information is equivalent to the provision of a new game machine, the inevitable immense expenditures associated with new game machines can be greatly curtailed.
    </p>
    <p num="34">Further, the present invention can provide an simulation experience with exalted reality because it is capable of providing each of the human players with varying images and sounds that correspond to the choice of the relevant human player, the position of the human player on the moving object, and the direction of the line of vision of the human player.</p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A game machine, comprising:</claim-text>
      <claim-text>a moving object to be occupied by at least one person, the moving object adapted to follow a course of movement; a position detecting device adapted on the moving object being operable to detect a position of a person riding on the moving object on a course of movement to obtain position information; a direction detection device being operable to detect a direction of a field of vision of the person to obtain direction information; a control unit adapted on the moving object and connected to said direction detection device, said control unit comprising:</claim-text>
      <claim-text>- a memory being operable to store visual and auditory information regarding a change in the course of movement, and - a central processing part being operable to select visual and auditory information corresponding to the position of the person and the direction of the field of vision of the person riding on the moving object based on the position information of said position detection device and the direction information of said direction detection device; a speaker being operable to output the selected auditory information;</claim-text>
      <claim-text>and a display being operable to output the selected visual information.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. A game machine for a moving object as claimed in claim 1, further comprising an input device being operable to allow the person to select a type of visual and auditory information, wherein said central processing part is operable to select visual and auditory information from the type of visual and auditory information corresponding to the position of the person and the direction of the field of vision of the person riding on the moving object based on the position information of said position detection device and the direction information of said direction detection device.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. A game machine for a moving object as claimed in claim 1, further comprising an input device being operable to allow the person to input information, wherein said central processing part is operable to select visual and auditory information based on the information and corresponding to the position of the person and the direction of the field of vision of the person riding on the moving object based on the position information of said position detection device and the direction information of said direction detection device.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. A game machine for a moving object as claimed in claim 1, wherein the course of movement is an endless track provided with curves and undulations.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. A game machine for a moving object as claimed in claim 1, wherein the moving object is formed in the shape of a ship.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. A game machine for a moving object as claimed in claim 1, wherein the moving object is provided with a plurality of seats for a plurality of people and corresponding pluralities of additional ones of said control unit, additional ones of said position detecting device, and additional ones of said direction detection device.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. A game machine for a moving object as claimed in claim 6, wherein each of said plurality of seats is provided with a built-in bodily-sensation device being operable to impart stimulation, including vibration, to the person in accordance with bodily-sensation information from said central processing part.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. A game machine for a moving object as claimed in claim 7, wherein the bodily-sensation information is synchronized with the auditory information.</claim-text>
    </claim>
  </claims>
</questel-patent-document>