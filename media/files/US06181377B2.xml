<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06181377B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06181377</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6181377</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference family-id="16050745" extended-family-id="4596501">
      <document-id>
        <country>US</country>
        <doc-number>08507075</doc-number>
        <kind>A</kind>
        <date>19950726</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1995US-08507075</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>4785777</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>JP</country>
        <doc-number>17856794</doc-number>
        <kind>A</kind>
        <date>19940729</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1994JP-0178567</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G06F   3/033       20060101AFI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>3</main-group>
        <subgroup>033</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G03B  13/02        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>03</class>
        <subclass>B</subclass>
        <main-group>13</main-group>
        <subgroup>02</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>H04N   5/225       20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>225</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>H04N   5/232       20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>232</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>348333020</text>
        <class>348</class>
        <subclass>333020</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>348240300</text>
        <class>348</class>
        <subclass>240300</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>348E05047</text>
        <class>348</class>
        <subclass>E05047</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>396051000</text>
        <class>396</class>
        <subclass>051000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G03B-013/02</text>
        <section>G</section>
        <class>03</class>
        <subclass>B</subclass>
        <main-group>13</main-group>
        <subgroup>02</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>H04N-005/232V</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>005</main-group>
        <subgroup>232V</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-005/23293</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>23293</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G03B-013/02</classification-symbol>
        <section>G</section>
        <class>03</class>
        <subclass>B</subclass>
        <main-group>13</main-group>
        <subgroup>02</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G03B-2213/025</classification-symbol>
        <section>G</section>
        <class>03</class>
        <subclass>B</subclass>
        <main-group>2213</main-group>
        <subgroup>025</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>S03B-213/02S</classification-symbol>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>40</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>8</number-of-drawing-sheets>
      <number-of-figures>15</number-of-figures>
      <image-key data-format="questel">US6181377</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Apparatus for setting imaging functions based on a detected viewpoint</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>WEINBLATT LEE S</text>
          <document-id>
            <country>US</country>
            <doc-number>4574314</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4574314</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>KODAMA SHINICHI</text>
          <document-id>
            <country>US</country>
            <doc-number>5365302</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5365302</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>KANEDA KITAHIRO</text>
          <document-id>
            <country>US</country>
            <doc-number>5541655</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5541655</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>ARAI TAKASHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5570156</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5570156</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>HIRASAWA MASAHIDE</text>
          <document-id>
            <country>US</country>
            <doc-number>5579048</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5579048</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>SUZUKI ETSURO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5581323</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5581323</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>CANON KK</text>
          <document-id>
            <country>JP</country>
            <doc-number>H0387818</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP03087818</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="8">
          <text>NAGANO AKIHIKO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5245371</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5245371</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="9">
          <text>CANON KK</text>
          <document-id>
            <country>JP</country>
            <doc-number>H01241511</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP01241511</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="10">
          <text>CANON KK</text>
          <document-id>
            <country>JP</country>
            <doc-number>H0232312</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP02032312</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>CANON KK</text>
          <document-id>
            <country>JP</country>
            <doc-number>H05191683</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP05191683</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Canon Kabushiki Kaisha</orgname>
            <address>
              <address-1>Tokyo, JP</address-1>
              <city>Tokyo</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>CANON</orgname>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Kobayashi, Takashi</name>
            <address>
              <address-1>Mitaka, JP</address-1>
              <city>Mitaka</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Fitzpatrick, Cella, Harper &amp; Scinto</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Ho, Tuan</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      An image pickup device displays, on a finder image area, an index mark indicating the wide angle side and the telephoto side of the zooming operations, an index mark indicating the zoom angle setting range in combination with the corresponding focal lengths, and an index mark indicating the current set position.
      <br/>
      When the photographer watches a desired position of the index mark, the viewpoint is detected by the viewpoint detecting device and the zooming operation is automatically conducted to the focal length corresponding to the viewpoint.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="2">The present invention relates to viewpoint detecting device.</p>
    <p num="3">2. Related Background Art</p>
    <p num="4">Imaging equipment such as video cameras have shown remarkable progress in recent years, toward a smaller size and more diversified functions.</p>
    <p num="5">Along with such progress, for the purpose of reducing the cumbersome operations associated with such diversified functions and of achieving the operation intended by the operator, there is being introduced the viewpoint detecting device enabling the execution of various functions and the control of various operations by viewpoint of the operator.</p>
    <p num="6">Such viewpoint detecting device, for example in case of a camera such as a video camera, enables focusing to a position watched by the operator or functions as a switch for executing any of the functions when a corresponding index mark is watched by the operator.</p>
    <p num="7">In the following there will be explained an example of the video camera in which the viewpoint detecting device is utilized for lens focusing and zooming.</p>
    <p num="8">The viewpoint detecting device, conventionally equipped in the video camera or the like, has the viewpoint input functions for effecting the zooming operation by selecting zooming marks "TELE" and "WIDE" displayed on the image area of the view finder with the viewpoint and the focusing operation at the watched position of said image area.</p>
    <p num="9">FIG. 1 is a schematic block diagram of a video camera with viewpoint switching function.</p>
    <p num="10">The video camera shown in FIG. 1 is provided with a phototaking lens system 1 including a zoom lens for taking the image of an object; a view finder 3 containing a finder image area 2 for observing the object to be taken by the phototaking lens system 1; an eyepiece lens 4 provided in front of the view finder 3; viewpoint detection means 6 for detecting the viewpoint of an eye 5 of the photographer; a display circuit 7 for displaying, on the image area 2, an AF frame approximately showing the focusing area, viewpoint switch marks to be explained later and other information such as tape counter and phototaking mode, required for the photographer; a system control circuit 8 for controlling various parts of the camera; a memory 9 for memorizing the coordinate values of the viewpoint switch marks on the finder image area; and an adder 10 for the outputs of the phototaking lens system 1 and the display circuit 7.</p>
    <p num="11">The above-mentioned viewpoint detecting means 6 is provided with an infrared light emitting diode 60 for irradiating the eye 5 of the photographer with infrared light; a dichroic mirror 61 transmitting the visible light but reflecting the infrared light; a condenser lens 62 for condensing the infrared light reflected by said dichroic mirror 61; a photoelectric converting element 63 for converting the infrared light, condensed by said condenser lens 62, into an electrical signal; and a viewpoint detecting circuit 64 for determining the point watched by the photographer on the finder image area, based on the image of the eye 5 of the photographer on said photoelectric converting element 63.</p>
    <p num="12">
      As the dichroic mirror 61 transmits the visible light, the photographer can observe the finder image area 2 through the eyepiece lens 4.
      <br/>
      Also as the dichroic mirror 61 reflects the infrared light, the reflected image of the eye 5, irradiated by the infrared light emitting diode 60, is condensed by the condenser lens 62 and focused on the photoelectric converting element 63.
    </p>
    <p num="13">The viewpoint detecting circuit 64 determines the viewpoint of the photographer on the finder image area 2, based on the image of the eye 5 on the photoelectric converting element 63, according to the above-mentioned principle or an algorithm disclosed in the Japanese Patent Laid-open Application Nos. 1-241511 and 2-32312.</p>
    <p num="14">In the following there will be explained the functions of the viewpoint switch provided in the view finder of the present conventional video camera.</p>
    <p num="15">An example of the display on the finder image area is schematically shown in FIG. 2.</p>
    <p num="16">
      On the finder image area 100, there is displayed a menu consisting of index marks 1a, 1b represented by letters "W" and "T" and indicating mutually different operations.
      <br/>
      For example "W" indicates the zooming operation toward the wide angle side, while "T" indicates that toward the telephoto side.
      <br/>
      A numeral "902" at the lower right corner indicates, for example, a date.
    </p>
    <p num="17">
      Now reference is made to a flow chart shown in FIG. 3, for explaining the zooming operation utilizing the viewpoint detection.
      <br/>
      Groups of coordinates of predetermined ranges including the visual switch index marks are memorized in a memory, and each group includes all the coordinates within the range of each index mark shown in FIG. 2.
      <br/>
      These groups are represented for example by  ALPHA  and  BETA  respectively for the wide angle side and the telephoto side.
      <br/>
      At first, when the power supply to the video camera is turned on (step S1), variables l and m are reset to zero (step S2), whereby the viewpoint switches are made ready.
      <br/>
      The variables l, m respectively indicate the numbers of coincidences of the watching point of the photographer with any of the coordinates of the groups  ALPHA  and  BETA .
      <br/>
      While the photographer looks into the view finder and the viewpoint detection is executed properly (step S3), the system control circuit 8 continuously receives the coordinate of the watching point of the photographer on the finder image area from the viewpoint detecting means 6.
    </p>
    <p num="18">
      In the following there will be explained, as an example, the functions when the photographer watches the wide angle index mark "W" in the finder image area.
      <br/>
      When the coordinate of the viewpoint coincides with any of the coordinates in the group  ALPHA  (step S4), the system control circuit 8 terminates any function other than the zooming operation toward the wide angle side (S6), then resets the variable m to 0 (S5), discriminates whether the variable l is equal to or larger than a predetermined number (5 in the present example) (S6), and, if less, adds 1 to l (S8).
      <br/>
      Then there is again discriminated whether l is equal to or larger than 5 (S9), and, if less, the sequence returns to the step S3 to receive the coordinate of the viewpoint from the viewpoint detecting circuit 64.
    </p>
    <p num="19">
      On the other hand, if the step S9 identifies that l is equal to or larger than 5, the zoom lens is shifted toward the wide angle side, and the sequence then returns to the step S3 to receive the coordinate of the viewpoint again.
      <br/>
      If the step S6 identifies that l is equal to or larger than 5, the sequence jumps to a step S11.
      <br/>
      Even when the coordinate of the viewpoint coincides with any of the coordinates in the group  ALPHA , if the coordinate of the viewpoint moves outside the group  ALPHA  before the number of coincidences reaches 5, the variable l is reset to zero (steps S13, S28).
      <br/>
      When the index mark "T" is looked at, a similar procedure is also executed.
    </p>
    <p num="20">In the above-explained configuration, however, the photographer is required to continue to look at the mark "W" for zooming toward the wide angle side or the mark "T" for zooming toward the telephoto side until the image angle reaches a value desired by the photographer by the zooming, so that the photographer becomes tired.</p>
    <p num="21">The above-mentioned drawback is not limited to the zooming operation but is associated with any analog adjustment of the function, and is commonly encountered in a control system utilizing the viewpoint detecting device.</p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="22">In consideration of the foregoing, a first object of the present invention is to provide a viewpoint detecting device capable of alleviating the fatigue of the photographer, resulting from continued watch of the index mark.</p>
    <p num="23">The above-mentioned object can be attained, according to a preferred embodiment of the present invention, by a viewpoint detecting device comprising display means for displaying index marks, showing settable ranges of a predetermined function, on a monitor image area; viewpoint detecting means for detecting one, on which the photographer's viewpoint is, of said index marks indicating the settable ranges; and setting means for setting said function at a state corresponding to the detected viewpoint.</p>
    <p num="24">Also according to another preferred embodiment, there is provided a viewpoint detecting device comprising display means for displaying index marks, showing settable ranges of a phototaking function and an index mark indicating the set state thereof on a monitor image area; viewpoint detecting means for detecting one, on which the photographer's viewpoint is, of said index marks indicating the settable ranges; and setting means for setting said function at a state corresponding to the detected viewpoint and transmitting said set state to said display means.</p>
    <p num="25">A second object of the present invention is to provide a viewpoint detecting device capable of setting adjustment means at an arbitrary adjustment state by the viewpoint.</p>
    <p num="26">A third object of the present invention is to provide an adjustment device provided with a viewpoint detecting device, capable of setting adjustment means at an arbitrary adjustment state by the viewpoint, wherein the displacement of the adjustment means to the thus set state can be conducted independently from the watching operation.</p>
    <p num="27">The above-mentioned objects can be attained, according to a preferred embodiment of the present invention, by a viewpoint detecting device comprising display means for displaying an adjusting scale of adjustment means for effecting a predetermined adjustment; viewpoint detecting means for detecting the position of the viewpoint of the operator; memory means for detecting, by means of said viewpoint detecting means, the viewpoint of the operator on said adjusting scale and memorizing the adjustment position corresponding to the viewpoint on said adjusting scale; and control means for displacing said adjustment means to said adjustment position memorized in said memory means with a predetermined velocity independent from said viewpoint.</p>
    <p num="28">A fourth object of the present invention is to provide an adjustment device utilizing viewpoint detecting means capable of memorizing the viewpoint on a scale in a monitor image area and displacing the adjustment means to the adjustment position with a velocity optimum for said adjustment means.</p>
    <p num="29">The above-mentioned object can be attained, according to a preferred embodiment of the present invention, by an adjustment device utilizing a viewpoint detecting device, comprising display means for displaying an adjusting scale of adjustment means for effecting a predetermined adjustment; viewpoint detecting means for detecting the position of the viewpoint of the operator; memory means for memorizing the adjustment position on said adjusting scale, corresponding to a viewpoint, in case said viewpoint detecting means detects that said viewpoint is on said adjusting scale at least for a predetermined time; and control means for displacing said adjustment means to said adjustment position memorized in said memory means, over a time longer than said predetermined time.</p>
    <p num="30">A fifth object of the present invention is to provide an image pickup device utilizing the above-mentioned adjustment device utilizing the viewpoint detecting means.</p>
    <p num="31">Still other objects of the present invention, and the features thereof, will become fully apparent from the following description, which is to be taken in conjunction with the attached drawings.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="32">
      FIG. 1 is a block diagram of a video camera proposed before by the present assignee;
      <br/>
      FIG. 2 is a schematic view showing an example of display on a finder image area of the video camera shown in FIG. 1;
      <br/>
      FIG. 3 is a flow chart showing the control sequence of the video camera shown in FIGS. 1 and 2;
      <br/>
      FIGS. 4A to 4D are views showing the principle of viewpoint detection;
      <br/>
      FIG. 5 is a block diagram of a video camera constituting an embodiment of the present invention;
      <br/>
      FIG. 6 is a schematic view showing an example of a display on the finder image area of the video camera of the above-mentioned embodiment;
      <br/>
      FIG. 7 is a flow chart showing the control sequence in a first embodiment of the present invention;
      <br/>
      FIG. 8 is a schematic view showing index marks according to the present invention;
      <br/>
      FIG. 9 is a map of a memory to be employed in the present invention;
      <br/>
      FIG. 10 is a block diagram showing an example of system control means to be employed in the present invention;
      <br/>
      FIG. 11 is a flow chart showing the control sequence in a second embodiment of the present invention; and
      <br/>
      FIG. 12 is a flow chart of a third embodiment of the present invention.
    </p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
    <p num="33">In the following there will be given a detailed explanation on an embodiment in which the viewpoint detecting device of the present invention and the adjustment device utilizing such a viewpoint detecting device are applied to a video camera.</p>
    <p num="34">At first there will be explained the principle of viewpoint detection in the viewpoint detecting device.</p>
    <p num="35">FIGS. 4C and 4D are respectively a plan view and a lateral view showing the principle of viewpoint detection.</p>
    <p num="36">
      Light sources 46a, 46b composed for example of infrared light emitting diodes (IRED), emitting infrared light insensitive to the observer, are positioned substantially symmetrically in the x (horizontal) direction with respect to the optical axis of an imaging lens 51 (cf. FIG. 4C) and somewhat lower in the y (vertical) direction (cf. FIG. 4D) and effect diverging illumination on the eye of the observer.
      <br/>
      A part of the illuminating light reflected by the eye 48 is focused by the imaging lens 51 onto an image sensor 52.
      <br/>
      FIG. 4A approximately shows the image of the eye projected on the image sensor 52, and FIG. 4B is a chart showing the output intensity of the image sensor 52.
    </p>
    <p num="37">Now the principle of viewpoint detection will be explained with reference to these drawings.</p>
    <p num="38">
      At first, in the horizontal plane, the infrared light emitted from the light source 46b illuminates, as shown in FIG. 4C, the cornea 50 of the eye 48 of the observer.
      <br/>
      A corneal reflected image d (false image) formed by the infrared light reflected on the surface of the cornea 50 is condensed by the imaging lens 51 and is focused on a position d on the image sensor 52.
      <br/>
      Similarly the infrared light from the light source 46a illuminates the cornea 50 of the eye, and a corneal reflected image e (false image) formed by the infrared light reflected on the surface of the cornea 50 is condensed by the imaging lens 51 and is focused at a position e' on the image sensor 52.
    </p>
    <p num="39">
      Also light beams from end portions a, b of the iris 44 (FIG. 4A) are focused, through the imaging lens 51, at positions a', b' on the image sensor 52.
      <br/>
      In case the rotation angle  THETA  of the optical axis of the eye 48 is small relative to the optical axis of the imaging lens 51, there can be determined, on the image sensor 52, a plurality of the x-coordinates xa, xb of the end portions a, b of the iris 44, as indicated by marks x in FIG. 4A. Thus, the center xc of the pupil is calculated, utilizing the minimum square method on a circle.
    </p>
    <p num="40">
      On the other hand, the rotation angle  THETA x of the eye 48 relative to the optical axis can be represented as follows, utilizing the x-coordinate xo of the center o of the curvature of the cornea 50:
      <br/>
      oc*sin  THETA x=xc-xo  (1)
    </p>
    <p num="41">
      Also xo can be determined in the following manner, in consideration of a predetermined correction value  DELTA x at the center k of the corneal reflected images d and e:
      <br/>
      xk=(xd+xe)/2
      <br/>
      xo=(xd+xe)/2+ DELTA x  (2)
    </p>
    <p num="42">DELTA x is a value geometrically determined from the method of installation of the device, distance to the eye etc. but the method of such determination will not be explained further.</p>
    <p num="43">
      By substituting (1) in (2),  THETA x can be determined as:
      <br/>
      THETA x=arc sin ��xc-+(xd+xe)/2+ DELTA x}�/oc�  (3)
    </p>
    <p num="44">
      Also the coordinates of the feature points projected on the image sensor can be defined, with suffix ', as follows:
      <br/>
      THETA x=arc sin ��xc'-+(xd'+xe')/2+ DELTA x'}�/oc/ BETA �  (4)
    </p>
    <p num="45">wherein  BETA  is a magnification determined by the eye distance size to the imaging lens 51 and obtained in practice as a function of the distance .vertline.xd'-xe'.vertline. of the corneal reflected images.</p>
    <p num="46">
      In the vertical plane, there is obtained a configuration as shown in FIG. 4D. The corneal reflected images formed by the two IRED's 46a, 46b are in a same position i. The rotation angle  THETA y of the eye 48 can be calculated in a similar manner as in the horizontal plane, except for the equation (2) which is replaced by the following equation (5) defining the y-coordinate yo of the center o of curvature of the cornea:
      <br/>
      yo=yi+ DELTA y  (5)
    </p>
    <p num="47">
      wherein  DELTA y is a value determined geometrically from the method of installation of the device, the distance to the eye etc. but the method of such determination will not be explained further.
      <br/>
      Thus the rotation angle  THETA y in the vertical direction can be represented as:
      <br/>
      THETA y=arc sin ��yc'-(yi'+ DELTA y')�/oc/ BETA �  (6)
    </p>
    <p num="48">wherein yc' is the vertical coordinate of the center of the pupil on the image sensor.</p>
    <p num="49">
      Also the coordinate (xn, yn) of a position on the finder image area of the video camera can be defined, with a constant m determined by the view finder optical system, as follows in the horizontal and vertical planes:
      <br/>
      xn=m*arc sin ��xc'-+(xd'+xe')/2+ DELTA x'}�/oc/ BETA �  (7)
      <br/>
      yn=m*arc sin ��yc'-+(yi'+ DELTA y')�/oc/ BETA �  (8)
    </p>
    <p num="50">
      As will be apparent from FIGS. 4A and 4B, the detection of the pupil edges utilized an upshift (xb') and a down-shift (xa') of the output waveform of the image sensor.
      <br/>
      Also the coordinates of the corneal reflected images are determined by sharp upshifts (xe', xd').
    </p>
    <p num="51">In the following there will be explained the configuration and function of the video camera of the present embodiment.</p>
    <p num="52">
      FIG. 5 shows the configuration of the video camera of the present embodiment, wherein components the same as those shown in FIG. 1 are represented by the same symbols and will not be explained further.
      <br/>
      In brief, the configuration shown in FIG. 5 is different from that in FIG. 1 in the process of the system control circuit 20 and the function of the memory 21.
    </p>
    <p num="53">In FIG. 5, there is additionally provided a trigger switch 11 for controlling the start and stop (stand-by) of the phototaking operation.</p>
    <p num="54">
      FIG. 6 shows an example of the display on the finder image area, wherein an index mark 31 indicates the wide angle side "W" of zooming while an index mark 32 indicates the telephoto side "T" of zooming.
      <br/>
      A mark 33, consisting of a horizontal line with short vertical lines is a scale representing the settable positions of zooming and indicating that the image angle can be set, in addition to the wide angle end and the telephoto end, at seven positions therebetween.
      <br/>
      If the focal lengths at the wide angle end and the telephoto end are respectively, for example, 6 mm and 54 mm, a section between the neighboring short vertical lines corresponds to a difference of 6 mm in the focal length.
      <br/>
      A mark 34 indicates the currently selected zooming image angle.
      <br/>
      In the example shown in FIG. 6, the mark 34 is at the third short line from the wide angle end, corresponding to a focal length of 24 mm.
      <br/>
      A number 35 at the lower right corner does not have the switching function but merely indicates, for example, a date.
    </p>
    <p num="55">The memory 21 in FIG. 5 stores the coordinates, on the finder image area 2, of the above-mentioned index mark 33 in 9 positions, or the wide angle end and the telephoto end and 7 interim positions.</p>
    <p num="56">
      In the following there will be explained the zooming process by the system control circuit 20, with reference to a flow chart shown in FIG. 7.
      <br/>
      After the process is initiated (S101), there is repeated a discrimination whether the trigger switch has been depressed (S102).
      <br/>
      When the trigger switch 11 is depressed, the coordinate of the viewpoint on the finder image area 2 in this state is obtained from the viewpoint detecting circuit 64 (S103).
      <br/>
      Also at this point the display position of the mark 34 is moved to the coordinate of the viewpoint.
      <br/>
      The coordinate of thus obtained viewpoint corresponds to the image angle selected by the photographer.
      <br/>
      Thus said coordinate is compared with the coordinates memorized in advance in the memory 21, whereby the focal length represented by the mark watched by the photographer is identified (S104).
      <br/>
      Then the phototaking lens system is driven to the thus identified focal length (S105).
      <br/>
      The system control circuit 20 is utilized as the setting means.
    </p>
    <p num="57">
      FIG. 8 shows an example of the relationship between the index mark 33 indicating the settable zoom positions and the coordinates of the portions representing the aforementioned 9 focal lengths.
      <br/>
      Starting from a coordinate (0, 0) of the mark 31 indicating the wide angle end "W", there are defined, toward the right, 9 coordinates to a coordinate (40, 0) of the mark 32 indicating the telephoto end "T".
    </p>
    <p num="58">
      FIG. 9 shows an example of the coordinates and focal lengths memorized in the memory 21.
      <br/>
      A memory area 211 contains 9 addresses from 001 to 009.
      <br/>
      Each address has two information areas 212 and 213.
      <br/>
      The portion 212 stores 9 coordinates in the lateral direction only, and the portion 213 stores the focal lengths respectively assigned to the coordinates.
    </p>
    <p num="59">
      Now reference is made to FIG. 10 for effecting the discrimination in the step S104 in FIG. 7.
      <br/>
      Referring to FIG. 10, a counter 201 provided in the system control circuit 20 generates addresses in succession from 001 to 009, and the coordinate values respectively corresponding to these addresses are supplied in succession from the memory 21 to the system control circuit 20.
      <br/>
      In case of coincidence with the coordinate value entered from the viewpoint detecting means 64, there is obtained a focal length stored in the address of such coinciding coordinate.
    </p>
    <p num="60">The phototaking lens system 1 is set at the thus determined focal length by providing the phototaking lens system 1 with so-called zoom encoder for detecting such 9 zoom positions and driving the phototaking lens system 1 in such a manner that the output of the encoder becomes equal to a value corresponding to the focal length obtained by the system control circuit 20.</p>
    <p num="61">In the above-explained configuration of the first embodiment, after the depression of the trigger switch 11, the zoom lens can be set at the desired focal length without continued watch of the photographer at the index mark.</p>
    <p num="62">
      In the foregoing first embodiment, the image angle of the zoom lens starts to change after the depression of the trigger switch 11 by the photographer, but it is also possible, as soon as the photographer watches any part of the aforementioned index mark 33 indicating the settable zoom position, to set the zoom lens at an image angle corresponding to the coordinate of thus watched part.
      <br/>
      FIG. 11 is a flow chart showing the control sequence in such case.
    </p>
    <p num="63">
      When the sequence is initiated (S201), the system control circuit 20 discriminates whether the coordinate obtained from the viewpoint detecting circuit 64 coincides with any of the 9 zoom setting positions of the index mark 32 shown in FIG. 6 (S202), and, if the watched point coincides with any of these setting positions, the focal length corresponding to the coordinate of the watched point is obtained from the memory 21.
      <br/>
      The sequence thereafter is the same as the steps S104 to S106 in the first embodiment, shown in FIG. 7.
    </p>
    <p num="64">This second embodiment allows the operator to set the zoom lens at a desired focal length, by merely watching the index mark 203 corresponding to the desired focal length for a short time, instead of continued watch.</p>
    <p num="65">In the following there will be explained, in combination with the state of actual use, an embodiment in which the viewpoint detecting device of the present invention is applied to a video camera.</p>
    <p num="66">
      The video camera of the present embodiment is similar, in configuration, to that shown in FIG. 5, but is different in the process executed in the system control circuit 20.
      <br/>
      FIG. 12 is a flow chart showing the process executed in the system control circuit 20.
    </p>
    <p num="67">When the sequence is initiated, a step S301 discriminates whether the video camera is in the camera mode, and, if it is in the camera mode, the sequence proceeds to a step S302, but, if not (in case of playback or recording of the external input in the VCR mode), the video camera enters the stand-by state.</p>
    <p num="68">
      In case the step S301 confirms that the video camera is in the camera mode, a step S302 activates the image pickup device, the signal processing circuits of the phototaking system, the electronic view finder and the lens systems and also activates the viewpoint detecting circuit, whereby the video camera enters the recording stand-by state.
      <br/>
      Thus the scale indicating the movable range of the zoom lens and the current position thereof are displayed in the finder image area.
    </p>
    <p num="69">When the operator looks into the electronic view finder in this state, the viewpoint of the operator is detected (S303).</p>
    <p num="70">Then a step S304 discriminates whether the detected viewpoint in the image area is on the scale, indicating the movable range of the zoom lens, as shown in FIG. 6, and, if it is on said scale or not, the sequence respectively proceeds to a step S305 or S311.</p>
    <p num="71">
      The step S305 discriminates whether a position on the scale is watched for a predetermined time, and, if watched, the sequence proceeds to a step S306 to release the coordinate of the viewpoint which has been watched for the predetermined time.
      <br/>
      If the step S305 cannot confirm the watch for the predetermined time, the sequence proceeds to the step S311.
    </p>
    <p num="72">
      The coordinate of the viewpoint obtained in the step S306 is compared in succession, in a step S307, with the coordinates of the gradations of the scale of the movable range of the zoom lens, stored in the memory 21, and a step S308 identifies and releases the coordinate of a stored position closest to the coordinate of the viewpoint.
      <br/>
      In this state an index mark representing the target position of the zoom lens is displayed as shown by 36 in FIG. 6.
    </p>
    <p num="73">
      A step S309 memorizes, as the target value for lens movement, the zoom lens position (focal length) corresponding to the coordinate released in the step S308, and a step S310 drives the zoom lens to the thus memorized target position of the zoom lens.
      <br/>
      In this manner the zoom lens can be driven to the position designated by the viewpoint on the scale indicating the movable range of the zoom lens.
      <br/>
      Along with the movement of the zoom lens, the index mark 34 indicating the current position of the zoom lens moves, so that the operator can confirm the moving state of the zoom lens.
    </p>
    <p num="74">The zoom lens is moved to the position designated by the viewpoint with a speed optimum for the zooming operation, regardless of the period of watching of the scale.</p>
    <p num="75">Thus the zoom lens does not instantaneously move to the designated position but is so controlled as to effect a natural zooming operation.</p>
    <p num="76">In the foregoing there has been explained an optical zooming operation with a zoom lens, but the zooming operation with the optimum speed can be achieved also in case of electronic zooming in which the image angle is changed electronically.</p>
    <p num="77">
      After the zoom lens drive in the step S310, a step S312 discriminates whether the selected target position of the zoom lens has been reached, and, if reached, a step S313 stop the zoom lens and the sequence returns to the step S301.
      <br/>
      When the zoom lens reaches the target position and is stopped, the mark 34 is also stopped and the mark 36 of the target position is extinguished.
    </p>
    <p num="78">If the step S312 identifies that the zoom lens has not reached the target position of zoom lens movement, the sequence moves to the step S301 to repeat the above-explained procedure, and the zoom lens is continuously driven until the step S312 confirms that the selected target position of the zoom lens movement has been reached.</p>
    <p num="79">On the other hand, in case the discrimination of the step S304 turns out negative, indicating that the viewpoint of the operator is not present on the scale indicating the movable range of the zoom lens, the sequence proceeds to a step S311 to discriminate whether the zoom lens is in movement, and, if not, the sequence moves to the step S301 and the zoom lens drive is not conducted until the selection is made again by the viewpoint.</p>
    <p num="80">On the other hand, in case the step S311 identifies that the zoom lens is in movement, the sequence proceeds to a step S312 to continue the drive until the current target position is reached.</p>
    <p num="81">
      Thus, the above-mentioned sequence is to continue the drive of the zoom lens to the set target position once the drive of the zoom lens is started by the watch of a desired position on the movable range scale of the zoom lens, even if the viewpoint of the operator is thereafter shifted from the scale.
      <br/>
      Thus, once designating the target position of the zoom lens, the operator need not continue to look at the scale, and the zoom lens is moved to the target position with the optimum speed for the zooming operation.
    </p>
    <p num="82">On the other hand, if the step S306 identifies that the watch has not continued for the predetermined time, the sequence proceeds to the step S311, and, if the zoom lens is in movement, the zoom lens is driven to the designated target position.</p>
    <p num="83">According to the above-explained procedure, once the operator has designated the target position of the zoom lens on the scale, such target position is not changed even if the viewpoint is shifted to another position on the scale, unless the watch is continued for the predetermined time.</p>
    <p num="84">On the other hand, even after the setting of the target position for zoom lens movement and during the zoom lens movement to said target position, the target position can be renewed through the steps S305 to S309 by watching another position on the scale for the predetermined time, whereby the zoom lens can be moved to the new target position.</p>
    <p num="85">
      According to the present embodiment, as explained in the foregoing, by watching a desired position on the scale, the zoom lens can be driven to a position or a focal length corresponding to the watched position, and, after the setting of the target position, the zoom lens can be driven to said target position, even if the viewpoint is shifted from the scale.
      <br/>
      Also even during the movement of the zoom lens, the target position of the zoom lens can be changed by watching another position on the scale.
    </p>
    <p num="86">In either case, the operator is not required to continue to watch the scale during the zoom lens movement, and the zoom lens is driven with the optimum speed for the zooming operation.</p>
    <p num="87">
      The foregoing embodiment, as explained in the foregoing, is so constructed as to display, on the finder image area, an index mark indicating the settable range of the phototaking function, to detect the viewpoint of the operator watching the index mark and to set the phototaking function at a range corresponding to the detected viewpoint.
      <br/>
      Thus the operator can automatically obtain a desired set state of the functions such as zooming by merely watching a desired setting range displayed on the finder image area, wherein the operator is not required to continue to watch the index mark so that the fatigue of the operator can be alleviated.
    </p>
    <p num="88">
      Also, the foregoing embodiment is so constructed as to display, on the finder image area, an index mark indicating the settable range of the phototaking function and the set state thereof, to detect the viewpoint of the operator on the index mark indicating the settable range, to set the phototaking function in a setting range corresponding to the detected viewpoint and to display the set state of said function on the finder image area.
      <br/>
      Thus the operator can automatically obtain a desired set state of the function such as zooming by merely watching a desired setting range displayed on the finder image area, wherein the operator is not required to continue to watch the index mark so that the fatigue of the operator can be alleviated, and the operator can easily know the current set state as it is also displayed.
    </p>
    <p num="89">The present invention is not limited to the foregoing embodiments but is naturally applicable to other equipment as an adjusting device utilizing the viewpoint detection.</p>
    <p num="90">It is also possible to achieve an operation similar to the conventional analog knob adjustment by the viewpoint, without the necessity of continued watch on the index mark.</p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>An image processing device comprising:</claim-text>
      <claim-text>(A) display means for displaying, on a monitor image area, an index mark indicating a variable range of control values of a predetermined function; (B) viewpoint detecting means for detecting the position of the viewpoint of the operator in said image area;</claim-text>
      <claim-text>and (C) control means for, when said viewpoint is detected on said index mark by said viewpoint detecting means, converting the position information of the detected viewpoint on the index mark into driving information, and for driving said predetermined function according to the driving information regardless of a change of the viewpoint and without a manual command.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. An image processing device according to claim 1, wherein said control means is adapted to set the target state of said predetermined function corresponding to a position on the index mark where said viewpoint detecting means identifies that the viewpoint remains fixed at least for a predetermined time.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. An image processing device according to claim 2, wherein said control means is adapted to effect a varying operation for the target state of said function, irrespective of the predetermined time for the detection of said viewpoint.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. An image processing device according to claim 1, wherein said monitor comprises an electronic view finder.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. An image processing device according to claim 3, wherein said index mark comprises a scale indicating said settable range, plural settable positions and the current set position of said function.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. An image processing device according to claim 5, wherein said predetermined function comprises zoom lens driving means, and wherein said index mark indicates the variable range of the focal length of said zoom lens.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. An image processing device according to claim 5, further comprising: a memory which stores the information on said settable range and on the plural settable positions within said settable range, together with control values for setting functions respectively corresponding to said positions.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. An image pickup device comprising: A) display means for displaying, on a monitor image area, an index mark indicating a variable range of control values of a predetermined function; B) viewpoint detecting means for detecting the position of the viewpoint of the operator in said image area;</claim-text>
      <claim-text>and C) control means adapted, when said viewpoint is detected on said index mark by said viewpoint detecting means, for storing position information of the detected viewpoint on the index mark as a control target value, and for converting the position information into driving information and driving said predetermined function according to the driving information at a predetermined speed and without a manual command, and for causing said display means to display the set state of said predetermined function.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. An image pickup device according to claim 8, wherein said control means is adapted to set the target driving value of said predetermined function corresponding to a position on the index mark where said viewpoint detecting means identifies that the viewpoint remains fixed at least for a predetermined time.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. An image pickup device according to claim 9, wherein said control means is adapted to effect a varying operation for the target driving value of said function, irrespective of the predetermined time for the detection of said viewpoint.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. An image pickup device according to claim 8, wherein said monitor comprises an electronic view finder.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. An image pickup device according to claim 10, wherein said index mark comprises a scale indicating said variable range, plural settable positions and the current set position of said function.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. An image pickup device according to claim 12, wherein said predetermined function is zoom means, and said index mark indicates the magnification of said zoom means.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. An image pickup device according to claim 10, further comprising: a memory which stores the information on said settable range and on the plural variable positions within said settable range, together with control values for setting functions respectively corresponding to set positions.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. An adjustment device comprising: A) adjustment means for effecting a predetermined adjustment; B) display means for displaying, on a monitor image area, an index mark indicating an adjustment range of said adjustment means; C) viewpoint detecting means for detecting a position of the viewpoint of the operator in said monitor image area; D) target setting means adapted, when the viewpoint is detected on said index mark by said viewpoint detecting means, for setting and storing a target adjustment value of said adjustment corresponding to the viewpoint on said index mark;</claim-text>
      <claim-text>and E) control means for converting the target adjustment value into an adjustment amount of said adjustment means and driving said adjustment means according to the adjustment amount, even when the viewpoint detected by said viewpoint detecting means is no longer on said index mark.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. An adjustment device according to claim 15, further comprising a memory storing plural adjustment states assumable by said adjustment means within said adjustment range and information on the positions on the index mark respectively corresponding to said adjustment states, in a mutually corresponding manner; wherein said target setting means is adapted to compare the position, on said index mark, of the viewpoint of the operator identified as fixed for at least a predetermined time by said viewpoint detecting means, with the information on said positions stored in said memory, and to set an adjustment state corresponding to the information of a matching position as a target adjustment state.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. An adjustment device according to claim 16, wherein said control means is adapted, in varying the adjustment state of said adjustment means to said target adjustment state, to effect said variation with a predetermined speed irrespective of the position of the viewpoint of the operator.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. An adjustment device according to claim 17, wherein said target setting means is adapted to vary the current target adjustment state to a new target adjustment state, when the viewpoint detecting means detects that another position on the index mark is watched for at least a predetermined time.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. An adjustment device according to claim 16, wherein said control means is adapted, once said target adjustment state is set by said target setting means, to continue the varying operation for the adjustment state of said adjustment means even if the viewpoint is changed thereafter.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. An adjustment device according to claim 19, wherein said index mark is composed of a scale indicating the adjustment range of said adjustment means by gradations, and the current adjustment state and the target adjustment state are displayed on said scale.</claim-text>
    </claim>
    <claim num="21">
      <claim-text>21. An adjustment device according to claim 20, wherein said adjustment means comprises zooming means, and the scale displayed on said monitor comprises an index mark on the image magnification.</claim-text>
    </claim>
    <claim num="22">
      <claim-text>22. An adjustment device according to claim 15, wherein said monitor comprises an electronic view finder.</claim-text>
    </claim>
    <claim num="23">
      <claim-text>23. An adjustment device comprising: A) adjustment means for effecting a predetermined adjustment; B) display means for displaying, on a monitor image area, an index mark indicating the adjustment range of said adjustment means; C) a memory storing plural positions on said index mark and adjustment positions of said adjustment means corresponding to said plural positions; D) viewpoint detecting means for detecting the position of the viewpoint of the operator in said monitor image area; E) target setting means adapted, when a position of the viewpoint fixed on said index mark for at least a predetermined time is detected according to the output of said viewpoint detecting means, to read one of said adjustment positions from said memory corresponding to said position of the viewpoint and to set thus read position as the target position;</claim-text>
      <claim-text>and F) control means for moving the adjustment position of said adjustment means to the target position set by said target setting means with a predetermined speed, and, even in case the output of said viewpoint detecting means is varied during the movement of said adjustment means, continuing the movement of said adjustment means to said target position.</claim-text>
    </claim>
    <claim num="24">
      <claim-text>24. An adjustment device according to claim 23, wherein said control means is adapted, in case the output of said viewpoint detecting means is varied during the movement of said adjustment means, to renew said target position if another position on the index mark is watched anew for at least said predetermined time, and to continue the movement of said adjustment means to the current target position if the watch is less than said predetermined time.</claim-text>
    </claim>
    <claim num="25">
      <claim-text>25. An adjustment device according to claim 24, wherein said control means is adapted to display said target position and the current position of said adjustment means on said index mark.</claim-text>
    </claim>
    <claim num="26">
      <claim-text>26. An electronic device comprising: display means for displaying, on a monitor image area, an index mark indicating the variable range of a zooming means for performing a zooming operation; viewpoint detecting means for detecting a position of a viewpoint of an operator in said image area;</claim-text>
      <claim-text>and control means adapted, when said viewpoint is detected on said index mark by said viewpoint detecting means, for (i) setting a value corresponding to the detected viewpoint on the index mark as a target value of said zooming means, (ii) converting the target value into a driving amount, and (iii) driving said zooming means according to the driving amount.</claim-text>
    </claim>
    <claim num="27">
      <claim-text>27. A device according to claim 26, wherein said control means is adapted to set the target value of said zooming means corresponding to a position on the index mark where said viewpoint detecting means detects that the viewpoint remains fixed for at least a predetermined period of time.</claim-text>
    </claim>
    <claim num="28">
      <claim-text>28. A device according to claim 27, wherein said control means is adapted to effect a varying operation for the target value of said zooming means irrespective of the predetermined time for the detection of said viewpoint.</claim-text>
    </claim>
    <claim num="29">
      <claim-text>29. A device according to claim 26, wherein said monitor comprises an electronic viewfinder.</claim-text>
    </claim>
    <claim num="30">
      <claim-text>30. A device according to claim 26, wherein said index mark comprises a scale indicating said variable range, plural variable positions, and the current set position of said function.</claim-text>
    </claim>
    <claim num="31">
      <claim-text>31. A device according to claim 30, wherein said zooming means comprises a zoom lens driving means, and wherein said index mark indicates the variable range of the focal length of said zoom lens.</claim-text>
    </claim>
    <claim num="32">
      <claim-text>32. A device according to claim 30, further comprising a memory which stores information on said variable range and on the plural variable positions within said variable range, together with control values for setting functions respectively corresponding to said positions.</claim-text>
    </claim>
    <claim num="33">
      <claim-text>33. A control method for an adjustment device having an adjustment part for detecting a predetermined adjustment, comprising the steps of: a step of displaying, on a monitor image area, an index mark indicating an adjustment range of said adjustment part; a step of detecting a position of the view-point of the operator in the monitor image area; a step of setting and storing a target adjustment value of the predetermined adjustment corresponding to the viewpoint on the index mark when the viewpoint is detected on the index mark in said detecting step;</claim-text>
      <claim-text>and a step of converting the target adjustment value into an adjustment amount of said adjustment part and driving said adjustment part according to the adjustment amount, even when the viewpoint is no longer on said index mark.</claim-text>
    </claim>
    <claim num="34">
      <claim-text>34. A method according to claims 33, further comprising a step of storing, in a memory, (i) plural adjustment states assumable by said adjustment part within said adjustment range and (ii) information on the positions on the index mark respectively corresponding to said adjustment states, in a mutually corresponding manner;</claim-text>
      <claim-text>and wherein said setting step is adapted to compare the position, on said index mark, of the viewpoint of the operator identified as fixed for at least a predetermined time in said detecting step, with the information on said positions stored in said memory, and to set an adjustment state corresponding to the information of a matching position as a target adjustment state.</claim-text>
    </claim>
    <claim num="35">
      <claim-text>35. A method according to claim 34, wherein said converting and driving step is adapted, in varying the adjustment state of said adjustment part to said target adjustment state, to effect said the variation with a predetermined speed irrespective of the position of the viewpoint of the operator.</claim-text>
    </claim>
    <claim num="36">
      <claim-text>36. A method according to claim 35, wherein said setting step is adapted to vary the current target adjustment state to a new target adjustment state, when another position on the index mark is watched for at least a predetermined time.</claim-text>
    </claim>
    <claim num="37">
      <claim-text>37. A method according to claim 34, wherein said converting and driving step is adapted, once said target adjustment state is set in said setting step, to continue the varying operation for the adjustment state of said adjustment part even if the viewpoint is changed thereafter.</claim-text>
    </claim>
    <claim num="38">
      <claim-text>38. A method according to claim 37, wherein said index mark comprises a scale indicating the adjustment range of said adjustment part by gradations, and wherein the current adjustment state and the target adjustment state are displayed on said scale.</claim-text>
    </claim>
    <claim num="39">
      <claim-text>39. A method according to claim 38, wherein said adjustment part comprises zooming means, and wherein the scale displayed on said monitor comprises an index mark on the image magnification.</claim-text>
    </claim>
    <claim num="40">
      <claim-text>40. A method according to claim 33, wherein said monitor comprises an electronic view finder.</claim-text>
    </claim>
  </claims>
</questel-patent-document>