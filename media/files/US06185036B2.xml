<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06185036B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06185036</doc-number>
        <kind>B2</kind>
        <date>20010206</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6185036</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="13324910" extended-family-id="21343256">
      <document-id>
        <country>US</country>
        <doc-number>09263055</doc-number>
        <kind>A</kind>
        <date>19990306</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1999US-09263055</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>21889427</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>JP</country>
        <doc-number>6675198</doc-number>
        <kind>A</kind>
        <date>19980317</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1998JP-0066751</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010206</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G02B  21/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>02</class>
        <subclass>B</subclass>
        <main-group>21</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G01B  11/24        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>01</class>
        <subclass>B</subclass>
        <main-group>11</main-group>
        <subgroup>24</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>359368000</text>
        <class>359</class>
        <subclass>368000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>359235000</text>
        <class>359</class>
        <subclass>235000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>359389000</text>
        <class>359</class>
        <subclass>389000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G02B-021/00M4A</text>
        <section>G</section>
        <class>02</class>
        <subclass>B</subclass>
        <main-group>021</main-group>
        <subgroup>00M4A</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>G02B-021/00M4A9</text>
        <section>G</section>
        <class>02</class>
        <subclass>B</subclass>
        <main-group>021</main-group>
        <subgroup>00M4A9</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G02B-021/008</classification-symbol>
        <section>G</section>
        <class>02</class>
        <subclass>B</subclass>
        <main-group>21</main-group>
        <subgroup>008</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G02B-021/0024</classification-symbol>
        <section>G</section>
        <class>02</class>
        <subclass>B</subclass>
        <main-group>21</main-group>
        <subgroup>0024</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>10</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>6</number-of-drawing-sheets>
      <number-of-figures>8</number-of-figures>
      <image-key data-format="questel">US6185036</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Confocal system</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>WAYLAND J HAROLD</text>
          <document-id>
            <country>US</country>
            <doc-number>4806004</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4806004</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>FUKUYAMA HIROYA</text>
          <document-id>
            <country>US</country>
            <doc-number>5225671</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5225671</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>KERSTENS PIETER J, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5248876</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5248876</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>TANAAMI TAKEO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5428475</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5428475</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>ISHIHARA MITSUHIRO</text>
          <document-id>
            <country>US</country>
            <doc-number>5737084</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5737084</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Yokogawa Electric Corporation</orgname>
            <address>
              <address-1>Tokyo, JP</address-1>
              <city>Tokyo</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>YOKOGAWA ELECTRIC</orgname>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Tanaami, Takeo</name>
            <address>
              <address-1>Tokyo, JP</address-1>
              <city>Tokyo</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <name>Kojima, Moonray</name>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Spyrou, Cassandra</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>GRANTED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A confocal system comprising a laser light source; a confocal scanner that emits an output light beam from the light source after passing through apertures; an optical microscope that focuses light passed through the apertures onto a sample; a detector that obtains cross sectional images of the sample by photographing the return light reflected from the sample; and a controller that determines focal positions of the sample using light intensity at cross sectional images based on a focal position light intensity characteristic, whereby focal postions and three dimensional shape of the sample is obtained without scanning in the direction of the optical axis.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">
      1.
      <br/>
      Field of Invention
    </p>
    <p num="2">This invention relates to a confocal system, and more particularly to such system which does not require scanning in the direction of the optical axis.</p>
    <p num="3">2. Description of the Prior Art</p>
    <p num="4">
      Conventional confocal systems provide confocal images in the following manner.
      <br/>
      A disk having a plurality of apertures is rotated.
      <br/>
      A sample is scanned by focusing thereon light beam which is passed through the apertures.
      <br/>
      A three dimensional shape of the sample, based on cross sectional images, is obtained by scanning the sample a plurality of times in the optical axis direction.
    </p>
    <p num="5">
      FIG. 1 shows a conventional confocal system comprising a light source 1, a confocal scanner 2, an optical microscope 3, a stage 4 on which a sample is placed, a detector 5, such as a camera, and a controller 6, such as a computer.
      <br/>
      Output light from the laser 1 is made incident on the confocal scanner 2 through an optical fiber or the like.
      <br/>
      Scanner 2 rotates a disk having a plurality of apertures therein and passes the laser light beam through the apertures.
      <br/>
      Optical microscope 3 focuses the light beam outputted from confocal scanner 2 onto a sample (not shown) placed on stage 4.
      <br/>
      Stage 4 drives the sample in the direction of the optical axis of the incident light.
      <br/>
      Furthermore, detector 5 is provided in confocal scanner 2 and an output signal from detector 5 is supplied to controller 6.
    </p>
    <p num="6">
      Operation of the system of FIG. 1 is as follows.
      <br/>
      Light beam is focused on the sample by optical microscope 3 after passing through the apertures of the disk of scanner 2.
      <br/>
      The sample reflects the light and the reflected (or otherwise called "return") light is again passed through the apertures of the scanner disk and is made incident on detector 5.
      <br/>
      The images obtained by detector 5 are confocal images.
      <br/>
      Since the disk is rotated, the spot of light focused on the sample scans the sample surface.
      <br/>
      Detector 5 then obtains cross sectional images of the sample on planes perpendicular to the direction of the optical axis.
    </p>
    <p num="7">
      A three dimensional image of the sample can be determined by storing the multiple cross sectional images obtained of the sample by scanning the sample in the direction of the optical axis by controlling stage 4, and then by reconstructing the cross sectional images.
      <br/>
      These procedures are performed in the controller 6.
    </p>
    <p num="8">That is, a three dimensional shape can be derived by storing a plurality of cross sectional images in planes perpendicular to the direction of the optical axis while scanning the sample in the direction of the optical axis by controlling stage 4 and by reconstructing the cross sectional images using controller 6.</p>
    <p num="9">
      However, in the confocal system of FIG. 1, a long measuring time is required to obtain one three dimensional image because scanning is done by utilizing stage 4 and in the optical axis direction to obtain the plurality of cross sectional images.
      <br/>
      Thus, if the conventional system is used, for example in factory automation, semiconductor production lines, etc, the length of measuring time presents a difficult problem.
      <br/>
      Also, another problem is that stage 4 must be provided separately and the accuracy of measurement then depends solely on the driving accuracy of the stage.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="10">Accordingly, an object of the invention is to overcome the aforementioned and other deficiencies, disadvantages, problems and drawbacks of the prior art.</p>
    <p num="11">Another object is to provide a confocal system that can obtain focal positions of the sample and a three dimensional shape thereof without scanning in the direction of the optical axis.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="12">
      FIG. 1 is a block diagram depicting a conventional confocal system.
      <br/>
      FIG. 2 is a block diagram depicting an illustrative embodiment of the invention.
      <br/>
      FIG. 3 is a graph depicting a characteristic curve showing the relationship between light intensity and focal point position obtained with the detector when a mirror is scanned in the optical axis direction.
      <br/>
      FIG. 4 is an illustration depicting the relationship between the characteristic curve of FIG. 3 and the sample.
      <br/>
      FIG. 5 is a graph depicting a characteristic curve showing the relationship between the light intensity and the focal point position obtained with the detector when a mirror is scanned in the optical axis direction.
      <br/>
      FIGS. 6(A) and 6(B) are illustrations depicting the relationship between the characteristic curve of FIG. 5 and the sample.
      <br/>
      FIG. 7 is a block diagram depicting another illustrative embodiment of the invention using two light sources.
    </p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
    <p num="13">
      In FIG. 2, the same symbols are used for the same components as in FIG. 1 and description thereof is omitted for sake of convenience except where relevant.
      <br/>
      The output light beam from laser light source 1 is made incident on confocal scanner 2 using an optical fiber or the like.
      <br/>
      Confocal scanner 2 rotates a disk having a plurality of apertures therein and provides an incident laser light beam after the light beam is passed through the apertures.
      <br/>
      Optical microscope 3 focuses the outputted light beam onto sample 8 using objective lens 7.
      <br/>
      Also, detector 5, such as a camera, is provided in or connected to confocal scanner 2, and the output signal from detector 5 is supplied to controller 6.
    </p>
    <p num="14">
      The embodiment operates as follows, taken in connection with FIGS. 3 and 4.
      <br/>
      FIG. 3 shows a characteristic curve showing the relationship between light intensity and focal point position obtained by detector 5 when a mirror is scanned in the direction of the optical axis in place of a sample.
      <br/>
      FIG. 4 shows the relationship between the characteristic curve of FIG. 3 and the sample.
      <br/>
      Description of the basic operational steps is omitted hereat since such operation is similar to that described with reference to FIG. 1.
    </p>
    <p num="15">
      In detector 5, the maximum light intensity is obtained when the mirror is positioned at the focal point and the light intensity is caused to decrease before and after the focal point.
      <br/>
      In other words, as shown in FIG. 3, the maximum light intensity can be obtained at the focal point, shown as FP01.
      <br/>
      The light intensity becomes lower in turn, as shown by L001, L002, and L003 in FIG. 3, as the mirror is moved to turn away from the focal point, as shown by Z001, Z002 and Z003.
      <br/>
      Accordingly, such focal point position light intensity characteristic is measured and stored in advance in controller 6.
    </p>
    <p num="16">
      On the other hand, as shown in FIG. 4, assume a sample 8 that has stepwise planes ST01, ST02, and ST03 disposed perpendicular to the direction of the optical axis, as shown as SP01.
      <br/>
      Also, assume that the reflectivity of each plane is 100%, that is the same value as that of the mirror.
      <br/>
      Assume further that the positions of the planes, shown by ST01, ST02, and ST03 in FIG. 4, of the sample, shown as SP01 in FIG. 4, are equal to the focal point positions shown by Z001, Z002 and Z003 in FIG. 3, respectively.
    </p>
    <p num="17">
      If the cross sectional image of the sample, as shown by SP01 in FIG. 4, in the relative positions described above, is photographed with detector 5, the cross sectional image shown as P001 in FIG. 4, for example, is obtained.
      <br/>
      In the cross sectional image, shown as P001 in FIG. 4, the positions of the planes indicated by ST01, ST02, and ST03 in FIG. 4, are equal in focal point positions, shown by Z001, Z002 and Z003, in FIG. 3.
      <br/>
      Thus, in the cross sectional images described above, the light intensity at the portions of the planes, shown as STO1, ST02, and ST03 in FIG. 4, is represented by L001, L002, and L003, of FIG. 3.
    </p>
    <p num="18">
      In this case, controller 6 analyzes the light intensity of the cross sectional image obtained by detector 5, based on the stored characteristic of the focal point position light intensity.
      <br/>
      If the light intensity if L001, the focal point position is determined to be Z001.
      <br/>
      On the other hand, if the light intensity is determined to be L002 or L003, the focal point position is determined to be Z002 or Z003, respectively.
      <br/>
      Controller 6 also reconstructs the three dimensional shape of the sample based on the foregoing positional information and displays or applies other operations to the sample images.
    </p>
    <p num="19">As a result, focal point positions of the sample can be obtained without scanning the sample in the direction of the optical axis and the three dimensional shape of the sample can be readily determined, based on the focal point positions, by analyzing the light intensity at the cross sectional images obtained with detector 5, based on the focal point position light intensity characteristic, using the controller 6 to achieve the foregoing steps.</p>
    <p num="20">
      However, the shape of the actual samples is not the preferable shape, as shown by SP01 in FIG. 4, but may have slopes, and the like, and the reflectivity of the samples in not usually 100%, but varies depending on the positions, in many cases.
      <br/>
      Operations in such a case will be described with reference to FIGS. 5 and 6.
    </p>
    <p num="21">
      FIG. 5 shows a characteristic curve of the relationship between light intensity and focal point position obtained with detector 5, when a mirror is scanned in the direction of the optical axis in place of the sample.
      <br/>
      FIG. 6 shows the relationship between the characteristic curve of FIG. 5 and the sample.
    </p>
    <p num="22">
      Two types of focal point position light intensity characteristics obtained for two focal point positions, shown as FP02 and FP03 in FIG. 5, are measured in advance and stored in controller 6.
      <br/>
      For example, assume that, if a focal point position is FP02, the light intensity is represented by L101, L102, L103 and L104 in the focal point positions Z101, Z102, Z103 and Z104, respectively.
      <br/>
      Also, assume that, if the focal point position is FP03, the light intensity would be represented by L201, L202, L203 and L204 in the focal point positions of Z101, Z102, Z103, and Z104, respectively.
    </p>
    <p num="23">A cross sectional image is obtained at the focal point position FP02, and another cross sectional image is obtained at the focal point position FP03 by detector 5, and the respective images are inputted to controller 6, for processing.</p>
    <p num="24">
      For example, assume that sample 8 has a shape, such as shown by SP02 and the apex of the sample is as shown by ST11 in FIGS. 6(A) and 6(B), and is located in the focal point position of Z101.
      <br/>
      Then, the light intensity at the cross sectional images for the focal point positions of FP02 and FP03 should be represented by L101 and L201, respectively, provided that the reflectivity of the sample, shown by SP02 in FIG. 6(A), is 100%.
      <br/>
      However, since reflectivity is actually low, the characteristics of the focal point light intensity provide the curves shown by the broken lines in FIG. 6(A).
      <br/>
      Thus, even if the focal point position is Z101, as shown by the enlarged drawing in FIG. 6(B), the light intensity at the cross sectional images for the focal point positions of FP02 and FP03 is decreased to L301 and L302, respectively.
    </p>
    <p num="25">
      The focal point position light intensity characteristic for the reflectivity of 100% is stored in controller 6.
      <br/>
      Thus, the focal point positions for the light intensity of L301 and L302 are erroneously determined to be Z301 and Z302, respectively, as different positions from the actual focal point positions, as seen in the enlarged drawing in FIG. 6(B).
    </p>
    <p num="26">
      However, both errors are changes in the opposite direction to each other.
      <br/>
      If it is assumed that the absolute values of the slopes of both broken lines in the enlarged drawing in FIG. 6(B) are equal, the error " DELTA Z" mutually becomes equal and the following equations hold:
      <br/>
      Z301=Z101+ DELTA Z  (1)
      <br/>
      Z302=Z101- DELTA Z  (2)
    </p>
    <p num="27">Accordingly, by adding equation (1) to equation (2) and dividing the result by 2, expression (3) is obtained:  (Equation image '1' not included in text)</p>
    <p num="28">Thus, the error component can be corrected.</p>
    <p num="29">
      Since the focal point position light intensity characteristic is generally a nonlinear function, it cannot be corrected simply as shown by expression (3).
      <br/>
      However, correction can be implemented through computing and processing by providing a correction table or by setting an approximation expression in the controller 6.
      <br/>
      That is, three dimensional shapes can be obtained even for samples that have slopes and other shapes and the reflectivity thereof varies depending on the positions thereof.
    </p>
    <p num="30">
      Accordingly, the focal point positions of the sample can be obtained without scanning in the direction of the optical axis even if the sample has an ordinary shape.
      <br/>
      The foregoing process is performed by analyzing light intensity for two types of cross sectional images in different focal point positions acquired by detector 5 based on two types of focal point position light intensity characteristics for different focal point positions in controller 6.
      <br/>
      Three dimensional shapes can also be obtained based on the focal point positions.
    </p>
    <p num="31">
      In addition, the thickness of sample 8 can be measured up to approximately full width at half maximum of the focal point position light intensity characteristic curve, as shown in FIG. 3.
      <br/>
      For example, let the magnification of objective lens 7 be one-fold, the diameter of the apertures in confocal scanner 2 be 50  MU m, then the full width at half maximum described above is calculated to be about 1 mm.
    </p>
    <p num="32">If an image is a dynamic image, such as a gear, or the like, moving in the optical direction, the position of the gear, or like, can be obtained based on a predetermined focal point position light intensity characteristic because the light intensity varies with the focal point position.</p>
    <p num="33">
      In order to obtain two cross sectional imaged which are different in focal point position, the focal point position may be changed by moving a lens or the stage of the optical microscope 3.
      <br/>
      The configuration, as shown in FIG. 7 may be used.
    </p>
    <p num="34">
      In FIG. 7, the system comprises laser light sources 1a, 1b; confocal scanners 2a, 2b; a beam splitter 9; and objective lens 10; and a sample 11.
      <br/>
      In addition, beam splitter 9 and objective lens 10 comprise a part of optical microscope 3, while detector 5 and controller 6 are omitted hereat for simplicity of description.
    </p>
    <p num="35">By combining the output light beams from two confocal scanners 2a and 2b, that have different focal point positions, through beam splitter 9 and by making the polarizing directions, the measuring wavelengths, or the measuring times different from each other, two cross sectional images for different focal point positions can be obtained using each detector, not shown.</p>
    <p num="36">
      For example, if a polarizing beam splitter is used as beam splitter 9, and the polarizing direction of confocal scanners 2a, 2b is selected to be "0 degree" and "90 degree" respectively, the light beams having the polarizing directions of "0 degree" and "90 degree" of the return or reflected beam from sample 11, are made to be incident on confocal scanners 2a and 2b.
      <br/>
      Thus, two cross sectional images for different focal point positions are obtained by each detector, not shown.
    </p>
    <p num="37">
      Also, for example, if a dichroic mirror is used as a beam splitter 9 and the wavelengths of the output light beams from the confocal scanners 2a and 2b are made different from each other, two cross sectional images having different focal point positions can be obtained similar to the foregoing description.
      <br/>
      In this case, the different focal point positions of FP02 and FP03 can also be realized by utilizing the chromatic aberrations of the objective lens.
    </p>
    <p num="38">Moreover, for example, if the measuring time is shifted in such a manner as , after obtaining a cross sectional image using confocal scanner 2a, measuring another cross sectional image using confocal scanner 2b, two cross sectional images having different focal point positions can be obtained.</p>
    <p num="39">Also, in FIG. 7, although two laser light sources 1a and 1b are shown, the output light beam from one laser light source can be divided into two branches to supply the two beams to confocal scanners 2a, and 2b.</p>
    <p num="40">
      In addition, in FIGS. 5 and 6, the three dimensional shape is obtained by determining two types of focal point position light intensity characteristic for different focal point positions, and by measuring two cross sectional images having different focal point positions.
      <br/>
      However, three or more cross sectional images can also be used to obtain more accurate three dimensional shapes.
    </p>
    <p num="41">
      Furthermore, the confocal scanner can be of the scan type confocal scanner that rotates a disk having a plurality of apertures therein and outputs the incident laser light beam after passing the beam through the apertures.
      <br/>
      However, the scanner can also be of the X-Y direction scan-less type confocal scanner, such as disclosed in Japanese Patent Application SN Hei09-009991 (1997) and Hei09-125481 (1997).
      <br/>
      In other words, the scanning method used in the invention wherein scanning is in planes perpendicular to the direction of the optical axis is not limited to that disclosed and other methods and apparatus can be used.
    </p>
    <p num="42">Focal point positions of a sample can be obtained without scanning in the direction of the optical axis by taking a configuration, as mentioned in the invention, and by analyzing the light intensity at the cross sectional image obtained by the detector based on the focal point position light intensity characteristic, using a controller.</p>
    <p num="43">Moreover, focal point positions of a sample having even an ordinary shape can also be obtained without scanning in the direction of the optical axis by analyzing with the controller the light intensity at two types of cross sectional images in different focal point positions obtained by the detector based on two types of focal point position light intensity characteristic for different focal point positions.</p>
    <p num="44">The foregoing two types of cross sectional images in different focal point positions can be obtained by changing the focal point positions by moving the stage or the lens of the optical microscope.</p>
    <p num="45">The two types of cross sectional images in different focal point positions can also be obtained by combining the output light beams from two confocal scanners having different focal point positions with a beam splitter and by making the polarizing directions of the output light beams from the two confocal scanners different from each other.</p>
    <p num="46">The two types of cross sectional images in different focal point positions can also be obtained by combining the output light beams from two confocal scanners having different focal point positions with a beam splitter and by making the measured wavelengths of the output light beams from the two confocal scanners different from each other.</p>
    <p num="47">The two types of cross sectional images in different focal point positions can also be obtained by combining the output light beams from two confocal scanners having different focal point positions with a beam splitter and by making the measuring time of the output light beams from the two confocal scanners different from each other.</p>
    <p num="48">In addition, the three dimensional shape of the sample can be obtained without scanning in the optical axis direction by determining the three dimensional shape of the sample based on the focal point positions of the sample obtained by teh controller.</p>
    <p num="49">Furthermore, he scanning mehtod for the planes perpendicular to the optical axis direction becomes unlimited by using a scanning type or an X-Y direction scan-less type of confocal scanner.</p>
    <p num="50">
      The foregoing description is illustrative of the principles of the invention.
      <br/>
      Numerous modifications and extensions thereof would be apparent to the worker skilled in the art.
      <br/>
      All such modifications and extensions are to be considered to be within the spirit and scope of the invention.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>In a confocal system comprising:</claim-text>
      <claim-text>a laser light source; a confocal scanner having a plurality of apertures through which output light beam from said laser light source is passed; an optical microscope to focus output light beam through said apertures onto a sample; detector means for obtaining a cross sectional image of said sample by photographing light beams reflected by said sample;</claim-text>
      <claim-text>and controller means for determining focal positions of said sample using light intensity at said cross sectional image based on a focal position light intensity characteristic, the improvement comprising: said controller means comprises:</claim-text>
      <claim-text>- means for storing at least one characteristic curve representing light intensity characteristic points as measured against focal position points of the surface of said sample; - means for receiving signals from said detector means representing the light intensity characteristic of said surface of said sample;</claim-text>
      <claim-text>and - means for processing the signal from the detector means in terms of the stored characteristic curve to determine the cross sectional image of the sample;</claim-text>
      <claim-text>whereby the shape of the sample is measured without necessity of moving the focus along the focus direction of measurement.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The system of claim 1, wherein said controller means determines focal positions of said sample using light intensity at two cross sectional images for different focal point positions obtained by said detector means.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The system of claim 2, wherein said two cross sectional images are obtained by moving a stage or a lens of said optical microscope.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The system of claim 2, wherein said two types of cross sectional images are obtained by combining output light beams passed through two confocal scanners with a beam splitter and concurrently producing different polarizing directions of the output light beams passed through said two confocal scanners.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The system of claim 2, wherein said two types of cross sectional images are obtained by combining output light beams passed through two confocal scanners with a beam splitter and concurrently producing different measured wavelengths of the output light beams passed through the two confocal scanners.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The system of claim 2, wherein said two types of cross sectional images are obtained by combining output light beams passed through two confocal scanners in one set or two sets with a beam splitter and concurrently changing measuring time of the output light beams passed through said two confocal scanners to be different from each other.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. The system of claim 2, wherein said controller means comprises means for determining three dimensional shape of said sample based on focal point positions as stored by said controller means.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The system of claim 1, wherein said controller means comprises means for determining three dimensional shape of said sample based on focal point positions of said sample.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. The system of claim 1, wherein said confocal scanner is a scanning type or X-Y direction scan-less type confocal scanner.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. A measuring method using a confocal system comprising: a laser light source; a confocal scanner having a plurality of apertures through which output light beam from said laser light source is passed; an optical microscope to focus output light beam through said apertures onto a sample; detector means for obtaining a cross sectional image of said sample by photographing light beams reflected by said sample;</claim-text>
      <claim-text>and controller means for determining focal positions of said sample using light intensity at said cross sectional image based on a focal position light intensity characteristic, said method comprising the steps of: - storing at least one characteristic curve representing light intensity characteristic points as measured against focal position points of the surface of said sample; - receiving signals from said detector means representing the light intensity characteristic of said surface of said sample;</claim-text>
      <claim-text>and - processing the signal from the detector means in terms of the stored characteristic curve to determine the cross sectional image of the sample;</claim-text>
      <claim-text>whereby the shape of the sample is measured without necessity of moving the focus along the focus direction of measurement.</claim-text>
    </claim>
  </claims>
</questel-patent-document>