<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06181813B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06181813</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6181813</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="25474787" extended-family-id="2565835">
      <document-id>
        <country>US</country>
        <doc-number>08940413</doc-number>
        <kind>A</kind>
        <date>19970929</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1997US-08940413</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>2669775</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>94041397</doc-number>
        <kind>A</kind>
        <date>19970929</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1997US-08940413</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G07D   7/00        20060101AFI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>07</class>
        <subclass>D</subclass>
        <main-group>7</main-group>
        <subgroup>00</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G06K   9/32        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>9</main-group>
        <subgroup>32</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>G06K   9/42        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>9</main-group>
        <subgroup>42</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>G07D   7/06        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>07</class>
        <subclass>D</subclass>
        <main-group>7</main-group>
        <subgroup>06</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="5">
        <text>G07D   7/20        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>07</class>
        <subclass>D</subclass>
        <main-group>7</main-group>
        <subgroup>20</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>382135000</text>
        <class>382</class>
        <subclass>135000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>382199000</text>
        <class>382</class>
        <subclass>199000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>382219000</text>
        <class>382</class>
        <subclass>219000</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>382289000</text>
        <class>382</class>
        <subclass>289000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G06K-009/32P</text>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>009</main-group>
        <subgroup>32P</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>G06K-009/42</text>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>9</main-group>
        <subgroup>42</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06K-009/3216</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>9</main-group>
        <subgroup>3216</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06K-009/42</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>9</main-group>
        <subgroup>42</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>10</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>2</number-of-drawing-sheets>
      <number-of-figures>4</number-of-figures>
      <image-key data-format="questel">US6181813</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Method for counterfeit currency detection using orthogonal line comparison</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>BOULIA DOROTHY I, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4594674</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4594674</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>CHEFALAS THOMAS E, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5287415</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5287415</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>MATSUBAYASHI KATSUYOSHI</text>
          <document-id>
            <country>US</country>
            <doc-number>5363949</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5363949</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>STOREY BRIAN E</text>
          <document-id>
            <country>US</country>
            <doc-number>5530772</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5530772</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>FAN ZHIGANG</text>
          <document-id>
            <country>US</country>
            <doc-number>5533144</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5533144</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>TAKARAGI YOICHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5731880</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5731880</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>OKUBO HIROMI</text>
          <document-id>
            <country>US</country>
            <doc-number>5781653</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5781653</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>KATOH MITSUTAKA, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5845008</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5845008</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="9">
          <text>POTU BRAHMAJI</text>
          <document-id>
            <country>US</country>
            <doc-number>5859651</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5859651</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="10">
          <text>GRAVES BRADFORD T, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5867589</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5867589</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="11">
          <text>LEE ROBERT ARTHUR</text>
          <document-id>
            <country>US</country>
            <doc-number>5909313</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5909313</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="12">
          <text>SONODA SHINYA, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>6014453</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US6014453</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="13">
          <text>FAN ZHIGANG</text>
          <document-id>
            <country>US</country>
            <doc-number>6026186</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US6026186</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="14">
          <text>YASUDA MICHIO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4153897</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4153897</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="15">
          <text>AHLBOM STEN HUGO NILS, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4922543</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4922543</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="16">
          <text>SUZUKI YOSHIYUKI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5216724</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5216724</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="17">
          <text>HORN BERTHOLD K P, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5220398</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5220398</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="18">
          <text>MOOREHEAD ROBERT M, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5253765</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5253765</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="19">
          <text>HECKMAN DEAN A, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5291243</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5291243</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="20">
          <text>OHTA EIJI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5430525</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5430525</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="21">
          <text>TANAKA TOSHINORI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5437897</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5437897</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="22">
          <text>KELLY NANCY R, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5528387</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5528387</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="23">
          <text>SAITO RIE, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5557412</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5557412</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="24">
          <text>TACHIKAWA MICHIYOSHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5652803</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5652803</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="25">
          <text>TACHIKAWA MICHIYOSHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5659628</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5659628</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="26">
          <text>MIYAZA MASAO</text>
          <document-id>
            <country>US</country>
            <doc-number>5678155</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5678155</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="27">
          <text>KUBOKI KEIJU, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5790165</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5790165</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="1">
          <text>An article by A. Rosefield and A.C. Kak entitled "Digial Picture Processing", Academic Press, Inc.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="2">
          <text>"Invariant Fitting of Planar Objects by Primitives," published in 1996 IEEE Proceedings of ICPR '96, pp. 508-512 Voss et al.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="3">
          <text>"Managing and Representing Image Workflow in Prepress Applications," Technical Association of the Graphic Arts (TAGA) vol. 1, 1995 Proceedings, pp. 737-785, Venable et al.</text>
        </nplcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Xerox Corporation</orgname>
            <address>
              <address-1>Stamford, CT, US</address-1>
              <city>Stamford</city>
              <state>CT</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>XEROX</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Fan, Zhigang</name>
            <address>
              <address-1>Webster, NY, US</address-1>
              <city>Webster</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Wu, John W.</name>
            <address>
              <address-1>Rancho Palos Verdes, CA, US</address-1>
              <city>Rancho Palos Verdes</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="3">
          <addressbook lang="en">
            <name>Micco, Felice A.</name>
            <address>
              <address-1>Grand Island, NY, US</address-1>
              <city>Grand Island</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="4">
          <addressbook lang="en">
            <name>Chen, Mike C.</name>
            <address>
              <address-1>Cerritos, CA, US</address-1>
              <city>Cerritos</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="5">
          <addressbook lang="en">
            <name>Phong, Kien A.</name>
            <address>
              <address-1>Anaheim, CA, US</address-1>
              <city>Anaheim</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Bella, Matthew C.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      An anti-counterfeit currency detection method is disclosed wherein local edge information is utilized for accurately detecting lines and curves of legitimate notes.
      <br/>
      The method can more accurately determine the location and orientation of a pattern and thus provides more reliable currency detection.
      <br/>
      A detector is trained off-line with example notes resulting in a stored template generated by recording a test pattern similar to a pattern to be tested; anchor lines are identified within said template which are further represented in subsequent test patterns.
      <br/>
      The template is rotated and shifted before matching it to the test pattern so that anchor lines align with long lines detected within the test pattern.
      <br/>
      The template and test pattern are then compared to determine whether there is a match.
      <br/>
      The system comprises a microprocessor is programmed to facilitate the training of a detector off-line with example notes which are scanned into said system wherein a template is generated by recording an image pattern of said example notes similar to a test pattern to be detected.
      <br/>
      The microprocessor identifies anchor lines within the template which are further represented in said test pattern; rotates and shifts the template before matching it to the test pattern so that anchor lines align with lines which may be detected within said test pattern; and compares the template to the test pattern to determine whether said anchor lines exist within said test pattern.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>FIELD OF THE INVENTION</heading>
    <p num="1">This invention is generally related to microprocessor based image recognition techniques and, more particularly, to an anti-counterfeit currency detection method using line detection within images.</p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="2">
      The ability to detect currency patterns in an image can be useful in copier machines or scanners for the purpose of preventing counterfeiting.
      <br/>
      The challenge of incorporating such a method in current copier or scanning technology is the difficulty with detecting images in a rotation or shift invariant manner.
      <br/>
      Specifically, the pattern could be of any orientation and at any location of the image.
      <br/>
      The orientation and the location of the currency or banknote can be relatively simple to estimate in the case of a single note with a plain background; however, it becomes a major obstacle if multiple notes are involved and/or the notes are embedded in some complicated image background.
    </p>
    <p num="3">Examples of skew angle identification and correction are can be found in the following patents:</p>
    <p num="4">
      U.S. Pat. No. 5,528,387 to Kelly et al., issued Jun. 18, 1996, which teaches electronic image registration in a scanner.
      <br/>
      In particular, the edge data of a document is detected and skew angle calculated.
      <br/>
      The image is then rotated based upon the skew angle and non-image areas are filled using an image generation feature.
    </p>
    <p num="5">
      U.S. Pat. No. 4,922,350 to Rombola et al., issued May 1, 1990, discloses a two-pass scanning apparatus for detecting the size and position of an original document on a scanner platen.
      <br/>
      Image signals captured on a first scan are employed to determine boundaries and a best-fit magnification so that the image may be fir to a recording sheet using image signals generated on a subsequent scanning pass.
    </p>
    <p num="6">
      U.S. Pat. No. 5,253,765 to Moorehead et al, issued Oct. 19, 1003, teaches a system for sorting randomly sized objects (e.g. mushrooms).
      <br/>
      Invariant moments are employed, utilizing the complete pixel information for all pixels within the border of a captured image, to extract information about the mushroom size and orientation.
    </p>
    <p num="7">U.S. Pat. No. 5,220,398 to Horn et al. teaches an analog VLSI microchip that uses moments to determine the position and orientation of an object in a scene.</p>
    <p num="8">
      In "Invariant Fitting of Planar Objects by Primitives," published in 1996 IEEE Proceedings of ICPR '96, pp. 508-512 Voss et al, teach a method of pattern recognition using primitives such as triangles, rectangles, circles, ellipses, superquadratics, etc.
      <br/>
      The author further describe a technique for describing the primitives using moments in a normalized manner; resulting in a decrease in the numerical effort.
    </p>
    <p num="9">In "Managing and Representing Image Workflow in Prepress Applications," Technical Association of the Graphic Arts (TAGA) Vol. 1, 1995 Proceedings, pp. 373-385, Venable et al. teach the use of structured images to manage prepress workflow.</p>
    <p num="10">
      Prior countefeit detection methods rely on point detection during recognition.
      <br/>
      As disclosed in U.S. Pat. No. 5,533,144 to Fan, entitled "Anti-counterfeit Pattern Detector and Method", an anti-counterfeit detector and method identifies whether a platen image portion to be photocopied contains one or several banknote patterns.
      <br/>
      With the '144 method, the detection is performed in a rotation and shift invariant manner.
      <br/>
      Specifically, the pattern can be of any orientation and at any location of the image, and can be embedded in any complicated image background.
      <br/>
      The image to be tested is processed block by block.
      <br/>
      Each block is examined to see if it contains an "anchor point" by applying an edge detection and orientation estimation procedure.
      <br/>
      For a potential anchor point, a matching procedure is then performed against stored templates to decide whether the preselected monetary note patterns are valid once detected.
    </p>
    <p num="11">Other anti-counterfeiting or pattern detection methods are presented by the following patents:</p>
    <p num="12">U.S. Pat. No. 4,153,897</p>
    <p num="13">Yasuda, et. al.</p>
    <p num="14">Issued May 8, 1979</p>
    <p num="15">U.S. Pat. No. 5,216,724</p>
    <p num="16">Suzuki, et. al.</p>
    <p num="17">Issued Jun. 1, 1993</p>
    <p num="18">U.S. Pat. No. 5,291,243</p>
    <p num="19">Heckman, et. al.</p>
    <p num="20">Issued Mar. 1, 1994</p>
    <p num="21">
      Yasuda et al. discloses a pattern recognition system where similarities between unknown and standard patterns are identified.
      <br/>
      Similarities are detected at first in respective shifting conditions where the unknown and standard patterns are relatively shifted from each other over the first limited extent, including the condition without shift.
      <br/>
      The maximum value of these similarities is then detected.
      <br/>
      The similarities are further detected in respective shifting conditions where the unknown and standard patterns are relatively shifted from each other over the second extent larger than the first limited extent, when the shifting condition which gave the maximum value is that without relative shift.
    </p>
    <p num="22">
      Suzuki et al. discloses an apparatus for image reading or processing that can precisely identify a particular pattern, such as banknotes or securities.
      <br/>
      A detecting unit detects positional information of an original image and a discriminating unit extracts pattern data from a certain part of the original image to discriminate whether the original image is the predetermined image based on the similarity between the pattern data and the predetermined pattern.
    </p>
    <p num="23">Heckman et al. discloses a system for printing security documents which have copy detection or tamper resistance in plural colors with a single pass electronic printer. a validating signature has two intermixed color halftone patterns with halftone density gradients varying across the signature in opposite directions, but different from the background.</p>
    <p num="24">
      A fundamental problem in electronic image pattern recognition is with line detection, or more generally, curve detection.
      <br/>
      In a pre-scan image lines might be detected to decide where the edges of a paper document are.
      <br/>
      Within a document text lines may be used to estimate the skew angle of the document.
      <br/>
      Also, line and other simple curve detection often serves as the first step for complex object detection, as the contour of a complex object can always be decomposed into simple curves.
    </p>
    <p num="25">
      Line detection can be done by many standard methods such as that described by A. Rosefield and A. C. Kak in an article entitled "Digital Picture Processing", Academic Press, Inc.
      <br/>
      In particular, it can be done by Hough Transform, which is probably the most important and most widely-used line detection algorithm.
    </p>
    <p num="26">
      This disclosure employs line detection to determine the location and orientation of the currency pattern in a manner that has advantages over prior detection methods.
      <br/>
      The proposed method is more accurate and requires less computation
    </p>
    <p num="27">All of the references cited herein are incorporated by reference for their teachings.</p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="28">
      In order to improve the speed and accuracy as discussed above, an electronic image detection method wherein line information is utilized to determine the location and orientation of the currency presented.
      <br/>
      The anti-counterfeit currency detection method disclosed utilizes line, rather than point, information for detection of counterfeit notes or currency.
      <br/>
      The use of "Anchor lines" instead of "anchor points" (as disclosed in '144 to Fan) in currency image detection methods are proposed.
    </p>
    <p num="29">
      A detect or is trained off-line with example notes resulting in a template generated by recording a test pattern similar to a pattern to be tested; anchor lines are identified within the template.
      <br/>
      The lines are detected during the testing; the template is rotated and shifted before matching the template to the test pattern so that the anchor lines align with long lines detected within the test pattern; and the template and the test pattern are compared to determine whether there is a match.
    </p>
    <p num="30">
      The method can be carried out in a system comprising having a microprocessor programmed to carry out the above steps of the method.
      <br/>
      The system's microprocessor facilitates the training of a detector off-line with example notes which are scanned into said system wherein a template is generated by recording an image pattern of the example notes similar to a test pattern to be detected; identifies anchor lines within the template.
      <br/>
      The lines are detected during the testing; rotates and shifts the template before matching the template to the test pattern so that the anchor lines align with long lines which may be detected within the test pattern; and compares the template to the test pattern to determine whether the anchor lines exist within the test pattern.
    </p>
    <p num="31">Other advantages and salient features of the invention will become apparent from the detailed description which, taken in conjunction with the drawings, disclose the preferred embodiments of the invention.</p>
    <heading>DESCRIPTION OF THE DRAWINGS</heading>
    <p num="32">
      The preferred embodiments and other aspects of the invention will become apparent from the following detailed description of the invention when read in conjunction with the accompanying drawings which are provided for the purpose of describing embodiments of the invention and not for limiting same, in which:
      <br/>
      FIG. 1A illustrates a sample template having anchor lines (dashed) which intersect in this sample--forming an "L" shape;
      <br/>
      FIG. 1B illustrates anchor lines which may be found in a test image;
      <br/>
      FIG. 1C illustrates detection of a legitimate currency after the template (FIG. 1A) is matched with the anchor lines within the image (FIG. 1B); and
      <br/>
      FIG. 2 is a block diagram of the system of the invention.
    </p>
    <heading>DETAILED DESCRIPTION OF THE INVENTION</heading>
    <p num="33">
      In order to detect whether a copier is used for counterfeiting, a detector incorporated within the scanning system of the copier is first trained off-line with example notes.
      <br/>
      A template is created by recording the image pattern of the currency notes or targeted image (test image) to be detected.
    </p>
    <p num="34">
      The training includes generating the templates and selecting one or several pairs of anchor lines.
      <br/>
      The anchor lines are straight, desirably long lines.
      <br/>
      They can be either straight lines within the currency pattern, or the currency edges.
      <br/>
      Each pair contains two lines which are orthogonal to each other in direction. a detector is trained off-line with currency images resulting in a template generated by recording a pattern similar to a test pattern to be sampled; anchor lines are identified within said template
    </p>
    <p num="35">
      In detection, a Hough Transform, or any other standard methods, can be first performed to detect long straight lines.
      <br/>
      The long lines detected are then grouped into pairs, each of which contains two long lines that are in orthogonal directions.
      <br/>
      Under the assumption that the detected long line pairs are the anchor line pairs, the test pattern is matched to the templates.
      <br/>
      FIG. 1A illustrates a sample template.
      <br/>
      Specifically, the template is first rotated and shifted before matching so that the anchor lines align with the detected long lines to be authenticated.
      <br/>
      This is best illustrated in FIG. 1B where the anchor lines which are similar to the template are shown in the upper part of the Figure.
      <br/>
      A legitimate currency pattern is declared to be detected after the template (FIG. 1A) is matched with the anchor lines within the image (FIG. 1B), as shown in FIG. 1C, wherein the template (FIG. 1A), after any necessary rotation and shifting, is overlaid on top of the test pattern anchor lines of FIG. 1B. The test result may then be determined as positive.
    </p>
    <p num="36">
      Since there are less "long lines" in an image than blocks containing points or edges, the number of pattern matching routines required for match determination is less in the proposed method than that in '144 to Fan.
      <br/>
      Also, as the long lines contain more information about the line direction than the short edges, orientation estimation is much more accurate.
      <br/>
      As a result, the reliability of pattern matching is also improved.
    </p>
    <p num="37">
      Referring to FIG. 2, system hardware necessary for the anti-counterfeit detection system 5 would include a scanner 1 for receiving the test image, a microprocessor 2 programmed to detect counterfeit currency by detecting lines in scanned documents, memory 3 for storing test patterns, and an indicator means 4 to indicate counterfeit detection and may further prevent duplication of test patterns which may occur in a larger system (not shown) such as a copier or through a computer.
      <br/>
      The indicator means 4 would provide an output signal to the larger system indicating the status of the tested image.
      <br/>
      The anti-counterfeit detection system would facilitate the training of the microprocessor 2 (also referred to as "detector") off-line with notes or currency, which are scanned 1 into said system wherein a template is generated by recording 3 an image pattern of said example notes similar to a test pattern to be detected.
      <br/>
      Anchor lines within the template, which are further represented in said test pattern, would be identified by the microprocessor 2.
      <br/>
      The microprocessor system would perform line detection during testing.
      <br/>
      It will allow for the rotation and shifting of the template before matching it to the test pattern so that anchor lines may align with long lines which may be detected within the test pattern.
      <br/>
      The system 2 would then compare the template, held in memory 3, to the test pattern that is scanned 1 or viewed by an image capturing means to determine whether the anchor lines exist within the test pattern.
    </p>
    <p num="38">
      While the invention is described with reference to a particular embodiment, this particular embodiment is intended to be illustrative, not limiting.
      <br/>
      Various modifications may be made without departing from the spirit and scope of the invention as defined in the amended claims.
      <br/>
      Modifications and alterations will occur to others upon reading and understanding this specification; therefore, it is intended that all such modifications and alterations are included insofar as they come within the scope of the appended claims or equivalents thereof.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A counterfeit currency detection method using line detection information for determining location and orientation of a predetermined image pattern for matching against a test pattern to be authenticated, comprising the steps of:</claim-text>
      <claim-text>training a detector off-line with at least one example currency note wherein at least one template is generated thereby; identifying at least 1 pair of anchor lines within said generated template wherein each pair of anchor lines contain at least 2 orthogonal lines, said identifying step using edge detection and algorithmic transforms; rotating and shifting said template so that said anchor lines align with lines detected within said test pattern;</claim-text>
      <claim-text>and comparing said template to said test pattern to determine whether said anchor lines exist within said test pattern.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The method of claim 1 wherein said anchor lines may comprise straight lines representing edges within said test pattern.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. A counterfeit detection system comprising a microprocessor programmed to: facilitate the training of a detector off-line with authentic currency documents which are scanned into said system wherein a plurality of templates are generated by recording an image pattern within said authentic currency documents resulting in at least one template wherein said at least one template is stored in a memory; identify at least 1 pair of anchor lines within said at least one template wherein each pair of anchor lines contain at least 2 orthogonal lines, said identifying step using edge detection and algorithmic transforms; rotate and shift said at least one template during counterfeit detection operations wherein matching of said at least one template to a scanned test pattern is facilitated so that said anchor lines align with similar lines which may be detected within said test pattern, thereby resulting in alignment;</claim-text>
      <claim-text>and comparing said at least one template to said test pattern to determine whether said anchor lines exist within said test pattern.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The invention of claim 3 further comprising a memory for storing said templates.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The invention of claim 3 further comprising a scanner for scanning images into said system.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The invention of claim 3 further comprising a indicator means for indicating whether said test pattern is counterfeit based on said comparing.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. The invention of claim 6 wherein said indicator means provides input to a controller that prevents photocopying or storage of said test pattern.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The invention of claim 4 further comprising a scanner for scanning images into said system.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. The invention of claim 8 further comprising a indicator means for indicating whether said test pattern is counterfeit based on said comparing.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. The invention of claim 9 wherein said indicator means provides input to a controller that prevents photocopying or storage of said test pattern.</claim-text>
    </claim>
  </claims>
</questel-patent-document>