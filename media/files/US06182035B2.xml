<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06182035B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06182035</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6182035</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="21953847" extended-family-id="74944384">
      <document-id>
        <country>US</country>
        <doc-number>09048307</doc-number>
        <kind>A</kind>
        <date>19980326</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1998US-09048307</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>43165332</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>4830798</doc-number>
        <kind>A</kind>
        <date>19980326</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1998US-09048307</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G10L  19/02        20130101A N20140531RMEP</text>
        <ipc-version-indicator>
          <date>20130101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>19</main-group>
        <subgroup>02</subgroup>
        <classification-value>N</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20140531</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G10L  25/78        20130101A I20140531RMEP</text>
        <ipc-version-indicator>
          <date>20130101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>25</main-group>
        <subgroup>78</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20140531</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>704236000</text>
        <class>704</class>
        <subclass>236000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>704230000</text>
        <class>704</class>
        <subclass>230000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>704240000</text>
        <class>704</class>
        <subclass>240000</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>704248000</text>
        <class>704</class>
        <subclass>248000</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>704E11003</text>
        <class>704</class>
        <subclass>E11003</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G10L-025/78</text>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>25</main-group>
        <subgroup>78</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G10L-025/78</classification-symbol>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>25</main-group>
        <subgroup>78</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G10L-019/0216</classification-symbol>
        <section>G</section>
        <class>10</class>
        <subclass>L</subclass>
        <main-group>19</main-group>
        <subgroup>0216</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>S10L-019/02T2</classification-symbol>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>26</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>7</number-of-drawing-sheets>
      <number-of-figures>9</number-of-figures>
      <image-key data-format="questel">US6182035</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Method and apparatus for detecting voice activity</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>TSIANG ELAINE Y L</text>
          <document-id>
            <country>US</country>
            <doc-number>5377302</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5377302</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>NGUYEN TRUONG Q</text>
          <document-id>
            <country>US</country>
            <doc-number>5436940</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5436940</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>KOVACEVIC JELENA</text>
          <document-id>
            <country>US</country>
            <doc-number>5490233</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5490233</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>GULLI CHRISTIAN</text>
          <document-id>
            <country>US</country>
            <doc-number>5826232</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5826232</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>BYRNES JAMES S, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5913186</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5913186</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>AMERICAN TELEPHONE &amp; TELEGRAPH</text>
          <document-id>
            <country>EP</country>
            <doc-number>0167364</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-167364</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>NEC CORP</text>
          <document-id>
            <country>EP</country>
            <doc-number>0599664</doc-number>
            <kind>A2</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-599664</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>AT &amp; T CORP</text>
          <document-id>
            <country>EP</country>
            <doc-number>0665530</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-665530</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="9">
          <text>MOTOROLA INC</text>
          <document-id>
            <country>GB</country>
            <doc-number>2256351</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>GB2256351</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="10">
          <text>FREEMAN DANIEL K, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5276765</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5276765</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>GUPTA PRABHAT K, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5459814</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5459814</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="12">
          <text>CHOW YEN-LU, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5596680</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5596680</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="13">
          <text>BRITISH TELECOMM, et al</text>
          <document-id>
            <country>WO</country>
            <doc-number>9508170</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>WO9508170</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="14">
          <text>NOKIA MOBILE PHONES LTD, et al</text>
          <document-id>
            <country>WO</country>
            <doc-number>9722117</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>WO9722117</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="1">
          <text>stegman et al., ("Robust voice activity detection based on the wavelet transform", Proceedings IEEE Workshop on Speech coding for telecommunications, 7-10, Sep. 1997, pp. 99-100).</text>
        </nplcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="2">
          <text>Evangelista et al., ("Discrete-time Wavelet transforms and their generalizations", IEEE International Symposium Circuits and Systems, 1990., vol. 3, May 1-3, 1990, pp. 2026-2029).</text>
        </nplcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="3">
          <text>S.C.Chan., ("A family of arbitrary length modulated orthonormal wavelets", IEEE International Symposium on Circuits and Systems, vol. 1, May 3-6, 1993, pp. 515-518).</text>
        </nplcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="4">
          <text>Gopinath et al., ("Wavelet Transforms and Filter Banks", Wavelets-A Tutorial in theory and Application, C.K. Chui ed., pp. 603-654, Academic Press, inc., Jan. 1992.</text>
        </nplcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="5">
          <text>J. Stegmann, et al., "Robust Voice-Activity Detection Based on the Wavelet Transform," Proceedings IEEE Workshop on Speech Coding for Telecommunications. Back to Basics: Attacking Fundamental Problems in Speech Coding, Sep. 7-10 1997, pp. 99-100.</text>
        </nplcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="6">
          <text>J. D. Hoyt, et al., "Detection of Human Speech Using Hybrid Recognition Models," Proceedings of the IAPR International Conference on Pattern Recognition (ICPR), vol. 2, Oct. 9-13 1994, pp. 330-333.</text>
        </nplcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="7">
          <text>F. Mekuria, "Implementation of the Fast Wavelet Transform for Noise Cancelling in Hands-free Mobile Telephony", ICSPAT-95, Ericsson Mobile Communication AB, 1995; pp. 312-315.</text>
        </nplcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="8">
          <text>F. Strang et al., "Wavelets and Filterbanks", Wellesley-Cambridge Press, 1996, pp. 24-35.</text>
        </nplcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Telefonaktiebolaget LM Ericsson (publ)</orgname>
            <address>
              <address-1>Stockholm, SE</address-1>
              <city>Stockholm</city>
              <country>SE</country>
            </address>
          </addressbook>
          <nationality>
            <country>SE</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>ERICSSON</orgname>
          </addressbook>
          <nationality>
            <country>SE</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Mekuria, Fisseha</name>
            <address>
              <address-1>Lund, SE</address-1>
              <city>Lund</city>
              <country>SE</country>
            </address>
          </addressbook>
          <nationality>
            <country>SE</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Burns, Doane, Swecker &amp; Mathis, L.L.P.</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Hudspeth, David R.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A voice activity detector that implements a fast wavelet transformation using filter pairs.
      <br/>
      A quadrature high pass filter provides an output signal corresponding to the upper half of the Nyquist frequency and a quadrature low pass filter provides an output signal corresponding to the lower half of the Nyquist frequency.
      <br/>
      The quadrature high pass filter is useful for catching and isolating transients in the input signal and the quadrature low pass filter is useful for fine frequency analysis.
      <br/>
      The voice activity detector can utilize multiple decomposition levels that are arranged in a pyramid or tree formation to increase the reliability of the voice activity decision.
      <br/>
      For example, the output of the quadrature low pass filter can be further decomposed using a second pair of filters.
      <br/>
      The voice activity decision can be generated by comparing a signal power estimate for the output of the filter pairs to threshold levels that are specific for each filter or frequency range.
      <br/>
      The reliability of the voice activity decision is maximized by training the system to determine the optimum threshold levels and by basing the decision on a combination of the signal outputs.
      <br/>
      While increasing the number of decomposition levels increases the reliability of the voice activity decision, three decomposition levels is usually sufficient for detecting speech activity.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND</heading>
    <p num="1">The present invention relates to distinguishing between two non-stationary signals, and more particularly, to using a wavelet transform to detect voice (speech) activity.</p>
    <p num="2">
      Speech is produced by excitation of an acoustic tube, the vocal tract, which is terminated on one end by the lips and on the other end by the glottis.
      <br/>
      There are three basic classes of speech sounds.
      <br/>
      Voiced sounds are produced by exciting the vocal tract with quasi-periodic pulses of airflow caused by the opening and closing of the glottis.
      <br/>
      Fricative sounds are produced by forming a constriction somewhere in the vocal tract and forcing air through the constriction so that turbulence is created, thereby producing a noiselike excitation.
      <br/>
      Plosive sounds are produced by completely closing off the vocal tract, building up pressure behind the closure, and then abruptly releasing it.
    </p>
    <p num="3">
      It is well known in the art that because a vocal tract has a constant shape, voiced signals can be modeled as the response of a linear time-invariant system to a quasi-periodic pulse train.
      <br/>
      Unvoiced sounds can be modeled as wideband noise.
      <br/>
      The vocal tract is an acoustic transmission system characterized by natural frequencies (formants) that correspond to resonances in its frequency response.
      <br/>
      In normal speech, the vocal tract changes shape relatively slowly with time as the tongue and lips perform the gestures of speech, and thus the vocal tract can be modeled as a slowly time-varying filter that imposes its frequency-response on the spectrum of the excitation.
    </p>
    <p num="4">
      FIG. 1a illustrates a waveform for the word "two." The waveform is an example of a non-stationary signal because the signal properties vary with time.
      <br/>
      Background noise is another example of a non-stationary signal.
      <br/>
      However, unlike background noise, the characteristics of a speech signal can be assumed to remain essentially constant over short (30 or 40 ms) time intervals.
    </p>
    <p num="5">
      FIG. 1b illustrates a spectrogram of the waveform shown in FIG. 1a. The frequency content of speech can range up to 15 kHz or higher, but speech is highly intelligible even when bandlimited to frequencies below about 3 kHz.
      <br/>
      Commercial telephone systems usually limit the highest transmitted frequency to the 3-4 kHz range.
    </p>
    <p num="6">
      A typical speech waveform consists of a sequence of quasi-periodic voiced segments interspersed with noise-like unvoiced segments.
      <br/>
      A GSM speech coder, for example, takes advantage of the fact that in a normal conversation, each person speaks on average for less than 40% of the time.
      <br/>
      By incorporating a voice activity detector (VAD) in the speech coder, GSM systems operate in a discontinuous transmission mode (DTX).
      <br/>
      Because the GSM transmitter is inactive during silent periods, discontinuous transmission mode provides a longer subscriber battery life and reduces instantaneous radio interference.
      <br/>
      A comfort noise subsystem (CNS) at the receiving end introduces a background acoustic noise to compensate for the annoying switched muting which occurs due to DTX.
    </p>
    <p num="7">
      Voice activity detectors are used quite extensively in the area of wireless communications.
      <br/>
      Voice activity detectors are not only used in GSM speech coders, but they are also used in other discontinuous transmission systems, noise suppression, echo canceling, and voice dialing systems.
      <br/>
      Because speech is usually accompanied by background noise, some segments of a speech signal have voiced sounds with background noise, some segments have noise-like unvoiced sounds with background noise, and some segments have only background noise.
      <br/>
      The voice activity detector's job is to distinguish voiced regions of the signal from unvoiced or background noise regions.
    </p>
    <p num="8">
      There are several known methods for voice activity detection.
      <br/>
      For example, U.S. Pat. No. 5,459,814 discloses a method in which an average signal level and zero crossings are calculated for the speech signal.
      <br/>
      Similarly, U.S. Pat. No. 5,596,680 discloses performing begin point detection using power/zero crossing.
      <br/>
      Once the begin point has been detected, the cepstrum of the input signal is used to determine the endpoint of the sound in the signal.
      <br/>
      After both the beginning and ending of the sound are detected, this system uses vector quantization distortion to classify the sound as speech or noise.
      <br/>
      While these methods are relatively easily to implement, they are not considered to be reliable.
    </p>
    <p num="9">
      Patent publication WO 95/08170 and U.S. Pat. No. 5,276,765 disclose a method in which a spectral difference between the speech signal and a noise estimate is calculated using linear prediction coding (LPC) parameters.
      <br/>
      These publications also disclose an auxiliary voice activity detector that controls updating of the noise estimate.
      <br/>
      While this method is relatively more reliable than those previously discussed, it is still difficult to reliably detect speech when the speech power is low compared to the background noise power.
    </p>
    <p num="10">
      Input signals are often analyzed by transforming the signal to a plane other than the time domain.
      <br/>
      Signals are usually transformed by utilizing appropriate basis functions or transformation kernels.
      <br/>
      The Fourier transform is a transform that is often used to transform signals to the frequency domain.
      <br/>
      The Fourier transform uses basis functions that are orthonormal functions of sines and cosines with infinite duration.
      <br/>
      The transform coefficients in the frequency domain represent the contribution of each sine and cosine wave at each frequency.
    </p>
    <p num="11">
      Patent publication WO 97/22117 is an example of how the Fourier transform is used to detect voice activity.
      <br/>
      WO 97/22117 discloses dividing an input signal into subsignals representing specific frequency bands, estimating noise in each subsignal, using each noise estimate to calculate subdecision signals, and using each subdecision signal to make a voice activity decision.
    </p>
    <p num="12">
      The problem with using the Fourier transform is that the Fourier transform works under the assumption that the original time domain signal is periodic in nature.
      <br/>
      As a result, the Fourier transform is poorly suited for nonstationary signals having discontinuities localized in time.
      <br/>
      When a non-stationary signal has abrupt changes, it is not possible to transform the signal using infinite basis functions without spreading the discontinuity over the entire frequency axis.
      <br/>
      The transform coefficients in the frequency domain can not preserve the exact occurrence of the discontinuity and this information is lost.
    </p>
    <p num="13">
      Unfortunately, many real signals are nonstationary in nature and the analysis of these signals involves a compromise between how well transitions or discontinuities are located and how finely long-term behavior can be identified.
      <br/>
      One attempt to improve the performance of the Fourier transform involves replacing the complex sinusoids of the Fourier transform with basis functions composed of windowed complex sinusoids.
      <br/>
      This technique, which is often referred to as the short time Fourier transform (STFT), is best illustrated by the equation,  (Equation image '1' not included in text)
    </p>
    <p num="14">
      where h(.) is a window function and TF ( OMEGA , TAU ) is the Fourier transform of x(t) windowed with h(.) shifted by  TAU .
      <br/>
      Although the STFT overcomes some of the problems associated with using infinite basis functions, the STFT still suffers from the fact that the analysis product is the same at all locations in the time-frequency plane.
      <br/>
      Generally speaking, voice activity detectors that use the Fourier transform or the short time Fourier transform are unreliable and require costly (power-consuming) computations.
      <br/>
      There is a need for a voice activity detector that can reliably and efficiently distinguish voiced regions of speech signals from unvoiced or background noise regions.
    </p>
    <heading>SUMMARY</heading>
    <p num="15">
      These and other drawbacks, problems, and limitations of conventional voice activity detectors are overcome according to exemplary embodiments of the present invention.
      <br/>
      It is an object of the present invention to use a wavelet transform to distinguish voiced regions of a signal from unvoiced or background noise regions.
    </p>
    <p num="16">
      A signal having voiced regions can be transformed using a wavelet transform.
      <br/>
      A wavelet transform uses orthonormal bases functions called wavelets.
      <br/>
      A short high frequency basis function is used to catch and isolate transients in the signal, and long low frequency basis functions are used for fine frequency analysis.
    </p>
    <p num="17">
      It is possible to implement the wavelet transform using quadrature mirror filters.
      <br/>
      A quadrature high pass filter provides an output signal corresponding to the upper half of the Nyquist frequency and a quadrature low pass filter provides an output signal corresponding to the lower half of the Nyquist frequency.
    </p>
    <p num="18">
      The voice activity detector can utilize multiple decomposition levels that are arranged in a pyramid or tree formation to increase the reliability of the voice activity decision.
      <br/>
      For example, the output of the quadrature low pass filter can be further decomposed using a second pair of filters.
      <br/>
      The voice activity decision can be generated by comparing a signal power estimate for the output of a particular filter to a threshold level that is specific for that filter.
      <br/>
      The reliability of the voice activity decision is maximized by training the system to determine the optimum threshold levels and by basing the decision on a combination of the signal outputs.
      <br/>
      While increasing the number of decomposition levels increases the reliability of the voice activity decision, three decomposition levels is usually sufficient for detecting speech activity.
    </p>
    <p num="19">
      Exemplary embodiments of the present invention are useful in discontinuous transmission systems, noise suppression, echo canceling, and voice dialing systems.
      <br/>
      An advantage of the present invention is that discontinuities in an input signal are isolated in time.
      <br/>
      Another advantage of the present invention is that there are fewer computations than other voice detection methods.
      <br/>
      It is not necessary to compute the inverse discrete wavelet transform, and if filter pairs are used repeatedly, the system implementation is code efficient.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="20">
      The foregoing, and other objects, features, and advantages of the present invention will be more readily understood upon reading the following detailed description in conjunction with the drawings in which:
      <br/>
      FIG. 1a illustrates a typical speech waveform of the word "two";
      <br/>
      FIG. 1b illustrates a spectrogram of the waveform shown in FIG. 1a;
      <br/>
      FIG. 2 illustrates a sampled portion of the waveform shown in FIG. 1a;
      <br/>
      FIG. 3 illustrates schematically a fast wavelet transform pyramid;
      <br/>
      FIG. 4a illustrates an exemplary set of filter coefficients for a quadrature mirror high pass filter;
      <br/>
      FIG. 4b illustrates an exemplary set of filter coefficients for a quadrature low pass filter;
      <br/>
      FIG. 5 illustrates a flowchart for generating a voice activity decision according to exemplary embodiments of the present invention;
      <br/>
      FIG. 6 illustrates a wavelet decomposition tree; and,
      <br/>
      FIG. 7 illustrates an exemplary embodiment of the present invention.
    </p>
    <heading>DETAILED DESCRIPTION</heading>
    <p num="21">
      The following description uses specific systems, structures, and techniques to describe the present invention.
      <br/>
      It will be evident to those skilled in the art that the present invention can be implemented using other systems, structures and techniques than those described below.
    </p>
    <p num="22">
      As discussed above, FIG. 1a illustrates a typical speech waveform of the word "two." Waveform 10 has regions having different signal characteristics.
      <br/>
      Because speech is a non-stationary signal, there are abrupt changes between region 20, region 30, and region 40.
      <br/>
      Generally speaking, region 20 can be described as having no sounds, region 30 can be described as having noise-like unvoiced sounds, and region 40 can be described as having voiced sounds.
    </p>
    <p num="23">
      As shown in FIG. 1b, the frequency components of waveform 10 are also discontinuous in nature.
      <br/>
      Region 20 has no frequency components, region 30 has relatively higher frequency components, and region 40 has relatively lower frequency components.
    </p>
    <p num="24">
      Speech can be transformed using a wavelet transform.
      <br/>
      A wavelet transform uses orthonormal basis functions called wavelets.
      <br/>
      According to the present invention, it is possible to choose short high frequency basis functions to catch and isolate transients in the signal, and long low frequency basis functions for fine frequency analysis.
      <br/>
      Wavelet transforms provide superior performance in analysis of signals by trading frequency and time resolution in a natural and efficient manner.
      <br/>
      This tradeoff can be achieved with a finite number of real and nonzero coefficients.
    </p>
    <p num="25">The basis functions can be obtained from a single primary wavelet function by utilizing a translation parameter ( MU ) and a scaling parameter ( ALPHA ), as follows.  (Equation image '2' not included in text)</p>
    <p num="26">
      The parameters  ALPHA  and  MU  are real numbers with  ALPHA &gt;0.
      <br/>
      For small values of  ALPHA , the basis function becomes a compressed (short window) version of the primary wavelet, i.e. a high frequency finction.
      <br/>
      A high frequency function provides better time resolution and is useful for catching and isolating transients in the signal.
      <br/>
      For large values of  ALPHA , the wavelet basis fimction becomes a stretched (long window) version of the primary wavelet, i.e., a low frequency function.
      <br/>
      A low frequency function is useful for fine frequency analysis.
    </p>
    <p num="27">Based on this definition of the wavelet basis functions, the wavelet transform in the time domain is defined by the following formula,  (Equation image '3' not included in text)</p>
    <p num="28">where w' is the transpose of w. The basis functions given in equation (2) enable the wavelet transform in equation (3) to provide better time resolution for small values of alpha and better frequency resolution for large values of alpha.</p>
    <p num="29">To reduce the redundancies associated with analyzing signals using continuous wave transform parameters ( ALPHA , MU ) the wavelet transform can be computed using a discrete time wavelet transform.</p>
    <p num="30">The computation of the wavelet transform in the discrete domain is performed by replacing the primary wavelet parameters ( ALPHA , MU ) given in equation (2) with discrete versions thereof, as follows,  (Equation image '4' not included in text)</p>
    <p num="31">
      where  ALPHA = ALPHA 0k,  MU =n ALPHA 0k MU 0, k and n are integers,  ALPHA 0 &gt;1 and  MU 0 =0.
      <br/>
      A particular set of orthonormal basis functions can be defined for the dyadic case when  ALPHA 0 =2 and  MU 0 =1.
      <br/>
      The pyramid algorithm for the fast wavelet transform (FWT) is based on this definition.
      <br/>
      If  ALPHA 0 =2 and  MU 0 =1, then the basis function is as follows,  (Equation image '5' not included in text)
    </p>
    <p num="32">where k controls the compression and expansion of the basis function and n controls the time translation of the basis function defined in equation (5).</p>
    <p num="33">
      From a signal processing point of view a wavelet is a bandpass filter.
      <br/>
      The definition in the dyadic case given in equation (5) actually represents an octave band filter It has been discovered that the wavelet transform can be implemented by using quadrature mirror filters (QMFs).
      <br/>
      A QMF pair of FIR filters can be used to spectrally decompose an input signal into quadrature low pass (QLP) and quadrature high pass (QHP) sections, where the Nyquist frequency bandwidth is divided equally between the two sections.
      <br/>
      The pair of filters can have FIR coefficients with the same values, but different signs.
      <br/>
      The pyramid algorithm described above is implemented by using the wavelet coefficients as the coefficients of a QMF FIR filter pair, as follows,
    </p>
    <p num="34">QLP:  (Equation image '6' not included in text)</p>
    <p num="35">QHP:  (Equation image '7' not included in text)</p>
    <p num="36">where the Ck s are orthonormal wavelet coefficients.</p>
    <p num="37">
      FIG. 2 illustrates a sampled portion of the waveform shown in FIG. 1a. In FIG. 1a, segment 50 is a 10 ms segment of waveform 10 and segment 60 is an adjacent 10 ms segment of waveform 10.
      <br/>
      FIG. 2 illustrates an enlarged and sampled view of segments 50 and 60.
    </p>
    <p num="38">
      The standard sampling rate for digital telephone communication systems is 8000 samples per second (8 kHz).
      <br/>
      If segment 50 is sampled at 8 kHz, then segment 50 is spanned by eighty samples.
      <br/>
      If segments 50 and 60 are sampled at 8 kHz, then segments 50 and 60 are spanned by 160 samples.
    </p>
    <p num="39">
      For simplicity purposes, FIG. 2 illustrates a sampling rate of 800 Hz.
      <br/>
      Sample 51 is the first sample of segment 50 and samples 52-58 are the second, third, fourth, fifth, sixth, seventh, and eighth samples of segment 50.
      <br/>
      Similarly, sample 61 is the first sample of segment 60 and samples 62-68 are the second, third, fourth, fifth, sixth, seventh, and eighth samples of segment 60.
      <br/>
      If segments 50 and 60 are sampled at 8 kHz then sample 51 is the 10th sample of segment 50 and samples 52-58 are the 20th, 30th, 40th, 50th, 60th, 70th, and 80th samples of segment 50.
      <br/>
      Similarly, sample 61 is the 10th sample of segment 60 and samples 62-68 are the 20th, 30th, 40th, 50th, 60th, 70th, and 80th sample of segment 60.
    </p>
    <p num="40">
      FIG. 3 illustrates schematically a fast wavelet transform pyramid.
      <br/>
      The fast wavelet transform is obtained by cascading QHP and QLP filters in a pyramid form.
      <br/>
      Signal 102 can be any sampled signal.
      <br/>
      Samples, such as those shown in FIG. 2, can be grouped into data vectors or frames.
      <br/>
      For example, the samples in segment 50 can form a frame, half a frame, or part of a frame.
      <br/>
      Signal 102 can be a frame of sampled speech that is, for example, 20 ms in length and that is spanned by 160 samples.
      <br/>
      The length of a frame or the number of samples will depend on the system, the desired application, and the sampling rate.
      <br/>
      Frames can overlap so that samples are used in more than one frame.
    </p>
    <p num="41">
      Signal 102 is filtered by filters 110 and 150.
      <br/>
      Filters 110 and 150 can be FIR filters.
      <br/>
      In the example shown, filter 110 is a quadrature high pass filter that has as its coefficients orthonormal wavelet coefficients.
      <br/>
      Filter 150 is a quadrature low pass filter that as its coefficients orthonormal wavelet coefficients.
      <br/>
      Filters 110 and 150 can have the same coefficients.
      <br/>
      However, because filter 110 is a high pass filter the coefficients should have positive and negative values.
      <br/>
      When splitting a frequency bandwidth the amount of information at the output of the filter is usually decimated by a factor of two.
      <br/>
      The decimation by two has the effect of translating the analysis window into the correct frequency region while removing redundant information from the filtered signal.
      <br/>
      It will be evident to those skilled in the art that the output of each filter can be decimated by a factor less than or greater than two.
    </p>
    <p num="42">
      FIG. 4a illustrates an exemplary set of filter coefficients for a quadrature mirror high pass filter.
      <br/>
      FIG. 4b illustrates an exemplary set of filter coefficients for a quadrature mirror low pass filter.
      <br/>
      Each high pass filter can use the same set of filter coefficients and each low pass filter can use the same set of filter coefficients, where the high pass filter coefficients and the low pass filter coefficients are given by the following formula.
      <br/>
      .vertline.HQLP (ejw).vertline.=.vertline.HQHP (ej( PI -w)).vertline.  (8)
    </p>
    <p num="43">
      Like the fast Fourier transform, the fast wavelet transform (FWT) algorithm does a linear operation on a data vector whose length is an integer power of two, and transforms the vector into a numerically different vector of the same length.
      <br/>
      The decimation translates the analysis window to the correct frequency region.
    </p>
    <p num="44">
      Referring back to FIG. 3, filter 110 transforms the input signal 102 into detail components 111.
      <br/>
      Detail components 111 can be used to determine whether there is any speech activity in input signal 102.
      <br/>
      A power estimator can estimate the signal power in signal 111 and compare the signal power estimate to a threshold value to determine whether there is any speech activity in input signal 102.
    </p>
    <p num="45">
      Filter 150 transforms the input signal 102 into approximation coefficients 151.
      <br/>
      Approximation coefficients 151 are filtered by filters 160 and 180.
      <br/>
      Filters 160 and 180 are FIR filters.
      <br/>
      More specifically, filter 160 is a quadrature high pass filter that has as its coefficients orthonormal wavelet coefficients.
      <br/>
      Filter 180 is a quadrature low pass filter that as its coefficients orthonormal wavelet coefficients.
    </p>
    <p num="46">
      Filter 160 transforms approximation coefficients 151 into detail components 161.
      <br/>
      Detail components 161 can be used to determine whether there is any speech activity in input signal 102.
      <br/>
      A power estimator can estimate the signal power in signal 160 and compare the signal power estimate to a threshold value to determine whether there is any speech activity in input signal 102.
    </p>
    <p num="47">
      Filter 180 transforms approximation coefficients 151 into approximation coefficients 181.
      <br/>
      Approximation coefficients 181 are filtered by filter 182 and filter 184, or alternatively, by filter 182 and additional filters until an N-point FWT is realized.
      <br/>
      The decimation by two implements the change in resolution that is due to parameter k in equation (5).
      <br/>
      An inverse FWT does the operation of the forward FWT in the opposite direction combining the transform coefficients to reconstruct the original signal.
      <br/>
      However, the inverse FWT is not necessary to determine whether there is any speech activity in input signal 102.
    </p>
    <p num="48">
      FIG. 5 illustrates a flowchart for generating a voice activity decision according to exemplary embodiments of the present invention.
      <br/>
      The method shown in FIG. 5 corresponds to a voice activity detector that is designed to minimize complexity and/or power consumption.
    </p>
    <p num="49">
      In step 210, an input signal is transformed using a first quadrature high pass filter.
      <br/>
      In step 211, a signal power estimator finds a signal power estimate for the output of the first QHP filter.
      <br/>
      In step 212, the signal power estimate is compared to a first threshold value that is specific for the frequency band of the first QHF filter.
      <br/>
      If the signal power estimate exceeds the threshold value, a voice activity decision generator generates a decision that there is voice activity in the input signal.
      <br/>
      If the signal power estimate exceeds the first threshold value, it is not necessary to perform additional steps 250-287.
    </p>
    <p num="50">
      In step 250, the input signal is transformed using a first quadrature low pass filter.
      <br/>
      In step 260, the output of the first QLP filter is transformed using a second QHP filter.
      <br/>
      In step 261, a signal power estimator finds a signal power estimate for the output of the second QHP filter.
      <br/>
      In step 262, the signal power estimate is compared to a second threshold value.
      <br/>
      If the signal power estimate exceeds the threshold value then a voice activity decision generator generates a decision that there is voice activity in the input signal.
      <br/>
      If the signal power estimate exceeds the second threshold value, it is not necessary to perform additional steps 283 and 287.
    </p>
    <p num="51">
      As shown in FIG. 5 by the omitted steps following decision block 262, the output of the first QLP filter can be transformed using additional filters and a signal power estimator can find a signal power estimate for at least one of these additional filters.
      <br/>
      The signal power estimate can be compared to a threshold value, and if the signal power estimate exceeds the threshold value then a voice activity decision generator can generate a decision that there is voice activity in the input signal.
      <br/>
      If the signal power estimate does not exceed the threshold value, the voice activity decision generator generates a decision that there is no voice activity in the input signal.
      <br/>
      This process will conclude after N iterations, as indicated by blocks 283 and 287, where N can be selected based on design consideration such as the background noise level and reliability versus complexity tradeoffs.
    </p>
    <p num="52">While the method illustrated in FIG. 5 is helpful in reducing the complexity or power consumption associated with voice activity detection, the decision generated by the voice activity decision generator can be made more reliable by basing the voice activity decision on multiple signal power estimates instead of a single power estimate.</p>
    <p num="53">
      A voice activity detector can use a fast wavelet transform pyramid as illustrated in FIG. 3 and can generate detail components corresponding to multiple levels, e.g. 111, 161, and 183, before generating a voice activity decision.
      <br/>
      The reliability of the voice activity decision is usually increased by basing the voice activity decision on more than one signal power estimate.
      <br/>
      The reliability of the voice activity decision is increased even more by using a wavelet decomposition tree as described below.
    </p>
    <p num="54">
      FIG. 6 illustrates a wavelet decomposition tree.
      <br/>
      A wavelet decomposition tree is especially useful for generating a voice activity decision for a noisy signal, i.e. a signal in which the voice activity is masked by high levels of background noise.
    </p>
    <p num="55">
      Signal 302 can be any sampled signal.
      <br/>
      For example, signal 302 can be a frame of sampled speech that is 20 ms in length and that is spanned by 160 samples.
      <br/>
      The length of a frame or the number of samples will depend on the system, the desired application, and/or the sampling rate.
      <br/>
      Frames can overlap so that samples are used in more than one frame.
    </p>
    <p num="56">
      The signal 302 is decomposed using a discrete wavelet transform tree 300.
      <br/>
      The discrete wavelet transform tree 300 can have a first level comprising filters 310 and 350.
      <br/>
      Filter 310 has an output node 311 and filter 350 has an output node 351.
      <br/>
      The discrete wavelet transform tree 300 can have a second level comprising filters 320, 340, 360, and 380.
      <br/>
      Filter 320 has an output node 321, filter 340 has an output node 341, filter 360 has an output node 361, and filter 380 has an output node 381.
    </p>
    <p num="57">
      The discrete wavelet transform tree 300 can have a third level comprising filters 322, 324, 342, 344, 362, 364, 382, and 384.
      <br/>
      Filters 322, 324, 342, 344, 362, 364, 382, 384 have output nodes 323, 325, 343, 345, 363, 365, 383, and 385.
      <br/>
      While the discrete wavelet transform tree 300 can have additional levels, three levels is usually sufficient for detecting voice activity.
    </p>
    <p num="58">
      The output signals at the output nodes 311, 351, 321, 341, 361, 381, 323, 325, 343, 345, 363, 365, 383, and 385 can be used to design a criteria for a voice activity decision.
      <br/>
      The detection of the voice activity regions is then based on the magnitude of the signals at the different decomposition levels.
    </p>
    <p num="59">
      For example, the output of filter 340 might indicate that there is no voice activity in signal 302, while the output of filter 382 indicates there is voice activity in signal 302.
      <br/>
      A combination of two decomposition levels can be used to design a robust criteria for the voice activity decision.
      <br/>
      When the voice activity decision is based on a combination of levels and/or nodes, the voice activity decision is usually more reliable.
    </p>
    <p num="60">
      Signal 300 is filtered by filters 310 and 350.
      <br/>
      In FIG. 5, H denotes high pass and L denotes low pass.
      <br/>
      Filters 310 and 350 can be FIR filters.
      <br/>
      In the example show, filter 310 is a quadrature high pass filter that has as its coefficients orthonormal wavelet coefficients.
      <br/>
      Filter 350 is a quadrature low pass filter that as its coefficients orthonormal wavelet coefficients.
      <br/>
      Filters 310 and 350 can have the same coefficients.
      <br/>
      However, because filter 310 is a high pass filter the coefficients will have different signs.
      <br/>
      When splitting a frequency bandwidth, the amount of information at the output of the filter is usually decimated by a factor of two.
      <br/>
      The decimation by two has the effect of translating the analysis window into the correct frequency region while removing redundant information from the filtered signal.
      <br/>
      It will be evident to those skilled in the art that the output of each filter can be decimated by a factor less than or greater than two.
    </p>
    <p num="61">
      As discussed above, speech is highly intelligible even when bandlimited to frequencies below about 3 kHz.
      <br/>
      For example, the signal 302 can be bandlimited to the frequency range 300 to 3400 Hz without significant loss to the speech quality of the signal.
      <br/>
      If, for example, the signal 302 has frequencies less than or equal to 3400 Hz, the Nyquist frequency for signal 302 is 3400 Hz and filters 310 and 350 can divide signal 302 into regions equal to half the Nyquist frequency.
      <br/>
      That is, filter 310 provides an output signal at node 311 representing frequencies 1700-3400 Hz and filter 350 provides an output signal at node 351 representing frequencies 0-1700 Hz.
    </p>
    <p num="62">
      The output signal at node 311 is filtered by QHP filter 320 and QLP filter 340 so that the output signal at node 321 represents frequencies 2550-3400 Hz and the output signal at node 341 represents frequencies 1700-2550 Hz.
      <br/>
      Similarly, the output signal at node 351 is filtered by QHP filter 360 and QLP filter 380 so that the output signal at node 61 represents frequencies 850-1700 Hz and the output signal at node 381 represents frequencies 0-850 Hz.
    </p>
    <p num="63">
      If the decomposition tree has a third level, the output signal at node 321 can be filtered by QHP filter 322 and QLP filter 324 so that the output signal at node 323 represents frequencies 2975-3400 Hz and the output signal at node 323 represents frequencies 2550-2975 Hz.
      <br/>
      The output signal at node 341 can be filtered by QHP filter 342 and QLP filter 344 so that the output signal at node 343 represents frequencies 2125-2550 Hz and the output signal at node 345 represents frequencies 1700-2125 Hz.
      <br/>
      Similarly, the output signal at node 361 can be filtered by QHP filter 362 and QLP filter 364 so that the output signal at node 363 represents frequencies 1275-1700 Hz and the output signal at node 364 represents frequencies 850-1275 Hz.
      <br/>
      The output signal at node 381 can be filtered by QHP filter 382 and QLP filter 384 so that the output signal at node 383 represents frequencies 425-850 Hz and the output signal at node 385 represents frequencies 0-425 Hz.
    </p>
    <p num="64">
      It is important to note that the use of quadrature filters to determine the voice activity in signal 302 requires fewer computations than other voice detection methods.
      <br/>
      Three decomposition levels is usually sufficient to reliably detect voice activity and it is not necessary to compute the inverse discrete wavelet transform.
      <br/>
      In addition, because the filter pairs are complimentary filters and because the filter pairs are used repeatedly, the system implementation is code efficient.
    </p>
    <p num="65">If, for example, the power estimate for the ith wavelet filter bank is given by the equation  (Equation image '8' not included in text)</p>
    <p num="66">
      for each frame of length N/M, where M is the decimation factor.
      <br/>
      The average of P over M a number of frames of speech can be used to form a cost function.
      <br/>
      FIG. 7 illustrates an exemplary embodiment of the present invention.
      <br/>
      A voice activity detector 400 can be used to control a discontinuous transmission handler 550 or to assist an echo/noise canceler 530.
      <br/>
      A microphone 510 provides an input signal to an analog-to-digital converter 520.
      <br/>
      The input signal can be filtered using a bandlimited filter (not shown).
      <br/>
      The analog-to-digital converter 520 samples the input signal and maps the samples to predetermined levels.
      <br/>
      The quantized signal can be filtered by a reconstruction filter (not shown).
      <br/>
      The sampled signal can be divided into frames of samples.
    </p>
    <p num="67">
      An echo/noise canceler 530 is used to cancel echos or to suppress noise in the input signal.
      <br/>
      Each frame of samples is coded using a speech coder 540.
      <br/>
      The discontinuous transmission handler 550 receives coded frames from the speech coder 540.
      <br/>
      If the voice activity decision is true, the frame of samples is transmitted.
      <br/>
      If the voice activity decision is false, the frame of samples is not transmitted.
      <br/>
      The voice activity decision can also be used to assist the echo/noise canceler 530.
      <br/>
      The voice activity decision enables the echo/noise cancels to form good estimates of the noise parameters and the speech parameters.
      <br/>
      Using the voice activity decision, the echo/noise canceled can detect double talk and high echos.
    </p>
    <p num="68">
      A voice activity detector 400 has a discrete wavelet transformer 410.
      <br/>
      The discrete wavelet transformer 410 transforms a frame of samples to provide output signals corresponding to different levels of decomposition.
      <br/>
      The voice activity detector 400 has a cost function processor 420 that evaluates at least one of the output signals.
      <br/>
      The cost function processor 420 can compare signal power estimates for the output signals to different threshold levels.
      <br/>
      The cost function processor 420 can be trained to determine the optimum threshold levels.
      <br/>
      The cost function processor 420 assists a voice activity decision generator 430 in generating a voice activity decision.
    </p>
    <p num="69">
      Generally speaking, if a n output signal has a signal power estimate that exceeds a threshold level, the voice activity decision is true.
      <br/>
      If none of the output signals have a signal power estimate that exceeds a threshold level, the voice activity decision is false.
      <br/>
      By basing the decision on more than one output signal, the voice activity decision can be made reliable.
      <br/>
      For example, if a background noise level increases, the signal power estimate for a particular output signal can increase.
      <br/>
      Therefore, a decision based on two or ore of the output signals is more reliable than a decision base on only one signal.
    </p>
    <p num="70">
      While the foregoing description makes reference to particular illustrative embodiments, these examples should not be construed as limitations.
      <br/>
      It will be evident to those skilled in the art that the disclosed methods and apparatuses for distinguishing between two non-stationary signals can be adapted and modified for other applications without departing from the spirit of the invention.
      <br/>
      For example, there are similar pyramid or tree structures that are less complex (i.e., have fewer transformations) or more reliable (i.e., have more transformations) than the exemplary embodiments described above.
      <br/>
      Thus, the present invention is not limited to the disclosed embodiments, but is to be accorded the widest scope consistent with the claims below.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>An audio signal activity detector comprising:</claim-text>
      <claim-text>a plurality of filters having orthonormal wavelet coefficients for transforming an input audio signal;</claim-text>
      <claim-text>and a signal activity decision generator that generates a signal activity decision based on at least one output of said plurality of filters.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. A detector in accordance with claim 1, wherein the signal activity decision generator is a voice activity decision generator that generates a voice activity decision.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. A detector in accordance with claim 1, wherein said plurality of filters further comprises: a first filter having orthonormal wavelet coefficients, the first filter transforming said input signal to provide a first output signal; a second filter having orthonormal wavelet coefficients, the second filter transforming the input signal to provide a second output signal; a third filter having orthonormal wavelet coefficients, the third filter transforming the first output signal to provide a third output signal; a fourth filter having orthonormal wavelet coefficients, the fourth filter transforming the first output signal to provide a fourth output signal; a fifth filter having orthonormal wavelet coefficients, the fifth filter transforming the second output signal to provide a fifth output signal;</claim-text>
      <claim-text>and a sixth filter having orthonormal wavelet coefficients, the sixth filter transforming the second output signal to provide a sixth output signal.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. A detector in accordance with claim 3, wherein the first filter is a quadrature high pass filter and the second filter is a quadrature low pass filter.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. A signal activity detector in accordance with claim 3, wherein the first filter is a quadrature high pass filter and the second filter is a quadrature low pass filter, the third filter is a quadrature high pass filter and the fourth filter is a quadrature low pass filter, and the fifth filter is a quadrature high pass filter and the sixth filter is a quadrature low pass filter.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. A signal activity detector in accordance with claim 5, wherein the signal activity decision is determined by a cost function that is dependent on at least two outputs selected from the group including outputs from the third filter, the fourth filter, the fifth filter, and the sixth filter.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. A signal activity detector in accordance with claim 5, wherein the cost function is dependent on at least one output selected from the group including outputs from the first filter and the second filter.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. A detector in accordance with claim 1, wherein the signal activity decision is based on more than one output signal.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. A detector in accordance with claim 1, further comprising a first signal power estimator that generates a first signal power estimate for one of the output signals of said plurality of filters.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. A detector in accordance with claim 9, further comprising a first comparator for comparing the signal power estimate to a first threshold level.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. A detector in accordance with claim 10, further comprising a second signal power estimator that generates a second signal power estimate for another one of the output signals of said plurality of filters.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. A detector in accordance with claim 11, further comprising a second comparator for comparing the second signal power estimate to a second threshold level, the second threshold level being different from the first threshold level.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. A method for detecting audio signal activity comprising the steps of: filtering an input signal using a first quadrature high pass filter and a first quadrature low pass filter; filtering an output of the high pass filter using a second quadrature high pass filter and a second quadrature low pass filter storing an output of the second quadrature high pass filter and an output of the second quadrature low pass filter; filtering an output of the first low pass filter using a third quadrature high pass filter and a third quadrature low pass filter; storing an output of the third quadrature high pass filter and an output of the third quadrature low pass filter;</claim-text>
      <claim-text>and generating a signal activity decision based on an output of at least two of the filters.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. A method in accordance with claim 13, wherein the step of generating a signal activity decision comprises the step of generating a first signal power estimate for one of the outputs of the filters.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. A method in accordance with claim 14, wherein the step of generating a signal activity decision further comprises the step of comparing the first signal power estimate to a first threshold level.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. A method in accordance with claim 15, wherein the step of generating a signal activity decision further comprises the step of generating a second signal power estimate for another one of the output signals.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. A method in accordance with claim 13, wherein the step of generating a signal activity decision comprises the step of evaluating a cost function that is dependent on at least two outputs selected from the group consisting of the output of the second quadrature high pass filter, the second quadrature low pass filter, the third quadrature high pass filter, and the third quadrature low pass filter.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. A method in accordance with claim 17, wherein the cost function is dependent on at least one output selected from the group consisting of the first quadrature high pass filter and the first quadrature low pass filter.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. An audio signal activity detector comprising: a first filter having orthonormal wavelet coefficients, the first filter transforming an input signal to provide a first output signal; a second filter having orthonormal wavelet coefficients, the second filter transforming the input signal to provide a second output signal; a third filter having orthonormal wavelet coefficients, the third filter transforming the first output signal to provide a third output signal; a fourth filter having orthonormal wavelet coefficients, the fourth filter transforming the first output signal to provide a fourth output signal; a fifth filter having orthonormal wavelet coefficients, the fifth filter transforming the second output signal to provide a fifth output signal; a sixth filter having orthonormal wavelet coefficients, the sixth filter transforming the second output signal to provide a sixth output signal;</claim-text>
      <claim-text>and a signal activity decision generator that generates a signal activity decision based on at least one output of the first filter, the second filter, the third filter, the fourth filter, the fifth filter and the sixth filter.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. The detector in accordance with claim 19, wherein the first filter, the third filter and the fifth filter are quadrature high pass filters and the second filter, the fourth filter and the sixth filter are quadrature low pass filters.</claim-text>
    </claim>
    <claim num="21">
      <claim-text>21. The detector in accordance with claim 19, wherein the signal activity decision is determined by a cost function that is dependent on at least one of the outputs of the first filter and the second filter.</claim-text>
    </claim>
    <claim num="22">
      <claim-text>22. The detector in accordance with claim 19, wherein the signal activity decision is determined by a cost function that is dependent on at least two of the outputs of the third filter, the fourth filter, the fifth filter and the sixth filter.</claim-text>
    </claim>
    <claim num="23">
      <claim-text>23. The detector in accordance with claim 19, further comprising a first signal power estimator that generates a first signal power estimate for one of the outputs of the first filter, the second filter, the third filter, the fourth filter, the fifth filter and the sixth filter.</claim-text>
    </claim>
    <claim num="24">
      <claim-text>24. The detector in accordance with claim 23, further comprising a first comparator for comparing the first signal power estimate to a first threshold level.</claim-text>
    </claim>
    <claim num="25">
      <claim-text>25. The detector in accordance with claim 24, further comprising a second signal power estimator that generates a second signal power estimate for another one of the outputs of the first filter, the second filter, the third filter, the fourth filter, the fifth filter and the sixth filter.</claim-text>
    </claim>
    <claim num="26">
      <claim-text>26. The detector in accordance with claim 25, further comprising a second comparator for comparing the second signal power estimate to a second threshold level, the second threshold level being different from the first threshold level.</claim-text>
    </claim>
  </claims>
</questel-patent-document>