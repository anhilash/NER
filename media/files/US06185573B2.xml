<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06185573B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06185573</doc-number>
        <kind>B2</kind>
        <date>20010206</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6185573</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="22052238" extended-family-id="42113627">
      <document-id>
        <country>US</country>
        <doc-number>09063899</doc-number>
        <kind>A</kind>
        <date>19980422</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1998US-09063899</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>43171922</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>6389998</doc-number>
        <kind>A</kind>
        <date>19980422</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1998US-09063899</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010206</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G06F  17/30        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>17</main-group>
        <subgroup>30</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <further-classification sequence="1">
        <text>705001100</text>
        <class>705</class>
        <subclass>001100</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>705007290</text>
        <class>705</class>
        <subclass>007290</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>707999103</text>
        <class>707</class>
        <subclass>999103</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>707999104</text>
        <class>707</class>
        <subclass>999104</subclass>
      </further-classification>
      <further-classification sequence="5">
        <text>707999107</text>
        <class>707</class>
        <subclass>999107</subclass>
      </further-classification>
      <further-classification sequence="6">
        <text>707E17009</text>
        <class>707</class>
        <subclass>E17009</subclass>
      </further-classification>
    </classification-national>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06F-017/30017</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>17</main-group>
        <subgroup>30017</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06Q-030/0201</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>Q</subclass>
        <main-group>30</main-group>
        <subgroup>0201</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>Y10S-707/99944</classification-symbol>
        <section>Y</section>
        <class>10</class>
        <subclass>S</subclass>
        <main-group>707</main-group>
        <subgroup>99944</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130518</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>Y10S-707/99945</classification-symbol>
        <section>Y</section>
        <class>10</class>
        <subclass>S</subclass>
        <main-group>707</main-group>
        <subgroup>99945</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130518</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>Y10S-707/99948</classification-symbol>
        <section>Y</section>
        <class>10</class>
        <subclass>S</subclass>
        <main-group>707</main-group>
        <subgroup>99948</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130518</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>36</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>11</number-of-drawing-sheets>
      <number-of-figures>11</number-of-figures>
      <image-key data-format="questel">US6185573</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Method and system for the integrated storage and dynamic selective retrieval of text, audio and video data</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>STIPANOVICH JOSEPH, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5117353</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5117353</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>LALONDE JAMES E, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5283731</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5283731</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>SALMON BARDWELL C, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5592375</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5592375</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>BARR THOMAS, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5742816</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5742816</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>HARTMAN RICHARD L, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5758324</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5758324</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>TAYLOR JEFFREY C</text>
          <document-id>
            <country>US</country>
            <doc-number>5832497</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5832497</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>WALKER JAY S, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5884270</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5884270</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>WALKER JAY S, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5884272</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5884272</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="9">
          <text>COLLINS GREGG</text>
          <document-id>
            <country>US</country>
            <doc-number>5963951</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5963951</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="10">
          <text>MCGOVERN ROBERT J, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5978768</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5978768</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="11">
          <text>SPEICHER GREGORY J</text>
          <document-id>
            <country>US</country>
            <doc-number>6064967</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US6064967</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="12">
          <text>HINOTE GARY L</text>
          <document-id>
            <country>US</country>
            <doc-number>4208109</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4208109</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="13">
          <text>BAYLESS GARY</text>
          <document-id>
            <country>US</country>
            <doc-number>4821469</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4821469</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="14">
          <text>TORNETTA MARK A</text>
          <document-id>
            <country>US</country>
            <doc-number>4870576</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4870576</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="15">
          <text>TORNETTA MARK A</text>
          <document-id>
            <country>US</country>
            <doc-number>5032989</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5032989</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="16">
          <text>LOGSTON GARY L, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5481542</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5481542</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="17">
          <text>VOETEN BART F, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5528282</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5528282</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="18">
          <text>GREENWOOD DAVID G, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5568181</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5568181</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="19">
          <text>BAKER DONN B, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5583561</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5583561</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="20">
          <text>DAWSON WILLIAM P, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5594490</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5594490</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="21">
          <text>HODGE WINSTON W, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5594491</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5594491</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="22">
          <text>SCHUCHMAN LEONARD, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5640453</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5640453</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="23">
          <text>ABECASSIS MAX</text>
          <document-id>
            <country>US</country>
            <doc-number>5664046</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5664046</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="24">
          <text>NAHAN KENNETH, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5664111</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5664111</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="25">
          <text>FRASER RICHARD</text>
          <document-id>
            <country>US</country>
            <doc-number>5664115</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5664115</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="26">
          <text>SUZUKI YOUKO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5675738</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5675738</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="1">
          <text>National Association of Realtors and RealSelect, Inc., Realtor.com, 1995, 1996, 1997, 11 pages.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="2">
          <text>Virtual Properties, Inc., Virtual-properties.com, 1997, 6 pages.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="3">
          <text>Online Milwaukee Journal Sentinel, Web acts as home browser, Aug. 10, 1997, 2 pages.</text>
        </nplcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Millenium Integrated Systems, Inc.</orgname>
            <address>
              <address-1>Broomall, PA, US</address-1>
              <city>Broomall</city>
              <state>PA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>MILLENIUM INTEGRATED SYSTEMS</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Angelucci, Vincent</name>
            <address>
              <address-1>Broomall, PA, US</address-1>
              <city>Broomall</city>
              <state>PA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Madaras, Stephen</name>
            <address>
              <address-1>Germantown, MD, US</address-1>
              <city>Germantown</city>
              <state>MD</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Alam, Hosain T.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>LAPSED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      The present invention is an automated system to input text, audio and video data, to integrate the storage of the data at a central location, to initiate queries of search criteria to the central location from remote locations, and to dynamically transmit text, audio and video data to the remote locations in accordance with the search criteria.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>FIELD OF THE INVENTION</heading>
    <p num="1">
      This invention relates generally to the integrated storage, searching, and dynamic, selective retrieval of text and video data for different applications including employment.
      <br/>
      More particularly, it pertains to an automated system to input text, audio and video data, to integrate the storage of the data at a central location, to initiate queries of search criteria to the central location from remote locations, and to dynamically and selectively transmit text, audio and video data to the remote locations in accordance with the search criteria.
    </p>
    <heading>BACKGROUND</heading>
    <p num="2">
      This invention involves a system and method for the integrated central storage and remote dynamic retrieval of text, audio, and video data for different applications including, but not limited to, an employment search system.
      <br/>
      The invention is particularly adapted for the input of text, audio and video data from employment candidates, the integrated storage of this employment data, and the dynamic, selective retrieval of text, audio, and video data at remote locations by employers based on their requirements.
    </p>
    <p num="3">
      Many different applications would benefit from a system which supports the integration of text, audio, and video data within a search system for the dynamic, selective retrieval of the data matching search criteria.
      <br/>
      For example, sellers and candidate buyers of real estate could use a real estate system which would enable a buyer to view text and video data on available residences which match the buyer's requirements on price, cost, tax, location, school district, floor space, yard size, etc.
      <br/>
      Also, a multimedia search system could be used in an athletic scouting service for viewing text and video data on available high school, college or professional athletes which match criteria on height, weight, age, athletic achievements such as basketball shooting percentage, baseball batting average, baseball fielding percentage, hockey goals, etc.
    </p>
    <p num="4">
      Other systems have disclosed the central storage and remote selective retrieval of text or video data.
      <br/>
      For example, U.S. Pat. No. 5,664,111 discloses a system and method for electronically executing transactions with a preprogrammed main computer having data and image storage and retrieval equipment. U.S. Pat. Nos. 4,870,576 and 5,032,989 disclose a system and method for locating real estate comprising a graphical interface for selection of a search area by a buyer.
    </p>
    <p num="5">Similarly, U.S. Pat. No. 5,675,738 discloses a video information system comprising a plurality of video servers and a selection mechanism to enable each of a plurality of remote clients to select a video from a library. U.S. Pat. No. 5,528,282 discloses another video information system wherein each of a plurality of remote user stations issues control signals to selectively retrieve video signals from a central video server.</p>
    <p num="6">
      However, none of the previous systems enables the dynamic, selective transmission of text and video data to remote locations in accordance with queries of search criteria initiated at remote locations as required by different applications such as an employment search service, or an athletic scouting service.
      <br/>
      Accordingly, there exists a need for a system and method to input text and video data, to integrate the storage of the data at a central location, to initiate queries of search criteria to the central location from remote locations, and to dynamically and selectively transmit text and video data to the remote locations in accordance with the search criteria.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="7">The invention provides a system and method to input text, audio, and video data, to integrate the storage of the data at a central location, to initiate queries of search criteria to the central location from remote locations, and to dynamically and selectively transmit text and video data to the remote locations in accordance with the search criteria.</p>
    <p num="8">In particular, it is an aspect of the present invention to present a system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria comprising:</p>
    <p num="9">one or more servers comprising:</p>
    <p num="10">
      - at least one input system for inputing text, audio, and video data;
      <br/>
      - at least one database collection for integrated storing of the text, audio, and video data wherein the input utilities store the text, audio, and video data the indexed collections;
      <br/>
      - at least one search system for inputing search criteria and for searching the database collection for the text, audio, and video data matching the search criteria;
      <br/>
      - at least one audio/video system for dynamically displaying the matching audio data and video data;
      <br/>
      - at least one client for specifying the text, audio, and video data and the search criteria and for viewing the text, audio, and video data; and
      <br/>
      - a communication network for communication between the servers and the clients.
    </p>
    <p num="11">
      It is a further aspect of the present invention to present a system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria wherein the input utility further comprises:
      <br/>
      an audio/video input system for inputing the audio data and the video data; and
      <br/>
      a text input utility for inputing the text data.
    </p>
    <p num="12">
      The present invention further presents a system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria wherein the search system further comprises:
      <br/>
      a query filter for parsing the search criteria and creating corresponding queries and for restricting the corresponding queries to predetermined data of the text, audio and visual data;
      <br/>
      a search engine for searching the indexed collections for the search criteria; and
      <br/>
      a search display utility for displaying the text, audio, and video data matching the search criteria.
    </p>
    <p num="13">
      It is a further aspect of the present invention to present a method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria comprising the steps of:
      <br/>
      inputing text, audio and video data with at least one input utility executing on one or more servers;
      <br/>
      integrated storing of the text, audio, and video data in at least one indexed collection with the input utilities;
      <br/>
      inputing search criteria and searching the indexed collection for the text, audio, and video data matching the search criteria with at least one search system;
      <br/>
      dynamically displaying the matching audio data and video data with at least one audio/video system;
      <br/>
      specifying the text, audio, and video data and the search criteria with at least one client;
      <br/>
      viewing the matching text, audio, and video data with the clients; and
      <br/>
      communicating between the servers and the clients with a communication network.
    </p>
    <p num="14">
      It is a further aspect of the present invention to present a method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria wherein the inputing text, audio and video data step further comprises the steps of:
      <br/>
      inputing the audio data and the video data with an audio/video input system; and
      <br/>
      inputing the text data with a text input utility.
    </p>
    <p num="15">
      It is a further aspect of the present invention to present a method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria wherein the inputing search criteria and searching the indexed collection step further comprises the steps of:
      <br/>
      parsing the search criteria and creating corresponding queries with a query filter;
      <br/>
      restricting the corresponding queries to predetermined data of the text, audio and visual data with the query filter;
      <br/>
      searching the indexed collections for the search criteria with a search engine; and
      <br/>
      displaying the text, audio, and video data matching the search criteria with a search display utility.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="16">
      These and other objects and features of the invention will be more clearly understood from the following detailed description along with the accompanying drawing figures, wherein:
      <br/>
      FIG. 1 is a block diagram showing the major operational elements of the invention;
      <br/>
      FIG. 2 is a flow chart describing the input and integrated storage of text, audio, and video data;
      <br/>
      FIGS. 3a-3d display a sample fill-out form for input of text data;
      <br/>
      FIG. 4 is a flow chart describing the initiation of queries and the dynamic, selective display of the search results at remote locations; and
      <br/>
      FIG. 5 displays a sample search fill-out form for the input of queries at remote locations.
      <br/>
      FIG. 6 displays a sample formatted page 600 of the search results.
      <br/>
      FIG. 7 displays a sample focus page 700 of the selected result.
      <br/>
      FIG. 8 displays a sample resume page 800 associated with the selected result.
    </p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT</heading>
    <p num="17">
      The present invention is an automated system to input text and video data, to store the data at a central location, to initiate queries of search criteria to the central location from remote locations, and to selectively transmit text and video data to the remote locations in accordance with the search criteria.
      <br/>
      Accordingly, the present invention provides a system for multimedia data storage and dynamic selective retrieval of multimedia data in accordance with specified search criteria.
    </p>
    <p num="18">
      Without limitation, the system and method of the present invention can be explained within the context of an employment service called REZVU.SM.. REZVU.SM. inputs text and audio/video data from employment candidates and stores this data in a database at a central location.
      <br/>
      REZVU.SM. inputs search criteria from employers seeking employment candidates and performs a corresponding search of the database.
      <br/>
      REZVU.SM. displays text and audio/video data for the employment candidates matching the search criteria.
    </p>
    <p num="19">
      While the present invention will be explained within the context of an employment service, it is apparent to one of ordinary skill in the art that the present invention can be applied to any application which would benefit from the storage of text and audio/video data and the selective retrieval of the data which matches specified search criteria.
      <br/>
      For example, the present invention could be used in a real estate system by a buyer to view text and video data on available residences which match the buyer's requirements on price, cost, tax, location, school district, floor space, yard size, etc.
      <br/>
      Also, the present invention could be used in an athletic scouting service for viewing text and video data on available high school, college or professional athletes which match criteria on height, weight, age, athletic achievements such as basketball shooting percentage, baseball batting average, baseball fielding percentage, hockey goals, etc.
    </p>
    <p num="20">
      FIG. 1 is a block diagram showing the major operational elements of the invention.
      <br/>
      A text input utility 108 executing on the central server 106 defines fill-out forms, processes the data specified on the fill-out forms and stores the data in a database 110.
      <br/>
      Preferably, the format of the fill-out forms to input the text data is specified with the HyperText Markup Language (HTML).
      <br/>
      HTML is a collection of platform-independent styles that define the various components of a World Wide Web document as specified in "A Beginner's Guide to HTML", The National Center for Supercomputing Applications, University of Illinois at Urbana-Champaign, Dec. 10, 1997, webmaster@ncsa.uiuc.edu, the contents of which are herein incorporated by reference.
    </p>
    <p num="21">
      Preferably, the text input utility 108 is a script executing on the central server 106.
      <br/>
      An exemplary scripting tool is Cold Fusion.
      <br/>
      Cold Fusion is a Web application tool for creating dynamic-page applications and interactive Web sites by combining standard HTML files with Cold Fusion Markup Language (CFML) tags as specified in "Cold-Fusion", http://www.allaire.com/services, the contents of which are herein incorporated by reference.
      <br/>
      Alternatively, the text input utility 108 is a program written in a language which manipulates text, files, and information, executing on the central server 106.
      <br/>
      An exemplary language is Perl as specified in, Programming Perl, Larry Wall and Randal L. Schwartz, O'Reilly &amp; Associates, Inc., March 1992 ("Programming Perl"), the contents of which are herein incorporated by reference.
    </p>
    <p num="22">
      Exemplary databases 110 include: Microsoft SQL Server, Microsoft Access 1.0, 2.0 and 7.0, Microsoft FoxPro 2.0, 2.5 and 2.6, Oracle 7.0, Borland Paradox 3.X and 4.X, Borland dBase III and dBase IV, and Microsoft Excel 3.0, 4.0 and 5 0 (slashed zero)  Cold Fusion is compatible with the Microsoft ODBC (Open Database Connectivity) Desktop Drivers which includes support for these databases 110.
      <br/>
      Cold Fusion, pg 4.
    </p>
    <p num="23">
      The audio/video encoder 133 inputs audio/video signals.
      <br/>
      For example, the audio/video encoder 133 can input audio/video signals from a Video Cassette Recorder (VCR) 130. Preferably, the audio/video encoder 133 is a workstation having a video card and an audio card to digitize video signals and to digitize audio signals respectively.
    </p>
    <p num="24">
      The extraction utility 112 transfers the data from the database 110 to a bulk insert file (bif) 114. A style file 116 defines the format of the bif 114.
      <br/>
      An indexing utility 118 transforms the data from the bif 114 to an indexed collection 120 which can be accessed by a search engine 128.
      <br/>
      Preferably, the search engine 128 is Verity available from Verity, Inc. as described in, "Introduction to Verity Search Technology", http://www.verity.com/support/, the contents of which are herein incorporated by reference.
      <br/>
      Preferably, the style file 116, the indexing utility 118, the indexed collection 120, the query filter 140, and the search engine 128 reside on the collection server 122.
      <br/>
      The Verity Information Server architecture allows seamless communication with the central server 106.
      <br/>
      Exemplary communication protocols include NSAPI for Netscape Servers, ISAPI for Microsoft Internet Information Server and CGI for other servers as the Verity Information Server architecture supports these communication protocols.
      <br/>
      Preferably, the indexing utility 118 for use with Verity is mkvdk.
    </p>
    <p num="25">
      A query filter 140 executing on the collection server 122 defines fill-out forms and processes the search criteria specified on the fill-out forms to create queries for the collection server 126.
      <br/>
      Preferably, a script executing on the central server 106 processes the search criteria.
      <br/>
      Preferably, the scripting language is Verity SEARCHScript.
      <br/>
      SEARCHScript provides a common framework for developing Web applications with different applications.
      <br/>
      For example, SEARCHScript lets you customize search result displays with commands to access the next page or the next document. (See "Introduction to Verity Search Technology", pg 4.).
      <br/>
      Alternatively, a program written in a language which manipulates text, files, and information, processes the search criteria on the central server 106.
      <br/>
      An exemplary language is Perl.
      <br/>
      See Programming Perl.
    </p>
    <p num="26">
      The Verity query language supports a standard full text query or a query by example.
      <br/>
      The standard full-text query ranges from a simple one-word query to a complex query expression.
      <br/>
      The various kinds of full-text queries include a single word, a phrase where the two words must be found together in the document, multiple words separated by simple boolean operators (AND, OR), zone (i.e. title, author, etc.) queries and multiple words separated by advanced operators (i.e. &lt;PARAGRAPH&gt;).
      <br/>
      The query by example allows searchers to cut and paste a few lines or a paragraph of text from a document.
      <br/>
      See "Introduction to Verity Search Technology".
      <br/>
      The query filter 140 may restrict the queries to a specific indexed collection 120.
      <br/>
      Preferably, the query filter 140 is the Verity Server Component called Query Filter.
    </p>
    <p num="27">
      The search engine 128 searches the indexed collection 120 in accordance with the queries from the query filter 140.
      <br/>
      Before performing the search, the search engine 128 optimizes the queries as specified in Database System Concepts, Henry F. Korth, Abraham Silberschatz, McGraw-Hill 1986, Chapter 9, the contents of which are herein incorporated by reference.
      <br/>
      Preferably, the search engine 128 is the Verity Search '97 Information Server.
    </p>
    <p num="28">
      The search display utility 124 displays the search results text data at the remote client sites 102.
      <br/>
      The search display utility 124 uses a scripting language to display the search results text data.
      <br/>
      Preferably, the scripting language is Verity SEARCHScript.
      <br/>
      SEARCHScirpt provides a common framework for developing Web applications with different applications.
      <br/>
      For example, SEARCHScript lets you customize search result displays with commands to access the next page or the next document. (See "Introduction to Verity Search Technology", pg 4.).
    </p>
    <p num="29">
      Preferably, the present invention displays the audio/video data associated with the search results using an on-demand video and audio streaming server.
      <br/>
      Preferably, the streaming server is RealServer (tm)  as explained in "RealServer Administration and Content Creation Guide", the contents of which are herein incorporated by reference.
      <br/>
      The Web Browser 134 executing on the remote clients 102 displays the web pages from the central server 106 including the fill-out form for data input, the fill-out form for input of search criteria and the search results text data.
      <br/>
      The Web page containing the search results text data contains a link to a metafile.
      <br/>
      The Web Browser 134 executing on the remote clients 102 requests the metafile from the central server 106 when the user clicks the link to the metafile.
    </p>
    <p num="30">
      The search display utility 124 delivers the metafile to the Web browser 134.
      <br/>
      If the metafile has a .ram file extension, the search display utility 124 sets the MIME type of the file to "audio/x-pn-RealAudio".
      <br/>
      If the metafile has a rpm file extension, the search display utility 124 sets the MIME type of the file to "video/x-pn-RealVideo-plugin" or "audio/x-pn-RealAudio-plugin".
      <br/>
      See RealServer Administration and Content Creation Guide, pg 18.
    </p>
    <p num="31">
      The Web browser 134 starts up the helper application 136 upon encountering a metafile with a ram file extension or a rpm file extension.
      <br/>
      Preferably, the helper application 136 is the RealPlayer, available from Real Networks Inc.
      <br/>
      The RealPlayer helper application 136 reads the first URL from the metafile and requests it from the audio/video server 132.
      <br/>
      Preferably, the audio/video server 132 is the RealServer, available from Real Networks Inc.
      <br/>
      The RealServer audio/video server 132 streams the requested video or audio clip to the RealPlayer helper application 136.
    </p>
    <p num="32">
      The applications executing on the remote clients 102 communicate with the applications executing on the central server 106 via the communication network 104.
      <br/>
      Preferably, the communication network 104 is the World Wide Web.
    </p>
    <p num="33">As shown in FIG. 1, the present invention can contain a plurality of remote client sites 102, a plurality of audio/video servers 132, a plurality of central servers 126 and a plurality of collection servers 126 to support higher capacity requirements.</p>
    <p num="34">
      FIGS. 3a-3d displays a sample fill-out form 300 for input of text data.
      <br/>
      In the preferred embodiment, the sample fill-out form contains the following fields:
    </p>
    <p num="35">Name 310: This field specifies the first name, middle initial and last name of the candidate seeking employment.</p>
    <p num="36">Address 312: This field specifies the street address, city, state and zip code of the candidate seeking employment.</p>
    <p num="37">Telephone and Fax Numbers 314: This field specifies the phone number, an alternate phone number and a facsimile number of the candidate seeking employment.</p>
    <p num="38">Email 316: This field contains the email address of the candidate seeking employment.</p>
    <p num="39">Personal URL 318: This field contains the personal URL of the candidate seeking employment.</p>
    <p num="40">
      Private 320: This field contains the privacy preference of the candidate seeking employment.
      <br/>
      If the candidate answers "Yes" to the privacy question, the employment search system will not return the candidate's data to search queries.
      <br/>
      Instead, the employment search system will only reveal the candidate's data to entities which have the candidate's identification number.
      <br/>
      Accordingly, the candidate can limit access to the candidate's data to a select number of entities by answering "Yes" to the privacy question and by revealing the identification number only to those select number of entities.
    </p>
    <p num="41">Next Page 322: This field contains an HTML link to the next page in the fill-out form 300.</p>
    <p num="42">Associates Degree 324: This field identifies associates degree information for the candidate seeking employment including the school, the major, the year and the grade point average (GPA).</p>
    <p num="43">Bachelor Degree 326: This field identifies bachelor degree information for the candidate seeking employment including the school, the major, the year and the GPA.</p>
    <p num="44">Master Degree 328: This field identifies masters degree information for the candidate seeking employment including the school, the major, the year and the GPA.</p>
    <p num="45">Doctorate Degree 330: This field identifies doctorate degree information for the candidate seeking employment including the school, the major and the year.</p>
    <p num="46">Foreign Languages 332: This field identifies the foreign language knowledge of the candidate seeking employment.</p>
    <p num="47">Professional Certifications 334: This field identifies the professional certifications of the candidate seeking employment.</p>
    <p num="48">Next Page 336: This field contains an HTML link to the next page in the fill-out form 300.</p>
    <p num="49">Commitment Interest 338: This field specifies whether the candidate is seeking full-time employment, part-time employment or both.</p>
    <p num="50">Field 340: This field specifies the field of interest of the candidate seeking employment.</p>
    <p num="51">Experience 342: This field specifies the number of years of experience of the candidate seeking employment in the specified field 340.</p>
    <p num="52">Level 344: This field specifies the employment level sought by the candidate.</p>
    <p num="53">Salary 346: This field specifies the salary requirement of the candidate seeking employment.</p>
    <p num="54">Travel 348: This field specifies the travel limitations of the candidate seeking employment.</p>
    <p num="55">Relocation 350: This field specifies whether the candidate seeking employment is willing to relocate.</p>
    <p num="56">Availability 352: This field specifies when the candidate seeking employment will be available to begin work.</p>
    <p num="57">Actively Looking 354: This field indicates whether the candidate seeking employment is actively looking or is willing to consider a new opportunity.</p>
    <p num="58">Major Accomplishments 356: This field identifies the major accomplishments of the candidate seeking employment in addition to the accomplishments previously specified in the fill-out form 300.</p>
    <p num="59">Next Page 357: This field contains an HTML link to the next page in the fill-out form 300.</p>
    <p num="60">Resume 358: This field includes the resume for the candidate seeking employment.</p>
    <p num="61">
      Preferably, the indexed collection 120 in Verity comprises two sets of tables.
      <br/>
      The first set of tables corresponds to specialized fields which are explicitly requested in the fill-out form 300.
      <br/>
      The second set of tables corresponds to data from the resume of the candidate seeking employment.
    </p>
    <p num="62">
      FIG. 2 is a flow chart describing the input and integrated storage of text, audio, and video data.
      <br/>
      In step 202, the text input utility 108 executing on the central server 106 processes the fill-out forms which are displayed on a remote client 102 by the Web Browser 134 and stores the data in a database 110.
      <br/>
      Similarly, in step 204, the text input utility 108 executing on the central server 106 processes free format text data such as a resume and stores the data in a text file.
    </p>
    <p num="63">After the candidate employee registers by sending a registration form, the service fee and an audio/video recording to REZVU.SM., the audio/video server 132 inputs the audio/video data and processes the audio/video data to create digitized audio and digitized video files in step 206.</p>
    <p num="64">
      In step 208, the extraction utility 112 assembles the text data from the database 110 for all registered candidates into the bulk insert file 114 in accordance with the format defined by the style file 116.
      <br/>
      The extraction utility 112 also provides a reference in the bulk insert file 114 to the resume text file in step 208.
      <br/>
      Next, in step 212, the indexing utility 118, using the style file 116, transforms the data from the bif 114 to an indexed collection 120 which can be accessed by the search engine 128.
    </p>
    <p num="65">
      FIG. 5 displays a sample search fill-out form 500 for input of queries at remote locations.
      <br/>
      In the preferred embodiment, the search fill-out form 500 contains the following fields:
    </p>
    <p num="66">Profession 502: This field specifies the profession which is desired by the employer seeking employment candidates.</p>
    <p num="67">State 504: This field specifies the state of the business location where the employer seeks employment candidates.</p>
    <p num="68">Relocate 506: This field specifies whether the employer is willing to relocate employment candidates.</p>
    <p num="69">Level 508: This field specifies the employment level which is desired by the employer seeking employment candidates.</p>
    <p num="70">Years of Experience 510: This field specifies the amount of experience which is desired by the employer seeking employment candidates.</p>
    <p num="71">Salary Range 512: This field specifies the salary range which is desired by the employer seeking employment candidates.</p>
    <p num="72">Degree 514: This field specifies the level of education which is desired by the employer seeking employment candidates.</p>
    <p num="73">Associate Degree 516: This field specifies the associates degree which is desired by the employer seeking employment candidates.</p>
    <p num="74">Bachelor Degree 518: This field specifies the bachelors degree which is desired by the employer seeking employment candidates.</p>
    <p num="75">Foreign Languages 520: This field specifies the foreign language skills which are desired by the employer seeking employment candidates.</p>
    <p num="76">Travel 522: This field specifies the travel requirements of the employer seeking employment candidates.</p>
    <p num="77">Desired Employment 524: This field specifies whether the employer is seeking candidate employees for full-time employment, part time employment, independent contractor employment or all types of employment.</p>
    <p num="78">Resume Time Period 526: This field specifies the resume dates of interest to the employer seeking candidate employees.</p>
    <p num="79">Video Requirement 528: This field specifies whether the employer is interested in candidates who do not have a video stored within the employment system.</p>
    <p num="80">Keywords 530: This field contains either a standard full text query or a query by example.</p>
    <p num="81">
      Candidate's User Id 532: This field specifies the user id of the candidate seeking employment.
      <br/>
      The field can be used by employers who have obtained the candidate's user id from the candidate.
      <br/>
      Accordingly, the field enables select employers to access data for candidates who have specified the Private option 320.
    </p>
    <p num="82">Search 534: This field executes the search based on the search criteria input by the user.</p>
    <p num="83">
      FIG. 4 is a flow chart describing the initiation of queries and the dynamic, selective display of the search results at remote locations.
      <br/>
      In step 402, the query filter 140 executing on the central server 106 defines search fill-out forms 500 (FIG. 5) which are displayed on a remote client 102 by the Web Browser 134.
      <br/>
      As previously explained by the discussion of FIG. 5, the search fill-out form 500 contains fields corresponding to the specialized fields of the text fill-out form 300 (502-528) and a field corresponding to resume data (530).
      <br/>
      In step 404, the query filter 140 processes the search criteria specified on the search fill-out forms 500 for both the specialized fields 502-528 and the resume data 530 to create queries for the collection server 126.
    </p>
    <p num="84">
      Next, the query filter 140 may restrict the queries to a specific indexed collection 120 in step 406.
      <br/>
      Accordingly, the query filter 140 may restrict the query within REZVO.SM. to prevent searching of text data associated with employment candidates who specified the Private option 320 on the text fill-out form 300.
    </p>
    <p num="85">
      After the employer seeking candidate employees hits the search HTML link 534 on the search fill-out form 500, a search engine 128 searches the indexed collection 120 in accordance with the specified search criteria in step 410.
      <br/>
      Before performing the search, the search engine 128 parses and optimizes the queries.
      <br/>
      See Database System Concepts, Chapter 9.
    </p>
    <p num="86">
      In step 412, the search display utility 124 forms the search results 600 (FIG. 6) which are displayed on a remote client 102 by the Web Browser 134.
      <br/>
      In step 413, the search display utility 124 and the Web browser operate to display a candidate focus page 700 for the candidate selected by the user (FIG. 7).
      <br/>
      In step 414, the search display utility 124 and the Web browser 134 operate to display the resume of the candidate selected by the user (FIG. 8) when the user clicks a resume link.
      <br/>
      In step 415, the search display utility 124, the Web browser 134, the helper application 136, and the audio/video server 132 operate to play the video and audio data associated with the displayed text data when the user clicks an audio/video link.
    </p>
    <p num="87">
      FIG. 6 displays a sample formatted page 600 of the search results.
      <br/>
      Preferably, the search results 600 contains the following fields:
    </p>
    <p num="88">Result Summary 602: This field identifies the number of employment candidates which met the search criteria and the number of employment candidates which are displayed on the search results 600.</p>
    <p num="89">focus link 604: This field contains a link to the candidate focus page 700 (FIG. 7).</p>
    <p num="90">Associates Degree 606: This field specifies the academic record of the employment candidate's Associates Degree including the major, graduation year, school, and grade point average.</p>
    <p num="91">Bachelors 608: This field specifies the academic record of the employment candidate's Bachelor's Degree including the major, graduation year, school, and grade point average.</p>
    <p num="92">Masters 610: This field specifies the academic record of the employment candidate's Master's Degree including the major, graduation year, school, and grade point average.</p>
    <p num="93">Doctorate 612: This field specifies the academic record of the employment candidate's Doctorate's Degree including the major, graduation year, school, and grade point average.</p>
    <p num="94">Certifications 614: This field specifies the certifications of the employment candidate which could include a license to practice law, to prosecute patent applications before the Pat. and Trademark Office, a Certified Public Accountant, etc.</p>
    <p num="95">Desired Salary Range 616: This field specifies the salary range which is desired by the employment candidate.</p>
    <p num="96">Desired Employment 618: This field specifies whether the employment candidate is seeking candidate a full-time position, a part-time position or an independent contractor position.</p>
    <p num="97">Travel 620: This field specifies the percentage of time which the employment candidate is willing to travel.</p>
    <p num="98">Years of Experience 622: This field specifies the amount of experience of the employment candidate.</p>
    <p num="99">Relocate 624: This field specifies whether the employment candidate is willing to relocate for employment.</p>
    <p num="100">Major Career Accomplishments 626: This field specifies the major career accomplishments of the employment candidate.</p>
    <p num="101">
      FIG. 7 displays a sample candidate focus page 700 of the selected result.
      <br/>
      Preferably, the candidate focus page 700 contains the following fields:
    </p>
    <p num="102">Name and Personal Data 702: This field contains the selected candidate's name, address, phone number, fax number, email address, personal URL and REZVU.SM. system number.</p>
    <p num="103">audio/video link 704: This field contains a link to play the audio and video associated with the employment candidate.</p>
    <p num="104">Associates Degree 706: This field specifies the academic record of the employment candidate's Associates Degree including the major, graduation year, school, and grade point average.</p>
    <p num="105">Bachelors 708: This field specifies the academic record of the employment candidate's Bachelor's Degree including the major, graduation year, school, and grade point average.</p>
    <p num="106">Masters 710: This field specifies the academic record of the employment candidate's Master's Degree including the major, graduation year, school, and grade point average.</p>
    <p num="107">Doctorate 712: This field specifies the academic record of the employment candidate's Doctorate's Degree including the major, graduation year and school.</p>
    <p num="108">Certifications 714: This field specifies the certifications of the employment candidate which could include a license to practice law, to prosecute patent applications before the Patent and Trademark Office, a Certified Public Accountant, etc.</p>
    <p num="109">Desired Salary Range 716: This field specifies the salary range which is desired by the employment candidate.</p>
    <p num="110">Desired Employment 718: This field specifies whether the employment candidate is seeking candidate a full-time position, a part-time position or an independent contractor position.</p>
    <p num="111">Travel 720: This field specifies the percentage of time which the employment candidate is willing to travel.</p>
    <p num="112">Years of Experience 722: This field specifies the amount of experience of the employment candidate.</p>
    <p num="113">Relocate 724: This field specifies whether the employment candidate is willing to relocate for employment.</p>
    <p num="114">Field 726: This field specifies the employment candidate's field.</p>
    <p num="115">Level 728: This field specifies the level of the employment candidate.</p>
    <p num="116">Availability 730: This field specifies when the employment candidate will be available.</p>
    <p num="117">Actively Looking 732: This field specifies whether the employment candidate is actively looking.</p>
    <p num="118">resume link 704: This field contains a link to the employment candidate's resume.</p>
    <p num="119">
      FIG. 8 displays a sample resume page 800 associated with the selected result.
      <br/>
      Preferably, the resume page 800 contains the following fields:
    </p>
    <p num="120">Name and Personal Data 802: This field contains the selected candidate's name, address, phone number, fax number, email address, personal URL and REZVU.SM. system number.</p>
    <p num="121">resume 804: This field contains the resume of the employment candidate.</p>
    <p num="122">search results link 806: This field contains a link to return to the search results 600 (FIG. 6).</p>
    <p num="123">search link 808: This field contains a link to return to the search fill out form 500 (FIG. 5).</p>
    <p num="124">
      While the above invention has been described with reference to certain preferred embodiments, the scope of the present invention is not limited to these embodiments.
      <br/>
      One skilled in the art may find variations of these preferred embodiments which, nevertheless, fall within the spirit of the present invention, whose scope is defined by the claims set forth below.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria comprising:</claim-text>
      <claim-text>one or more servers comprising:</claim-text>
      <claim-text>- at least one input utility for inputting text, audio, and video data wherein said text data comprises:</claim-text>
      <claim-text>-  predefined text data;</claim-text>
      <claim-text>and -  free format text data; - at least one database collection for integrated storing of said text, audio, and video data wherein said at least one input utility stores said text, and video data in said at least one indexed collection; - at least one search system for inputting search criteria and for searching said database collection for said text, audio, and video data matching said search criteria; - at least one audio/video system for dynamically displaying said matching audio data and video data; at least one client for specifying said text, audio, video data and said search criteria and for viewing said text, audio, and video data;</claim-text>
      <claim-text>and a communication network for communication between said one or more servers and said at least one client.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 1 wherein said at least one input utility further comprises: an audio/video input system for inputing said audio data and said video data;</claim-text>
      <claim-text>and a text input utility for inputing said text data.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 2 wherein said audio/video input system further comprises a video card for digitizing said audio and video data.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 2 wherein said text input utility further comprises: a text processing utility for inputing said text data to a database; an extraction utility for assembling said text data from said database to a bulk insert file;</claim-text>
      <claim-text>and an indexing utility for organizing said text data from said bulk insert file and said audio and video data into said at least one indexed collection.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 4 further comprising a style file for defining a format of said bulk insert file.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 4 wherein said text processing utility inputs said text data from a data input fill-out form.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 6 wherein a hypertext mark up language defines a format of said data input fill-out form.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 6 wherein said text processing utility is a script for manipulating said text data.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 6 wherein said text processing utility is a program for manipulating said text data.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 1 wherein said search system further comprises: a query filter for parsing said search criteria and creating corresponding queries and for restricting said corresponding queries to predetermined data of said text, audio and visual data; a search engine for searching said at least one indexed collection for said search criteria;</claim-text>
      <claim-text>and a search display utility for displaying said text, audio, and video data matching said search criteria.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 10 wherein said search engine searches said at least one indexed collection by executing said corresponding queries from said query filter.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 10 wherein said query filter parses said search criteria from a search fill-out form.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 12 wherein a hypertext mark up language defines a format of said search fill-out form.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 12 wherein said query filter further comprises a script for manipulating said search criteria.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 12 wherein said query filter further comprises a program for manipulating said search criteria.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 1 wherein said communication network is the World Wide Web.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 1 wherein said indexed collection comprises: at least one first table corresponding to said predefined text data;</claim-text>
      <claim-text>and at least one second table corresponding to said free format text data.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. A system for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 1 wherein: said predefined text data is data associated with an employment candidate; said free format text data is resume data;</claim-text>
      <claim-text>and said audio and video data is an audio/visual recording of the employment candidate.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria comprising the steps of: inputing text, audio and video data with at least one input utility executing on one or more servers comprising the step of: - partitioning the text data into predefined text data and free format text data; integrated storing of said text, audio, and video data in at least one indexed collection with the at least one input utility; inputing search criteria and searching the indexed collection for the text, audio, and video data matching the search criteria with at least one search system; dynamically displaying the matching audio data and video data with at least one audio/video system; specifying the text, audio, and video data and the search criteria with at least one client; viewing the matching text, audio, and video data with the at least one client;</claim-text>
      <claim-text>and communicating between the one or more servers and the at least one client with a communication network.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 19 wherein said inputing text, audio and video data step further comprises the steps of: inputing the audio data and the video data with an audio/video input system;</claim-text>
      <claim-text>and inputing the text data with a text input utility.</claim-text>
    </claim>
    <claim num="21">
      <claim-text>21. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 20 wherein said inputing the audio data and the video data step further comprises the step of digitizing the audio and video data with an audio/video card.</claim-text>
    </claim>
    <claim num="22">
      <claim-text>22. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 20 wherein said inputing the text data step further comprises the steps of: inputing the text data to a database with a text processing utility; assembling the text data from the database to a bulk insert file with an extraction utility;</claim-text>
      <claim-text>and organizing the text data from the bulk insert file and the audio and video data into the at least one indexed collection with an indexing utility.</claim-text>
    </claim>
    <claim num="23">
      <claim-text>23. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 22 wherein said assembling the text data step further comprises the step of defining a format of the bulk insert file with a style file.</claim-text>
    </claim>
    <claim num="24">
      <claim-text>24. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 22 wherein said inputing said text data step inputs the text data from a data input fill out form.</claim-text>
    </claim>
    <claim num="25">
      <claim-text>25. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 24 wherein said inputing the text data step further comprises the step of defining a format of the data input fill out form with a hypertext mark up language.</claim-text>
    </claim>
    <claim num="26">
      <claim-text>26. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 24 wherein said inputing the text data step further comprises the step of manipulating the text data with a script.</claim-text>
    </claim>
    <claim num="27">
      <claim-text>27. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 24 wherein said inputing the text data step further comprises the step of manipulating the text data with a program.</claim-text>
    </claim>
    <claim num="28">
      <claim-text>28. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 19 wherein said inputing search criteria and searching the indexed collection step further comprises the steps of: parsing the search criteria and creating corresponding queries with a query filter; restricting the corresponding queries to predetermined data of the text, audio and visual data with the query filter; searching the at least one indexed collection for the search criteria with a search engine;</claim-text>
      <claim-text>and displaying the text, audio, and video data matching the search criteria with a search display utility.</claim-text>
    </claim>
    <claim num="29">
      <claim-text>29. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 28 wherein said searching said at least one indexed collection further comprises the step of executing the corresponding queries from the query filter.</claim-text>
    </claim>
    <claim num="30">
      <claim-text>30. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 28 wherein said parsing the search criteria step parses the search criteria from a search fill-out form.</claim-text>
    </claim>
    <claim num="31">
      <claim-text>31. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 28 wherein said parsing the search criteria step further comprises the step of formatting the search fill out form with a hypertext mark up language.</claim-text>
    </claim>
    <claim num="32">
      <claim-text>32. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 19 wherein said communicating step uses the World Wide Web.</claim-text>
    </claim>
    <claim num="33">
      <claim-text>33. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 32 wherein said parsing the search criteria step further comprises the step of manipulating the search criteria with a script.</claim-text>
    </claim>
    <claim num="34">
      <claim-text>34. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 32 wherein said parsing the search criteria step further comprises the step of manipulating the search criteria with a program.</claim-text>
    </claim>
    <claim num="35">
      <claim-text>35. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 19 wherein said integrated storing of the text, audio, and video data further comprises the steps of: defining at least one first table corresponding to the predefined text data;</claim-text>
      <claim-text>and defining at least one second table corresponding to the free format text data.</claim-text>
    </claim>
    <claim num="36">
      <claim-text>36. A method for multimedia data storage and dynamic, selective retrieval of multimedia data in accordance with specified search criteria as in claim 19 wherein said inputted text, audio and video data further comprises the step of: associating the predefined text data with data about an employment candidate; defining the free format text data as resume data;</claim-text>
      <claim-text>and defining the audio and video data as an audio/visual recording of the employment candidate.</claim-text>
    </claim>
  </claims>
</questel-patent-document>