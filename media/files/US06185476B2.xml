<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06185476B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06185476</doc-number>
        <kind>B2</kind>
        <date>20010206</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6185476</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference family-id="26689270" extended-family-id="70107904">
      <document-id>
        <country>US</country>
        <doc-number>09093086</doc-number>
        <kind>A</kind>
        <date>19980608</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1998US-09093086</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>59973759</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>9308698</doc-number>
        <kind>A</kind>
        <date>19980608</date>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1998US-09093086</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>US</country>
        <doc-number>68886096</doc-number>
        <kind>A</kind>
        <date>19960731</date>
        <priority-linkage-type>1</priority-linkage-type>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1996US-08688860</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="3">
        <country>US</country>
        <doc-number>1695896</doc-number>
        <kind>P</kind>
        <date>19960506</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="3">
        <doc-number>1996US-60016958</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010206</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G05B  19/4097      20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>05</class>
        <subclass>B</subclass>
        <main-group>19</main-group>
        <subgroup>4097</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G05B  19/418       20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>05</class>
        <subclass>B</subclass>
        <main-group>19</main-group>
        <subgroup>418</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>G06Q  10/06        20120101A I20150218RMEP</text>
        <ipc-version-indicator>
          <date>20120101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>Q</subclass>
        <main-group>10</main-group>
        <subgroup>06</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20150218</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>G06T   7/40        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>7</main-group>
        <subgroup>40</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="5">
        <text>G06T  17/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>17</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="6">
        <text>G06T  19/00        20110101A I20140524RMEP</text>
        <ipc-version-indicator>
          <date>20110101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>19</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20140524</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>700182000</text>
        <class>700</class>
        <subclass>182000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>072379200</text>
        <class>072</class>
        <subclass>379200</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>072389100</text>
        <class>072</class>
        <subclass>389100</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>700083000</text>
        <class>700</class>
        <subclass>083000</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>700145000</text>
        <class>700</class>
        <subclass>145000</subclass>
      </further-classification>
      <further-classification sequence="5">
        <text>700163000</text>
        <class>700</class>
        <subclass>163000</subclass>
      </further-classification>
      <further-classification sequence="6">
        <text>700165000</text>
        <class>700</class>
        <subclass>165000</subclass>
      </further-classification>
      <further-classification sequence="7">
        <text>700179000</text>
        <class>700</class>
        <subclass>179000</subclass>
      </further-classification>
      <further-classification sequence="8">
        <text>700180000</text>
        <class>700</class>
        <subclass>180000</subclass>
      </further-classification>
      <further-classification sequence="9">
        <text>715964000</text>
        <class>715</class>
        <subclass>964000</subclass>
      </further-classification>
      <further-classification sequence="10">
        <text>715965000</text>
        <class>715</class>
        <subclass>965000</subclass>
      </further-classification>
      <further-classification sequence="11">
        <text>715966000</text>
        <class>715</class>
        <subclass>966000</subclass>
      </further-classification>
      <further-classification sequence="12">
        <text>715967000</text>
        <class>715</class>
        <subclass>967000</subclass>
      </further-classification>
    </classification-national>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-019/00</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>19</main-group>
        <subgroup>00</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G05B-019/4097</classification-symbol>
        <section>G</section>
        <class>05</class>
        <subclass>B</subclass>
        <main-group>19</main-group>
        <subgroup>4097</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G05B-019/4181</classification-symbol>
        <section>G</section>
        <class>05</class>
        <subclass>B</subclass>
        <main-group>19</main-group>
        <subgroup>4181</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06Q-010/06</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>Q</subclass>
        <main-group>10</main-group>
        <subgroup>06</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="CPC">
          <date>20170101</date>
        </classification-scheme>
        <classification-symbol>G06T-007/41</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>7</main-group>
        <subgroup>41</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170102</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="6">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2200/24</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2200</main-group>
        <subgroup>24</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150303</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="7">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2207/30136</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2207</main-group>
        <subgroup>30136</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="8">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2219/028</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2219</main-group>
        <subgroup>028</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150303</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="9">
        <classification-scheme office="EP" scheme="CPC">
          <date>20151101</date>
        </classification-scheme>
        <classification-symbol>Y02P-090/06</classification-symbol>
        <section>Y</section>
        <class>02</class>
        <subclass>P</subclass>
        <main-group>90</main-group>
        <subgroup>06</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20151126</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="10">
        <classification-scheme office="EP" scheme="CPC">
          <date>20151101</date>
        </classification-scheme>
        <classification-symbol>Y02P-090/20</classification-symbol>
        <section>Y</section>
        <class>02</class>
        <subclass>P</subclass>
        <main-group>90</main-group>
        <subgroup>20</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20151204</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="11">
        <classification-scheme office="EP" scheme="CPC">
          <date>20151101</date>
        </classification-scheme>
        <classification-symbol>Y02P-090/265</classification-symbol>
        <section>Y</section>
        <class>02</class>
        <subclass>P</subclass>
        <main-group>90</main-group>
        <subgroup>265</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20151204</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="12">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>Y10S-715/964</classification-symbol>
        <section>Y</section>
        <class>10</class>
        <subclass>S</subclass>
        <main-group>715</main-group>
        <subgroup>964</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130518</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="13">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>Y10S-715/965</classification-symbol>
        <section>Y</section>
        <class>10</class>
        <subclass>S</subclass>
        <main-group>715</main-group>
        <subgroup>965</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130518</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="14">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>Y10S-715/966</classification-symbol>
        <section>Y</section>
        <class>10</class>
        <subclass>S</subclass>
        <main-group>715</main-group>
        <subgroup>966</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130518</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="15">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>Y10S-715/967</classification-symbol>
        <section>Y</section>
        <class>10</class>
        <subclass>S</subclass>
        <main-group>715</main-group>
        <subgroup>967</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130518</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>30</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>68</number-of-drawing-sheets>
      <number-of-figures>96</number-of-figures>
      <image-key data-format="questel">US6185476</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Apparatus and method for managing and distributing design and manufacturing information throughout a sheet metal production facility</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>JONES EVERETT E, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4998206</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4998206</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>TANG SING C, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5463558</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5463558</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>ITO SHUNITSU</text>
          <document-id>
            <country>US</country>
            <doc-number>5706711</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5706711</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>HIRAI HAYAO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5815400</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5815400</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>BOURNE DAVID ALAN, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5969973</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5969973</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="6">
          <text>AOYAMA YOSHITADA, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4912644</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4912644</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="7">
          <text>SARTORIO FRANCO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5005394</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5005394</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="8">
          <text>WAKAHARA TAKASHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5029462</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5029462</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="9">
          <text>LEE MARK S, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5089970</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5089970</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="10">
          <text>WATANABE KOTARO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5115400</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5115400</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>ROBERTS ANDREW F, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5237647</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5237647</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="12">
          <text>MIZUKAMI YUTO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5276606</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5276606</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="13">
          <text>KIENZLE KENT H, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5297054</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5297054</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="14">
          <text>CONRADSON SCOTT A, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5307282</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5307282</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="15">
          <text>KASAGAMI FUMIO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5315222</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5315222</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="16">
          <text>KAUFFMAN KENNETH A, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5315522</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5315522</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="17">
          <text>ULRICH KARL T, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5396265</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5396265</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="18">
          <text>HARLOW JR ALBERT L, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5429682</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5429682</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="19">
          <text>KOKO BOMA R, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5434791</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5434791</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="20">
          <text>WRIGHT MICHAEL R, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5453933</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5453933</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="21">
          <text>LECLAIR STEVEN R, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5485390</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5485390</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="22">
          <text>VOLL ROBERT, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5551028</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5551028</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="23">
          <text>SEBASTIAN DONALD H</text>
          <document-id>
            <country>US</country>
            <doc-number>5552995</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5552995</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="24">
          <text>CONRADSON SCOTT A, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5587914</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5587914</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="25">
          <text>NORTHROP CORP</text>
          <document-id>
            <country>EP</country>
            <doc-number>0290809</doc-number>
            <kind>A2</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-290809</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="26">
          <text>HEWLETT PACKARD GMBH</text>
          <document-id>
            <country>EP</country>
            <doc-number>0397904</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-397904</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="27">
          <text>FANUC LTD</text>
          <document-id>
            <country>EP</country>
            <doc-number>0402475</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-402475</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="28">
          <text>HEWLETT PACKARD CO</text>
          <document-id>
            <country>EP</country>
            <doc-number>0419013</doc-number>
            <kind>A2</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-419013</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="29">
          <text>AMERICA BIOMECHANICS CORP</text>
          <document-id>
            <country>EP</country>
            <doc-number>0485766</doc-number>
            <kind>A2</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-485766</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="30">
          <text>OMRON TATEISI ELECTRONICS CO</text>
          <document-id>
            <country>EP</country>
            <doc-number>0664186</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-664186</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="31">
          <text>AMADA CO LTD</text>
          <document-id>
            <country>JP</country>
            <doc-number>H01309728</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP01309728</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="32">
          <text>AMADA CO LTD</text>
          <document-id>
            <country>JP</country>
            <doc-number>H01309727</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP01309727</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="33">
          <text>AMADA CO LTD</text>
          <document-id>
            <country>JP</country>
            <doc-number>H0215827</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP02015827</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="34">
          <text>AMADA CO LTD</text>
          <document-id>
            <country>JP</country>
            <doc-number>H0215828</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP02015828</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="35">
          <text>EMORI RYUJI, et al</text>
          <document-id>
            <country>JP</country>
            <doc-number>H05216525</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP05216525</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="36">
          <text>NIPPON TELEGRAPH &amp; TELEPHONE</text>
          <document-id>
            <country>JP</country>
            <doc-number>H07121418</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP07121418</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="1">
          <text>An International Written Opinion issued in counterpart PCT Application No. PCT/US97/07473, on Sep. 28, 1998.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="2">
          <text>An International Written Opinion issued in counterpart PCT Application No. PCT/US97/07472, on Oct. 16, 1998.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="3">
          <text>An International Preliminary Examination Report issued in counterpart PCT Application No. PCT/US97/07474, on Nov. 20, 1998.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="4">
          <text>An English Language Abstract of JP 5-216525.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="5">
          <text>An English Language Abstract of JP 2-15828.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="6">
          <text>An English Language Abstract of JP 1-309727.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="7">
          <text>An English Language Abstract of JP 63-154220 which corresponds to JP 7-121418.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="8">
          <text>An English Language Abstract of JP 2-15827.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="9">
          <text>An English Language Abstract of JP 1-309728.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="10">
          <text>Chu et al., Wesley W., Coopertive Query Answering Via Type Abstraction Heirarchy, Computer Science Department Technical Report, CSD-900032, Department of Computer Science, University of California, Los Angeles, pp. 1-28 (Oct. 1990).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="11">
          <text>Chiang, Kuorong, Automatic Generation of Type Abstraction Hierarchies For Cooperative Query Answering (A dissertation submitted as part of the requirements for the degree of Doctor of Philosophy in Computer Science), University of California, Los Angeles, pp. 1-98 (1995).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="12">
          <text>Mortenson, Michael E., Geometric Modeling (Title Page &amp; Table of Contents), John Wiley &amp; Sons,New York, (1988).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="13">
          <text>Foley et al., James D.The Systems Programming Series: Fundamentals of Interactive Computer Graphics, (Title Page &amp; Table of Contents), Addison-Wesley Publishing Co., Reading, Massachusetts (Mar. 1983).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="14">
          <text>Mantyla, Martti, An Introduction To Solid Modeling (Title Page &amp; Table of Contents), Computer Science Press, Inc. Rockville, Maryland (1988).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="15">
          <text>Wesley et al., M.A., "Fleshing Out Projections", IBM J. Res. Develop., vol. 25, No. 6, pp. 934-954 (Nov. 1981).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="16">
          <text>Aomura et al., Shigeru, "Creating Solid Model With Machine Drawings", The Sixth Computational Mechanics Conference, JSME, No. 930-71, pp. 497-498, Japan (1983).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="17">
          <text>Aomura, Shigeru, "Recent Trends And Future Prospect of Research And Practical Use (Automatic Reconstruction of 3D Solid From Drawings", JSME, No. 586-61, pp. 2180-2187, Japan (1995).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="18">
          <text>Open GL Reference Manual (Title Page &amp; Table of Contents), Release 1,Open GL Architecture Review Board, Addison-Wesley Publishing Co., Reading, Massachusetts (Jan. 1995).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="19">
          <text>Open GL Programming Guide (Title Page &amp; Table of Contents),Release 1,Open GL Architecture Review Board, Addison-Wesley Publishing Co., Reading, Massachusetts (Jun. 1995).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="20">
          <text>RenderWare, API Reference Manual (Title Page &amp; Table of Contents), V2.0, Criterion Software Ltd., United Kingdom (Oct. 1995).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="21">
          <text>2D-3D: UNKEI/Solid and UNKEI/ Drawing Check &amp; Projection/Reconstruction System, Sales Brochure, Toyo Engineering Corp. (TEC), Tokyo, Japan (1993).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="22">
          <text>Naessens, Diederik, "Flexible Automation on Press Brakes", American Machinist, pp. 36-39 (Jun. 1994).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="23">
          <text>Wysong Literature, The Perfect Forming Touch: New, PH PLUS Series, DNC Press Brakes, Cat. PHP-1, Wysong &amp; Miles Company, Greensboro, North Carolina (1993).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="24">
          <text>Bourne, David A., "Intelligent Manufacturing Workstrations", Knowledge-Based Automation of Processes, Session at the 1992 ASME Winter Annual Meeting (Nov. 1992).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="25">
          <text>Wang, Cheng-Hua, "A Parallel Design System For Sheet Metal Parts", Mechanical Engineering Report, presented to the Mechanical Engineering Department, Carnegie Mellon University, Pittsburgh, Pennsylvania, pp. 1-31 (May 1992).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="26">
          <text>Wang et al., Cheng-Hua, "Concurrent Product/Process Design With Multiple Representations Parts", IEEE, No. 1050-4729/93, pp. 298-304 (1993).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="27">
          <text>Amada Unfold: Manual for Autocad, Table of Contents, Index &amp; pp. 1-18, U.S. Amada, Ltd., Buena Park, California (May 1994).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="28">
          <text>Amada Windows Unfold: Manual for Cadkey, Table of Contents &amp; pp. 1-28 U.S. Amada, Ltd., Buena Park, California (Nov. 1995).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="29">
          <text>AMACOM: AP40 Literature, Version 4, Amada Co., Ltd., Japan (Jul. 1996).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="30">
          <text>AMACOM: AP60 Literature, Amada Co., Ltd., Japan (Jul. 1996).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="31">
          <text>AMACOM: AP200 Literature, Amada Co., Ltd., Japan (Jul. 1996).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="32">
          <text>Bending Soft, Literature on the AMACOM AP40, No. 9112-01, Amada Co., Ltd., Japan (Publication Date Unknown).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="33">
          <text>Amada Windows Unfold: Manual for Cadkey, Table of Contents, pp. 1-35, &amp; Index, U.s. Amada, Ltd., Buena Park California (Nov. 1995).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="34">
          <text>"Method For Understanding Drawing Attributes For 3D Models", IBM Technical Disclosure Bulletin, vol. 37, No. 7, pp. 99-104 (Jul. 1994).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="35">
          <text>Tseng et al., Yuan-Jye, "Recognizing Multiple Interpretations Of Interacting Machining Features", Computer-Aided Design, vol. 26, No. 9, pp. 667-688 (Sep. 1994).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="36">
          <text>Gu et al., P. "Product Modelling Using STEP", Computer-Aided Design, vol. 27, No. 3, pp. 163-179 (Mar. 1995).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="37">
          <text>Trappey et al., "A Data Representation scheme For Sheet Metal Parts: Expressing Manufacture and Features and Tolerance Requirements"-Journal of Manufacturing Systems, vol. 14, No. 6, pp. 393-405, ISSN-0278-6125 (1995).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="38">
          <text>"Computer Dictionary"-Microsoft Press, 1994, pp. 133-226.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="39">
          <text>Papanikolopoulos, Nikolaos P., "FORS: A System For Flexible Design," Conference Proceedings: 1990 IEEE International Conference On Systems, Man, And Cybernetics, Nov. 4-7, 1990, Los Angeles, California, pp. 724-726.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="40">
          <text>Patent Abstracts of Japan, vol. 18, No. 689 (P-1850), Dec. 26, 1994.</text>
        </nplcit>
      </citation>
    </references-cited>
    <related-documents>
      <continuation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>68886096</doc-number>
              <kind>A</kind>
              <date>19960731</date>
            </document-id>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>5828575</doc-number>
              <kind>A</kind>
              <date>19981027</date>
            </document-id>
          </parent-doc>
        </relation>
      </continuation>
      <related-publication>
        <document-id>
          <country>US</country>
          <doc-number>60/016,958</doc-number>
          <date>19960506</date>
        </document-id>
        <document-id>
          <country>US</country>
          <doc-number>60/016958</doc-number>
          <date>19960506</date>
        </document-id>
      </related-publication>
    </related-documents>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Amada Soft America, Inc.</orgname>
            <address>
              <address-1>La Mirada, CA, US</address-1>
              <city>La Mirada</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>AMADA SOFT AMERICA</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Sakai, Satoshi</name>
            <address>
              <address-1>Newport Coast, CA, US</address-1>
              <city>Newport Coast</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Greenblum &amp; Bernstein, P.L.C.</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Gordon, Paul P.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      An apparatus and method is provided for managing and distributing design and manufacturing information throughout a factory in order to facilitate the production of components, such as bent sheet metal components.
      <br/>
      In accordance with an aspect of the present invention, the management and distribution of critical design and manufacturing information is achieved by storing and distributing the design and manufacturing information associated with each job.
      <br/>
      By replacing the traditional paper job set-up or work sheet with, for example, an electronically stored job sheet that can be accessed instantaneously from any location in the factory, the present invention improves the overall efficiency of the factory.
      <br/>
      In addition, through the various aspects and features of the invention, the organization and accessibility of part information and stored expert knowledge is improved.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>RELATED APPLICATION DATA</heading>
    <p num="1">
      This application is a continuation application of U.S. patent application Ser.
      <br/>
      No. 08/688,860 filed Jul. 31, 1996 now U.S. Pat. No. 5,828,575 issued Oct. 27, 1998, entitled "Apparatus and Method for Managing and Distributing Design and Manufacturing Information Throughout a Sheet Metal Production Facility," filed on Jul. 31, 1996, which claims the benefit of U.S. Provisional Application No. 60/016,958, filed May 6, 1996.
      <br/>
      The contents of U.S. patent application Ser.
      <br/>
      No. 08/688,860 and U.S. Provisional Application No. 60/016,958 are expressly incorporated herein by reference in their entireties.
    </p>
    <heading>COPYRIGHT NOTICE</heading>
    <p num="2">
      A portion of the disclosure of this patent document contains material which is subject to copyright protection.
      <br/>
      The copyright owner has no objection to the facsimile reproduction by anyone of the patent disclosure, as it appears in the U.S. Patent and Trademark Office patent files or records, but otherwise the copyright owner reserves all copyright rights whatsoever.
    </p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="3">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="4">
      The present invention generally relates to the field of manufacturing and to the production of components, such as sheet metal components.
      <br/>
      More particularly, the present invention relates to an apparatus and method for managing and distributing design and manufacturing information throughout a factory in order to facilitate the production of bent sheet metal components.
    </p>
    <p num="5">2. Background Information</p>
    <p num="6">
      Traditionally, the production of bent sheet metal components at, for example, a progressive sheet metal manufacturing facility, involves a series of production and manufacturing stages.
      <br/>
      The first stage is a design stage during which a sheet metal part design is developed based on a customer's specifications.
      <br/>
      A customer will typically place an order for a particular sheet metal component to be produced at the facility.
      <br/>
      The customer's order will usually include the necessary product and design information so that the component may be manufactured by the factory.
      <br/>
      This information may include, for example, the geometric dimensions of the part, the material required for the part (e.g., steel, stainless steel, or aluminum), special forming information, the batch size, the delivery date, etc.
      <br/>
      The sheet metal part requested by the customer may be designed and produced for a wide variety of applications.
      <br/>
      For example, the produced component may ultimately be used as an outer casing for a computer, an electrical switchboard, an armrest in an airplane, or part of a door panel for a car.
    </p>
    <p num="7">
      During the design stage, a sheet metal part design may be developed by the design office of the manufacturing facility using an appropriate Computer-Aided Design (CAD) system.
      <br/>
      Based on a customer's specifications, a 2-dimensional (2-D) model of the sheet metal part may be developed by a programmer with the CAD system.
      <br/>
      Typically, a customer will provided a blueprint containing one or more drawings of the component and the critical geometric dimensions of the part.
      <br/>
      The blueprint may also indicate any special forming or marking to be included in the part, as well as the location of holes or other types of openings on the surface(s) of the sheet metal part.
      <br/>
      The design programmer will often use this blueprint to develop a 2-D model on the CAD system.
      <br/>
      The 2-D model may include a flat view and one or more other perspective views of the sheet metal part, with bending line and/or dimensional information.
    </p>
    <p num="8">
      Before actual bending of the sheet metal part takes place, the part must first be punched and/or cut from initial stock material.
      <br/>
      Computer Numerical Control (CNC) or Numerical Control (NC) systems are typically used to control and operate punch presses and plasma or laser cutting machinery to process the stock material.
      <br/>
      In order to facilitate processing of the stock material, a Computer-Aided Manufacturing (CAM) system or CAD/CAM system can be used by a design programmer to generate control code based on the 2-D model.
      <br/>
      The control code may comprise a part program that is imported to and utilized by the punch press and/or cutting machinery to punch or cut the sheet metal component from the stock material.
    </p>
    <p num="9">
      The next stage in the production process is a bending plan stage.
      <br/>
      During this stage, a bending plan is developed by a bending operator at the shop floor.
      <br/>
      The operator will normally be provided with the blueprint or 2-D drawing of the component, along with one or more samples of the cut or punched stock material.
      <br/>
      With these materials, the bending operator will develop a bending plan which defines the tooling to be used and the sequence of bends to be performed.
      <br/>
      The bending workstation may include CNC metal bending machinery, such as a CNC press brake, that enables the operator to enter data and develop a bending code or program based on the bending plan.
    </p>
    <p num="10">
      Once the bending plan is developed, the operator will set up the workstation for initial testing of the bending sequence.
      <br/>
      During this testing stage, the punched or cut stock material will be manually loaded into the press brake and the press brake will be operated to execute the programmed sequence of bends on the workpiece.
      <br/>
      The operator will analyze the final bent sheet metal part and inspect it for conformance with the customer's specification.
      <br/>
      Based on the results of the initial runs of the press brake, the operator may modify the bending sequence by editing the bending program.
      <br/>
      The operator may also provide feedback to the design office so that the sheet metal part design can be appropriately modified.
      <br/>
      Further testing will typically be conducted until the bent sheet metal component is within the required design specifications.
    </p>
    <p num="11">
      One of the final stages in the production process is the bending stage.
      <br/>
      After the bending plan has been developed and tested, the bending operator will set up the required tooling at the bending station and operate the press brake based on the bending plan and the stored bending program or code.
      <br/>
      Job scheduling is also performed in order to ensure that the necessary amount of punched or cut stock material will be available on time at the bending station, and so that other jobs will be completed by the requested delivery dates.
      <br/>
      Job scheduling may be developed or modified by a shop floor foreman during the earlier stages of the production process and/or concurrently throughout the entire process.
      <br/>
      After the final bent sheet metal parts have been produced, the parts may then be assembled and packaged for shipping to the customer.
    </p>
    <p num="12">
      The conventional production and manufacturing process described above suffers from several drawbacks and disadvantages.
      <br/>
      For example, although the design and manufacturing data for each customer's order is normally archived physically (e.g., by paper in a file cabinet) or electronically (e.g., by storing on a disk or magnetic tape), such data are normally stored separately and not easily retrievable.
      <br/>
      Further, in most factory settings, the distribution of critical job information takes the form of a paper job or work sheet that is distributed throughout the factory floor.
      <br/>
      As a result, data is often lost or damaged, and it is difficult to search for both the design and manufacturing data relating to a previous or similar job.
      <br/>
      In addition, due to the inefficient manner in which the data is stored, valuable time is lost in attempting to distribute the design and manufacturing information to the shop floor and to other locations throughout the factory.
      <br/>
      Considerable manufacturing time is also lost during the development of the sheet metal part design and bending plan, since the development of the part design and bending plan is primarily performed by the design programmer and bending operator, and relies heavily on the individual's knowledge, skill and experience.
    </p>
    <p num="13">
      In recent years, there have been developments and attempts to improve the conventional sheet metal manufacturing process and to improve the efficiency of the overall process.
      <br/>
      For example, the use and development of 2-D and 3-dimensional (3-D) modeling in commercially available CAD/CAM systems has facilitated and improved the production process and modeling of bent sheet metal components.
      <br/>
      The design programmer and operator can now utilize both the 2-D and 3-D representations to better understand the geometry of the part and more efficiently develop a part design and bending code sequence.
      <br/>
      The ability to store and transfer data electronically has also improved the flow of information from the design office to locations on the shop floor.
      <br/>
      With the advancement of computers and data communication networks, it is no longer necessary to search through a cabinet or file of old paper tapes or magnetic disks.
    </p>
    <p num="14">
      Despite such advancements, there is still a need to improve the organization and flow of design and manufacturing information throughout the factory environment.
      <br/>
      For example, conventional manufacturing systems do not logically associate both critical design and manufacturing information associated with each customer's order so that it may be easily accessed and retrieved from any area in the factory.
      <br/>
      Previous systems also fail to provide the ability to search previous job information based on various criteria, such as the features and attributes of the sheet metal component.
      <br/>
      The ability to search and retrieve previous job information based on, for example, an identical or similar part search, would greatly enhance the overall production process and reduce the required manufacturing time for future jobs.
    </p>
    <p num="15">
      Past attempts also fail to facilitate the development of the sheet metal part design and bending plan by the design programmer and shop floor operator.
      <br/>
      While the introduction of 2-D and 3-D modeling systems have enabled the designer to have a better understanding of the shape and geometry of the part, such systems have not reduced the burdens placed on the design programmer and shop floor operator.
      <br/>
      For example, such systems have not enabled the design programmer to easily convert an existing 2-D CAD model into a 3-D representation.
      <br/>
      In addition, while 2-D and/or 3-D drawings of the component may be provided to the shop floor operator to assist in the development of the bending plan, the operator must still determine and develop the tooling requirements and bending sequence by hand and/or experimentation.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="16">In view of the foregoing, the present invention, through one or more of its various aspects, embodiments and/or specific features or sub-components thereof, is provided to bring about one or more objects and advantages, such as those specifically noted below.</p>
    <p num="17">A general object of the present invention is to provide an apparatus and method for managing and distributing design and manufacturing information throughout a factory in order to facilitate the production of components, such as bent sheet metal components.</p>
    <p num="18">A further object of the present invention is to provide an apparatus and method that prevents the loss or destruction of critical job information, and that enhances the efficiency and organization of stored expert knowledge at, for example, a progressive sheet metal production facility.</p>
    <p num="19">Another object of the invention is to provide an apparatus and method for logically storing both the design and manufacturing information for each customer's order, so that it may be easily accessed and retrieved from any area in the factory.</p>
    <p num="20">
      Yet another object of the present invention is to provide an apparatus and method for managing and distributing design and manufacturing information, wherein the job data is stored at a central database or file server in a logical fashion so that it may be easily searched and retrieved from any location throughout the factory.
      <br/>
      The job data may provide not only the design and manufacturing information associated with the job, but also the actual bend code for executing the required bending operations.
    </p>
    <p num="21">
      Still another object of the present invention is to provide an apparatus and method for searching previous job information, including design and manufacturing information, based on various search criteria.
      <br/>
      The search criteria may include, for example, the basic features and attributes of the sheet metal component to be manufactured, so that previous job information relating to an identical or similar part can be utilized to reduce the overall manufacturing time of future jobs.
    </p>
    <p num="22">
      Another object of the present invention is to replace the traditional paper job or work sheet, associated with each customer's order, with an electronic job sheet that can be instantaneously accessed from any location in the factory.
      <br/>
      The electronic job sheet may be displayed at any location and include critical design and manufacturing information, including the 2-D and/or 3-D model view of the component, the tooling selection, the optimum bending sequence, the required staging information, and the bar code or identification number associated with the job.
      <br/>
      The electronic job sheet may also include an audio and/or video portion recorded by a bending operator to indicate, for example, any special instructions or procedures that may be helpful when running the same job or a similar job again in the future.
    </p>
    <p num="23">
      Another object of the invention is to shorten the time required to analyze a part drawing by providing 2-D and 3-D computerized views of the sheet metal part.
      <br/>
      Various viewing modes may be provided, including a solid 3-D viewing mode, a 3-D wire frame viewing mode, a 2-D flat screen viewing mode, and an orthographic viewing mode.
      <br/>
      Different viewing functions may also be provided, including zooming, panning, rotating and auto-dimensioning, to facilitate analysis of the sheet metal part.
    </p>
    <p num="24">
      A further object of the invention is to provide an apparatus and method that facilitates the development of the sheet metal part design and bending plan by the design programmer and shop floor operator.
      <br/>
      For example, it is an object of the present invention to enable the design programmer to easily develop a 3-D representation of the component from an existing 2-D model.
      <br/>
      It is also another object of the invention to provide a graphical user interface to shorten the time required to develop the bending plan and programmed bending code.
    </p>
    <p num="25">
      The present invention, therefore, is directed to a system and method is provided for developing a bending plan through the use of a graphical user interface, wherein the bending plan is adapted for use in the production of a part at a facility.
      <br/>
      The system comprises a bend sequence display system for generating and displaying a bend sequence input window on a display device, wherein the bend sequence input window comprises a 2-D flat image of the part.
      <br/>
      A tooling display system is also provided for generating and displaying tooling information on the display device, and an input device is provided for entering a bend sequence based on the 2-D flat image of the part and for selecting tooling based on the tooling information displayed on the display device.
      <br/>
      In addition, the system includes a bending plan storage system for storing the bending plan for the part based on the bend sequence and the tooling entered and selected by the input device.
    </p>
    <p num="26">
      The 2-D flat image of the part may include representations of each bendline of the part, and the input device may be adapted to enter the bend sequence by selecting each of the bendlines displayed in the 2-D flat image of the part.
      <br/>
      The input device may also be adapted to enter the bend sequence based on a sequence in which each the bendline is selected.
      <br/>
      Alternatively, or in combination, the input device may also be adapted to enter the bend sequence based on a bend sequence number entered by the input device when each the bendline is selected.
      <br/>
      As disclosed herein, the input device that is used with the system may comprises a joystick device or mouse device.
    </p>
    <p num="27">
      The system may further comprise a bend sequence number display system for displaying, on the display device, a bend sequence number for each of the bendlines based on the bend sequence entered by the input device.
      <br/>
      An insert direction determination system may also be provided for determining and displaying, on the display device, insert direction information for each of the bendlines of the part.
      <br/>
      The insert direction information may include an arrow representing an insert direction for each bendline may be displayed.
      <br/>
      Further, each of the bendlines may divide the part into two sides, and the insert direction determination system may be adapted to determine the insert direction information for each of the bendlines based on the side of the part that has a smaller predetermined dimension.
      <br/>
      The predetermined dimension may relate to a length of each side that is perpendicular to the bendline or it may relate to an area of each side relating to the bendline.
    </p>
    <p num="28">
      The bend sequence display system may be further adapted to generate and display a plurality of images of the part on the display device based on the bend sequence, wherein each of the plurality of images relate to a representation of the part at a stage within the bend sequence.
      <br/>
      The plurality of images that are displayed may be displayed in a sequence corresponding to the bend sequence.
      <br/>
      A drag and drop editing system may also be provided for modifying the bend sequence based on a modification of the displayed sequence of the plurality of images on the display device.
      <br/>
      The drag and drop editing system may be adapted to modify the displayed sequence when one of the plurality of images is selected by the input device and moved to a different position within the displayed sequence.
    </p>
    <p num="29">
      In accordance with an aspect of the invention, the displayed tooling information may comprise a plurality of tool icons displayed on the display device, wherein each of the tool icons represents a predetermined tool.
      <br/>
      The displayed tooling information may also comprise a table of tool data displayed on the display device, wherein each entry within the table of tool data relates to a predetermined tool.
      <br/>
      According to one feature of the invention, the tooling information is displayed by the tooling display system through a series of successively displayed screen displays, whereby at least one of the successively displayed screen displays is displayed based on a previous selection by the input device.
    </p>
    <p num="30">
      For example, the tooling display system may be adapted to display, on the display device, a first screen display comprising a plurality of tool type icons, wherein each of the tool type icons represents a tool type.
      <br/>
      The tool type may relate to at least one of a punch, die, die holder or die rail.
      <br/>
      The tooling display system may also be adapted to display, in response to the selection of one of the tool type icons, a second screen display on the display device, wherein the second screen display comprises a plurality of tool shape icons, and each of the tool shape icons relate to the tool type icon selected by the input device.
      <br/>
      The tooling display system may be further adapted to display, in response to the selection of one of the tool shape icons, a table of tool dimension data on the display device, wherein the tool dimension data relates to a plurality of tools, and each of the tools relate to the tool shape icon selected by the input device.
      <br/>
      At least part of the tooling may be selected and entered by the input device based on a selection of data from the table of tool dimension data.
    </p>
    <p num="31">
      Other feature may be included with the system of the present invention.
      <br/>
      For example, the tooling information may comprise tool set-up information relating to the tooling location within a bending machine for each tool to be used in the bending plan.
      <br/>
      Further, the tooling display system may be adapted to generate and display a tool set-up window on the display device for entering the tool set-up information with the input device.
      <br/>
      In addition, the system may be adapted such that a 2-D flat image of the part and the plurality of images of the part are simultaneously displayed on the display device.
    </p>
    <p num="32">
      According to yet another aspect of the invention, a method for developing a bending plan through the use of a graphical user interface is provided.
      <br/>
      The method comprises the steps of: generating and displaying a bend sequence input window on a display device, wherein the bend sequence input window comprises a 2-D flat image of the part; entering, with an input device, a bend sequence based on the 2-D flat image of the part; generating and displaying tooling information on the display device, wherein the tooling information relates to a plurality of tools; selecting, with the input device, tooling based on the tooling information displayed on the display device; and storing, in a storage device, the bending plan for the part based on the entered bend sequence and the selected tooling.
    </p>
    <p num="33">
      According to the method, the 2-D flat image of the part may include representations of each bendline of the part, and the bend sequence may be entered by selecting each the bendline displayed in the 2-D flat image of the part.
      <br/>
      In particular, the bend sequence may be entered based on a sequence in which each the bendline is selected or based on a bend sequence number entered by the input device when each the bendline is selected.
      <br/>
      As disclosed herein, the input device that is used with the method may comprises a joystick device or mouse device.
    </p>
    <p num="34">
      The method may further comprise displaying, on the display device, a bend sequence number for each bendline based on the bend sequence entered by the input device.
      <br/>
      Other steps may also be provided, such as determining and displaying, on the display device, insert direction information for each the bendline of the part.
      <br/>
      The insert direction information for each the bendline may be determined based on the side of the part, divided by the bendline, that has a smaller predetermined dimension.
      <br/>
      In addition, the displayed insert determination information for each the bendline may comprise an arrow relating to an insert direction for the bendline.
    </p>
    <p num="35">
      According to another feature, the invention may include the step of generating and displaying a plurality of images of the part on the display device based on the bend sequence, wherein each of the plurality of images of the part relates to a representation of the part at a stage within the bend sequence.
      <br/>
      A drag and drop editing step may be provided to modify the bend sequence based on a modification of the displayed sequence of the plurality of images on the display device.
      <br/>
      The displayed sequence may be modified by moving at least one of the plurality of images to a different position within the displayed sequence, and the plurality of images and each the representation of the part may be regenerated and displayed based on the modified bend sequence.
    </p>
    <p num="36">
      The method may also include displaying the tooling information through a series of successively displayed screen displays, wherein at least one of the successively displayed screen displays is displayed based on a previous selection by the input device.
      <br/>
      The step of displaying may be provided to display, on the display device, a first screen display comprising a plurality of tool type icons, for each of the tool type icons representing a tool type.
      <br/>
      Further, the method may also include the steps of selecting one of the tool type icons with the input device and displaying, in response to the selection of one of the tool type icons, a second screen display on the display device, wherein the second screen display comprises a plurality of tool shape icons, and each of the tool shape icons relate to the tool type icon selected by the input device.
      <br/>
      The method may also include the step of selecting one of the tool shape icons with the input device and displaying, in response to the selection of one of the tool shape icons, a table of tool dimension data on the display device.
      <br/>
      The tool dimension data may relate to a plurality of tools, and each of the tools may relate to the tool shape icon selected by the input device.
    </p>
    <p num="37">
      According to yet another aspect of the invention, a system is provided for developing a bend sequence through the use of a graphical user interface.
      <br/>
      The system includes a bend sequence display system for generating and displaying a bend sequence input window on a display device, wherein the bend sequence input window comprises a 2-D flat image of the part, and an input device for entering a bend sequence based on the 2-D flat image of the part.
      <br/>
      The bend sequence display system may further be adapted to generate and display a plurality of images of the part based on the bend sequence entered by the input device, and each of the plurality of images of the part may relate to a representation of the part at a stage within the bend sequence.
    </p>
    <p num="38">
      The system may also comprise a bending sequence storage system for storing the bending sequence for the part based on the bend sequence entered by the input device.
      <br/>
      The bend sequence may be entered by the input device by selecting each of the bendlines of the part displayed in the 2-D flat image of the part.
      <br/>
      A bend sequence number display system may also be provided for displaying, on the display device, a bend sequence number for each of the bendlines based on the bend sequence entered by the input device.
      <br/>
      In addition, an insert direction determination system may be provided for determining and displaying, on the display device, insert direction information for each the bendline of the part.
    </p>
    <p num="39">
      In order to modify the bend sequence, a drag and drop editing system may be provided for modifying the bend sequence based on a modification of the displayed sequence of the plurality of images on the display device.
      <br/>
      The drag and drop editing system may comprise means for modifying the displayed sequence when one of the plurality of images is selected by the input device and moved to a different position within the displayed sequence.
      <br/>
      The bend sequence display system may also comprise means for regenerating and displaying the plurality of images and each the representation of the part based on the modified bend sequence.
    </p>
    <p num="40">
      A method for developing a bend sequence through the use of a graphical user interface is also provided, wherein the bend sequence is adapted for use in the production of a part at a facility.
      <br/>
      The method comprises the steps of: generating and displaying a bend sequence input window on a display device, wherein the bend sequence input window comprises a 2-D flat image of the part; entering, through an input device, a bend sequence based on the 2-D flat image of the part; and generating and displaying a plurality of images of the part based on the bend sequence entered by the input device, such that each of the plurality of images of the part relate to a representation of the part at a stage within the bend sequence.
    </p>
    <p num="41">
      According to yet another aspect of the invention, a system is provided for developing tooling for a part through the use of a graphical user interface.
      <br/>
      The system comprises a tooling display system for generating and displaying tooling information on the display device, whereby the tooling information is displayed through a series of successively displayed screen displays, and an input device for selecting tooling based on the tooling information displayed on the display device.
    </p>
    <p num="42">
      At least one of the successively displayed screen displays may be displayed based on a previous selection by the input device.
      <br/>
      The displayed tooling information may relate to a plurality of tools and may comprise a plurality of tool icons displayed on the display device, wherein each of the tool icons represents a predetermined tool.
      <br/>
      The displayed tooling information may also comprise a table of tool data displayed on the display device, wherein each entry within the table of tool data is related to a predetermined tool.
    </p>
    <p num="43">
      According to the present invention, a method may also be provided for developing tooling for a part through the use of a graphical user interface.
      <br/>
      The method comprises the steps of: generating and displaying tooling information on the display device, wherein the tooling information is displayed on a series of successively displayed screen displays; and selecting, with an input device, tooling based on the tooling information displayed on the display device.
      <br/>
      The method may further comprise displaying at least one of the successively displayed screen displays based in part on a previous selection made by the input device.
    </p>
    <p num="44">
      The step of displaying may also be provided to display, on the display device, a first screen display comprising a plurality of tool type icons, for each of the tool type icons representing a tool type.
      <br/>
      Further, the method may also include the steps of selecting one of the tool type icons with the input device and displaying, in response to the selection of one of the tool type icons, a second screen display on the display device, wherein the second screen display comprises a plurality of tool shape icons, and each of the tool shape icons relate to the tool type icon selected by the input device.
      <br/>
      The method may also include the step of selecting one of the tool shape icons with the input device and displaying, in response to the selection of one of the tool shape icons, a table of tool dimension data on the display device.
      <br/>
      The tool dimension data may relate to a plurality of tools, and each of the tools may relate to the tool shape icon selected by the input device.
    </p>
    <p num="45">
      Further features and/or variations may be provided in addition to those noted above.
      <br/>
      For example, the invention may be directed to various combinations and subcombinations of the above-described features and/or combinations and subcombinations of several further features noted below in the detailed description.
    </p>
    <p num="46">The above-listed and other objects, features and advantages of the present invention will more be more fully set forth hereinafter.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="47">
      The present invention is further described in the detailed description which follows, by reference to the noted plurality of drawings by way of non-limiting examples of preferred embodiments of the present invention, in which like reference numerals represent similar parts throughout the illustrations, and wherein:
      <br/>
      FIG. 1A is a block diagram illustration of a progressive sheet metal manufacturing facility constructed according to an embodiment of the present invention;
      <br/>
      FIG. 1B is a block diagram illustration of a progressive sheet metal manufacturing facility constructed according to another embodiment of the present invention;
      <br/>
      FIG. 2 illustrates the respective data flow between the server module, database and station modules, in accordance with an aspect of the present invention;
      <br/>
      FIG. 3 is a flow chart of the general processes and operations that may be performed by the server module, according to another aspect of the invention;
      <br/>
      FIG. 4 is a representative flow chart of the basic processes and operations that may be performed by each of the station modules, in accordance with the teachings of the present invention;
      <br/>
      FIGS. 5A and 5B are flowcharts that illustrate the logic flow of a similar part search algorithm or process, according to an aspect of the present invention;
      <br/>
      FIGS. 6A, 6B, 6C, 6D, 6E, 6F and 6G illustrate, in accordance with an aspect of the invention, a feature extraction operation for a four bend box with touched corners and for a four bend box with open corners;
      <br/>
      FIGS. 7A, 7B and 7C illustrate, in accordance with another aspect of the present invention, a feature relation operation and process for identifying search keys for a part having a four bend box, a bridge and another four bend box;
      <br/>
      FIG. 8 is a flow chart that illustrates the logic flow of the processes and operations that may be performed to develop a 3-D model from a 2-D, single view drawing using a folding algorithm;
      <br/>
      FIGS. 9A, 9B, 9C, 9D and 9E illustrate examples of an auto-trimming function and cleanup function that may be performed to prepare a drawing for a face detection process;
      <br/>
      FIGS. 10A, 10B, 10C, 10D, 10E, 10F, 10G, and 10H illustrate the various processes and operations that may be performed in a face detection process, in accordance with an aspect of the present invention;
      <br/>
      FIGS. 11A and 11B illustrate the development of a final bend graph data structure from the execution of a face detection process and bend line detection operation, according to an aspect of the present invention;
      <br/>
      FIG. 12 is a flow chart of the basic logic flow for developing a 2-D model based on an original 3-D drawing (with no thickness) using an unfolding algorithm and other processes, according to the teachings of the invention;
      <br/>
      FIG. 13 is a flow chart of the basic logic flow for developing a 3-D model based on an original 2-D, three view drawing using a 2-D clean-up operation, in accordance with an aspect of the present invention;
      <br/>
      FIG. 14A is a flow chart, according to an aspect of the invention, of the basic logic flow of the processes and operations for performing a 2-D clean-up operation on a 2-D, three view drawing;
      <br/>
      FIGS. 14B and 14C illustrate views and aspects of an exemplary 2-D, three view drawing that may be processed by the 2-D clean-up operation of the present invention;
      <br/>
      FIG. 14D illustrates a rotated view feature of the 2-D clean-up operation of the present invention;
      <br/>
      FIG. 14E illustrates, in accordance with an aspect of the present invention, a canonical form relating to the 2-D clean-up operation of the present invention;
      <br/>
      FIGS. 15A and 15B illustrate an example of a 2-D, three view drawing with thickness and a simplified 2-D, three view drawing model with no thickness that may be developed using an eliminate thickness procedure, according to the teachings of the present invention;
      <br/>
      FIG. 15C is an illustration of a cross thickness line and thickness arc of an exemplary part, according to an aspect of the invention;
      <br/>
      FIG. 16 is a flow chart of the logic flow of the various processes and operations that may be implemented to develop a 3-D model with no thickness from a 3-D drawing with thickness, in accordance with an aspect of the present invention;
      <br/>
      FIG. 17 illustrates an exemplary data structure and access algorithm of the bend model that may be utilized when implementing the present invention through, for example, object oriented programming techniques;
      <br/>
      FIG. 18 illustrates a block diagram of the structure of the bend model viewer, in accordance with another aspect of the present invention;
      <br/>
      FIG. 19 illustrates an exemplary solid view window display that may be provided as output to a display screen;
      <br/>
      FIG. 20 illustrates an exemplary wire frame view window display that may be provided as output to a display screen;
      <br/>
      FIG. 21 illustrates a 2-D flat screen image window display that may be provided as output to a display screen;
      <br/>
      FIG. 22 illustrates an orthographic view screen image that may be provided as output to a display screen;
      <br/>
      FIG. 23 illustrates an example of the various dimension items that may be displayed in an automatic dimension mode of the present invention;
      <br/>
      FIGS. 24A, 24B and 24C illustrate a manner in which the flange length may be defined for various different parts, according to an aspect of the invention;
      <br/>
      FIGS. 25A and 25B illustrate, in accordance with another aspect of the present invention, adding an auxiliary flange length for two different types of parts;
      <br/>
      FIGS. 26A, 26B and 26C illustrate a manner in which the flange length may be indicated for various parts that are displayed with thickness, in accordance with yet another aspect of the invention;
      <br/>
      FIGS. 27A and 27B illustrate manners in which the flange length of parts with acute bend angles may displayed, in accordance with a tangent dimension method and an intersection dimension method of the invention;
      <br/>
      FIG. 28 is a flow chart of the logic flow of the processes and operations that may be performed to develop a bending plan through the use of a graphical user interface, in accordance with another aspect of the present invention;
      <br/>
      FIG. 29A illustrates an example of a bend sequence input screen image that may be displayed to a bending operator for developing a bending sequence;
      <br/>
      FIGS. 29B and 29C illustrates examples of selection a bend sequence and modifying the insertion direction, in accordance with another aspect of the present invention;
      <br/>
      FIGS. 29D and 29E illustrate further examples of a bend sequence input screen image and a related screen display;
      <br/>
      FIG. 30 illustrates, in accordance with an aspect of the present invention, a drag and drop editing feature that may be provided to facilitate a bending operator in modifying and editing a proposed bend sequence;
      <br/>
      FIG. 31 illustrates an example of the various display menus and data tables that may be graphically displayed to aid a bending operator in selecting tooling;
      <br/>
      FIG. 32 illustrates an exemplary tool set-up window that may be displayed to a bending operator to facilitate the set-up of tooling in a proposed bending plan;
      <br/>
      FIG. 33A illustrates an example of a 3-D solid view window display with audio and visual information attached through the use of pasted icons;
      <br/>
      FIG. 33B illustrates another example of a display window that may be incorporated with icons for retrieving stored audio and video information, in accordance with an aspect of the invention;
      <br/>
      FIG. 34 illustrates an example of an image editing window that may be implemented in accordance with the teachings of the present invention;
      <br/>
      FIGS. 35A and 35B illustrate examples of a collision check function of the present invention that may be implemented through a graphical user interface;
      <br/>
      FIGS. 36A and 36B illustrate a manipulation system of the invention for manipulating the rotation and display of 3-D geometrical shapes by using, for example, a joystick;
      <br/>
      FIG. 37 illustrates a manipulation system of the invention for manipulating the zooming and display of 3-D geometrical shapes by using, for example, a joystick and zoom button;
      <br/>
      FIG. 38 illustrates a manipulation system of the invention for manipulating the panning and display of 3-D geometrical shapes by using, for example, a joystick and pan button;
      <br/>
      FIG. 39 is an exemplary flow chart of the processes and operations that may be performed in order to implement the 3-D navigation and manipulation system of the present invention;
      <br/>
      FIG. 40 illustrates an example of mapping joystick movements to cursor movements, in accordance with an aspect of the invention;
      <br/>
      FIG. 41 is an exemplary flow chart of the processes and operations that may be performed to dynamically calculate the rotation axis of the rendered part;
      <br/>
      FIG. 42 illustrates an example of a main menu window display that may be provided and displayed at, for example, a station module;
      <br/>
      FIG. 43 illustrates an exemplary part information window display that may be provided to permit a user to enter and modify part information;
      <br/>
      FIG. 44 illustrates an exemplary bendline information window display that may be provided to permit a user to enter and modify bendline information;
      <br/>
      FIG. 45 illustrates an exemplary bend sequence window display of the present invention for viewing the intermediate bend stages of a sheet metal part;
      <br/>
      FIG. 46 illustrates an exemplary bend simulation window display of the invention for simulating the intermediate bend stages of a sheet metal part;
      <br/>
      FIGS. 47A and 47B are an exemplary menu screen diagram and structure of the present invention that may be provided and displayed to users for 2-D to 3-D conversions; and
      <br/>
      FIG. 48 is an exemplary menu screen diagram and structure for a 2-D clean-up operation of the present invention.
      <br/>
      FIG. 49A illustrates an example of a 3-D representation of a part before one sided open lines are removed, and
      <br/>
      FIG. 49B illustrates the part after the one sided open lines have been removed from the 3-D representation, according to a 3-D clean-up process of the invention that may be used when developing a 3-D model of a part from a 2-D, three view drawing of the part;
      <br/>
      FIG. 50A illustrates an exemplary 3-D representation of a part before the bendlines have been identified, and
      <br/>
      FIG. 50B illustrates the part after the mold lines have been added, according to a 3-D clean-up process of the invention; and
      <br/>
      FIG. 51A illustrates an exemplary section of a part before cleaning the bendlines and trimming the faces, and
      <br/>
      FIG. 51B shows the section of the part after cleaning and trimming has been performed, according to a 3-D clean-up process of the invention.
    </p>
    <heading>BRIEF DESCRIPTION OF THE APPENDICES</heading>
    <p num="48">In order to further facilitate the detailed description of the present invention, reference is made to the noted plurality of appendices by way of non-limiting examples of preferred embodiments of the present invention, in which sample source code and comments are provided with respect to the various features, operations and functions of the invention, and wherein:</p>
    <p num="49">
      Appendix A is an exemplary source code for executing a feature extraction operation of the present invention when performing, for example, a similar part search;
      <br/>
      Appendix B is an exemplary source code for effectuating a similarity index operation when performing, for example, a similar parts search of the invention;
      <br/>
      Appendix C is an exemplary source code for performing a bendline detection operation of the invention;
      <br/>
      Appendix D is an exemplary source code for implementing a 2-D cleanup operation of the present invention, which may be utilized when developing a 3-D model of a sheet metal part based on an original 2-D, three view drawing;
      <br/>
      Appendix E is an exemplary source code for implementing the various view modes and functions of a bend model viewer of the present invention;
      <br/>
      Appendices F, G, H and I are exemplary source code and comments relating to executing and performing an auto dimensioning feature of the present invention;
      <br/>
      Appendix J is an exemplary source code for implementing a part and entity visibility function of the bend model viewer of the invention;
      <br/>
      Appendix K includes general comments relating to the implementation of the bend model and the organization of the part structure, according to the various teachings of the present invention; and
      <br/>
      Appendix L includes exemplary source code for implementing a 3-D manipulation and navigation system with dynamic calculation of the rotation axis of the rendered part.
    </p>
    <heading>DETAILED DESCRIPTION OF THE INVENTION</heading>
    <p num="50">
      According to an aspect of the present invention, an apparatus and method are provided for managing and distributing design and manufacturing information throughout a factory, and for facilitating the production of components within the factory.
      <br/>
      The features of the present invention may be used in a wide variety of factory environments and settings and, more particularly, the invention may be implemented in factory environments wherein a series of production and manufacturing stages are effectuated at different locations.
      <br/>
      By way of non-limiting embodiments and examples, the present invention will now be described with reference to the production of bent sheet metal components at, for example, a progressive sheet metal manufacturing facility.
    </p>
    <p num="51">
      Referring to FIG. 1A, a progressive sheet metal manufacturing facility 38 is generally illustrated in block diagram form, according to an embodiment of the present invention.
      <br/>
      As shown in FIG. 1A, the sheet metal manufacturing facility or factory 38 may include a plurality of locations 10, 12, 14 . . . 20 that are dispersed throughout the factory.
      <br/>
      These locations may comprise a design office 10, an assembly station 12, a shipping station 14, a punching station 16, a bending station 18, and a welding station 20.
      <br/>
      Although the sheet metal factory 38 in FIG. 1A is depicted as having only six discrete locations, the factory may of course include more than six discrete locations and may also include more than one location for each type of office or station illustrated in FIG. 1A. For example, depending on the size of and production capacity requirements for the facility 38, more than one punching station 16, bending station 18, and/or welding station 20 may be provided.
      <br/>
      In addition, the factory 38 may include more than one design office 10, assembly station 12 or shipping station 14, and may also include other types of locations for facilitating the production and manufacturing of components, such as bent sheet metal components.
    </p>
    <p num="52">
      Each of the locations 10, 12, 14 . . . 20 within the factory 38 may be adapted and include equipment to execute one or more of the discrete production and manufacturing stages or processes associated with the production and manufacturing of the components.
      <br/>
      For example, the design office 10 may include an appropriate CAD/CAM system, to facilitate the development of the sheet metal part design based on a customer's specification.
      <br/>
      The CAD/CAM system may comprise one or more personal computers, a display unit, a printer, and commercially available CAD/CAM software.
      <br/>
      By way of a non-limiting example, the CAD/CAM system of the design office 10 may include AUTOCAD or CADKEY, or an Amada AP40 or AP60 CAD/CAM system available from Amada America, Inc. (previously operating under the corporate name of U.S. Amada Ltd.), Buena Park, Calif.
      <br/>
      In addition, other commercially available CAD systems may be used, such as VELLUM, which is a Windows based CAD system available from Ashlar Incorporated.
      <br/>
      With the CAD/CAM software, the design programmer may develop a 2-D model and/or 3-D model of the sheet metal part based on the drawings and data provided in the customer's order.
      <br/>
      The design programmer may also generate control code based on the sheet metal part design, in order to generate a part program for controlling, for example, CNC punch presses and/or cutting machinery to punch or cut the sheet metal component from stock material.
    </p>
    <p num="53">
      Punching station 16 and bending station 18 may each be provided with any combination of CNC and/or NC based machine tools.
      <br/>
      For example, punching station 16 may include one or more CNC and/or NC punch presses, such as COMA series and/or PEGA series Amada turret punch presses or other commercially available CNC and/or NC punch presses, and bending station 18 may include one or more CNC and/or NC press brakes, such as RG series Amada press brakes or other commercially available multiple-axis, gauging press brakes.
      <br/>
      Further, welding station 20 may be provided with appropriate welding machinery in order to effectuate any required welding to the sheet metal component.
      <br/>
      Punching station 16, bending station 18 and welding station 20 may be located at various areas on the factory floor of the facility 38 and include machinery that is manually operated by skilled operators (e.g., punch press operators, bending operators, etc.).
      <br/>
      Fully automated or robot assisted machinery, such as the Amada CELLROBO MINI and the Amada PROMECAM, may also be provided at these locations.
      <br/>
      The required punching and bending operations, and any necessary welding operations, may be performed at these stations during the production process.
    </p>
    <p num="54">
      As further shown in FIG. 1A, the progressive sheet metal facility 38 may also include assembly station 12 and shipping station 14.
      <br/>
      Assembly station 12 and shipping station 14 may include the necessary packaging, routing and/or transportation equipment to facilitate the assembly and shipping of the manufactured components to the customer.
      <br/>
      The assembly and shipping of the components may be performed or controlled manually by factory personnel and also may be machine automated and/or machine assisted.
      <br/>
      In addition, assembly station 12 and shipping station 14 may be physically located near the factory floor (e.g., in close proximity to punching station 16, bending station 18 and/or welding station 20) or within a separate facility or area of the sheet metal factory 38.
    </p>
    <p num="55">
      In accordance with an aspect of the present invention, the management and distribution of critical design and manufacturing information is achieved by electronically storing and distributing the design and manufacturing information.
      <br/>
      By replacing or at least supplementing the traditional paper job set-up or work sheet with an electronic job sheet that can be accessed instantaneously from any location in the factory, the present invention improves the overall efficiency of the factory.
      <br/>
      In addition, through the various aspects and features of the invention, the organization and accessibility of stored design and manufacturing information is improved.
      <br/>
      Further, the ability to access and retrieve previous job information relating to similar or identical sheet metal parts is enabled through the various features of the invention.
    </p>
    <p num="56">
      To this end, the various aspects of the present invention may be implemented and effectuated by providing a communications network 26 that interconnects a server module 32 and a database 30 to each of the plurality of locations 10, 12, 14 . . . 20 within the sheet metal facility 38.
      <br/>
      As further discussed below, each of the locations 10, 12, 12 . . . 20 may include station modules that interface with communications network 26 and database 30.
      <br/>
      FIGS. 1A, 1B and 2 illustrate non-limiting examples of these features and implementation of the invention.
    </p>
    <p num="57">
      As shown in FIGS. 1A and 1B, communications network 26 may interconnect each of the various locations 10, 12, 14 . . . 20 of the facility 38 with server module 32 and database 30.
      <br/>
      Communications network 26 may comprise any network capable of transmitting data and information to and from the locations 10, 12, 14 . . . 20 and the server module 32 and database 30.
      <br/>
      Such transmission may be achieved electronically, optically, by RF transmission or by infrared transmission.
      <br/>
      By way of non-limiting example, communications network 26 may be implemented by a Local Area Network (LAN), Ethernet or an equivalent network structure.
      <br/>
      As further discussed below, each of the locations 10, 12, 14 . . . 20 may also include station modules having network terminating equipment (such as a computer, minicomputer or workstation) and/or peripheral devices (such as a display monitor or screen, printers, CD-ROMs, and/or modems) to transmit and receive information over communications network 26.
      <br/>
      The network terminating equipment and peripheral devices may include hardware and appropriate software or programmed logic for interfacing with communications network 26 and for providing the various features and aspects of the present invention, as more fully discussed below.
      <br/>
      If a computer is provided at the factory location, the computer may be a stand-alone, personal computer or a general purpose computer that is part of an interface device of the equipment or machinery provided at the location.
      <br/>
      For example, the computer may be an IBM compatible personal computer or may be a computer that is part of an interface/control system of the machinery, such as an Amada AMNC system.
    </p>
    <p num="58">
      Server module 32 and database 30 are also connected to communications network 26.
      <br/>
      Server module 32 may comprise network terminating equipment, such as a personal computer, minicomputer or mainframe, with suitable hardware and software for interfacing with communications network 26.
      <br/>
      Server module 32 may also include software or firmware for implementing the various features of the invention, such as those described in greater detail hereinafter.
      <br/>
      Further, according to an aspect of the present invention, server module 32 may also include database 30 for storing the design and manufacturing information associated with each customer's order.
      <br/>
      Database 30 may be implemented by any commercial available database with sufficient memory capacity for storing the design and manufacturing information of the factory's customers and storing other data, tables and/or programs.
      <br/>
      For example, database 30 may comprise a SCSI memory disk with 4 GB or more of available memory space.
      <br/>
      The design and manufacturing information that is stored in database 30 may be accessed and distributed to the various locations 10, 12, 14 . . . 20 within the sheet metal facility 38 via communications network 26.
      <br/>
      Various data formats, such as Structured Query Language (SQL), may be used for accessing and storing data to database 30.
      <br/>
      In addition, information that is stored in database 30 may be backed-up and stored on a wide variety of storage medium, such as magnetic tape, optical disks or floppy disks.
      <br/>
      Server module 32 and database 30 may be connected to communications network 26 at a separate area or location within the factory 38 (see, e.g., FIG. 1A), or at a location that is within or in close proximity to one of the predefined stations (e.g., within design office 10).
      <br/>
      Although the embodiment of FIG. 1A depicts database 30 as being part of server module 32 and interfacing with communications network 26 via the server module, database 30 may of course be physically located separately from server module 32 and connected to communications network 26 via a network database module 34, such as that shown in FIG. 1B.
    </p>
    <p num="59">
      By way of a non-limiting example, and in accordance with a preferred embodiment of the present invention, server module 32 and each of the locations 10, 12, 14 . . . 20 may comprise a personal computer, such as an IBM compatible computer with a 100-200 MHz central processor unit (CPU), including a Pentium or an equivalent microprocessor, at least 32 MB of memory and a high resolution display screen, such as any commercially available SVGA monitor with 800 * 600 resolution.
      <br/>
      Server module 32 and locations 10, 12, 14, . . . 20 may also include a joystick or mouse device and a Sound Blaster or compatible sound and game port adapter card for interfacing and controlling the display of information.
      <br/>
      Operating system software may also be provided to support communications.
      <br/>
      For example, server module 32 may be provided with Microsoft Windows New Technology (NT) or Windows 95 operating system software (both of which are available from Microsoft Corporation, Redmond, Wash.), and each of the locations 10, 12, 14 . . . 20 may include Microsoft Windows 95 operating system software.
      <br/>
      In addition, server module 32 and locations 10, 12, 14 . . . 20 may be adapted to support multiple languages (such as English, Japanese, etc.) and full support for an Object Linking and Embedding (OLE) server, such as an OLE2 server, may be provided.
    </p>
    <p num="60">
      Various database languages and management systems may also be used for creating, maintaining and viewing information stored in database 30.
      <br/>
      A database language such as Structured Query Language (SQL) may be used for defining, manipulating and controlling data in database 30.
      <br/>
      For example, SQL Server (which is a retail product available from Microsoft Corporation) may be utilized to implement the present invention.
      <br/>
      In addition, the invention may be provided with an Open Database Connectivity (ODBC) compatible driver to facilitate access of information from database 30 over communications network 26.
      <br/>
      More information concerning OBDC may be found, for example, in the Microsoft Open Database Connectivity Software Development Kit Programmers Reference manual.
    </p>
    <p num="61">
      FIG. 1B illustrates, in block diagram form, a progressive sheet metal manufacturing facility constructed according to another embodiment of the present invention.
      <br/>
      In the embodiment of FIG. 1B, the database 30 and server module 32 are provided separately, with the database 30 being connected to communications network 26 via a network database module 34.
      <br/>
      As discussed above, the present invention is not limited to this arrangement and the database 30 and server module 32 may be provided together (as shown, e.g., in FIG. 1A), with the functionality of the network database module 34 for providing access to the database being incorporated in the server module.
      <br/>
      The embodiment of FIG. 1B also illustrates an example of the station module 36 that may be provided at each of the various locations 10, 12, 14 . . . 20 throughout the sheet metal manufacturing facility 38.
      <br/>
      For purposes of illustration, an exemplary station module 36 that may be located at bending station 18 is provided in FIG. 1B. Although not depicted in the example of FIG. 1B, similar station modules 36 may also be provided at the other locations within the facility 38.
    </p>
    <p num="62">
      As shown in FIG. 1B, each of the modules (i.e., server module 32, network database module 34, and station module 36) may be connected to communications network 26 via a network interface card or port 42.
      <br/>
      The network interface card 26 may be vendor specific and be selected based on the type of communications network that is selected.
      <br/>
      Each of the modules 32, 34 and 36 may also include network software or programmed logic for interfacing with the communications network 26.
      <br/>
      The communications network 26 may be an Ethernet with any of a number of commercially available cable types, such as 10 Base/T (twisted pair), 10 Base/2 (coax), or 10 Base/5 (thick cable), with the cable type being selected based on the size of facility 38 and the amount or length of the cable required.
    </p>
    <p num="63">
      In FIG. 1B, server module 32 may comprise a personal computer 40 with display monitor or CRT 44 and input/output devices 46, which may include a keyboard, mouse and/or joystick.
      <br/>
      The network interface card 42 may be plugged into an available expansion slot or port of the personal computer 40.
      <br/>
      In addition, personal computer 40 may comprise an IBM compatible computer with 100-200 Mhz operating speed and a Pentium or Pentium Pro microprocessor.
      <br/>
      Personal computer 40 may also include, for example, 32 MB or more of available main memory and 1.2 GB or more of available random access memory (RAM).
      <br/>
      Display 44 may include a high resolution display screen, such as any commercially available SVGA monitor with, for example, 800 * 600 resolution.
      <br/>
      To support the various graphics and information that may be displayed on display 44, personal computer 40 may also include any commercially available graphics card such as a PCI graphics card.
      <br/>
      Further, computer 40 may include a Sound Blaster or compatible sound and game port adapter card and input/output devices 46 may include a keyboard, joystick and/or mouse device.
    </p>
    <p num="64">
      In order to implement the various features of the invention, server module 32 may be configured with software and various software packages.
      <br/>
      For example, server module 32 may be provided with operating system software, such as Microsoft Windows NT (workstation version) or Windows 95.
      <br/>
      Further, in order to provide the server module specific functionality and features of the invention (see, e.g., FIG. 3), server module 32 may include software or programmed logic implemented routines.
      <br/>
      As discussed in greater detail below, these routines may be developed using a high level programming language, such as C++, and object oriented programming techniques.
      <br/>
      Server module 32 may also include or interface with CAD or CAD/CAM software, such as VELLUM or Amada AP40 or AP60 software, to enter and/or develop original 2-D and 3-D drawings based on a customer's specifications.
      <br/>
      For this reason, server module may be located in the design office 10 of the manufacturing facility 38.
      <br/>
      In order to access data from database 30, server module 32 may also include an OBDC driver, such as Microsoft ODBC driver, and may use SQL as a standard for accessing data.
      <br/>
      An OLE server, such as OLE2 server, may also be provided to link the data.
    </p>
    <p num="65">
      In the embodiment of FIG. 1B, database 30 is provided separate from server module 32 and is connected to communications network 26 via network database module 34.
      <br/>
      As indicated above, database 30 may comprise a SCSI disk with appropriate memory space (e.g., 1-4 GB), which may be selected based on the size of the factory 38 and the amount of part information to be stored in the database.
      <br/>
      Network database module 34 may include a personal computer 40, such as an IBM compatible computer with a Pentium microprocessor, and an expansion slot fitted with network interface card 42 for interfacing with communications network 26.
      <br/>
      Database 30 may be connected to personal computer 40 via a data bus and personal computer 40 may include standard display and input/output devices (not shown in FIG. 1B), such as a display monitor or CRT and a keyboard.
    </p>
    <p num="66">
      In order to facilitate access to database 30 based on SQL, personal computer 40 of network database module 34 may be configured with a commercially available SQL server, such as a Microsoft SQL server or Oracle SQL server.
      <br/>
      An OLE server, such as OLE2 server, may also be provided to link the data.
      <br/>
      Personal computer 40 may also be configured with various operating software, such as DOS and Microsoft Windows NT (server version).
    </p>
    <p num="67">
      The embodiment of FIG. 1B also includes an exemplary implementation of one station module 36.
      <br/>
      In this embodiment, the station module 36 is implemented at bending station 18.
      <br/>
      As shown in FIG. 1B, the station module 36 may include similar hardware to that of the server module 32.
      <br/>
      That is, each station module (e.g., at the other stations shown in FIG. 1A) may comprise a computer 48 with display monitor or CRT 44 and input/output devices 46, which may include a joystick or mouse.
      <br/>
      The network interface card 42 may be plugged into an available expansion slot or port of the computer 40.
      <br/>
      As discussed above, the computer of the station module 36 may be a stand-alone, personal computer or a general purpose computer that is part of an interface device of the equipment or machinery provided at the location.
      <br/>
      For example, computer 48 may comprise a free-standing, personal computer such as an IBM compatible computer with 100-200 Mhz operating speed and a Pentium or Pentium Pro microprocessor, or computer 48 may be a computer that is part of or built into an interface/control system of the machinery, such as an Amada AMNC system.
      <br/>
      Computer 48 may also include, for example, 32 MB or more of available main memory and 1.2 GB or more of available random access memory (RAM).
      <br/>
      Display 44 may include a high resolution display screen, such as any commercially available SVGA monitor with, for example, 800 * 600 resolution.
      <br/>
      To support the various graphics and information that may be displayed on display 44, computer 48 may also include any commercially available graphics card such as a PCI graphics card.
      <br/>
      Further, computer 48 may include a Sound Blaster or compatible sound and game port adapter and to support, for example, a joystick or mouse of the input/output devices 46.
    </p>
    <p num="68">
      In order to implement the various features of the invention, station module 36 may also be configured with software and various software packages.
      <br/>
      For example, station module 36 may be provided with operating system software, such as Microsoft Windows 95 or Windows NT (workstation version).
      <br/>
      Further, in order to provide the station module specific functionality and features of the invention (see, e.g., FIG. 4), station module 36 may include software or programmed logic implemented routines.
      <br/>
      As discussed in greater detail below, these routines may be developed using a high level programming language, such as C++, and object oriented programming techniques.
      <br/>
      In order to access and link data, station module 36 may also include an OBDC driver, such as Microsoft ODBC driver, and an OLE server, such as OLE2 server.
      <br/>
      Similar to server module 32, station module may use SQL as a standard for accessing data from database 30.
    </p>
    <p num="69">
      If the station module 36 of bending station 18 is provided as a free-standing personal computer, then software may be provided to create bending code data (i.e., NC data) and to interface with the machinery 25 (e.g., a CNC or NC controlled press brake).
      <br/>
      In the embodiment of FIG. 1B, computer 36 is illustrated as being implemented as a personal computer and is configured with software to interface with bending machinery 25 via a standard RS-232-C wire interface.
      <br/>
      This interface may be provided to permit the station module 36 to communicate with and send or receive bending code data to the bending machinery 25 via the RS-232-C interface.
      <br/>
      The implementation of the interface is vendor specific and will depend on the data format and machine instruction set used for the bending machinery 25.
      <br/>
      All data that is sent from the station module 36 to the bending machinery 25 should thus be formatted based on the machine instruction set that is defined for the machinery.
      <br/>
      The computer 48 of station module 36 may also be provided with any commercially available CNC or NC software for generating bending code data, in order to simulate the functionality that is normally provided by a built-in computer of CNC or NC systems (such as a Amada AMNC) for such machinery.
    </p>
    <p num="70">
      FIG. 2 illustrates an exemplary embodiment of the respective data flows between server module 32, database 30 and the various locations of the sheet metal manufacturing facility 38.
      <br/>
      For purposes of illustration, and to better facilitate the description of the respective data flow in the embodiment, server module 32 and database 30 (integrated with network database module 34) are each shown in FIG. 2 as being separately and directly connected to communications network 26, with the data flow between these elements being carried out across the communications network. of course, as will be appreciated by those skilled in the art, a wide variety of data flow arrangements may be provided between these elements; and, if database 30 is arranged to be directly connected to server module 32, then the data and information can be directly transferred from the server module to the database without use of communications network 26.
      <br/>
      In addition, for purposes of facilitating the description herein, the illustration of communications network 26 in FIG. 2 has been simplified and only punching station 16 and bending station 18 are shown in the drawing.
      <br/>
      Nonetheless, it will be appreciated that the data flow to and from locations 10, 12, 14 . . . 20 (as well as any other location or area that may be present in the factory) may be carried out in a similar manner to that described for punching station 16 and bending station 18.
    </p>
    <p num="71">
      The design and manufacturing information associated with each customer's order may be organized and stored in database 30.
      <br/>
      When a customer's order is initially received, basic product and design information may be entered at server module 32 and then transferred and stored to database 30.
      <br/>
      As discussed above, server module 32 may include any suitable means for entering the data, such as a personal computer with a keyboard, etc.
      <br/>
      If a personal computer is utilized at server module 32, software may be provided to generate menu driven screens to facilitate the entry of the data by factory personnel.
      <br/>
      The data entry program may be, for example, a Microsoft Windows based application with help and/or menu screens, etc.
      <br/>
      By way of a non-limiting example, the data that is entered and/or developed at server module 32 and transferred to database 30 may include part information, bend model data, feature extraction data, and bend line information, as generally illustrated in FIG. 2.
    </p>
    <p num="72">
      The part information may comprise, for example, a part or order reference number, the customer's name, a brief description of the part, the batch size or quantity, and scheduled delivery date.
      <br/>
      The bend model data may include, for example, part geometry and manufacturing data, such as the overall dimensions of the part (e.g., width, height, depth), and part material information such as the material type (e.g., steel, stainless steel, or aluminum), thickness and tensile strength.
      <br/>
      Further, feature extraction data may be manually entered and/or automatically generated to identify the key features of the part and to facilitate similar part searches and other searches of the database.
      <br/>
      The feature extraction data may be stored in a separate data file in database 30, or may be stored with the bend model data and other job information for each part.
      <br/>
      The feature extraction data may comprise, for example, features of the part such as the number of surfaces or faces, the number or types of bends present (e.g., a positive bend between two faces or a negative bend between two faces), the relationships between the faces and/or the number of holes or other types of openings in the part.
      <br/>
      As discussed more fully below, such data may be represented and organized in a feature based part matrix and/or a sequence of search keys (see, e.g., FIGS. 5-7 below).
      <br/>
      Lastly, bend line information may be entered at server module 32 for storage in database 30.
      <br/>
      The bend line information may comprise, for example, pertinent bend line information for each bend in the part, including the bend angle, the bend length, the inside radius (IR) of the bend, the amount of deduction, and the bend direction (e.g., front or back).
    </p>
    <p num="73">
      In order to transmit to and receive data from database 30 over communications network 26, each of the locations 10, 12, 14 . . . 20 may comprise a station module (such as station module 36 described above) that is connected to the communications network.
      <br/>
      In FIG. 2, punching station 16 and bending station 18 are generally illustrated in block diagram form with a station module.
      <br/>
      As discussed above, the station module may comprise, for example, software or control logic and a stand-alone personal computer or a general purpose computer that is part of the equipment or machinery provided at the location.
      <br/>
      For each customer's order, the design and manufacturing information (including the part information, bend line information, and bend model data) may be accessed and retrieved by entering, for example, a predetermined reference number or code.
      <br/>
      The reference number or code may be entered manually (e.g., by keyboard or digital input pad) or by scanning a bar code with a bar code reader or scanner provided at the station module.
      <br/>
      In addition, in accordance with an aspect of the present invention, previous job data may be accessed and retrieved from database 30 from any location 10, 12, 14 . . . 20 within the factory 38 by performing a similar part search.
      <br/>
      As discussed more fully in the detailed description that follows, a similar part search may be conducted based on the feature extraction data or search keys stored in database 30 so that previous job information relating to identical or similar part(s) can be retrieved and utilized to reduce the overall manufacturing time of future jobs.
    </p>
    <p num="74">
      The design and manufacturing information that is retrieved from database 30 may be used by the shop floor operators to develop and test the bending plan.
      <br/>
      For example, a bending operator at bending station 18 may access and retrieve the part information, bend line information and bend model data from database 30 in order to determine the necessary tooling and the optimum bend sequence for the sheet metal part.
      <br/>
      In accordance with an aspect of the present invention, an ODBC driver may be provided to permit each station module to interface database 30 and display information stored in the database.
      <br/>
      In addition, server module 32 or the network database module of database 30 may comprise a SQL server to facilitate the access and retrieval of data stored in the database.
      <br/>
      Once the bending code has been programmed based on the final bending plan, the bending code along with the bend sequence and tool setup information may be sent from the station module of bending station 18 to database 30 over communications network 30, as generally shown in FIG. 2.
      <br/>
      This information may then be stored along with the other design and manufacturing information associated with that job.
    </p>
    <p num="75">
      Other information may also be stored in database 30.
      <br/>
      For example, the 2-D and/or 3-D image representation of the part may be stored with the bend model data for the part.
      <br/>
      The 2-D or 3-D image representation may be developed at design station 10 or another location with a CAD/CAM system and transferred to database 30 via the station module of the design station (or another appropriate location) and through the communications network 26.
      <br/>
      Alternatively, the 2-D or 3-D image may be developed at server module 32, by utilizing or interfacing with an appropriate CAD/CAM system or modeling software and performing a series of functions or operations, as will be discussed more fully below.
    </p>
    <p num="76">
      Referring now to FIGS. 3 and 4, a detailed description of the processes and operations that may be programmed and performed by server module 32 and the station modules of each of the locations 10, 12, 14 . . . 20 will be provided.
      <br/>
      FIGS. 3 and 4 are flow charts of the basic logic flow that may be performed by server module 32 and the station modules of each of the locations 10, 12, 14 . . . 20 within the sheet metal manufacturing facility 38.
      <br/>
      While FIG. 4 is directed to the processes and operations that would typically be performed at, for example, bending station 18, it will be appreciated that other processes and steps may be performed depending upon the operations performed at each particular location within the facility 38.
      <br/>
      The processes and operations discussed below may be implemented by software and by using any one of a wide variety of programming languages and techniques.
      <br/>
      For example, in accordance with an aspect of the present invention, the processes and operations described below with reference to the accompanying drawings may be implemented by using a high level programming language such as C++ and using object oriented programming techniques.
      <br/>
      Further, by way of a non-limiting example, VISUAL C++ may be utilized, which is a version of the C++ programming language written by Microsoft Corporation for Windows based applications.
    </p>
    <p num="77">
      FIG. 3 is a flow chart of the basic processes and operations performed by server module 32, in accordance with an aspect of the invention.
      <br/>
      FIG. 3 illustrates the basic logic flow of the processes and operations performed by the software or programmed logic of server module 32.
      <br/>
      Server module 32 may include a Windows based application with tool bar icons and help and/or menu screens to assist an operator or user in selecting and executing the various processes and operations of the server module.
      <br/>
      The process begins at step S.1, when a customer's order is received at the sheet metal manufacturing facility 38.
      <br/>
      The customer's order will normally include the necessary product and design information so that the component may be manufactured by the factory 38.
      <br/>
      This information may include, for example, the geometric dimensions of the part, the material required for the part, and other design information.
      <br/>
      Based on the information received from the customer, server module 32 may perform a search of previous job information stored in database 30, as illustrated in step S.3. The job information stored in database 30 may be searched based on a wide variety of search criteria.
      <br/>
      For example, information may be searched based on a predetermined reference or job number or a similar part search may be performed based on certain design features of the part, so that previous job information relating to an identical or similar part can be retrieved and utilized for the current job.
      <br/>
      A more detailed description of a similar parts search that may be utilized is provided below with reference to FIGS. 5-7.
    </p>
    <p num="78">
      At step S.5, the results of the search of the database are analyzed to determine whether the current customer's order relates to a new part, a part that is similar to a previous job, or a repeat of a previous job.
      <br/>
      If an identical match is found (e.g., the same part or reference number is located) and the present customer's order is a complete repeat of a previous job performed at the factory, then no further modifications to the job information is necessary and the previous job information may be accessed from database 30 and used to carry out the present customer's order, as shown at step S.11. The search of the database may provide the part or reference number and/or file name of the previous job so that the job information may be accessed from the database by an operator at the server module 32 or any of the station modules.
      <br/>
      If only the part or reference number is provided, then a translation table may be provided so that the file name of the previous job information may be determined and accessed based on the entry of the part reference or job number by an operator.
      <br/>
      Thus, an operator at, for example, server module 32 may access the job information and the 2-D and 3-D modeling information from database 30 to analyze the geometry of the part and confirm that it is similar to that of the repeat order.
      <br/>
      If the order is confirmed to be a repeat order, then a bending operator located at the station module of bending station 18 may also access the previous job information and utilize the manufacturing information, including the bending code data and tool setup information, to bend and produce the part.
      <br/>
      The use of such stored expert knowledge thus enables repeat orders to be manufactured more efficiently and without the need to reproduce previously entered and developed job information.
    </p>
    <p num="79">
      If, however, it is determined at step S.5 that the current customer's order is similar to a previous job or the same as a previous job but requires modification of, for example, the job or reference number or batch size, etc., then at step S.7 the previous job data located by the search may be retrieved from database 30, and edited and modified by an operator at server module 32.
      <br/>
      An editing function may be provided to allow editing and modification of previous job data to create new job data that may be stored in database 30 for the present customer's order.
      <br/>
      The amount of editing required will depend upon the amount of similarity that exists between the previous job and the current job.
      <br/>
      The amount of editing may encompass simply modifying the reference or job number or batch size, and/or may involve more extensive modifications such as editing the dimensions of the part and the defined bend sequence.
      <br/>
      After the previous job information has been edited, the revised job information may then be stored in database 30 at step S.9. The revised job information may be stored under a new reference or job number.
      <br/>
      In addition, various database management functions (such as copy, delete, save, rename, etc.) may be provided to permit the previous job information to be maintained in database 30 or to permit the previous job information to be erased or overwritten upon entry of a special command.
    </p>
    <p num="80">
      If it is determined that there is no similar or identical match to the current job and, thus, that the present customer's order relates to a new job, then logic flow proceeds to step S.15, as shown in FIG. 3.
      <br/>
      Since, in this case, the current job relates to a new job it will be necessary to independently develop and enter the design and manufacturing information.
      <br/>
      Menu and/or help screens may be provided by the server module 32 to assist the operator in entering all of the necessary job information.
      <br/>
      In accordance with an aspect of the invention, an operator at server module 32 may create a new file by first entering the basic part information for the new job.
      <br/>
      The part information may comprise, for example, a reference or job number, the customer's name, a brief description of the part, the required batch size or quantity for the job, and the scheduled delivery date.
      <br/>
      The feature extraction data or search keys may also be entered at step S.15, or this data may be automatically developed or extracted concurrently with the development of the bend model data, as described below.
      <br/>
      Other data or information may also be entered at step S.15, or entered after or during the entry of the bend model data, such as the bend line information which may comprise, for example, the bend angle, radius and length for each bend line in the part.
      <br/>
      After step S.15, logic flow proceeds so that the bend model data may be developed and entered at server module 32 by an operator, as shown in FIG. 3.
    </p>
    <p num="81">
      The development and entry of the bend model data may depend upon the original drawings and information provided from the customer.
      <br/>
      The customer's order may include, for example, a 2-D, single view flat drawing of the part to be manufactured and/or a 2-D, three view (e.g., including top, front and side views) drawing of the part.
      <br/>
      Occasionally, the customer may also provide a 3-D, wire frame drawing of the part, with or without the thickness of the material of the part being indicated in the drawing.
      <br/>
      In accordance with an aspect of the present invention, the bend model data may include both the unfolded (i.e., the 2-D flat representation) and the folded (i.e., the 3-D representation) information for the part to be manufactured.
      <br/>
      Thus, if only a 2-D flat drawing is provided by the customer, it will be necessary to develop a 3-D drawing of the part by applying, for example, a folding algorithm or process to the 2-D drawing.
      <br/>
      Alternatively, if only a 3-D drawing of the part is provided, then it will be necessary to develop a 2-D flat drawing by applying, for example, an unfolding algorithm or process to the 3-D drawing.
      <br/>
      In accordance with another aspect of the present invention, the 2-D and 3-D models that are saved in the bend model may be developed and represented without the sheet material thickness (i.e., with no thickness).
      <br/>
      This is possible due to the unique symmetry of all sheet metal parts.
      <br/>
      Providing and representing the 2-D and 3-D drawings with no thickness provides modeling and simulation views of the part that can be more easily interpreted and understood by the design programmer, the bending operator and other users.
      <br/>
      Removing the thickness information also shortens and improves the processing time required by the server module and station modules when performing and executing the various features of the invention described herein.
      <br/>
      A more detailed description of such features, as well as the folding and unfolding algorithms that may be utilized in the present invention, is provided below with reference to the accompanying drawings.
    </p>
    <p num="82">
      FIG. 3 shows the general processes and operations performed when developing the bend model data.
      <br/>
      The various types of drawings that may be received or developed based on the customer's order and that may be entered to develop the bend model data are generally shows at steps S.19, S.23, S.27 and S.31. A tool icon bar and menu and/or help screens may be provided by the server module 32 to assist the operator in selecting and executing each of these steps.
      <br/>
      The processing of these drawings to develop the 2-D and 3-D models of the part for the bend model will depend on what type of drawings are initially provided.
      <br/>
      These drawings may be manually entered or developed at server module 32, or they may be downloaded from a tape or disk.
      <br/>
      Server module 32 may, for example, interface with a CAD/CAM system located at, for example, design office 10, or server module 32 may include a stand alone CAD/CAM system.
      <br/>
      Further, the 2-D and 3-D drawings may be saved as DXF or IGES files and imported to server module 32.
    </p>
    <p num="83">
      If a 2-D, single view flat drawing is provided, then processing to develop the bend model may begin at step S.19, as shown in FIG. 3.
      <br/>
      At step S.19, the 2-D, flat drawing that was received or developed may be entered at server module 32.
      <br/>
      Other bend model data, such the overall dimensions of the part (e.g., width, height, depth), and part material information may also be enter at step S.19. Thereafter, a folding algorithm or process may be utilized to develop a 3-D model (with no material thickness) based on the original 2-D single view drawing, as generally shown at step S.21. An example of the processes and operations that may be performed to develop a 3-D model from a 2-D, flat drawing is provided below with reference to FIGS. 8-11.
    </p>
    <p num="84">If a 3-D, wire frame drawing (with no material thickness) of the part is received or developed, the drawing information may be entered at step S.27. In addition, other bend model data, such the overall dimensions of the part (e.g., width, height, depth), and part material information may be entered at step S.27. Thereafter, an unfolding algorithm or process may be executed at server module 32 in order to develop a 2-D model of the part, as shown at step S.29. An example of the processes and operations that may be performed to develop a 2-D model from a 3-D drawing (with no thickness) is provided below with reference to, for example, FIG. 12.</p>
    <p num="85">
      The 2-D and 3-D model representations of the part may be stored as part of the bend model for that part.
      <br/>
      In addition, as noted above, during the development and entry of the 2-D and 3-D models, other bend model data may be entered (such as the part material information and other manufacturing information) so that it may be stored with the bend model data in database 30.
      <br/>
      The various features and data structure arrangements that may be implemented for organizing and storing the bend model data are discussed more fully below (see, for example, FIGS. 17 and 18).
    </p>
    <p num="86">
      As shown in FIG. 3, if a simple 3-D drawing (with no material thickness) of the component is not originally developed or received, additional processing may be necessary in order to develop a 3-D model of the part (with no thickness), before executing the necessary unfolding algorithm or processes to develop the final 2-D model.
      <br/>
      Steps S.23, S.25, S.31 and S.33 generally show the additional processing and operations that may be performed by server module 32 before executing an unfolding algorithm and developing the 2-D model at step S.29.
    </p>
    <p num="87">
      For example, if a 2-D, three-view drawing of the part is originally provided or developed, then at step S.23 the drawing may be entered at or imported to server module 32.
      <br/>
      Further, other bend model data, such the overall dimensions of the part (e.g., width, height, depth), and part material information may also be enter at step S.23. Thereafter, at step S.25, a simple 3-D, flat drawing of the part may be developed based on the 2-D, three-view drawing that was entered.
      <br/>
      The developed 3-D drawing may then be used to develop the 2-D model at step S.29, as shown in FIG. 3.
      <br/>
      An example of the processes and operations that may be performed to develop a 3-D model from a 2-D, three view drawing is provided below with reference to, for example, FIG. 13.
    </p>
    <p num="88">
      If, however, a 3-D drawing with material thickness is originally received or developed, then the drawing information may be entered at step S.31 for further processing before applying the unfolding algorithm.
      <br/>
      Other bend model data, such the overall dimensions of the part (e.g., width, height, depth), and part material information may also be enter at step S.31. Thereafter, at step S.33, an eliminate thickness procedure may be executed to eliminate the thickness in the 3-D drawing.
      <br/>
      In accordance with an aspect of the invention, server module 32 may prompt the operator or user to indicate the thickness in the drawing and to indicate which surfaces (e.g., the outside or inside) should be retained when executing the eliminate thickness procedure.
      <br/>
      An example of an eliminate thickness procedure that may be utilized in the present invention is provided below with reference to, for example, FIGS. 15A and 15B.
      <br/>
      After the thickness in the 3-D drawing has been eliminated at step S.33, logic flow will proceed to step S.29, where the revised 3-D model with no thickness may be utilized and an appropriate unfolding algorithm or process may be applied to develop the final 2-D model.
      <br/>
      An example of an unfolding process and the various processes and operations that may be performed to develop a 2-D model from a 3-D drawing is provided below with reference to, for example, FIG. 12.
    </p>
    <p num="89">
      As shown in FIG. 3, after all of the relevant information has been developed and entered, the part information, bend model information and other data associated with the customer's order may be transferred from server module 32 and stored in database 30 at step S.35. The data stored in database 30 may include feature extraction or search data that may be utilized when performing database searches.
      <br/>
      As described below, the feature extraction or search data may include data that is indicative of the basic or key features of the part associated with each job, so that searches of the database may be performed to locate job information and stored expert knowledge relating to the same or similar parts.
      <br/>
      The data and information entered at server module 32 may be sent directly to database 30 or transferred over communications network 26, as shown, for example, in FIG. 2.
      <br/>
      As indicated above, a more detailed description of the various processes and operations that may be performed for the various drawings when developing the bend model data will be provided below with reference to the accompanying drawings.
    </p>
    <p num="90">
      FIG. 4 is a flow chart of the basic processes and operations performed by each of the station modules that may be provided at the locations 10, 12, 14 . . . 20 of the sheet metal manufacturing facility 38.
      <br/>
      For purposes of illustration, FIG. 4 provides an example of basic logic flow of the processes and operations that may be performed by a station module located at, for example, bending station 18.
      <br/>
      As will be appreciated by those skilled in the art based on the teachings of the present invention, the logic flow illustrated in FIG. 4 may of course be modified for each station module depending upon the nature of the operations and processes to be performed at each of the locations.
      <br/>
      Further, as with server module 32, the processes and operations of the station module described below may be implemented by software or programmed logic.
      <br/>
      In addition, the station module may include a Windows based application with tool bar icons or help and/or menu screens to facilitate an operator or user in selecting and executing the various processes and operations of the station module.
      <br/>
      Such help and/or menu screens may also be provided to facilitate the entry or transfer of data at the station module.
    </p>
    <p num="91">
      As shown in FIG. 4, after initializing the station module at step S.51, an operator may input one or more database search criteria or key terms at step S.53. The search criteria may be entered to locate previous job information or job information relating to a new or current job that is stored in database 30.
      <br/>
      The operator may input, for example, a predetermined reference number or code in order to retrieve particular job information from database 30.
      <br/>
      For example, in accordance with an aspect of the present invention, a bar code may be provided on a routing sheet or may be affixed to the punched stock material and scanned by a bar code reader at the station module to access the information.
      <br/>
      Alternatively, the reference code or number could be entered manually through a keyboard or digital input pad at the station module.
      <br/>
      A translation table may be provided so that the file name of the previous job information may be determined based on the entry of the part reference or job number by an operator.
      <br/>
      In addition, it is contemplated that search criteria or keys may be entered to perform a similar part search for previously stored job information.
      <br/>
      Such a search may be performed based upon the various design features or feature extraction data of the part.
      <br/>
      A description of a similar part search that may be implemented, in accordance with an aspect of the present invention, is provided below with reference to FIGS. 5-7.
    </p>
    <p num="92">
      After the search criteria has been entered at step S.53, the station module may execute a search of the database 30 at step S.55 via communications network 26 and network database module 34.
      <br/>
      The results of the search may then be sent back to the station module and analyzed at step S.57 in order to determine whether the operator or user has requested information relating to a new job or a similar previous job, or whether the request relates to the complete repeat of a previous job.
    </p>
    <p num="93">
      If an identical match is found (e.g., the same part or reference number is located) and it is determined that a previous job is to be repeated, then the stored design and manufacturing information relating to the job may be transferred from database 30 to the station module, where it may be displayed for viewing by the operator, as generally shown at step S.59. The station module may include one or more menu display screens or directories to permit the operator to select and display the various information retrieved from database 30.
      <br/>
      The operator may review the displayed information and run various simulations, such as a 3-D bending simulation at step S.61, to view the various stages in the bending sequence and to understand the geometry of the part for that job.
      <br/>
      The operator may also review other information such as the required tooling and any other special instructions or messages that may have been recorded with the job information.
      <br/>
      After confirming the job information, the operator can then set-up the bending or other required machinery and operate the machinery to produce the specified sheet metal components.
      <br/>
      The job information that is retrieved from database 30 may include the final bending plan data, including the bending code to control the machinery at, for example, bending station 18.
      <br/>
      The set-up and actual operation of the machinery may thus be carried out by the operator, as generally shown at step S.63 in FIG. 4.
    </p>
    <p num="94">
      If no identical or similar job information is located and it is determined that the information relates to a new job (i.e., only preliminary job information has been entered at the server module 32 and complete job information has not yet been developed), then the partial part information and bend model data may be downloaded from database 30 and sent to the station module where it may be viewed by the operator at step S.77. Since the information requested relates to a new job, it will be necessary for the operator to develop and enter a bending plan, including the required tooling and bending sequence.
      <br/>
      Thus, at step S.79, with the information provided at the station module, the bending operator may develop and define the bending sequence and tooling selection for the new job.
      <br/>
      As will be discussed in greater detail below, a graphical user interface (GUI) and other features may be provided at the station module to facilitate the bending operator in developing the bending plan.
      <br/>
      The GUI may be provided to help the operator develop a bending plan by, for example, displaying tooling options, automatically checking for potential collisions between the part and tool(s), and simulating each of the intermediate steps in a proposed bend sequence.
      <br/>
      After developing and entering the bending plan at the server module, the operator may program the bending sequence at step S.80 to generate the bending code (i.e., the CNC or NC code for executing the bend sequence with the bending machinery).
      <br/>
      The bending code may be directly entered at the server module or imported to the server module by interfacing with, for example, a CNC or NC controller of the bending machinery.
      <br/>
      Thereafter, the operator may set-up and test the bending plan at the bending work station at step S.81. When all of the necessary testing and any necessary modifications to the bending plan have been completed, the final bending data may be entered and saved to database 30 at step S.83. The final bending data may include the bend sequence and tool set-up information, as well as the bending program.
      <br/>
      This information may be sent from the station module of, for example, bending station 18 to database 30 so that it may be saved with the other design and manufacturing information associated with the new job.
    </p>
    <p num="95">
      If it is determined at step S.57 in FIG. 4 that the information relates to a similar part of a previous job or the same part of a previous job but having, for example, a different reference or job number or batch size, etc., then logic flow may proceed to step S.65. At step S.65, the previous job information may be retrieved from database 30 and displayed at the bending station 18.
      <br/>
      The bending operator or user may then view the data to determine which changes to the data will be necessary for the similar part.
      <br/>
      Once again, the station module may include a series of menu display screens or directories to enable the operator to select which information to display and the manner in which the information is to be displayed or modified.
      <br/>
      For example, at step S.69, the station module may provide a 3-D bending simulation based on the retrieved information in order to facilitate the operator's development of a bending plan for the similar part.
      <br/>
      After reviewing the previous job information, the operator may modify the tooling and bending information, as well as the bending program, at step S.70. Other job information, such as the dimensions of the part, the reference number or batch size, may also be modified and edited at step S.70. Thereafter, at step S.71, actual tooling set-up and testing may be performed by the operator on the shop floor in order to test the modified bending plan.
      <br/>
      Upon completion of testing and any further modifications to the bending plan, the operator may enter at step S.73 the final bending data and store the same in database 30 under a new reference or job number.
      <br/>
      As noted above, the previous job information may be maintained in database 30 along with the other stored job files.
      <br/>
      Further, various database management functions may be provided for storing, deleting, renaming, etc. the files stored in the database.
    </p>
    <p num="96">
      Referring now to FIGS. 5-7, a detailed description of an example of a similar part search function that may be implemented in accordance with the teachings of the invention will be provided.
      <br/>
      In accordance with an aspect of the present invention, a similar part search procedure may be provided that utilizes a feature based topology similarity search algorithm to search and retrieve previous job information from database 30.
      <br/>
      The similar part search may involve a search for identical and/or similar parts based the design features and/or manufacturing information relating to the part to be produced.
      <br/>
      Further, the similar part search may be implemented through use of software or programmed logic residing within, for example, server module 32 and/or the various station modules throughout the factory 38.
      <br/>
      The similar part search may be executed from server module 32 or any of the station modules of the locations 10, 12, 14 . . . 20 within the sheet metal bending factory 38.
      <br/>
      A high level programming language, such as C++ or Microsoft's VISUAL C++ programming language, and object oriented programming techniques may be utilized to implement the various processes and operations of the similar part search.
    </p>
    <p num="97">
      FIGS. 5A and 5B illustrate the logic flow of a similar part search algorithm or process that may be utilized.
      <br/>
      As shown in FIG. 5A, the relevant part model data file may be accessed at step S.100. The part model may comprise, for example, the bend model data developed at a CAD system located at design office 10 and/or the data developed and entered at server module 32.
      <br/>
      The part model data may include, for example, part topology data representing the orientation, geometric relationships and relative position of the various surfaces or faces and bendlines of the part.
      <br/>
      After the part model data has been retrieved, or after the bend model data for a part has been manually entered, a feature extraction operation may be performed at step S.102 to automatically derive feature extraction data for that part based on the bend model and/or part topology data of the part.
    </p>
    <p num="98">
      According to an aspect of the present invention, feature extraction data may be derived automatically by analyzing the various features of the sheet metal part.
      <br/>
      For example, various surface or face features and bend features may be analyzed to determine the similarities between various parts.
      <br/>
      For instance, the various faces of a part may be analyzed to determine whether adjacent faces have open or touching corners.
      <br/>
      Other features such as the existence of parallel bends, serial bends, collinear bends or opposite bends may be analyzed to determine and extract the distinct and unique features of each part.
    </p>
    <p num="99">
      Table 1 indicates various bend and face features that may be analyzed when performing a similar part search.
      <br/>
      The extraction features that should be included in the feature extraction operation include the positive bend and negative bend features, as well as the touch corner and open corner features.
      <br/>
      In addition, the feature extraction operation should also include at least feature analysis of parallel bends, serial bends, collinear bends, different phase, collinear bends and thickness offset bends.
    </p>
    <p num="100">
      -- TABLE 1
      <br/>
      -- Feature       Brief Description
      <br/>
      -- PosBend       positive bend between two faces
      <br/>
      -- NegBend       negative bend between two faces
      <br/>
      -- P90Bend       90 degree positive bend angle
      <br/>
      -- N90Bend       90 degree negative bend angle
      <br/>
      -- MrPosBend     multiple positive bendlines between two faces
      <br/>
      -- MrNegBend     multiple negative bendlines between two faces
      <br/>
      -- ZBend         Z bend
      <br/>
      -- heMBend       Hemming bend in positive direction
      <br/>
      -- hemBend       Hemming bend in negative direction
      <br/>
      -- TouchCnr      two faces touched in corners with same bend direction
      <br/>
      -- OpenCnr       two faces open in corners with same bend direction
      <br/>
      -- PrllBend      two parallel bendlines with same bend angle direction
      <br/>
      --               and opposite bendline direction
      <br/>
      -- SerlBend      two parallel bendlines with same bend angle direction
      <br/>
      --               and same bendline direction
      <br/>
      -- cLnrBend      collinear bendlines with same bend angle direction on
      <br/>
      --               one face
      <br/>
      -- DfClnrBend    collinear bendlines with same bend angle and on
      <br/>
      --               different faces
      <br/>
      -- tHkoffBend    thickness offset bendlines with same bend angle
      <br/>
      --               direction and on two neighboring faces
      <br/>
      -- touchCnr      two faces touched in corners with opposite bend
      <br/>
      --               direction
      <br/>
      -- openCnr       two faces open in corners with opposite bend direction
      <br/>
      -- prllBend      two parallel bendlines with opposite bend angle
      <br/>
      --               direction and opposite bendline direction
      <br/>
      -- serlBend      two parallel bendlines with opposite bend angle
      <br/>
      --               direction and same bendline direction
      <br/>
      -- clnrBend      collinear bendlines with opposite bend angle direction
      <br/>
      --               on one face
      <br/>
      -- thkOffBend    thickness offset bendlines with opposite bend angle
      <br/>
      --               direction on two neighboring faces
      <br/>
      -- NoRelation    no relation between two faces
    </p>
    <p num="101">
      The feature extraction operation performed at step S.102 may include a series of operations including analyzing the bend model data and topology for each feature, modifying the topologies, and developing feature based matrices from the topologies for further analysis.
      <br/>
      For purposes of illustration, FIGS. 6A-6G show an example of a feature extraction operation for a part consisting of a four bend box with touched corners and a part consisting of a four bend box with open corners.
      <br/>
      For purposes of illustration, FIGS. 6A-6G show the feature extraction based on the corner relationship of adjacent faces.
      <br/>
      For a closed, four bend box, with five faces (1-5) such as that shown in FIG. 6A, and for an open, four bend box, with five faces (1-5) such as that shown in FIG. 6B, the same simple face topology, such as that shown in FIG. 6C, may be provided to represent either part.
      <br/>
      This topology may be stored in and provided with the part or bend model data.
      <br/>
      The simple face topology of FIG. 6C, however, only provides basic information regarding the relationship of the faces (1-5) of the part and does not provide any information as to the various features of the part, such as the corner relationship between adjacent faces or the type of bends that are included.
      <br/>
      Accordingly, during the feature extraction operation, by analyzing the part or bend model data and the related face topology stored therewith, the basic face topology may be modified to contain additional information with respect to the various features of the part.
    </p>
    <p num="102">
      For instance, by examining the part or bend model data for the closed, four bend box of FIG. 6A, the corner relationship of adjacent faces may be analyzed and a modified face topology, such as that indicated in FIG. 6D, may be developed to indicate the touched corner status of the respective faces.
      <br/>
      Similarly, by examining the part or bend model data of the open, four bend box of FIG. 6D, a modified face topology, such as that shown in FIG. 6E, may be developed to indicate the open corner relationship between the various adjacent faces in the part.
      <br/>
      As shown in FIGS. 6D and GE, special connectors may be added to the face topology to indicate the relationship (e.g., touched or open) between the corners of the faces.
      <br/>
      Other data may be added to the face topology data structure to indicate other features (e.g., the type of bends present, etc.) and to developed a featured based, face topology.
      <br/>
      After modifying the topology to include the feature based information, a matrix may be developed so that the extracted information may be more easily analyzed and compared.
      <br/>
      For example, based on the feature based face topology of FIG. 6D, a matrix such as that shown in FIG. 6F may be developed to indicate the various features of the closed, four bend box of FIG. 6A. Similarly, for the open, four bend box of FIG. 6B, a matrix such as that shown in FIG. 6G may be developed based on the feature based face topology shown for example in FIG. 6E. Other feature extraction data may also be indicated in the matrix, such as the bend features of the part (e.g., a 90 (degree)  positive bend angle or a 90 (degree)  negative bend angle, etc.).
    </p>
    <p num="103">
      As noted above, the features extraction operation of step S.102 may be performed by analyzing the bend model data and topologies to determine if various features are present in the part.
      <br/>
      In accordance with an aspect of the present invention, the feature extraction operation may be performed on the bend model and topology data provided for the part.
      <br/>
      This data includes all of the critical geometric and location data (e.g., in 2-D space (X,Y) and/or 3-D space (X,Y,Z)) relating to the sheet metal part, including face data, bendline data (e.g., bendline length and location, etc.), face-bendline relationship data, bend angle data, and special features data (e.g., data relating to special bending such as Z-bends and Hemming, etc.).
      <br/>
      The lines, bendlines and other entities may be defined by endpoints and/or vectors.
      <br/>
      For example, each 2D line may be specified by a set of 2D endpoints (e.g., X1,Y1 and X2,Y2) and each 3D line may be defined by a set of 3D endpoints (e.g., X1,Y1,Z1 and X2,Y2,Z2).
      <br/>
      Bendlines may be represented by vectors, which indicate 2D or 3D space location as well as direction of the bendline.
      <br/>
      Further, 2D arcs may be specified by 2D space data (e.g., CenterX, CenterY, Radius, Begin Angle, End Angle) and 3D arcs may be defined by 3D space data (e.g., CenterX, CenterY, CenterZ, View Matrix, Radius, Begin Angle, End Angle).
      <br/>
      Part topology data may also be provided to indicate the location of the various faces and bendlines of the part, as well as their geometric relationships to one another.
      <br/>
      Each face may be defined by a collection or linked data list of lines and/or arcs.
    </p>
    <p num="104">
      To extract features of the part, the feature extraction operation may be performed on the bend model and topology data to analyze and determine whether certain features are present in the part.
      <br/>
      This process may include analyzing the bend model and topology data for the part based on the various characteristics and relationships associated with each of the features to be extracted.
      <br/>
      By analyzing the bend model and topology data for the existence of the characteristics and relationships for each feature to be analyzed, the presence of features (such as a touched corner or open corner feature between faces, or a parallel or serial bends feature) may be detected.
      <br/>
      Different processes may be provided to detect the particular characteristics and relationships of each feature in the feature extraction operation.
      <br/>
      Based on the similarity of characteristics and relationships among the features to be analyzed, processes may be combined or developed to check for the existence of more than one feature in the part.
    </p>
    <p num="105">
      By way of a non-limiting example, a process that may be performed during the feature extraction operation of step S.102 in order to extract and detect corner features, such as a touch corner feature of two faces having the same bend direction (i.e., a TouchCnr feature in Table 1), will be provided.
      <br/>
      The process described below may also be applied to detect other features, such as a touch corner feature of two faces having with opposite bend direction (i.e., a touchCnr feature in Table 1) or open corner features between two faces having the same or opposite bend direction (i.e., a OpenCnr or openCnr feature in Table 1).
      <br/>
      The process may also be modified to detect other features (e.g., parallel bends, serial bends, etc.).
      <br/>
      In addition, the data relating to each possible combination of faces may be analyzed for the characteristics and relationships of each of the features to be extracted.
    </p>
    <p num="106">
      For example, for the touched corner feature TouchCnr, the basic characteristics or relationship to be detected include: two faces with a common face; the same bendline directions; non-parallel bendline directions; and bendlines with a common vertex (or vertices with a distance therebetween that is within a predefined range).
      <br/>
      For the touched corner feature touchCnr, similar characteristics or relationships should be detected; however, instead of the faces having bendlines that are in the same direction, the faces should have bendlines that are in the opposite direction (see, e.g., Table 1).
      <br/>
      The open corner features OpenCnr and opencnr may be similarly detected, however, for each feature the presence of an open corner between the faces (e.g., the bendlines of the faces are spaced apart by a distance that is greater than a predefined range) instead of a touched corner relationship, and the detection of the bendlines having the same bendline direction or the opposite direction (see, e.g., Table 1 and the definitions provided therein for OpenCnr and opencnr) should be analyzed.
    </p>
    <p num="107">
      To detect the touch corner feature (e.g., the TouchCnr feature in Table 1), the bend model and topology data for any two faces may first be analyzed to determine if the two faces are attached to a common face.
      <br/>
      This may be detected by looking at the bendline data for each of the faces and the bendline-face relationship data for each of the bendlines to determine if a common face exists.
      <br/>
      If the two faces are attached to a common face, then the bendline direction of each of the faces may be analyzed to see if they have the same bendline direction (or the opposite bendline direction if detecting, for example, the touchcnr feature).
      <br/>
      This may be determined by analyzing, for example, the vector data indicating the bendline direction for each of the faces.
    </p>
    <p num="108">
      If it is determined that the two faces have a common face and have the same bendline direction based on the bend model and topology data, then the data may be checked to detect if the bendlines are parallel.
      <br/>
      Various methods may be used to detect whether the bendlines are parallel based on the bend model and topology data.
      <br/>
      For example, the detection of parallel bendlines may be determined by taking the cross-product of the vectors defining the bendline directions.
      <br/>
      If the cross-product of the vectors equals zero (or is approximately zero), then it may be determined that the bendlines are parallel.
      <br/>
      If the cross-product of the vectors does not equal zero (or is not approximately zero), then the bendlines of the two faces are not parallel.
    </p>
    <p num="109">
      After determining that the two faces have a common face, the same bendline direction and the bendlines are not parallel, then the bend model data may be analyzed to determine the corner relationship between the faces (e.g., touched or open).
      <br/>
      The corner relationship of the two faces may be determined by detecting from the bend model data whether the bendlines of the faces have a common vertex.
      <br/>
      If the bendlines have a common vertex, then the two faces have a touched corner relationship with the same bendline direction (e.g., TouchCnr feature in Table 1).
      <br/>
      If the bendlines have a common vertex, but it was determined that the bendlines of the two faces do not have the same direction, then it may be determined that the two faces instead have a touched corner relationship with opposite bendline direction (e.g., touchCnr feature in Table 1).
    </p>
    <p num="110">
      If the bendlines of the two faces do not have a common vertex, then it still may be determined that the two faces have a touched corner relationship if the distance between the vertices is within a predefined range.
      <br/>
      Often, a minimum amount of space will be provided between adjacent faces of the part to provide clearance for passage of, for example, the punch tool.
      <br/>
      This spacing is usually defined by the width of the tool at the height of the flange.
      <br/>
      By way of example, a touched corner feature may be determined to be present if the spacing between the vertices of the bendlines of the two faces is within 0-5 mm.
      <br/>
      If the spacing between the corner of the two faces is greater than the predefined range, then it may determined that a open corner feature is present (e.g., the OpenCnr or opencnr feature of Table 1).
    </p>
    <p num="111">
      The above described process may be performed for every possible combination of faces in the part, to determine the corner feature of each of the faces.
      <br/>
      Other features relating to the faces and bendlines of the part may be conducted in a similar fashion by analyzing the part geometry and topology data.
      <br/>
      An exemplary code for performing the feature extraction operation of step S.102 is provided in Appendix A. The code was written in C++ programming language and includes the various processes for extracting and detecting features such as those noted in Table 1.
      <br/>
      Comments are provided in the code of Appendix A to facilitate the analysis of the logic and algorithms used therein.
      <br/>
      In addition, the terminology for the various features in Table 1 is maintained in the sample code to aid understanding of the same.
    </p>
    <p num="112">
      After detecting the various features of the part, the basic topology of the part may be modified to include the extracted features.
      <br/>
      While it may be useful to provide feature based topologies, such topologies can not be easily compared with one another.
      <br/>
      Instead, the inventors of the present application have discovered that it is more efficient and easier to compare feature extraction information when provided in the form of matrices.
      <br/>
      Therefore, according to one of the features of the present invention, a feature based part matrix (such as the representative matrix shown in FIGS. 6F and 6G) may be created based on the features detected during the feature extraction operation.
      <br/>
      The feature based matrix for the part may then be compared with other predefined and stored matrices to determine what basic shapes or features are included in the part.
    </p>
    <p num="113">
      A feature based matrix may be created and stored for each part after detecting and extracting the various features for the part.
      <br/>
      As shown in FIGS. 6F and 6G, the matrix may be a two dimensional matrix that is symmetric and that has an order that is equal to the number of faces in the part.
      <br/>
      The matrix may contain all of the detected feature information for the part, with the various features between each of the faces being provided in each of the locations of the matrix.
      <br/>
      The feature based part matrix may be temporarily stored in the memory of the server or station module and only used and compared with the predefined matrices during execution of the similar part search.
      <br/>
      Alternatively, the feature based part matrix may be permanently stored with the other job information in database 30 and accessed from any location within the factory.
    </p>
    <p num="114">
      Referring back to FIG. 5A, after the feature extraction operation has been performed, the resultant feature extraction data matrix may be compared with predefined feature extraction data matrices provided in a feature topology library.
      <br/>
      The feature topology library may be stored as a separate datafile in a database, such as database 30, or the memory of the server module or the station module.
      <br/>
      The feature library may consist of predefined matrices with feature extraction data corresponding to or defining basic or fundamental part shapes (e.g., a four bend box, a bridge, etc.).
      <br/>
      Each of the predefined feature based matrices, as well as the feature based part matrix, may be stored as ASCII or text files.
      <br/>
      The comparison at step S.104 may be conducted to determine the basic or fundamental shapes/features that are present in the sheet metal part, as illustrated at step S.106. A stored lookup table may be provided to indicate which fundamental shape corresponds to each of the predefined feature matrices.
      <br/>
      When a match is located, the lookup table may be accessed at step S.106 to determine which fundamental shapes are present.
      <br/>
      The matched matrices from the predefined library may be of the same order as the feature based part matrix (in which case the part is determined to exactly correspond and include only one fundamental shape), or may be sub-matrices of the part matrix (in which case the part may include more than one fundamental shape).
    </p>
    <p num="115">
      Recursive programming techniques may be utilized to compare the feature based part matrix with the matrices in the predefined library.
      <br/>
      By interchanging the indexes of the matrices when comparing the information therein, the use of data assignments may be avoided and the amount of required processing time reduced.
      <br/>
      The use of recursive programming techniques and interchanging of indexes also facilitates the comparison of matrices that have different orders and different base faces.
    </p>
    <p num="116">
      According to an aspect of the present invention, the comparison operation that is performed at step S.104 may consist of a series of comparisons and may initially begin based on the comparisons of matrices relating to more complicated shapes (e.g., those shapes containing multiple bends or complex forming such as tabs) and then proceed through less complicated shapes (e.g., those shapes containing fewer bends or less complex bends or number of faces).
      <br/>
      This series of comparisons may be performed until a predetermined number of fundamental shapes are located in the part.
      <br/>
      For example, the comparison operation may be performed to extract the three most complicated features or shapes within any particular part.
      <br/>
      In addition, this operation may be performed by first conducting the series of comparisons on groups of matrices that relate to shapes that are more common or frequently found in sheet metal parts, and then proceeding to less common shapes.
      <br/>
      Various methods for comparing the part with the predefined library may be performed to provide useful results.
    </p>
    <p num="117">
      For example, the series of comparisons may be first applied to a right angle group of matrices that include fundamental shapes that include right angle bends, such as rectangular and square shapes with multiple right angle bends and simple parts with right angle bends.
      <br/>
      This group of matrices may be searched based upon a series of comparisons extending from more complex matrices within the group (e.g., a matrix corresponding to a four bend box with tabs) to less complex matrices within the group (e.g., a matrix relating to a simple hat part).
      <br/>
      The series of the comparisons may then be applied to a polygonal part group of matrices and then a special features group of matrices.
      <br/>
      The polygonal part group may include matrices defining parts having more than five sides and at least one bend angle that is greater than 90 degrees.
      <br/>
      The special features group of matrices may include matrices within the predefined library that relate to parts with special features or forming, such as Z-bends or Hemming.
      <br/>
      Once again, the series of comparisons between the feature based matrix of the part and the predefined matrices within each of the groups may be performed based on decreasing levels of complexity.
      <br/>
      Thereafter, other groups of predefined matrices may be compared, such as a multiple features group of matrices that includes parts that have two or more features on a single face of the part.
    </p>
    <p num="118">
      By comparing the part with the matrices in the predefined library in order of complexity, and by applying the series of comparisons to groups of matrices based on frequency of appearance and use, a more effective and efficient comparison of the library may be conducted to determine the fundamental shapes in the part.
      <br/>
      In addition, an overlap of detected features is prevented and only the more complex shapes are identified.
    </p>
    <p num="119">
      At step S.108, a feature relation operation may be performed to determine the relationship between the fundamental features or shapes located in the part.
      <br/>
      The relation between the features or shapes may be defined in terms of distance.
      <br/>
      The distance between any two shapes may be determined based on the number of bendlines or faces between the base face of each of the shapes.
      <br/>
      Alternatively, the relationship between features may be defined in terms of the physical distance or real dimension between the features, by geometrically analyzing the part and the relative position and distance between the base face of each of the features.
    </p>
    <p num="120">
      Assume, for purposes of illustration, that the three most complicated features or shapes determined at step S.106 for the part consist of a four bend box, a bridge, and another four bend box, as shown in FIG. 7A. A feature relation operation performed on such a part may be conducted to determine, for example, the number of bendlines between the base surface or face of each fundamental feature.
      <br/>
      As shown in FIG. 7B, the feature relation between the base (1) of the first four bend box and the base (2) of the bridge is a spacing of two bendlines.
      <br/>
      Further, the relation between the base (1) of first four bend box and the base (3) of the second four bend box is a spacing of four bendlines, and the relation between the base (2) of the bridge and the base (3) of the second four bend box is a spacing of two bendlines.
    </p>
    <p num="121">
      Various processes may be provided for determining the number of bendlines between the base faces of the fundamental shapes of the part.
      <br/>
      For example, a matrix analysis of the feature based part matrix and the predefined shape matrices may be utilized to determine the feature relation in step S.108. First, the corresponding base faces of each of the fundamental shapes may be located in the part matrix.
      <br/>
      This may be performed by correlating the base face of the predefined shape matrix with the face index in the part matrix.
      <br/>
      As discussed above, the predefined shape matrices isolated during the comparison operation may be sub-matrices of the part matrix.
      <br/>
      In order to locate the corresponding base face for each fundamental shape in the part matrix, the location of the shape matrix within the part matrix and the correlation between the indices of the matrices may be analyzed.
      <br/>
      With the base face of each of the fundamental shapes being predefined and located within the first column of the shape matrix, the corresponding location and base face within the part matrix may be located.
    </p>
    <p num="122">
      After determining the base faces of each of the fundamental shapes in the feature based part matrix, the distance between the base faces of each shape may be analyzed to determine the feature relationships.
      <br/>
      This analysis may include a search process to identify the distance between any two base faces.
      <br/>
      By looking at the feature and bendline information in the part matrix, the number of bendlines between any two base faces may be determined.
      <br/>
      If more than one path is possible between two faces, the minimum distance may be used to define the feature relation at step S.108.
    </p>
    <p num="123">
      After performing the feature relation operation, logic flow continues to step S.110. As shown in FIG. 5B, an identification of database search keys may be performed at step S.110 in order to determine the search keys to be utilized in the similar part search of the database.
      <br/>
      The search keys may consist of any number of combination of features and feature relations identified for the part.
      <br/>
      In addition, any hierarchy of criteria may be used for assembling the search keys.
      <br/>
      By way of a non-limiting example, the search keys may be developed by the following criteria: (i) the first and second most complicated features or shapes identified in the part; (ii) the distance or feature relation between the two most complicated features; (iii) the third most complicated feature or shape identified in the part; and (iv) the feature relation or distance between the first most complicated feature and the third most complicated feature, and the distance or feature relation between the second most complicated feature and the third most complicated feature identified in the part.
      <br/>
      FIG. 7C illustrates the search keys that may be developed based on the example of FIG. 7A.
    </p>
    <p num="124">
      In order to simplify the search of the database, the search keys may be represented by a string of integers, with predetermined codes being assigned to the various fundamental shapes defined in the topology library.
      <br/>
      For example, assume that the integer code "16" was assigned to a four bend box, and that the integer code "32" was assigned to a bridge.
      <br/>
      In such a case, the search keys of the example in FIG. 7C would be represented by a string of integers comprising "16, 16, 4, 32, 2, 2", wherein "4" and "2" represent the various distances between the fundamental shapes or features.
      <br/>
      The representation of the search keys, however, is not limited to integer strings and any combination of integers and/or character strings may be used to represent the search keys.
    </p>
    <p num="125">
      The search keys for each part may be stored with the job information (as a separate file or in the same file) in a database, e.g., database 30.
      <br/>
      The search keys, which are representative of the feature extraction data, may be manually entered or automatically developed, as described above.
      <br/>
      Additional feature extraction data, such as the feature based part matrix, may also be stored with the search keys.
      <br/>
      If the search keys are stored in a separate data file, a lookup table may be provided for locating the part information associated with each set of search keys.
      <br/>
      Alternatively, the search keys may be saved with a data field identifying the part information (e.g., by part or reference number).
    </p>
    <p num="126">
      At step S.112, a cooperative search of the database is performed based on the identified search keys.
      <br/>
      The cooperative search is a search using a cooperative database search technique.
      <br/>
      The cooperative search technique not only locates parts with identical search keys, but also parts having similar search keys.
      <br/>
      This enables the identification of similar and identical parts in the database.
      <br/>
      When a search is performed based on a particular part, the identified search keys for that part may be compared with the other search key data in the database.
      <br/>
      The cooperative search performed at step S.112 may be adapted to identify those items in the database which exactly match or are most similar to a particular part defined by the search keys, by relaxing or modifying the sequence of search keys.
      <br/>
      Various processes and methods may be employed for adapting the search keys during the cooperative search.
    </p>
    <p num="127">
      For example, an initial search of the database is performed to identify parts having the exact sequence of search keys as that identified for the part to be searched.
      <br/>
      This is performed by comparing the identified search keys with the search keys stored in the database.
      <br/>
      After identifying the parts (if any) with the same search keys, subsequent searches of the database may be performed based on different modified search key sequences to locate other similar parts.
      <br/>
      Initially, the items or criteria within the search keys that are less critical or sensitive (such as the feature relation or distances) may be modified and searched before modifying the more critical or sensitive search items (such as the fundamental features or shapes located within the part).
      <br/>
      In addition, each of these items may be modified in terms of their importance, with more weight or importance given to those items relating to the first and second most complicated features or shapes located in the part.
      <br/>
      For instance, a first subsequent search may be performed after modifying the defined distances between the third most complicated feature and the first and second most complicated features.
      <br/>
      The distance may be modified by increasing the distance by a predetermined number of bendlines (e.g., 1-3) or defining a predetermined range for the distance based on the current value for the distance.
      <br/>
      Thereafter, the distance between the first and second most complicated features or shapes may be altered to provide another set of modify search keys for searching the database.
      <br/>
      After modifying the feature relation or distance search keys for the part, the identified shapes may be altered to derive additional modified search keys in the cooperative search.
      <br/>
      For example, the search key item relating to the third most complicated feature or shape may be changed to a related but less complex shape depending on the current feature or shape (e.g., from a four bend box with tabs to a simple four bend box).
      <br/>
      In addition, the search keys for the first and second most complicated features may be similarly altered to provided further modified search keys for the cooperative search.
    </p>
    <p num="128">
      The manner in which the distance and feature/shape related to the search keys are modified during the cooperative search may be executed according to various methods and techniques.
      <br/>
      As described above, the amount by which to vary the distance may depend on the current value of the distance.
      <br/>
      The distance amount (e.g., 4 bendlines) may be modified to a distance range (e.g., 3-5 bendlines) to expand and make the search more cooperative.
      <br/>
      For the features or shapes, modification of the search keys may also be performed to identify similar parts.
      <br/>
      The features or shapes may be modified through a hierarchical structure of feature types.
      <br/>
      For example, the current feature type (e.g., a four bend box) may be modified to a less complex feature type (e.g., a three bend box) that is related and within the same feature type.
      <br/>
      The hierarchical structure by which the features/shapes are modified may be predetermined and developed based on different methodologies, such as type abstraction hierarchy (TAH).
      <br/>
      More information on TAH and TAH generation are provided, for example, in CHU et al., Wesley W., Cooperative Query Answering via Type Abstraction Hierarchy, CSD-900032, Department of Computer Science, University of California, Los Angeles, (October 1990) and CHIANG, Kuorong, Automatic Generation of Type Abstraction Hierarchies for Cooperative Query Answering, a dissertation submitted as part of the requirements for a Degree of Philosophy in Computer Science, University of California, Los Angeles, (1995), the disclosures of which are expressly incorporated herein by reference in their entireties.
    </p>
    <p num="129">
      Other processes and steps may be performed during the cooperative search.
      <br/>
      For example, in addition to searching the database based on the identified search keys relating to the features of the part, searching may also be performed based on search criteria relating to the manufacturing information for the part.
      <br/>
      For instance, additional search keys may be utilized to compare, for example, the machine set-up required for each part.
      <br/>
      The machine set-up information may include the type of machine or machinery required to produced the part, the tool(s) and tool set-up used to produce the part, and/or the backgaging setting(s) of the machinery.
      <br/>
      The additional search keys may be developed based on the machine set-up information and/or other manufacturing information and be used along with the identified search keys when performing the cooperative search of the present invention.
      <br/>
      As a result, the parts that are identical or similar to the part to be produced may be identified based on both the design and manufacturing features of the part.
    </p>
    <p num="130">
      In order to select the most similar parts, a selected parts search may be executed at step S.114 to perform a more detailed comparison of the results from the cooperative search and to select a predetermined number of parts that are the same or most similar to the part searched.
      <br/>
      The selected parts search may involve the analysis of additional information or characteristics of each of the parts identified from the cooperative search.
      <br/>
      This may involve analyzing various features of the located parts, such as the dimensions of the part or the types of holes or openings in the part, which are not provided from the search key data.
      <br/>
      This may also involve comparing the manufacturing information relating to each of the located parts, such as the machine set-up required for each part.
      <br/>
      As noted above, the machine set-up information may include the type of machine or machinery required to produced the part, the tool(s) and tool set-up used to produce the part, and/or the backgaging setting(s) of the machinery.
      <br/>
      In order to perform the selected parts search, the bend model and other job information for each part may be accessed from the database based on the search keys identified during the cooperative search.
      <br/>
      As noted above, a lookup table or additional data field may be provided to provide the job reference number or code associated with each set of search keys.
      <br/>
      After retrieving the part information from the database, the additional information concerning each part (e.g., part dimension, material type, special forming, part holes or openings, etc.) may be analyzed to determine which parts are most similar to the part searched.
      <br/>
      This process is optional and may act as an additional screening process for selecting and grouping those parts from the database that are most similar to the part.
      <br/>
      By analyzing and matching this additional information or characteristics of the part, the selected parts search may be performed to identify or select a predetermined number or set of most similar parts.
      <br/>
      For example, the selected parts search may identify the five most similar parts based on the number of matching search keys and matching additional part characteristics.
      <br/>
      The number of parts to be selected from the selected parts search is not limited to five, and may be selected based on the needs of the factory and the number of the parts actually stored in the database.
      <br/>
      This number may also be selectively modified to provide more effective and useful search results, and the user may be given the opportunity to modify this number to vary the search set.
    </p>
    <p num="131">
      After performing the selected parts search, a similarity index may be calculated at step S.116 to rank the parts (in terms of similarity of features and number of matching search keys) identified in the selected parts search.
      <br/>
      The similarity index may be calculated and provided as output at the server or station module at step S.118, so that the user may select which job files are to be retrieved from the database and provided for viewing.
      <br/>
      The similarity index may provide a ranking of the selected parts (e.g., a ranking of 1 through 5 with the job or reference number for each part) based on the level of similarity of features between the selected parts and that of the searched part.
      <br/>
      For this purpose, the feature based matrix for each of the parts may be compared to that of the searched part.
      <br/>
      Comparing the feature based matrices may provide a better indication of the similarity between the selected parts and the searched part.
      <br/>
      As noted above, a feature based part matrix may be stored along with search keys for each part.
      <br/>
      However, permanently storing the feature based part matrix for each previous job along with the search keys may unnecessarily take up a large amount of memory space (particularly when a large number of parts are stored on the database).
      <br/>
      As such, it is possible to only store the search key data for each of the parts and to automatically generate the feature based matrix for each of the selected parts when a similar part search is performed.
    </p>
    <p num="132">
      Accordingly, after the bend model and other job information has been retrieved for each of the selected parts, a feature based matrix may be developed through the feature extraction operation of the invention, as described above with respect to step S.102. The feature based matrix for the searched part, which may be temporarily stored during a similar part search, may then be compared with each of the developed feature based matrices of the selected parts.
      <br/>
      Various methods and processes may be utilized to compare the feature based matrices of the parts and to determine the similarity between the parts.
      <br/>
      For example, for each feature based matrix of the selected parts, the locations within the matrix may be compared with those of the searched part.
      <br/>
      Each location within the matrices may be compared based on recursive programming techniques.
      <br/>
      The information in the matrices may be compared by determining the location of corresponding base faces in each matrix and interchanging the indexes of the matrices.
      <br/>
      Since the selected parts may correspond to or have shapes that are sub-features of the searched part, and since the indexes of the matrices may not be identical or numbered in the same way, it will be necessary to locate comparable faces in the part matrices and to switch the indices when comparing the information therein.
      <br/>
      In addition, where more than one sub-feature is located in a searched part, it may also be necessary to introduce one or more pseudo faces (i.e., face columns and rows in the matrix with no or blank information) in order to provide matrices of the same order when comparing the information in the matrices.
    </p>
    <p num="133">
      When comparing the information in the matrices, different ranking schemes may be used in order to determine the level of similarity between each of the selected parts and the searched part.
      <br/>
      For example, a penalty based ranking scheme may be used wherein a predetermined penalty level or amount is assigned for each non-matching location within the matrix.
      <br/>
      After comparing all of the information in the matrices, the total penalty level for each selected part may then be used to determine the similarity index.
      <br/>
      The selected part with the lowest penalty level may be determined to be the most similar part to the searched part.
      <br/>
      The other selected parts may also be ranked based on the total penalty level associated with each part (e.g., the lower the penalty level the higher the similarity index).
    </p>
    <p num="134">
      In accordance with another aspect of the present invention, the penalty levels for each non-matching location may be assigned based on the type of information located therein.
      <br/>
      The penalty level may be an integer amount and may be varied based on the criticality or importance of the non-matching information.
      <br/>
      For example, a higher penalty level or amount may be assigned for non-matching locations relating to different and unrelated feature groups (e.g., a parallel bend feature versus a serial bend feature).
      <br/>
      In contrast, for non-matching locations relating to different but similar feature groups (e.g., a touch corner feature with same bendline direction versus a touch corner feature with opposite bendline direction).
      <br/>
      The penalty levels or amounts may be predetermined and categorized based on the type of information and the type of difference present for non-matching locations.
    </p>
    <p num="135">
      An exemplary code for performing the similarity index operation of step S.116 is provided in Appendix B. The code was written in C++ programming language and includes the various processes and operations described above with respect to comparing the matrices and assigning penalty levels for non-matching location.
      <br/>
      As noted above, the resultant total penalty levels for each selected part that was compared may be used to derive and display the similarity index.
      <br/>
      The code listing in Appendix B includes comments to facilitate understanding of the logic and structure of the exemplary program code therein.
    </p>
    <p num="136">
      Referring now to FIGS. 8-16, a more detailed description of the various processes and operations that may be performed for developing the bend model data and developing the 2-D and 3-D models of the part based on various 2-D and 3-D drawings will be provided in accordance with an aspect of the present invention.
      <br/>
      As discussed above, the bend model data associated with each sheet metal component includes data relating to both the 2-D and 3-D representations of the part.
      <br/>
      Based on the type of original drawings provided or developed based on the customer's order, various folding and unfolding algorithms and other processes may be utilized to develop the 2-D and 3-D models.
      <br/>
      In particular, FIGS. 8-11 show an example of the logic flow of the folding algorithm and other processes that may be utilized for developing a 3-D model based on an original 2-D, single view drawing of the part.
      <br/>
      Further, FIG. 12 shows an example of the basic logic flow of the unfolding algorithm and other processes that may be used for developing a 2-D model based on an original 3-D drawing (with no thickness).
      <br/>
      Lastly, FIGS. 13-15 and FIG. 16 show examples of the logic flow of the various processes and operations that may be implemented to develop a 3-D model with no thickness from, respectively, a 2-D, three view drawing and a 3-D drawing with thickness.
      <br/>
      The resultant 3-D model (with no thickness) that is developed from these processes and operations may then be utilized to develop a 2-D model based on an unfolding algorithm or process, such as that disclosed herein.
    </p>
    <p num="137">
      FIG. 8 illustrates the logic flow of the processes and operations for developing a 3-D model from a 2-D, single view drawing using a folding algorithm.
      <br/>
      The functions and operations performed in the flow chart of FIG. 8 may be implemented with software or programmed logic residing in, for example, server module 32.
      <br/>
      At step S.120, the 2-D, single view flat drawing that was provided or originally developed based on the customer's specifications is entered or imported to the server module 32.
      <br/>
      The 2-D flat drawing may be developed and entered into the server module 32 through the use of CAD software, or may be imported to the server module by interfacing with an appropriate CAD or CAD/CAM system, such as VELLUM or CADKEY.
      <br/>
      The 2-D drawing may be stored, for example, as a DXF or IGES file and may illustrate the punched and/or cut stock material that is to be bent.
      <br/>
      The 2-D flat drawing may also indicate the location of the bending lines and the location of holes or other openings in the surfaces or faces of the sheet metal part.
      <br/>
      In order to prepare the 2-D drawing for later processing, an auto-trimming and cleanup function may be performed by server module 32 at step S.122, before a succeeding face detection process is performed at step S.124 and a bendline detection operation is executed at step S.126.
    </p>
    <p num="138">
      The auto-trimming and cleanup function of the present invention is provided in order to prepare the 2-D flat drawing for processing.
      <br/>
      The 2-D flat drawing is a 2-D representation of the sheet metal part in its unfolded state and includes part entities, such as lines and arcs, that make up and represent the geometry of the part, as well as indicate the location of any openings or holes in the part.
      <br/>
      Normally, the entities of such 2-D flat drawings are entered and developed using a CAD or CAD/CAM system.
      <br/>
      However, when constructing the 2-D flat drawing, such entities are often improperly connected or overlapped, and a single entity may be used to indicate the boundaries of more than one face.
      <br/>
      Further, outside lines defining the boundary of the part may be disconnected at their adjacent corners, making it difficult to detect the out dimensions of the part and each face.
      <br/>
      Further, the 2-D flat drawing may include extraneous information, such as dimensional information and text.
      <br/>
      Such irregularities make it difficult to properly analyze the original 2-D drawing and to uniformly detect the faces and bendlines of the part.
      <br/>
      By providing the auto-trimming and cleanup operation of the present invention, each of the faces may be represented by a unique set of connected entities.
      <br/>
      As a result, the 2-D flat drawing may be more easily and efficiently analyzed for subsequent processing and eventual folding in order to develop the 3-D model representation.
    </p>
    <p num="139">
      As shown in FIG. 9A, an original 2-D drawing may not provide trimming between faces and a single line entity in the drawing may define the outer boundary or boundaries of more than one face.
      <br/>
      As discussed above, such an arrangement makes it difficult to detect each of the faces.
      <br/>
      The auto-trimming function of the present invention may be provided to analyze the end points and intersection points of each of the part entities (such as lines, arcs and bendlines), in order to determine connectivity information and to break such entities at their intersection points.
      <br/>
      Such a trimming function may include setting the endpoints for each of the broken entities to the determined intersection point.
      <br/>
      For example, trimming of the intersection point illustrated in FIG. 9A would result in three meeting entities (two lines and one bendline), each having a common endpoint at the intersection point.
      <br/>
      By providing such a trimming function, the faces of the part may be more easily detected based on entity analysis and connectivity.
      <br/>
      A more detailed description of a face detection operation that may be implemented is provided below with reference to FIGS. 10A-10G.
    </p>
    <p num="140">
      Various processes and operations may be utilized to detect the intersection points of the entities of the 2-D drawing.
      <br/>
      Such processes and operations may be developed based on the format and arrangement of the data in the 2-D drawing file.
      <br/>
      Typically, a 2-D flat drawing will include geometrical data (defining the various part entities, etc.) and non-geometrical (e.g., text, etc.) data.
      <br/>
      It is possible to distinguish between the geometrical data from the non-geometrical data based on the keywords provided for each line or sequence of data.
      <br/>
      Such keywords are set in accordance with the data format of the 2-D drawing.
      <br/>
      Common formats for 2-D and 3-D drawings include DXF and IGES formats.
      <br/>
      By analyzing the geometrical data for each of the entities, the end points and intersection points for such entities may be detected and, where appropriate, trimming may be performed.
    </p>
    <p num="141">
      As discussed above, the lines, bendlines and other entities may be defined by endpoints and/or vectors.
      <br/>
      For example, for a 2-D flat drawing, each 2-D line may be specified by a set of 2-D endpoints (e.g., X1,Y1 and X2,Y2) and bendlines may be represented by vectors, which indicate 2-D space location as well as direction of the bendline.
      <br/>
      Further, 2-D arcs may be specified by 2-D space data (e.g., CenterX, CenterY, Radius, Begin Angle, End Angle).
      <br/>
      The geometrical data may also include attributes to distinguish between the various types of line entities (e.g., arc, solid line, dashed line, dot-dashed line, etc.).
      <br/>
      Typically, arc entities are used to indicate holes and openings in a sheet metal part, and solid lines are used to indicate the boundaries and shape of the part.
      <br/>
      Bendlines are usually represented by dashed lines, and the centerline of the part is represented by a dot-dashed line.
    </p>
    <p num="142">
      The geometrical data from the original 2-D flat drawing may be analyzed to determine the intersection points between each entity.
      <br/>
      Various data analysis techniques, such as data assignment or recursion, may be used to analyze the geometrical data for each entity of the 2-D drawing.
      <br/>
      Based on the endpoints and/or other 2-D space data for each entity, simple geometrical analysis may be applied to determine whether lines and other entities intersect.
      <br/>
      If two entities are determined to intersect, then each entity may be broken at the determined intersection point and the resultant entities may have their endpoints assigned to a common point defined by the intersection point.
    </p>
    <p num="143">
      The manner in which trimming is performed may be based on the type of entities that are detected to intersect.
      <br/>
      For example, if two solid line entities are detected to intersect, then each line entity may be broken to provide four line entities that meet at the determined intersection point, as shown in FIG. 9B. Further, if a line entity and arc entity are determined to intersect, such as that shown in FIG. 9C, then each entity may be broken to provide two line entities and arc entities that have common endpoints.
      <br/>
      Detection of the intersection of other entities, however, may not result in trimming.
      <br/>
      For example, if any entity is determined to intersect with a centerline (e.g., a dot-dashed entity), then no breaking of the entities is required, since the centerline of any part does not define or distinguish the faces or bendlines of the part and trimming is not required.
      <br/>
      In addition, unconnected entities may be broken if the open intersection or area is within a predetermined tolerance.
      <br/>
      For instance, if the endpoint of a potentially intersecting line is within a predetermined tolerance or distance e (e.g., 0.0-0.01 mm, or 0.0-0.001 inches) of actually intersecting another entity, then the entities may be treated as connecting and intersecting at that projected point; and the entities may be broken, as shown, for example, in FIG. 9D.
    </p>
    <p num="144">
      After auto-trimming has been performed, the resultant data may then be processed by a cleanup function to detect and correct non-connected entities; however, the present invention is not limited to such processing; and, in order to reduce processing time, the cleanup function may performed simultaneously with the auto-trimming function while each of the entities are being analyzed.
      <br/>
      During cleanup, the geometrical data of the 2-D drawing is analyzed to detect open intersections or areas between adjacent entities.
      <br/>
      As with the auto-trimming function, the endpoints and other 2-D space data of each entity may be analyzed to detect an open intersection areas between the entities.
      <br/>
      Simple geometrical analysis may be applied to such data to determine whether the endpoints of the entities are within a predetermined tolerance or distance  EPSILON  (e.g., 0.0-0.01 mm, or 0.0-0.001 inches) of one another.
      <br/>
      If the endpoints of the entities are determined to have such an open intersection, then the entities may be connected and assigned a common endpoint, such as that shown in FIG. 9E.
    </p>
    <p num="145">
      Once again, the manner in which the cleanup function is performed may be controlled based on the type of entities that are detected to have an open intersection.
      <br/>
      If two solid lines are detected to have an open intersection, then the endpoints of the lines may be assigned a common endpoint (see, for example, FIG. 9E).
      <br/>
      However, if any entity is determined to have an open intersection with a centerline of the part (e.g., a dot-dashed entity), then the entities should not be connected nor assigned a common endpoint and the centerline entity should be ignored.
      <br/>
      In addition, the cleanup function may include additional processes or operations for deleting the non-geometrical data (text, etc.) from the 2-D drawing.
      <br/>
      As noted above, the non-geometrical data may be distinguished from the geometrical data based on the keywords provided with the 2-D drawing data.
      <br/>
      The cleanup function may also incorporate other cleanup functions, such as those described in greater detail below with reference to the 2-D cleanup function of the invention (see, for example, FIGS. 14A-14E).
    </p>
    <p num="146">
      After the auto-trimming and cleanup functions are performed at step S.122, a face detection procedure may be performed on the processed 2-D drawing, at step S.124. In accordance with an aspect of the present invention, the face detection procedure may include face detection logic for detecting and defining the faces of the part based on entity (line and arc) and loop analysis.
      <br/>
      FIGS. 10A-10H illustrate an example of the various processes and operations that may be performed in the face detection procedure.
      <br/>
      Loop detection techniques may be used in the present invention to determine and detect the faces of the part.
      <br/>
      The face detection procedure may be implemented through software or programmed logic residing at, for example, server module 32.
    </p>
    <p num="147">
      According to an aspect of the present invention, a loop detection analysis of the outside boundary of the part followed by analysis of the minimum or inside loops of the part may be utilized to detect each of the faces.
      <br/>
      Due to the unique geometry of sheet metal parts, the faces and openings of the part may be detected based on the analysis of the sequence of the relative maximal (e.g., outside) and minimal (e.g., inside) loops.
      <br/>
      As discussed below, loop analysis may be performed based on the connectivity of the line and arc entities of the part.
      <br/>
      By performing loop analysis from the outside of the part and proceeding towards the center of the part, the openings and faces of the part may be detected based on the boundaries defined between the loops in accordance with a cyclic sequence (e.g., face material, opening, face material, opening, etc.).
    </p>
    <p num="148">
      Assume that a 2-D flat drawing, such as that shown in FIG. 10A, is provided with various line entities for each face as shown in the drawing.
      <br/>
      As noted above, loop and entity analysis may be performed by starting from the outside boundary of the part.
      <br/>
      Any entity on the outside boundary of the part may be used as an initial reference point.
      <br/>
      By way of non-limiting example, the left most side line entity may be detected and used as an initial reference point, as shown in FIG. 20B. The left most side line entity may be detected by comparing the geometrical data of each of the entities in the 2-D drawing and determining which entity has the lowest X-coordinate value.
      <br/>
      After the left most line entity has been detected, an outward appearance of the part may be derived from a point P1 to detect the outside boundary of the part, as shown in FIG. 10C. Either endpoint of the left most line entity may be used to define point P1.
      <br/>
      In the illustrated embodiment of FIG. 10C, the upper endpoint (i.e., the endpoint with the greatest Y-coordinate value) has been used as point P1.
    </p>
    <p num="149">
      Conventional loop analysis techniques may be used to derive the outward appearance or loop about the part.
      <br/>
      For example, lead line vectors may be projected from the initial point P1 and the endpoints of the connecting entities as the outward appearance of the part is followed.
      <br/>
      As each entity is detected and traversed, a flag may be provided to indicate that the entity has been picked (e.g., a flag in memory may be set to 1 to indicate that it has been selected once).
      <br/>
      The loop path may be initiated in either direction from the initial point P1.
      <br/>
      For example, the lead line vector may be projected in the counterclockwise direction (e.g., by projecting the lead line vector in the Y-coordinate direction) from the point P1.
      <br/>
      The loop is completed when the loop path returns to the initiating point (i.e., point P1).
    </p>
    <p num="150">
      As noted above, from the initial point P1 a lead line vector may be projected in the counterclockwise direction (e.g., by initiating the first lead line vector in the Y-coordinate direction).
      <br/>
      Thereafter, in order to detect the first entity in the path of the loop, the angle that each unselected entity about point P1 forms with the lead line vector is measured and analyzed based on a coordinate frame, with the entity that forms the smallest angle with the lead line vector being selected.
      <br/>
      For the outside loop, each angle may be measured based on the outside angle that the entity line forms with the lead line vector.
      <br/>
      The entities about point P1 may be determined based on which entities have an endpoint that is common to point P1.
      <br/>
      The unselected status of each entity may be determined by analyzing the flag associated with each entity.
      <br/>
      As shown in FIG. 10C, two entity lines (one extending in the X-coordinate and one extending in the Y-coordinate) are provided about P1 in the exemplary 2-D drawing illustrated therein.
      <br/>
      When analyzing these entities, the line entity that extends in the Y-coordinate would be selected since it forms a smaller angle (i.e., 0 degrees) with the lead line vector than the angle (i.e., 270 degrees) of the other line entity.
    </p>
    <p num="151">
      The loop analysis would then continue to the other endpoint of the selected line entity, which would have a flag set to indicate that it has been selected.
      <br/>
      At that endpoint, another lead line vector would be projected and the unselected entities about that point would be compared to determine which forms the smaller angle with the lead line vector.
      <br/>
      Once again, the angle should be measured from the outside of the lead line vector and a coordinate frame may be used to determine the angle amount.
      <br/>
      If an arc entity is encountered, then the angle should be measured from the outside of the lead line vector to a line that is tangent to the arc.
      <br/>
      Further, if only one entity is about the next endpoint (such as at the corner positions of the part), then no comparison is necessary and that entity is simply selected and included in the loop.
    </p>
    <p num="152">
      As the loop path proceeds about the outward appearance of the part, each selected entity may be included in a linked list to indicate the connectivity of the entities within the loop.
      <br/>
      When the path returns to the initial point P1, the cycle is complete and the loop may be defined (L4) based on the outward appearance and the linked list of entities or lines that indicate the outside boundary of the part.
      <br/>
      Each of the lines or entities within the loop L4 may be connected at their end points.
      <br/>
      The direction of the loop L4 may be turned in the opposite direction (i.e., clockwise), as shown in FIG. 10D, in order to indicate that it is an outside loop.
      <br/>
      The direction of the loop may be defined based on the order in which the lines are linked in the loop L4; and, thus, the direction may be changed by reversing the order of the link list.
    </p>
    <p num="153">
      After the outward loop has been completed, inside loop analysis of the part may be performed based on a similar process to that used for the outside loop analysis.
      <br/>
      In the inside loop analysis, however, each of the unselected entities are compared based on the inside angle that each entity forms with the lead line vector.
      <br/>
      Further, during the inside loop analysis, where both entities about a point are indicated as being selected (e.g., when comparing two outside line entities which border a face), the two entities may still be compared unless they have been selected twice (i.e., a flag setting of 2).
      <br/>
      When there is an entity that has been selected at least once (e.g., an outside entity) and an unselected entity (e.g., an inside entity), no comparison may be performed and the unselected entity may be selected as part of the loop.
      <br/>
      FIGS. 10E-10G illustrated exemplary inside loops that may be performed to detect and define the faces of the part shown in FIG. 10A.
    </p>
    <p num="154">
      The inside loop analysis may begin at any of the outside entity endpoints or by detecting an entity that has not been selected.
      <br/>
      For example, point P1 may be selected to initiate the inside loop analysis and may be used to project the lead line vector; alternatively, one of the inside line entities that was not selected during the outside loop analysis may also be used as an initial point for analysis.
      <br/>
      As with the outside loop analysis, the lead line vector may be extended in the counterclockwise direction (e.g., by initiating the first lead line vector in the Y-coordinate direction).
      <br/>
      Each entity about point P1 is then compared to determine which entity forms the smallest angle with the lead line vector.
      <br/>
      A coordinate frame may be used to determine the angle formed with the lead line vector.
      <br/>
      As noted above, during inside loop analysis the entities are compared based on the inside angle that each entity forms with the lead line vector instead of with the outside angle.
      <br/>
      After the initial entity has been selected and included in the linked list for the loop, its flag may be increment by one and further analysis may be performed by projecting the next lead line vector.
      <br/>
      The process continues until the loop returns to the initial starting point, at which point the first inside loop is defined (e.g., L1) by its associated linked list of entities.
    </p>
    <p num="155">
      Further inside loop analysis may performed in a similar fashion by proceeding inwardly of the part.
      <br/>
      Subsequent starting points may selected by determining which entities have been only selected once.
      <br/>
      Entities with flags that have been selected twice will indicate that it is an outside entity that has already been selected for the outside loop (e.g., L4) and for at least one of the inner loops (e.g., L1).
      <br/>
      Once again, as each entity is selected, its associated flag may be incremented by one to indicate that it has been included in the inside loop link list.
    </p>
    <p num="156">
      After all of the inside loops have been defined (e.g., after all of the entities have been selected twice in the example of FIG. 10G), the resultant loops may be used to construct a loop tree.
      <br/>
      FIG. 10H illustrates an exemplary loop tree that may be defined based the detected loops L1-L4.
      <br/>
      The outside loop (L4) of the part may be defined as the root of the tree, with each inside loop (L1-L3) that has a common entity with the outside loop being defined as children of the root.
      <br/>
      The presence of common entities may be detected based on analyzing and comparing the linked list of entities that define each loop.
      <br/>
      If additional entities (e.g., holes or openings) are detected within the inside loops, then these loops may be defined as children of the inside loops (i.e., grandchildren of the root of the loop tree) within which they are located.
    </p>
    <p num="157">
      After the face detection procedure has been performed at step S.124, a bendline detection operation may be performed at step S.126. As shown for example in FIG. 11A, when detecting and analyzing the loops of a part at step S.124, the face detection logic of the invention may utilize the loop tree to define the face information and store the detected faces as nodes in a bend graph data structure.
      <br/>
      The faces of the part may be detected from the sequence of the outside and inside loops in the loop tree.
      <br/>
      As indicated above, each of the loops may include a link list of entities or lines.
      <br/>
      These entities may be used to define the boundaries of each face of the part.
      <br/>
      The bendline detection operation of step S.126 may then be performed to determine the relationship between the faces and bendlines of the part.
      <br/>
      The bendline detection operation of step S.126 may include bendline detection logic for detecting all of the bendlines between the various faces of the part by searching for common edges or line entities between any two adjacent faces.
      <br/>
      Further, for faces that connect at more than one area (e.g., when applying the bendline detection algorithm to a 3-D model--see, e.g., FIG. 12 discussed below) a number of heuristics may also be applied to detect and select the minimum number of bendlines for the part.
      <br/>
      The detected bendlines then may be stored as connecting agents between the face nodes to produce the final bend graph data structure, as shown for example in FIG. 11B.
    </p>
    <p num="158">
      The bendline detection operation of the present invention may be implemented through software or programmed logic residing at, for example, server module 32.
      <br/>
      The purpose of the bendline detection operation is to detect and select the bendlines for the part so that the part becomes connected with the minimum number of bendlines.
      <br/>
      The bendline detection operation may be provided for both 2-D and 3-D versions of the part.
      <br/>
      A discussion of an application of the bendline detection operation in connection with an original 3-D model is provided below with reference to FIG. 12. As noted above, the detected bendlines may be stored as connecting agents between the face nodes to produce the final bend graph data structure.
      <br/>
      This final bend graph data structure may then be utilized to fold and construct the 3-D version of the part from the 2-D data model.
    </p>
    <p num="159">
      The original 2-D drawing that is provided as input at step S.120 in FIG. 8 may not include bendline information or such bendline information may be ambiguous and not uniquely or consistently defined.
      <br/>
      Thus, the bendline detection operation may be performed to detect the bendlines and their relation to the detected faces of the part.
      <br/>
      During this process, the linked list of entities defining each of the faces may be analyzed to determine adjacent edges or line entities that each face has with other faces of the part.
      <br/>
      This may performed by analyzing all possible contacts between any given two faces.
      <br/>
      A contact may be determined based on the presence of a common line entity (or entities that are within a predetermined distance tolerance of one another) that has a length that is greater than 0 (i.e., the line entity is not a point but a real line).
      <br/>
      The geometrical data in the linked lists may be analyzed to determine the presence of such contact between any two faces in the part.
    </p>
    <p num="160">
      If a particular face only has one common edge or area of contact with another face, then the entity that is common to both faces may be defined as a bendline.
      <br/>
      For faces that have common contact at more than one area (e.g., a 3-D model; however, this may occur with 2-D models as well), a number of heuristics may be applied to detect and select the minimum number of bendlines for the part.
      <br/>
      The heuristics that are applied should be adapted so that the faces of the part become connected at the bendlines and so that no continuous loop of faces is formed (since such a bend sheet metal part is impossible to manufacture).
    </p>
    <p num="161">
      For example, one such heuristic that may be applied is to select the common area that has the longest contact area as the bendline.
      <br/>
      Thus, where a face has more than one common edge with other faces, this heuristic may be applied so that the common entity having the longest length is selected as the bendline for the face.
      <br/>
      This heuristic is based on the principal that is usually better to have a longer contact area when manufacturing bent sheet metal parts.
      <br/>
      Another heuristic that may be applied relates to selecting among different possible combinations of bendlines (such as when determining the bendlines for a 3-D model).
      <br/>
      According to this heuristic, when all possible common areas are detected and various combinations of bendlines may be selected, the combination of bendlines that produces the minimum number of bendlines is selected.
    </p>
    <p num="162">
      After the bendlines have been detected, the faces of the part and the determined bendlines may be displayed to the operator for verification.
      <br/>
      If the operator is not satisfied with the selection of bendlines for the part, the bendline detection operation may provide a manual selection feature to permit the operator at the server module 32 to selectively indicate the preferred bendlines for the sheet metal part.
      <br/>
      The operator may indicate to keep or change a bendline by any suitable input means, such as a mouse or keyboard, etc.
      <br/>
      The revised bendlines selected by the operator may then be used for developing the final 3-D (or 2-D) part.
    </p>
    <p num="163">
      Various processes and operations may be provided to implement the bendline detection operation of the present invention.
      <br/>
      An exemplary code for implementing the bendline detection operation is provided in Appendix C attached hereto.
      <br/>
      The sample code was written in C++ programming language and includes comments to facilitate the understanding of the logic flow therein.
      <br/>
      The sample code is an exemplary implementation for the bendline detection operation that may be performed on a 2-D or 3-D model, and includes heuristics (such as those described above) for determining the optimum selection of bendlines.
    </p>
    <p num="164">
      The detected face and bendline information may be utilized in the folding and unfolding process of the invention.
      <br/>
      By performing a three dimensional rotation around each bendline during folding or unfolding, the resultant 3-D or 2-D model may be derived.
      <br/>
      This task may be accomplished by simply applying matrix transformation, involving rotations and translations, to each of the faces and other entities of the part.
      <br/>
      The features of various commercially available unfolding and folding software applications may be utilized to implement these basic unfolding or folding steps of the invention.
      <br/>
      For example, the Amada UNFOLD and FOLD system software may be utilized to perform these basic operations.
      <br/>
      The Amada UNFOLD and FOLD system software is available from Amada America, Inc. (previously operating under the corporate name of U.S. Amada Ltd.), Buena Park, Calif.
      <br/>
      Information concerning the Amada UNFOLD and FOLD system software may be found in the Amada UNFOLD Manual for AUTOCAD (March 1994 Edition), the Amada UNFOLD Manual for CADKEY (May 1994 Edition), and the Amada Windows UNFOLD Manual for CADKEY (November 1995 Edition), the disclosures of which are expressly incorporated herein by reference in their entireties.
      <br/>
      Further discussion of the folding process to develop the 3-D model from the 2-D model is provided below with reference to step S.132.
    </p>
    <p num="165">
      Referring back to FIG. 8, after the bendline detection operation has been performed at step S.126, server module 32 may prompt the user for pertinent bend and deduction information for subsequent use during the folding process.
      <br/>
      For example, at step S.128, server module 32 may prompt the user to indicate the bend amount for each bend line, including the bend angle and/or bend inside radius, as well as the bend direction (e.g., front or back, etc.).
      <br/>
      At step S.130, the user may also be prompted by the server module 32 to enter the V-width, material type, and/or the deduction amount.
      <br/>
      This information may be utilized to compensate for bend deduction during the folding process.
      <br/>
      Depending upon the thickness and type of material used for the sheet metal part, as well as the angle of the bend and the V-width of the die to be utilized, the actual sheet metal part will tend to stretch by a deduction amount during folding of the sheet metal part.
    </p>
    <p num="166">
      In order to compensate for this effect in the model, the deduction amount information may be utilized so that the dimensions of the faces of the part are stretched by half of the deduction amount on each side of the bending line when constructing the 3-D model through the folding process.
      <br/>
      In accordance with an aspect of the present invention, this deduction amount may be entered directly by the user at the server module 32 (e.g., by keyboard, etc.).
      <br/>
      Alternatively, a material table may be displayed to the operator that includes the deduction amounts based on the material type and thickness of the part.
      <br/>
      The material table may indicate the various deduction amounts based on different bend angles and V-widths.
      <br/>
      The user may then automatically set the deduction amount by selecting a desired V-width and bend angle from the material table displayed at the server module 32 (e.g., by mouse or keyboard).
      <br/>
      The inside radius of the bend angle may also be automatically set by the user through the material table when selecting a desired V-width.
    </p>
    <p num="167">
      The deduction amount entered by the operator may be in (or converted after entry by the operator to) a unit measure of length (e.g., mm) that is identical to that represented by the part geometry data.
      <br/>
      During a folding process, the dimensional length of each of the faces on either side of the bendline may be increased by one-half of the deduction amount entered for that particular bendline.
      <br/>
      The dimensional length of the face that is perpendicular to the bendline may be increased by extending the endpoints of the entities defining the boundaries of the faces that are located on either side of the bendline.
      <br/>
      Such deduction compensation may also be performed at each of the other bendlines of the part based on the deduction amount provided by the operator for each bend.
    </p>
    <p num="168">
      In step S.132, a folding process is performed with deduction compensation to develop the 3-D model based on the processed 2-D, flat drawing.
      <br/>
      As noted above, the folding procedure may be carried out by conventional geometric modeling methods, including the use of matrix transformation and using each of the respective bendlines defined in the final bend graph data structure as a rotational axis.
      <br/>
      In addition, in order to compensate for the effect of deduction, when folding and developing the 3-D model, the faces of the part may be stretched by half of the deduction amount on each side of the bendline to more accurately reflect the change in the dimensions of the faces when actual bending of the sheet metal is performed.
    </p>
    <p num="169">
      For example, when performing the folding process at step S.132, the part geometry and topology data (or bend graph structure) may be utilized, along with the bend parameters (e.g., bend angle, inside radius, etc.).
      <br/>
      A transformation matrix may be computed for each face, bendline, hole and forming in the part represented in 2-D space.
      <br/>
      Conventional matrix transformation may be applied to the 2-D flat data to get the 3-D space data.
      <br/>
      The transformation generally involves a rotation followed by a translation.
      <br/>
      As noted above, rotation is performed about each bendline axis in accordance with bend angle amount.
      <br/>
      Translations are performed for shifting and moving the geometrical data about space.
      <br/>
      Such translations may be determined based on the bending radius, bending angle and deduction amount for each bend.
      <br/>
      During folding, deduction compensation is performed so as to stretch or increase the dimensions of the faces by one-half of the deduction amount on either side of the bendline, as described above.
      <br/>
      Such deduction compensation will provide a 3-D representation of the part that more accurately reflects the dimensions of the 2-D sheet metal part when it is folded by bending machinery.
    </p>
    <p num="170">
      For further information on geometrical modeling and transformations, see, for example, MORTENSON, Michael M., Geometric Modeling, John Wiley &amp; Sons, New York (1988) and FOLEY et al., James, The Systems Programming Series: Fundamentals of Interactive Computer Graphics, Addison-Wesley Publishing Company, Reading, Mass. (1983), the disclosures of which are expressly incorporated herein by reference in their entireties.
      <br/>
      Chapter 8 of MORTENSON provides a discussion of geometrical transformations, including translations and rotations (see, e.g., pp. 345-354).
      <br/>
      Further, FOLEY et al. at Chapter 7, pp. 245-265 provides information on geometrical transformations, including matrix representation of 2-D and 3-D transformations.
      <br/>
      Additional information of modeling and geometrical transformations may also be found in MANTYLA, Martti, An Introduction to Solid Modeling, Computer Science Press, Inc., Rockville, Md. (1988), the disclosure of which is expressly incorporated herein by reference in its entirety.
      <br/>
      Information on coordinate transformations may be found at pp. 365-367 of MANTYLA.
    </p>
    <p num="171">
      Referring now to FIG. 12, a description of the processes and operations that may be performed for developing a 2-D model based on an original 3-D, flat drawing (with no thickness) will be provided, in accordance with another aspect of the present invention.
      <br/>
      Similar to the folding process described above with reference to FIG. 8, the various processes and operations for unfolding a 3-D drawing and developing a resultant 2-D model may be implemented through the software and/or programmed logic at server module 32.
      <br/>
      As shown in FIG. 12 at step S.140, the original 3-D, flat drawing which was provided or developed based on the customer's specification may be entered or imported into server module 32.
      <br/>
      The 3-D drawing may be stored as a DXF or IGES file and may be entered by interfacing with or utilizing a CAD or CAD/CAM system from server module 32.
      <br/>
      After entering the 3-D drawing, an auto-trimming and cleanup operation may be performed at step S.142 by server module 32 to prepare the drawing for subsequent face detection and other processing.
      <br/>
      As discussed above with reference to FIGS. 9A-9E, the auto-trimming and cleanup functions may break and connect entities and surfaces so that the various faces of the part may be properly detected and defined.
    </p>
    <p num="172">
      The auto-trimming and cleanup operation described above with reference to FIGS. 8 and 9 may similarly be applied to the geometric data of the 3-D drawing entered at step S.140 of FIG. 12. Instead of analyzing the data in 2-D space (as was the case with the 2-D flat drawing), each of the entities (e.g., lines, arcs, etc.) represented in the 3-D drawing may be analyzed based on the 3-D coordinate and space information provided therein.
      <br/>
      The intersection points and open intersection areas may be detected by analyzing each entity individually and comparing it with other entities one at a time.
      <br/>
      Once again, basic geometrical analysis of the endpoints and other attributes of the entities may be utilized to determine intersection points and open intersection areas within tolerance.
    </p>
    <p num="173">
      After performing auto-trimming and cleanup functions on the 3-D drawing, at step S.144 a face detection operation may be performed to detect and define each of the faces of the sheet metal part.
      <br/>
      Face detection for the 3-D drawing may be performed by analyzing and detecting each of the faces in 2-D space and developing a loop tree, similar to that described above.
      <br/>
      Face detection may be executed by starting at any predetermined entity.
      <br/>
      For example, the left most entity (i.e., the entity with the lowest X-coordinate) may be used as the initial entity.
      <br/>
      Thereafter, a plane may be defined by taking the initial line entity and another connecting or adjacent line entity (e.g., any entity with a common endpoint to the initial entity).
      <br/>
      A face detection operation may then be performed using loop and entity analysis, such as that described above with respect to FIGS. 10A-10H. As each entity is detected within the defined 2-D plane, the various outside and inside loops may be defined and the entities may be marked (e.g., by setting or incrementing a flag of the selected entity) to indicate that they have been selected and included in a linked list defining one of the loops in that plane.
    </p>
    <p num="174">
      Subsequent loop analysis may then be performed in the other 2-D planes that comprise the 3-D drawing.
      <br/>
      In order to proceed with loop analysis of the other entities, additional planes may be defined by searching for unmarked or unselected entities within the 3-D drawing.
      <br/>
      Such planes may be defined between two unselected entities or an unselected entity and a previously selected entity that was previously analyzed.
      <br/>
      In each of the additional 2-D planes, further loop analysis may be performed to detect the inside and outside loops.
      <br/>
      Once again, linked lists of connecting entities may be maintained and the selected entities marked (e.g., by incrementing a flag associated with the selected entity) as each of the loop paths are defined.
    </p>
    <p num="175">
      After all of the entities have been detected, the resulting loops may be used to develop a loop tree for each of the 2-D planes that were analyzed.
      <br/>
      As discussed above, a loop tree may be provided to determine the faces and opening or holes in the sheet metal part.
      <br/>
      For a 3-D drawing, a loop tree may be developed for each of the planes of the sheet metal part.
      <br/>
      The loops detected within each plane may be grouped and analyzed to develop each loop tree.
      <br/>
      The root of each tree may be defined as the outside loop detected in the plane, with each inside loop of that plane that has a common entity with the outside loop being defined as children of the root.
      <br/>
      The presence of common entities may be detected based on analyzing and comparing the linked list of entities that define each loop.
      <br/>
      If additional entities (e.g., holes or openings) are detected within the inside loops of the plane, then these loops may be defined as children of the inside loops (i.e., the grandchildren of the root of the loop tree) within which they are located.
      <br/>
      The generated loop trees may then be used to detect all of the faces of the 3-D drawing.
      <br/>
      The detected faces may then be stored as nodes in a bend graph data structure.
    </p>
    <p num="176">The resultant bend graph structure may then be supplemented with the connecting bending line connecting agents after performing a bendline detection operation at step S.146. The bendline detection operation and the development of the final bend graph structure or part topology may be carried out in a similar manner to that described above with reference to FIGS. 11A and 11B.</p>
    <p num="177">
      As discussed above, an exemplary code for implementing the bendline detection operation is provided in Appendix C attached hereto.
      <br/>
      The sample code is an exemplary implementation for the bendline detection operation that may be performed on a 2-D or 3-D model, and includes heuristics (such as those described above) for determining the optimum selection of bendlines.
      <br/>
      The bendline detection operation may include a manual selection feature to permit the operator at the server module 32 to selectively indicate the preferred bendlines for the sheet metal part if not satisfied with the bendlines that were detected.
      <br/>
      The operator may indicate to keep or change a bendline by any suitable input means, such as a mouse or keyboard, etc.
      <br/>
      The revised bendlines selected by the operator may then be used for developing the final 2-D part.
    </p>
    <p num="178">
      Before performing an unfolding process about the bending lines of the final bend graph structure, the user may be prompted for the V-width, material type and/or deduction amount at step S.148. As discussed above, since metal tends to stretch when it is folded, the dimensions of the 3-D part will be slightly larger than that of the 2-D flat part.
      <br/>
      As such, during unfolding of the sheet metal part, the dimensions of the part should be shrunk or reduced by the deduction amount based on the material type and V-width selected.
      <br/>
      Accordingly, in accordance with an aspect of the present invention, a shrinking process may be performed when unfolding the 3-D model to more accurately develop the 2-D model and the respective dimensions of its surfaces.
      <br/>
      As described above, the deduction amount may be entered directly by the user or a material table may be displayed in order to enable the user to automatically set the deduction amount by selecting a desired V-width and bend angle.
    </p>
    <p num="179">
      The deduction amount entered by the operator may be in (or converted after entry by the operator to) an unit measure of length (e.g., mm) that is identical to that represented by the part geometry data.
      <br/>
      During an unfolding process, the dimensional length of each of the faces on either side of the bendline may be decreased by one-half of the deduction amount entered for that particular bendline.
      <br/>
      The dimensional length of the face that is perpendicular to the bendline may be decreased by reducing the endpoints of the entities defining the boundaries of the faces that are located on either side of the bendline.
      <br/>
      Such deduction compensation may also be performed at each of the other bendlines of the part based on the deduction amount provided by the operator for each bend.
    </p>
    <p num="180">
      After entry of all of the necessary data, an unfolding process may be performed at step S.150 to develop the 2-D model.
      <br/>
      Conventional methods may be used for unfolding the 3-D bend model, including the use of matrix transformation with each of the bending lines being used as a rotational axis.
      <br/>
      During the unfolding process, each of the bend angles may be measured and the part may be unfolded by the bend angle amount to develop the flat 2-D model.
      <br/>
      In addition, based on the deduction amount entered, a shrinking or reduction of the dimensions of the faces may be performed by half of the deduction amount on each side of the bending line to more accurately simulate the physical characteristics of the sheet metal material and the difference between the 3-D and 2-D models.
    </p>
    <p num="181">
      When performing the unfolding process at step S.150, the part geometry and topology data (or bend graph structure) may be utilized, along with the bend parameters (e.g., bend angle, inside radius, etc.).
      <br/>
      A transformation matrix may be computed for each face, bendline, hole and forming in the part represented in 3-D space.
      <br/>
      Conventional matrix transformation may be applied to the 3-D data to get the 2-D space data.
      <br/>
      The transformation generally involves a rotation followed by a translation.
      <br/>
      As noted above, rotation is performed about each bendline axis in accordance with bend angle amount.
      <br/>
      For unfolding, rotation is carried out in the reverse direction until there is a 180 degree angle between the two faces (i.e., until the part is flat).
      <br/>
      Translations are performed for shifting and moving the geometrical data about space.
      <br/>
      Such translations may be determined based on the bending radius, bending angle and deduction amount for each bend.
      <br/>
      During unfolding, deduction compensation is performed so as to shrink or decrease the dimensions of the faces by one-half of the deduction amount on either side of the bendline, as described above.
      <br/>
      Such deduction compensation will provide a 2-D representation of the part that more accurately reflects the dimensions of the sheet metal part before it is folded during a bending operation.
    </p>
    <p num="182">
      Once again, further information on geometrical modeling and transformations may be found in MORTENSON, FOLEY et al. and MANTYLA.
      <br/>
      As indicated above, Chapter 8 of MORTENSON provides a discussion of geometrical transformations, including translations and rotations (see, e.g., pp. 345-354).
      <br/>
      Further, FOLEY et al. at Chapter 7, pp. 245-265 provides information on geometrical transformations, including matrix representation of 2-D and 3-D transformations.
      <br/>
      In addition, information on coordinate transformations may be found at pp. 365-367 of MANTYLA.
    </p>
    <p num="183">
      As discussed above with reference to FIG. 3, if a 2-D, three view drawing or a 3-D, wire frame drawing with thickness is originally provided or developed based upon the customer's order, then further processing will be required in order to develop a 3-D model without thickness; and, thereafter, the developed 3-D model without thickness may be used to create a 2-D model by applying an unfolding process or algorithm.
      <br/>
      FIGS. 13-15 illustrate the various processes and operations that may be applied in order to develop a 3-D model based on an original 2-D, three view drawing.
      <br/>
      Further, FIG. 16 illustrates, in accordance with another aspect of the present invention, the additional processes and operations that may be applied for developing a 3-D model without thickness from an original 3-D, wire frame drawing with thickness.
      <br/>
      Once again, the various processes and operations depicted in FIGS. 13-16 may be implemented through the software and/or programmed logic residing at, for example, server module 32.
    </p>
    <p num="184">
      Referring now to FIG. 13, a description of the logic flow of the operations and processes that may be performed in order to develop a 3-D model (with no thickness) based on an original 2-D, three view drawing will be provided, in accordance with the teachings of the invention.
      <br/>
      Initially, the 2-D, three view drawing may be entered or imported to server module 32 at step S.160. The original 2-D, three view drawing may comprise various views of the part (e.g., a front view, a top view and a right side view--see, e.g., FIGS. 14B and 14C) and may be a CAD drawing such as a DXF or IGES file that may be downloaded or imported to server module 32.
      <br/>
      Thereafter, at step S.162, a 2-D cleanup operation may be performed by server module 32 in order to prepare the drawing for subsequent processing into the 3-D model.
      <br/>
      The 2-D cleanup operation may be performed in order to eliminate extraneous and non-geometrical information, including text, centerlines and dimension lines, which do not represent the actual geometry of the part.
      <br/>
      The 2-D cleanup operation may also be performed in order to connect all exterior lines at, for example, their connecting ends and to break and trim any intersecting lines or entities.
      <br/>
      FIG. 14A illustrates an example of the logic flow of the various processes that may be carried out when the 2-D cleanup operation is performed by server module 32.
    </p>
    <p num="185">
      As shown in FIG. 14A, the 2-D drawing is first read from a data file or loaded at step S.180 by server module 32.
      <br/>
      Thereafter, at step S.182, server module 32 may analyze the respective entities and geometrical data in the 2-D drawing and break the various entities in order to prepare the drawing for further processing.
      <br/>
      The break and trimming function performed at step S.182 may be carried out in a similar manner to that described above with respect to the auto-trimming and cleanup function of the present invention.
      <br/>
      Thus, at step S.182, all of the geometrical data in the 2-D, three view drawing may be analyzed in order to detect the intersection of entities and any open intersections that are within tolerance.
      <br/>
      Any intersecting lines may be broken, with the resultant entities meeting at a common endpoint defined by the intersection point.
      <br/>
      Further, for entities having an open intersection area that is within a predetermined tolerance (e.g., 0.0-0.01 mm or 0.0-0.001 inches), such entities may be joined, in a similar manner to that described above with respect to, for example, FIG. 9E.
    </p>
    <p num="186">
      At step S.184, the perimeter of the 2-D drawing sheet may be detected and any exterior lines or data (such as border lines, coordinate grids and numbers, etc.) may be eliminated.
      <br/>
      As shown in FIG. 14B, a 2-D, three view drawing will often be provided on a drawing sheet.
      <br/>
      The drawing sheet may include extraneous and non-geometrical information that is not necessary to process the views of the sheet metal part.
      <br/>
      As such, during step S.184, this type of information may be detected and eliminated from the 2-D drawing when developing the 3-D model utilizing the 2-D clean-up process of the invention.
    </p>
    <p num="187">
      The 2-D drawing data may include key words or type fields to indicate the type of data contained therein (e.g., geometrical or non-geometrical/text).
      <br/>
      Thus, these key words or type fields, which are provided based on the data format of the drawing file, may be used to eliminate various extraneous information, such as text and other non-geometrical data.
      <br/>
      However, further processing is usually necessary in order to properly eliminate all of the unwanted drawing sheet data.
      <br/>
      Often, the border lines and other outside information are saved as entities (e.g., lines, etc.) that can not easily be distinguished based on the data key words or type fields.
      <br/>
      As such, according to an aspect of the present invention, a connectivity graph structure may be developed when analyzing the data of the 2-D drawing.
      <br/>
      The connectivity graph structure may indicate for each entity a list of incident vertices and a list of connected entities.
      <br/>
      For each vertex, a list of adjacent vertices and a list of entities on which it is incident may also be provided.
      <br/>
      With this graph structure, which may be developed when performing the break and trimming function of step S.182, it may be determined which entities are connected by matching endpoints.
      <br/>
      As a result, extraneous data, such as as border lines, information boxes and other non-geometrical data, may be eliminated since this data will typically not be constructed with or include connecting entities.
    </p>
    <p num="188">
      As noted above, the 2-D, three view drawing may include extraneous information, such as dimension lines, arrow lines, centerlines, and text, which do not represent the actual geometry of the part.
      <br/>
      These entities may be detected at step S.186 and deleted from the 2-D data file in order to prepare the 2-D drawing for further processing.
      <br/>
      The detection of these extraneous entities may be performed automatically by server module 32 (e.g., by detecting items in the 2-D data file that do not relate to the actual geometry of the part).
      <br/>
      For example, by using the connectivity data graph structure, two-sided opened entities (e.g., lines used for underlining text or to indicate a dimension or centerline in the part) may be detected and eliminated.
      <br/>
      Other entities, such as arrows, may also be detected based on the presence of floating endpoints and other characteristics of such entities.
      <br/>
      In order to effectively eliminate all unnecessary data, the server module 32 may also provide a manual editing function to permit an operator to indicate (e.g., by mouse or keyboard) which items in the 2-D drawing should be eliminated.
      <br/>
      Through the assistance or confirmation of the operator, additional extraneous information may thus also be removed from the drawing.
    </p>
    <p num="189">
      After step S.186, the various views in the 2-D drawing may be grouped and then respectively defined at step S.188. In accordance with an aspect of the present invention, server module 32 may support predefined or standard views and orientations, such as a top view, front view, right side view layout, such as that shown in FIGS. 14C and 14D.
      <br/>
      Other views and layouts, such as combinations of a top view, a front or back view, and a right or left view, may also be supported.
      <br/>
      As further described below, server module 32 may also support rotated views (see, for example, FIG. 14D) in order to process the views in the 2-D drawing into the 3-D representation of the part.
      <br/>
      In any event, at least two (and preferably three) different views of the part with thickness representations should be provided so that a 3-D model of the part may be constructed.
      <br/>
      By analyzing the connectivity and grouping of the entities in the connectivity graph structure, server module 32 may group and define the views based on the relative position and/or coordinate location of each of the views.
    </p>
    <p num="190">
      By way of a non-limiting example, the definition of the views by server module 32 may be carried out in accordance with a predefined or customary arrangement or layout for analyzing the views in the data file, and/or based upon detecting the orientation of the views and matching the various dimensions of the part in each of the respective views in the drawing.
      <br/>
      A predefined or canonical form, such as that shown in FIG. 14E, may be used to determine and define each of the views according to possible view types.
      <br/>
      Geometric comparisons of the various endpoints and relationships between the entities defining each group may be performed in order to effectuate step S.188. The view detection feature of server module 32 may label each of the views according to one of plurality of possible view types (e.g., top view, front view, back view, left view, right view).
      <br/>
      The detection of each of the views may be based on a predefined or canonical view layout or form, and based on the detected relationships between each of the views that are present.
    </p>
    <p num="191">
      Various processes and operations may be used at step S.188 to group and define the views in the 2-D, three view drawing.
      <br/>
      For example, after accessing the processed 2-D, three view drawing, the server module 32 may first identify the top view of the part in the drawing data.
      <br/>
      The top view may be detected based on the predefined or canonical form, view layout (such as that in FIG. 14E).
      <br/>
      If three separate views are detected in either a horizontal or vertical direction, then the center view may be defined as the top view.
      <br/>
      Further, if three separate views are not detected, and only two separate views are detected in a vertical direction, then the upper view may be defined as the top view.
      <br/>
      Once again, the connectivity and grouping of the entities in the connectivity graph structure may be utilized to detect each of the views.
      <br/>
      A stored lookup table or matrix representing the predefined or canonical form may be used to compare the views of the 2-D drawing and detect each of the views.
    </p>
    <p num="192">
      After detecting the top view from the 2-D, three view drawing data, the other views of the part may be detected based on the relative position of each of the views to the detected top view.
      <br/>
      For example, based on the canonical view layout of FIG. 14E, if a view grouping is located above the top view, then the view may be defined as a back view.
      <br/>
      If, however, a view grouping is located below the top view, then the view may be defined as a front view of the part.
      <br/>
      Further, a right view and a left view may be detected based on their relative position on the corresponding right hand side and left hand side, respectively, of the top view.
      <br/>
      Thereafter, any remaining views, which do not conform to the canonical form (such as FIG. 14E), may be detected based on their relative position to the detected views (e.g., a detected back view or front view).
      <br/>
      For example, for the layout B shown in FIG. 14D, the right view has been provided in a rotated position relative to the top view.
      <br/>
      The right view in layout B, however, may still be detected based on its relation to the detected front view.
      <br/>
      That is, undetected views that are present on the right hand side or left hand side of a detected back or front view may be defined, respectively, as a right view or a left view of the part.
    </p>
    <p num="193">
      Various predefined or canonical view layouts may be used to detect and define views in the 2-D, three view drawing.
      <br/>
      The canoncial forms (such as that in FIG. 14C or FIG. 14D) may be selected based on the numbers of view types that are to be supported and/or based on the view layouts that are more prevalent or selected/required by the manufacturing facility.
      <br/>
      If any views are not detected, a warning signal may be provided by the server module so that an operator may modify the 2-D, three view drawing data in accordance with the preferred view layout, or take other appropriate action.
      <br/>
      In addition to providing a predefined or canonical form for detecting the views in the 2-D drawing, a predefined or canonical form (such as layout A in FIG. 14D) may also be provided for processing the detected views and developing the 3-D model of the part.
      <br/>
      As such, a rotated view feature may be provide to properly group the detected views in accordance with the canonical form before further processing is performed.
    </p>
    <p num="194">
      As mentioned above, the 2-D cleanup operation may support and detect rotated views which do not conform to the predefined or canonical form for detecting views in a drawing.
      <br/>
      With the rotated view option, non-conforming views that have been detected may be rotated or translated so that each of the views conform to the predefined or canonical view form for processing and developing the 3-D model of the part.
      <br/>
      Assuming a canonical form such as that illustrated in FIG. 14E for detecting views of the part, each of the views in layout B in FIG. 14D may be detected based on the relative position of the views to the top view and the other detected views, as described above.
      <br/>
      If, for example, the layout A in FIG. 14D is to be used as a predefined or canonical view layout for processing the various views in a 2-D drawing having a top view, front view and a right view, then at step S.188 the right view in layout B may be rotated by 90 degrees to provide a modified view layout for the part that is similar to layout A. By rotating the right view in layout B by 90 degrees so that the right view of the part is provided on the right side of the top view of the part, the views in the drawing may be processed in accordance with the canonical form represented by layout A. A stored lookup table or matrix representing the predefined or canonical form may be used to compare the views of the 2-D drawing and to determine which views require rotation and translation.
    </p>
    <p num="195">
      In order to ensure that an accurate 3-D model of the part is developed from the views in the 2-D drawing, the respective dimensions in each of the views should be checked for consistency and matching.
      <br/>
      As further shown in FIG. 14A, at step S.190, the boundaries of the views in the data file may be detected in order to confirm that all of the dimensions of the respective views are in scale with one another.
      <br/>
      If it is determined that the views do not match within a predetermined tolerance (e.g., 0.0-0.01 inches), then appropriate modification may be made at step S.190 to redimension any particular view in order to ensure that all of the views are provided in the same scale.
      <br/>
      A warning component may be provided in server module 32 to alert a user that the view dimensions do not match so that the necessary modifications can be made to the 2-D drawing data that is present.
    </p>
    <p num="196">
      Various operations and processes may be utilized to detect and verify the consistency of the dimensions in the respective views of the part.
      <br/>
      For example, the corresponding dimensions of each of the views may be compared to determine if they are within a predetermined tolerance of one another.
      <br/>
      Such an analysis may include comparing the line entities that define the boundaries of each view of the part.
      <br/>
      Assuming the canonical form in FIG. 14E, a top view may be detected as matching a right view or a left view if the difference, for each view, between a maximal Y coordinate position and a minimal Y coordinate position is within a predetermined tolerance (e.g., 0.0-0.01 inches).
      <br/>
      Further, the top view may be detected as matching a front view or a back view if the difference, for each view, between a maximal X coordinate position and a minimal X coordinate position is within a predetermined tolerance (e.g., 0.0-0.01 inches).
      <br/>
      Moreover, the left view or right view may be determined as matching a front view or a back view if the difference between a maximal X coordinate position and a minimal X coordinate position compared to the difference between a maximal Y coordinate postion and a minimal Y coordinate position is within a predetermined tolerance (e.g., 0.0-0.01 inches).
      <br/>
      Once again, a warning component or module may be provided in server module 32 to alert a user when the view dimensions or related face dimensions do not match so that the necessary modifications can be made to the 2-D drawing data that is present.
    </p>
    <p num="197">
      Finally, at step S.192, the inside loops, holes and shapes of the part may be detected in accordance with the teachings of the face detection procedure of the present invention.
      <br/>
      The various holes and shapes provided on the interior of the faces of each view may be detected by looping through the various lines and boundaries of the part from the exterior of the part towards the center.
      <br/>
      Loop and entity analysis may be performed on each view of the part in the 2-D drawing.
      <br/>
      By analyzing each view from the outside and working inwardly towards the center of the part, the detected loops will define the boundaries and areas of the material and openings of the part based upon a cyclic sequence (e.g., material, opening, material, etc.).
      <br/>
      A loop tree, such as that in FIG. 10H, may be developed for each view to determine the location of the faces and any openings within each face.
      <br/>
      Unconnected entities, such as floating arcs or lines, within the faces of the part may also be detected and eliminated during step S.192.
    </p>
    <p num="198">
      An exemplary code for performing the 2-D clean-up operation of the present invention is provided in Appendix D. The code was written in C++ programming language and includes comments to facilitate the analysis of the logic and algorithms used therein.
      <br/>
      The code includes the various processes and operations of the 2-D clean-up mode, such as those discussed above with reference to FIGS. 14A-14C.
    </p>
    <p num="199">
      Referring back to FIG. 13, after a 2-D clean-up operation has been performed, logic flow will then continue to step S.164 where it may be determined whether the 2-D drawing represents or includes the thickness of the material (i.e., whether the 2-D drawing is with thickness).
      <br/>
      If the 2-D drawing is determined to contain the thickness amount, then at step S.166, an eliminate thickness procedure may be performed by server module 32 in order to prepare the 2-D drawing for subsequent processing into a 3-D model.
      <br/>
      The determination of the existence of thickness in the 2-D drawing may be performed automatically by server module 32 based on the data of the drawing, or may be performed by the server module through the assistance or response from the operator (e.g., the operator may be prompted to indicate whether thickness removal is necessary or desired).
      <br/>
      The thickness of the part may be eliminated due to the unique symmetry of all sheet metal parts.
      <br/>
      By eliminating the thickness of the part, the resultant sheet metal part with no thickness may be more easily analyzed by a sheet metal operator or designer.
      <br/>
      Further, the inventors of the present application have found that by eliminating the thickness of the 2-D, three view drawing, the time required to convert the 2-D drawing and develop the 3-D model may be substantially reduced.
    </p>
    <p num="200">
      Since most 2-D, three view drawings include a material thickness amount, an operator may often be confused by which bend lines should be selected in order to make a 3-D model from the 2-D drawing.
      <br/>
      As a result, considerable time is wasted in selecting the appropriate bend lines so that the 2-D, three view drawing may be converted into a 3-D model.
      <br/>
      An example of a three view, 2-D drawing with thickness is shown in FIG. 15A. According to an aspect of the present invention, an eliminate thickness procedure may be provided to display a simplified 2-D, three view drawing model which is represented and processed with no material thickness, but retains the material thickness amount and the inside or outside dimensions of the part in the bend model data.
      <br/>
      FIG. 15B illustrates the simplified three view, 2-D drawing that may be viewed and displayed to the operator at server module 32 after performing the eliminate thickness procedure.
    </p>
    <p num="201">
      When the eliminate thickness procedure is executed, the user may be prompted to specify the material thickness in the 2-D, three view display, and may be prompted to specify which dimension (i.e., the outside dimension or inside dimension) is to be retained in the display.
      <br/>
      The operator may indicate the thickness and surface to retain in one of the views by use of, for example, a mouse.
      <br/>
      Based upon the data entered by the user, server module 32 may modify the 2-D, three view drawing to eliminate the material thickness indicated by the user and to retain the inside or outside dimension based on the operator's selection.
    </p>
    <p num="202">
      In order to eliminate the thickness in the 2-D, three view drawing, the server module 32 may analyze each of the three views based on the selections made by the operator.
      <br/>
      The selected surface may be projected into each of the other views by geometrical computations (e.g., by detecting the corresponding entities that lie in the same X-coordinate or Y-coordinate projection as the selected entity line or surface) to detect the corresponding entities and lines in each of the views.
      <br/>
      The corresponding entities may be marked and retained, with the nonmatching entities or surfaces being eliminated or not displayed on the screen, such as that shown in FIG. 15B. Further, the thickness dimension line indicated by the operator may be similarly projected into each of the other views, with the matching thickness dimension lines or entities being eliminated, as further shown in the example if FIG. 15B. As a result, each of the views in the drawing may appropriately modified and then displayed to the user at the server module 32.
      <br/>
      The resultant 2-D, three drawing with no thickness may also be used for subsequent processing in order to develop the 3-D model of the part.
    </p>
    <p num="203">
      The thickness elimination procedure of the present invention may include a manual thickness elimination mode to permit an operator to selectively indicate in each view the thickness lines to be eliminated and the surface entities to be retained.
      <br/>
      A mouse or other appropriate input device may be used by the operator to indicate which areas in each of the displayed views are to be eliminated and which surfaces are to be retained.
      <br/>
      Based on the data entered by the operator, the server module 32 may eliminate each line entity selected by the operator from the 2-D, three view drawing in order to provide a drawing with no thickness.
    </p>
    <p num="204">
      The present invention may also include a warning system or module to analyze and detect whether all the thickness representations have been properly identified in the 2-D, three view drawing, and to alert the user when there are unmarked thickness components and/or when there are inconsistencies in the drawing data.
      <br/>
      For example, a thickness warning component may be provided to highlight on the display screen possible unmarked thickness segments, and a face warning component may be provided to highlight on the screen possible mismatched faces when the face dimension does not match the thickness mark in another view.
      <br/>
      A bendline warning component may also be provided to highlight inconsistent bendlines and highlight mismatching thickness arcs.
      <br/>
      An arc may be highlighted when at least one bendline projected on this arc is not bound by two cross thickness lines.
      <br/>
      For instance, FIG. 15C illustrates a thickness arc that is properly bounded by two or another non-zero even number of cross-thickness lines (i.e., a small line crossing the thickness in one of the views).
      <br/>
      Each bendline should also be bound by two or another non-zero even number of cross-thickness lines.
      <br/>
      The analysis of these entities of the part in each view may be based on performing a loop analysis on and analyzing the connectivity of the line and arc entities that make-up each view.
      <br/>
      An open thickness line may be defined based on a thickness line that has at least one end point that is not connected to another thickness line or arc.
      <br/>
      A side that includes an open thickness line may be defined as an open thickness side.
      <br/>
      A thickness line may be highlighted if the open thickness side of an open thickness line does not match the bounding box of a minimal loop.
      <br/>
      By providing such warnings relating to the processed 2-D, three view image to a user, the user may be alerted of inconsistencies in the drawing data, and the user will thus be able to modify and/or correct the drawing data before further processing is performed to develop the 3-D model of the part.
      <br/>
      Inclusion of such a warning system and user interaction also improves the accuracy of the representation of the part by the 3-D model.
    </p>
    <p num="205">
      At step S.168 in FIG. 13, the processed 2-D, three view drawing with no material thickness may then be converted and developed into a 3-D model.
      <br/>
      The conversion and development of the 3-D model from the 2-D, three view drawing may be performed by using well-known or established projection and/or extrusion methods.
      <br/>
      For example, in order to develop the 3-D model from the three view, 2-D drawing, the depths of each of the views may be detected and then each of the views projected in order to develop a 3-D model.
      <br/>
      The resultant 3-D model may then be used when developing the bend model data and also converted into a single view, 2-D flat drawing by applying the above-described unfolding algorithm.
      <br/>
      For more information geometric modeling techniques, see MORTENSON, FOLEY et al. and MANTYLA.
      <br/>
      For additional information on projection techniques to construct 3-D models from 2-D drawings, see, for example, WESLEY et al., W. A., Fleshing Out Projections, IBM J, Res.
      <br/>
      Develop., Vol. 25, No. 6, p.934-954 (1981); AOMURA, Shigeru, Creating Solid Model with Machine Drawings, The 6th Computational Mechanics Conference, JSME, No. 930-71, Japan, pp. 497-98 (1993); and AOMURA, Shigeru, Recent Trends and Future Prospect of Research and Practical Use(Automatic Reconstruction of 3D Solid from Drawings), Toyo Engineering Corp., Japan, pp. 6-13 (1995); the disclosures of which are expressly incorporated herein by reference in their entireties.
    </p>
    <p num="206">
      When developing the 3-D model at step S.168, an additional clean-up process may be included in order to further process and refine the resultant 3-D model.
      <br/>
      In accordance with an aspect of the invention, a 3-D clean-up process may be provided to compensate for ambiguities that are present in the 2-D, three view drawing of the part and that create extraneous or superfluous information in the developed 3-D representation of the part.
      <br/>
      As will be appreciated by those skilled in the art, a 2-D, three view representation of a part includes ambiguities concerning the representations of various features of the part in 3-D coordinate space.
      <br/>
      When developing the 3-D model from the three view, 2-D drawing, extraneous and superfluous information may be generated as a result of these ambiguities.
      <br/>
      As such, according to an aspect of the invention, the 3-D clean-up process may include processes and operations for detecting and removing one sided open lines and for detecting and cleaning bendlines and trimming faces.
      <br/>
      The 3-D clean-up process may be performed automatically when developing the resultant 3-D model of the part, or may be selectively performed based on input from an operator when the developed 3-D model is determined to require further processing.
    </p>
    <p num="207">
      According to the 3-D clean-up process, by analyzing the developed 3-D drawing data, every line or arc which is determined to be not connected to another entity at one of its endpoints may be identified and defined as a one sided open line.
      <br/>
      Any entity that is determined to be a one sided open line may be removed from the 3-D representation of the part.
      <br/>
      Once an open line is removed, it may cause another line or entity to be open.
      <br/>
      As such, new one sided open lines are also identified and removed recursively until all open lines or entities are removed.
      <br/>
      FIG. 49A illustrates an example of a 3-D representation of a part before one sided open lines are removed, and FIG. 49B illustrates the part after the one sided open lines have been removed from the 3-D representation.
    </p>
    <p num="208">
      As noted above, the 3-D clean-up process that may be performed at step S.168 may also include a process for detecting and cleaning bendlines.
      <br/>
      Bendlines may be identified and cleaned (e.g., by adding mold lines) in order to facilitate the detection of face information of the part in 3-D space.
      <br/>
      Based on the developed 3-D model data, each bendline may be identified from the detection of a pair of 3-D arcs (e.g., represented by arc entities in the drawing data) which have the same normal defined by their centers.
      <br/>
      During this process, mold lines may be added to the bendlines that are identified.
      <br/>
      The mold lines may be added by identifying corresponding endpoints in each pair of 3-D arcs, and extending mold lines (e.g., represented by line entities) between the corresponding endpoints of the 3-D arcs.
      <br/>
      FIG. 50A illustrates an exemplary 3-D representation of a part before the bendlines have been identified, and FIG. 50B illustrates the part after the mold lines (represented by dashed lines in the drawing) have been added.
    </p>
    <p num="209">
      After the bendlines have been identified and the mold lines have been added, the 3-D clean-up process may further process the 3-D representation of the part to further clean all bendlines and trim the faces of the part.
      <br/>
      Due to frequent ambiguities in the views of the 2-D, three view drawing data, superfluous sections of the faces may be generated in the 3-D representation of the part.
      <br/>
      The 3-D clean-up process may identify these superfluous sections of the faces and trims the faces using sheet-metal domain knowledge (e.g., knowledge relating to what is unfoldable).
      <br/>
      Other extraneous information, such as extra holes or openings, may also be identified and eliminated.
      <br/>
      As a result, the superfluous sections of the part may be removed and the 3-D representation may provide a more accurate representation of the sheet metal part.
      <br/>
      FIG. 51A illustrates an exemplary section of a part before cleaning the bendlines and trimming the faces, and FIG. 51B shows the section of the part after cleaning and trimming has been performed.
    </p>
    <p num="210">
      FIG. 16 illustrates an example of the logic flow of the processes and operations that may be performed in order to develop a 3-D drawing with no material thickness from an original 3-D drawing with material thickness.
      <br/>
      At step S.200, the original 3-D drawing with material thickness may be entered or imported to server module 32.
      <br/>
      The 3-D model may be a 3-D, wire frame drawing with material thickness and may be a CAD drawing file, such as a DXF or IGES file.
      <br/>
      After the 3-D drawing has been imported to the server module 32, an eliminate thickness procedure may be performed at step S.204. The eliminate thickness procedure at step S.204 on the 3-D model may be performed in a similar manner to that provided in the Amada UNFOLD software system, described above.
      <br/>
      In order to eliminate the thickness in the 3-D model, the operator may first be prompted to indicate the thickness and to select the surface to be retained.
      <br/>
      Based on the operator's selection, the thickness is measured by analyzing the endpoints of the entity line defining the thickness.
      <br/>
      Thereafter, the boundaries of the selected surface may be traced, in a similar manner to that described above with respect to the loop and entity analysis process, with the entities to be kept being marked (e.g., by setting or incrementing a flag) and the corresponding thickness entities being eliminated.
      <br/>
      When tracing the entities of the 3-D part, the entities may be distinguished based on the length of the thickness entity selected by the user.
      <br/>
      Generally, all entities having the same length of the thickness entity may not be selected and eliminated, with the other entities that are not of the same length being marked and retained.
      <br/>
      Any remaining entities that are not marked during the surface trace of the 3-D part may also be eliminated.
      <br/>
      Once again, the server module 32 may provide a manual thickness removal mode, in which an operator may manually indicate each entity in the 3-D part that is to be removed.
    </p>
    <p num="211">After step S.204, the resultant 3-D model with no material thickness may be developed and/or displayed to the operator at step S.206. An unfolding algorithm or process may then be applied to the 3-D model with no material thickness to develop the single view, 2-D flat drawing for the bend model data, as described in greater detail above.</p>
    <p num="212">
      As discussed above, the design and manufacturing information that is stored in database 30 may include a bend model data file comprising part geometry and topology as well as manufacturing data for the sheet metal component.
      <br/>
      Further, the software that may be used to implement the various features of the invention may be developed using a high level programming language such as C++ and by using object oriented programming techniques.
      <br/>
      Different object oriented techniques may be used, such as Booch or OMT to implement the various features of the invention.
      <br/>
      If object oriented programming is utilized, an object oriented data model may be utilized to represent the sheet metal part and the bend model for the part may be implemented through a completely self-contained class library.
      <br/>
      In accordance with an aspect of the present invention, a description will now be provided of any exemplary data structure and access algorithm for the bend model, based on object oriented programming techniques.
    </p>
    <p num="213">
      FIG. 17 illustrates an exemplary data structure and access algorithm of the bend model that may be utilized when implementing the present invention through object oriented programming.
      <br/>
      Object oriented programming is a type or form of software development that can model the real world by combining objects or modules that contain data as well as instructions that work upon that data.
      <br/>
      In object oriented programming, objects are software entities that may model something physical, like a sheet metal part, or they may model something virtual, like business transactions.
      <br/>
      Objects may contain one or more attributes (i.e., fields) that collectively define the state of the object, and may contain an identity that distinguishes it from all other objects.
      <br/>
      In addition, objects may include behavior that is defined by a set of methods (i.e., procedures) that can modify the attributes or perform operations on the object based on the existence of certain conditions.
    </p>
    <p num="214">
      According to an embodiment of the present invention, the sheet metal part may be represented as an object oriented data model.
      <br/>
      As shown in FIG. 17, the bend model for the sheet metal part may be defined as a completely self-contained class library.
      <br/>
      All of the required data manipulation and functions for the sheet metal part (e.g., folding, unfolding, etc.) may be captured as member functions of the class library.
      <br/>
      All of the geometrical and topological data may be defined in objects that are grouped within the bend model.
      <br/>
      The bend model class library may be a hierarchy of classes or objects with a part class being the top level class in the hierarchy.
      <br/>
      The part class may include a part object with various part attributes and may have various objects that define the part and the actions that may be performed on or to the part.
    </p>
    <p num="215">
      FIG. 17 shows an example of the various objects that may be grouped in the bend model class library.
      <br/>
      For example, a part class 50 may be provided that includes various attributes 52.
      <br/>
      The part attributes 52 may include various part information such as the part number and/or name, the part material type and the thickness of the part.
      <br/>
      The attributes 52 may also include bend sequence information for indicating the order in which the bends are to be performed and other manufacturing information such as tolerance requirements for the various dimensions of the part.
      <br/>
      Part class 50 may also comprise various objects, such as a faces object 54, a holes object 56, a formings object 58, and a bendlines object 60, as shown in FIG. 17. Each of the objects 54, 56, 58 and 60 may actually consist of a group of objects for each of the entities (e.g., faces, holes, formings, and bendlines) represented therein.
      <br/>
      The faces object 54, holes object 56, formings object 58 and bendlines object 60 may each include geometry and dimension data, location and coordinate data in both 2-D and 3-D space representations, and data relating to the edges and surfaces of their respective entities (e.g., faces, holes, formings, and bendlines) of the part.
      <br/>
      For example, the faces object 54 may include geometry and dimension data for each of the faces, location space data of the faces in both 2-D and 3-D representation, and edges and surface data for the edges and surfaces of the faces.
      <br/>
      In addition, the formings object 58 may include data relating to special formings in the part, including geometry and dimension data, 2-D and 3-D location space data, and edges and/or surfaces data.
    </p>
    <p num="216">
      As further shown in embodiment of FIG. 17, the part class 50 may also include a topology object 62 and a bend properties object 64.
      <br/>
      The topology object 62 may include the part topology data for the faces, holes, formings and bendlines of the part.
      <br/>
      The data in the topology object 62 may indicate the structure and geometric relationships of the various features of the part.
      <br/>
      The bend properties object 64 may also be provided and include information concerning special manufacturing constraints for one or more features of the part.
      <br/>
      For example, bend properties information concerning how the sheet metal part should be bent may be provided in the bend properties object 64.
      <br/>
      The bend properties information may include specific manufacturing data for different bend property types (e.g., simultaneous bend, colinear bend, Z-bend, etc.).
    </p>
    <p num="217">
      The bendlines object 60 may also include manufacturing specific data relating to the bends to be performed.
      <br/>
      Thus, in addition to providing geometry and dimension data, 2-D and 3-D location space data, and edges data for each bendline, the bendlines object 60 may also include V-width data, bend pitch data, bend count data and/or orientation data for each of the bendlines.
      <br/>
      Each of the bendlines may also include an associated bending operation, as shown in FIG. 17. The bending operations may be implemented as a group of objects with data and operations/instructions for performing bends at each bendline.
      <br/>
      If provided as an object, each bending operation may include data and instructions indicating how and what type of bending is be performed (e.g., conic bend, Z-bending, Hemming, arc bending, etc.), as well as pertinent bend data such as the bend angle, bend radius and/or bend deduction amount.
    </p>
    <p num="218">
      By implementing the bend model of the part through an object oriented data model, all of the complex mathematical calculations, computational geometry and matrix transformations may be built into a single class library.
      <br/>
      Special bending operations, such as hemming, Z-bending and arc bending, may also be captured inside the class library.
      <br/>
      Further, manufacturing information, such as the V-width, the bend deduction amount, and the bend sequence, may be also captured within the class library.
      <br/>
      With the bend model, simultaneous dual representation of both the 2-D flat model and 3-D model may be effectuated, as shown in FIG. 17. Further, bending operations may be performed in accordance with the bend lines object 60 of the bend model.
      <br/>
      General comments regarding the bend model and the part structure, as well as implementation of the same, are provided in Appendix K attached hereto.
    </p>
    <p num="219">
      A bend model viewer may be provided to interpret the bend model and display visual images of the part in 2-D and/or 3-D space representation.
      <br/>
      FIG. 18 illustrates a block diagram of the structure of the bend model viewer and its relation to the bend model, in accordance with another aspect of the present invention.
      <br/>
      The bend model viewer may be implemented through object oriented programming techniques and may be a Windows based application that permits users at the station modules of the various locations 10, 12, 14 . . . 20 in the facility 38 to display various views of the part based on the information provided in the bend model.
      <br/>
      The bend model viewer may comprise a set of application library modules that are used to visualize the sheet metal part.
      <br/>
      Further, the bend model viewer may be designed as a base view class of the Windows application so that it can be used as a base view class for any Windows application.
      <br/>
      Most of the standard operations to view the 2-D and 3-D models (e.g., zoom 92, rotate 96, pan 100, dimension 102, etc.) may be implemented as member functions of the bend model viewer.
      <br/>
      Geometric transformations and fundamental computer graphics techniques may be applied to the bend model objects when performing viewing operations.
      <br/>
      In addition, the bend model viewer may comprise view model attributes 88, that comprise, for example, four major view modes including a solid view, a wire frame view, a 2-D flat view and an orthographic view.
    </p>
    <p num="220">
      According to an aspect of the invention, the bend model class library 80 may include a set of procedures or functions that act upon sheet metal parts depending upon the selected view (e.g., solid, wire, 2-D flat or orthographic view).
      <br/>
      The bend model viewer view class 84 may comprise a series of standard operations, such as zoom 92, rotation 96, pan 100 and dimension 102; and, depending upon the state of the bend model viewer, the bend model viewer view class may call functions from the bend model class library 80.
      <br/>
      As shown in FIG. 18, the various view model attributes or features 88 that may be selected by a user may include a solid view, a wire frame view, a 2-D flat view and an orthographic view.
      <br/>
      A brief description of these various view modes that may be provided in the present invention is provided below with reference to FIGS. 19-22.
    </p>
    <p num="221">
      Fundamental computer graphics and geometric modeling techniques, such as geometric transformations and 3-D geometry techniques, may be utilized to implement the various features of the bend model viewer and to provided the different viewing modes and functions.
      <br/>
      Recent advancements and developments in computer-based 2-D and 3-D modeling and simulation, such as the availability of graphics libraries or packages, may be applied to implement these features of the present invention.
      <br/>
      In addition, a wide variety of publications and material are available regarding computer graphics and modeling.
      <br/>
      See, for example, MORTENSON, FOLEY et al., and MANTYLA, each of which is referenced above.
    </p>
    <p num="222">
      In order to provide the various viewing and modeling features of the present invention, each station module and the server module may be provided with a high resolution display screen, such as a SVGA screen with 800 * 600 resolution.
      <br/>
      A joystick and game card may also be provided at the station module and server module to permit the user to selectively modify and view the different 2-D and 3-D representations of the part.
      <br/>
      Software based graphics packages, such as OpenGL and RenderWare, may be used to provide graphical computations.
      <br/>
      Such graphics libraries or packages may be Windows based applications and can be used to render the various viewing modes.
      <br/>
      OpenGL, for example, may be used to render the various 2-D wire frame views based on the part geometry and topology data provided in the bend model.
      <br/>
      Further, Renderware may be utilized to render the various 2-D and 3-D solid views of the sheet metal part based on the part data provided in the bend model.
      <br/>
      For more information on OpenGL, see, for example, the OpenGL Reference Manual and the OpenGL Programming Guide, Release 1, OpenGL Architecture Review Board, Addison-Wesley Publishing Company, Reading, Mass. (1992).
      <br/>
      For information on RenderWare, see, for example, the RenderWare API Reference Manual, V2.0, Criterion Software Ltd., United Kingdom (1996).
    </p>
    <p num="223">
      In order to render the various views of the part, the bend model may be accessed from the database 30 by, for example, the station module of the operator.
      <br/>
      The bend model data may then be reformatted in accordance with the data format utilized by the graphics library or package (e.g., OpenGL or RenderWare) that is utilized.
      <br/>
      Thereafter, the graphics data may be processed in accordance with various programmed routines in order to render the viewing mode (wire, solid, etc.) selected by the operator or perform the viewing function (zoom, pan, etc.) executed by the user.
    </p>
    <p num="224">
      When a particular view mode is selected by an operator, the selected viewing mode is detected along with the current zoom ratio or factor and orientation of the view.
      <br/>
      This information is then used to make function calls to the graphics package to update the current display.
      <br/>
      Function calls to the graphics package may be made in accordance with the viewing mode to be rendered, as well as the zoom or other viewing function to be performed.
      <br/>
      Based on these function calls, the graphics package provides the necessary data so that the station module may render the view of the part to the operator.
      <br/>
      Based on the modifications to the 2-D or 3-D representation by the user (e.g., by moving a joystick or a mouse) additional function calls may be made to the graphics library to update the rendered image.
    </p>
    <p num="225">
      To provide the wire frame views of the part, the line entity data of the part may be provided to the graphics package to perform the necessary graphical computations.
      <br/>
      With solid views, however, one or more polygons should be derived for each of the faces and provided as input to the graphics package to render the view.
      <br/>
      Graphics packages such as OpenGL and RenderWare will take as input polygonal data and fill in the areas defined by the polygons to provide a solid image.
      <br/>
      Polygons may be derived from the face and bendline information in the bend model and by determining the boundaries of each face.
      <br/>
      Polygons should be created to present and define each face of the part.
      <br/>
      The faces may then be connected, based on the part topology and other data in the bend model, in order to render the overall sheet metal part.
      <br/>
      If a face contains an opening or hole, then it will be necessary to define the face with several polygons that do not encompass such openings.
      <br/>
      For orthographic views, data for each of the individual views (which may be wire frame or solid) may be sent to the graphics package and the resultant views combined on a single display screen, such as that further shown in FIG. 22.
    </p>
    <p num="226">
      An exemplary code for implementing the various viewing modes and functions of the bend model view is provided in Appendix E. The sample code is written in C++ and includes comments relating to the processes and operations performed therein.
      <br/>
      The code in combination with an appropriate graphics package (such as OpenGL and RenderWare) may not only be used to render the different views (e.g., 2-D and 3-D wire frame or solid), but also provide the functionality of each of the viewing functions (e.g., zoom, rotate, pan, etc.).
      <br/>
      A brief description of the various viewing mode display screens that may be rendered is provided below.
    </p>
    <p num="227">
      The solid view mode displays a solid rendered 3-D view of the part defined by the bend model.
      <br/>
      FIG. 19 illustrates an exemplary solid view window that may be provided as output to a display screen provided at any of the locations 10, 12, 14 . . . 20 within the sheet metal facility 38.
      <br/>
      In the solid view mode, the user or operator may be provided with a plurality of viewing functions for manipulating 3-D space navigation and 3-D automatic dimensioning.
      <br/>
      The basic functions that may be provided for altering the solid view of the part may include rotation, zooming, panning, and/or standard view selections.
      <br/>
      The standard views that may be provided and selected by the user may include the following: isometric, top, bottom, front, back, left and right.
      <br/>
      An automatic or manual dimension operation may also be provided to display the critical dimensions of the part based on the current viewing angle.
      <br/>
      An exemplary embodiment of the dimension feature of the present invention is provided below with reference to FIGS. 23-27.
    </p>
    <p num="228">
      As shown in FIG. 19, the solid view window may be a Windows based application; and, thus, multiple windows or sectional views of the part may be provided.
      <br/>
      The multiple view windows may include a worm view that provides a very close-up isolated view within a window, and a bird's eye view which provides a very far away view of the part in an isolated window.
      <br/>
      The sectional view may provide a partial view of the object as selected by the user.
      <br/>
      In order to control the various viewing functions, a joystick interface may be provided at the server module 32 and the station modules of each of the locations 10, 12, 14 . . . 20. Operation of the joystick alone and/or in combination with operation of certain keys on the keyboard (e.g., a shift key or control key) may be performed by the user in order to carry.
      <br/>
      Each type may consist of many shapes, and for each shape there may be many tools with different sizes and dimensions.
      <br/>
      To select a tool, a user would first pick one tool type by selecting one icon from the tool type icons that are displayed, such as that illustrated in FIG. 31. Thereafter, the user would be provided with a menu of different shapes that are available for the selected tool.
      <br/>
      After analyzing the tool shapes, the user may select a tool shape by selecting one of the shape icons from the displayed shape icons for the selected tool (e.g., in FIG. 31 a goose neck shape punch has been selected).
      <br/>
      Finally, the user may select the appropriate size and dimension for the tool shape that has been selected.
      <br/>
      As further shown in FIG. 31, a table may be displayed to the user to indicate the different sizes and dimensions of tools available for the tool shape that was selected.
      <br/>
      By selecting an item from the table, the selected tool may be displayed as an icon to replace the generic tool type icon and to confirm the selection of the tool.
    </p>
    <p num="229">
      At step S.240, the bend operator may then set-up the various tool stages in the press brake by aid of a graphical interface.
      <br/>
      FIG. 32 illustrates an exemplary tool set-up window that may be provided to the bending operator to facilitate definition of the tool set-up to be used in the bending plan.
      <br/>
      Various punch, die and rail data may be indicated in the tool set-up window, as shown for example in FIG. 32. The tool and die information for the sheet metal part may be entered by the operator.
      <br/>
      A joystick may be provided at the bending operator's station module to permit the bending operator to indicate the tooling location and to select the tool and dies from a list of available tools and dies.
      <br/>
      In the tool set-up window, the left hand side of the screen may display the profile of the current tool set-up and the right hand side of the screen may display the location of the current set-up in the press brake.
      <br/>
      The current set-up location may be highlighted or shaded, as shown in FIG. 32.
    </p>
    <p num="230">
      Finally, once the bend operator is satisfied with the bend sequence, the bending plan information including the tooling and bend sequence information, may be saved with the bend model in the database 30, as generally shown at step S.242 in FIG. 28. Actual testing of the bend sequence may then be performed with the press brake in order to verify the bend sequence selected by the bend operator.
      <br/>
      If required, any further modifications to the tooling definitions or bend sequence may be performed by the operator or designer at the station module.
    </p>
    <p num="231">
      Various other features of the invention may be provided to aid the bending operator in the development of the bending plan.
      <br/>
      For example, in accordance with another aspect of the present invention, a tooling expert may be provided to automatically provide to the bending operator suggested tooling and bend sequences based on the part geometry and other information stored in the bend model.
      <br/>
      The suggestions from the tooling expert may be followed or revised by the bending operator after analyzing the same.
      <br/>
      In addition, a more complex tooling expert system may be provided to make tooling suggestions and bend sequence suggestions as to more complex operations based on the geometry of the part in the bend file and a profile analysis of the tooling to check for potential collisions and interference.
      <br/>
      Such expert systems may be used and implemented with either manual or robot assisted bending machinery.
      <br/>
      By way of non-limiting examples, the present invention may be implemented with the features and teachings disclosed in pending U.S. patent application Ser.
      <br/>
      No. 08/386,369, entitled "Intelligent System for Generating and Executing a Sheet Metal Bending Plan," in the names of David A. BOURNE et al., and U.S. patent application Ser.
      <br/>
      No. 08/338,115, entitled "Method for Planning/Controlling Robot Motion," in the names of David A. BOURNE et al., the disclosures of which are expressly incorporated herein by reference in their entireties.
    </p>
    <p num="232">
      As described above, a graphical user interface and various functions may be provided to facilitate the bend operator when developing the bending plan for a sheet metal part.
      <br/>
      In accordance with another aspect of the present invention, additional features may also be provided to aid in the design and manufacturing of the part.
      <br/>
      As described more fully below, various multimedia features may be implemented into the present invention, such as the storage of audio and visual information, to provide additional assistance to the bending operator when developing the bending plan or executing a bend sequence.
      <br/>
      Further, a collision check feature may be provided that automatically checks for potential interference and collision between the tools and the parts at each of the intermediate bending stages.
      <br/>
      This collision check feature may be provided to replace the cumbersome and time consuming manual check of the tool profiles and spacing in the part, which is customarily performed by bending operators when developing a bending plan.
      <br/>
      These features and others will now be described with reference to the accompanying drawings.
    </p>
    <p num="233">
      In accordance with an aspect of the present invention, a method may be provided for storing audio and video information with the bend model data.
      <br/>
      Various audio and video instructions can be recorded at the shop floor to provide special instructions with respect to, for example, the handling and bending of the sheet metal part.
      <br/>
      For this purpose, a CCD camera or digital camera may be provided at each of the station modules of the various locations 10, 12, 14 . . . 20, along with an audio microphone.
      <br/>
      Other equipment, such as a video camera with an audio microphone, may be provided at the station modules to permit the operator or user to record audio and video information.
      <br/>
      The various recording equipment may be connected to a station module computer at the shop floor.
      <br/>
      By way of a non-limiting example, an Intel PROSHARE personal conferencing CCD camera (available from Intel Corporation) may be used for recording audio and video information.
      <br/>
      Other commercially available CCD cameras or digital cameras may also be utilized to record such information.
    </p>
    <p num="234">
      The various audio and video information that is stored with the bend model data may be accessed and retrieved by the user according to various methods and procedures.
      <br/>
      For example, menu options may be displayed by the station module to permit the replay of stored audio and video information.
      <br/>
      In addition, in accordance with a preferred embodiment of the present invention, an operator may be provided the ability to attach and associate the stored audio and video information with the various display screens and views of the part by selecting and creating icons that are displayed in the view window.
      <br/>
      This feature may be implemented through software and object oriented programming techniques, whereby an icon object is created and stored within the bend model data structure.
      <br/>
      The icon object may contain procedures for retrieving attached audio and video information from memory based on certain conditions (e.g., the selection of the icon by the operator by double clicking a mouse or indicating selection by use of a joystick or other input means).
      <br/>
      With the icon feature of the present invention, the operator may associate different audio and video messages or information with different parts of the sheet metal part and to any display.
      <br/>
      By incorporating the icon into the part representation, the icons may be adapted to zoom, rotate and translate with the 2-D and/or 3-D model displays of the part as the view is changed on the screen.
    </p>
    <p num="235">
      FIG. 33A illustrates an example of attaching audio and visual information through the use of icons pasted to a 3-D solid model of the part.
      <br/>
      After the user has recorded the audio and visual information, the operator may paste an icon at any location within the 3-D model window.
      <br/>
      When the icon is subsequently selected by an operator or user, the stored audio and visual information may be played back and displayed in the window to provide any special instructions or messages concerning the part or the area of the part to which the icon was placed.
      <br/>
      Other information, such as the simulation or recording of the bending motion, may be associated with the part by placing icons in proximity to the various bend lines of the part.
      <br/>
      The video information concerning the bending motion may then be played back to the user when the icon is selected.
    </p>
    <p num="236">
      The operator or user may record both audio and video information, or only record a simple audio message or a still or motion video signal, that may be selectively played back to the user.
      <br/>
      The icons that are attached to the window display may graphically indicate the type of information that is stored (e.g., a microphone icon may be depicted to indicate that audio information has been stored or a display monitor icon may be provided to indicate that video information has been stored) Special icons may also be provided to indicate that both audio and visual information are associated with that icon (e.g., an "A/V" symbol or a video camera icon that includes a microphone).
      <br/>
      A directory of icons may be provided and displayed to allow the user to select among the various icons when attaching audio and/or video information to the screen display or image.
    </p>
    <p num="237">
      FIG. 33B illustrates another example of a display window that may be incorporated with icons for retrieving stored audio and video information.
      <br/>
      The display window depicted in FIG. 33B relates to the tool set-up screen image, such as that described above with reference to FIG. 30. In the example of FIG. 33B, audio information may be stored and retrieved by a microphone icon and separate video information may be stored and retrieved by pasting a video icon to the display window.
      <br/>
      The audio and video information may relate to special instructions or information regarding tool set-up or operation.
      <br/>
      Further, regardless of the type of window display that is currently active, the operator may paste as many icons as required to the various areas in the window display so that different audio and video information may be later retrieved.
    </p>
    <p num="238">
      In accordance with another aspect of the invention, an image editing window feature may be provided to facilitate the operator in selecting stored images and applying them to different screens.
      <br/>
      The imaging editing window feature may be provided as a Windows based application that may be accessed at, for example, server module 32 or any of the station modules provided throughout the manufacturing facility.
      <br/>
      FIG. 34 illustrates an example of the image editing window that may be implemented in accordance with the teachings of the present invention.
      <br/>
      The images displayed in the image editing window may include images shot by a digital camera or a CAM coder.
      <br/>
      The images that are displayed on the screen may be selectively chosen by the operator (e.g., through a mouse or other appropriate data input means) and copied to different screens so that they may be associated with particular model views of a part.
      <br/>
      The operator may then paste the image or an icon to the model window (e.g., a 3-D solid model window of the part, such as that shown above with respect to FIG. 33B).
      <br/>
      The images shown in FIGS. 33 and 34 are photocopy reproductions of actual screen images; the actual video images will themselves be clearer, dependent upon the resolution of the camera and screen used.
      <br/>
      The images can include, e.g., a still or motion video image of a bending operator discussing or illustrating special handling or other instructions relating to a bending operation, or may be a video image of a sheet metal bending operation.
      <br/>
      In other words, any actual image which may be useful can be taken and later displayed.
      <br/>
      Thus, the actual images shown in FIGS. 33-34 are for illustrative purposes only.
    </p>
    <p num="239">
      Referring now to FIGS. 35A and 35B, an example of a collision check function of the present invention will be provided.
      <br/>
      In accordance with an aspect of the present invention, a collision check function may be provided to allow users to check for potential collisions between the part and punch tool through use of a graphical user interface.
      <br/>
      The collision check function may be a Windows based application that may be accessed at any station module or location within the manufacturing facility.
      <br/>
      The automatic collision check function of the present invention may be used by a bending operator in place of the traditional and cumbersome manual profile check that is customarily performed when developing the bending plan.
    </p>
    <p num="240">
      Traditionally, when developing a bending plan for a sheet metal part, a bending operator will first determine the bend sequence for the part.
      <br/>
      The bend sequence defines the order and manner in which the sheet metal part is to be bent during production.
      <br/>
      After the bend sequence has been determined, the bending operator will select and define the tooling to be used to carry out each of the bending operations.
      <br/>
      During this process, the profile of the tools selected and the intermediate shapes of the part will be analyzed to ensure that there is no interference or collision(s) between the tools and the part when carrying out each of the bending steps.
      <br/>
      If a collision or interference is detected, then the type of tooling selected (or, if necessary, the bend sequence) will have to be modified so that the bending operations may be carried out without interference or collision between the tool(s) and the sheet metal part.
    </p>
    <p num="241">
      When detecting for potential collisions or interference, bending operators have traditionally relied upon manual methods to analyze the clearance between the profile of a tool and the bent parts or shapes of the sheet metal component.
      <br/>
      Typically, a model of the tool profile is constructed and used by a bending operator.
      <br/>
      The tool profile model is manually matched or overlaid with engineering or technical drawings (having the same scale size as the tool profile model) of the various intermediate shapes of the sheet metal.
      <br/>
      By fitting and matching the tool profile model with the drawings of the part, the bending operator can determine whether there is sufficient space and clearance between the tool and the part at each of the bending steps.
      <br/>
      This process, however, tends to be cumbersome and time consuming.
    </p>
    <p num="242">
      The present invention overcomes the disadvantages of such traditional methods by providing an automatic collision check function.
      <br/>
      The collision check function of the present invention may be implemented through a graphical user interface to permit the bending operator to check for collisions at each intermediate step within a defined bending sequence.
      <br/>
      FIGS. 35A and 35B illustrate examples of the collision check function implemented through a graphical user interface.
      <br/>
      When activated, the collision check function will automatically check for collisions between each intermediate shape of the part within the bending sequence and the punch tool or tools defined for that sequence.
      <br/>
      The intermediate shapes may be displayed on the screen (see, for example, FIGS. 35A and 35B) and if a collision is found, the step at which the collision is detected may be highlighted on the screen.
      <br/>
      In addition, other display indications, such as text, may be provided to indicate the number of collisions detected.
      <br/>
      In the examples of FIGS. 35A and 35B, the collision information is provided in the upper right hand area of the display window.
      <br/>
      In addition, the type of punch tool or tools for which the collision has been checked may be displayed or indicated in the upper left hand area of the display window.
    </p>
    <p num="243">
      If a collision is detected for the punch tool selected by the operator, the intermediate shapes or stages at which the collision is detected may be highlighted on the screen.
      <br/>
      In this case, an operator may select another punch tool for that particular bending stage and the collision check function may be reexecuted to determine if a collision will occur with the second choice for the punch tool.
      <br/>
      The operator may select a punch tool for each bend and check for collisions with the collision check function.
      <br/>
      Drag and drop editing may be provided to allow the user to change the bend sequence displayed in the window display by dragging the intermediate bending shapes and dropping it to a desired position within the proposed bend sequence.
      <br/>
      The bend sequence may then be modified based on the drag and drop editing performed by the operator, in a similar manner to that described above with reference to FIG. 32.
    </p>
    <p num="244">
      Various processes and operations may be used to implement the collision check feature of the present invention.
      <br/>
      For example, in order to detect for a potential collision, the geometry for the selected tool and the geometry for the part at each intermediate shape may be accessed.
      <br/>
      The geometrical data relating to the part at each intermediate step may be generated based on the bend sequence and the part dimensions and topology data.
      <br/>
      Each flange of the part may be folded in accordance with the bend data (e.g., bend angle, bendline location, deduction amount, etc.) in order to render the part at each intermediate stage in the bending sequence.
      <br/>
      The above described folding process and deduction compensation features of the invention may then be applied when generating the geometrical data for the part at each intermediate stage.
      <br/>
      With the tool and part geometry, the tool and part may be oriented with respect to one another by placing the tip of the tool at the bendline of the part at each of the bending stages.
      <br/>
      A collision may be detected by analyzing the geometrical data and boundaries of the tool and the part and determining whether there are common points or overlapping points in the tool and the part.
      <br/>
      When a collision is detected at a particular bending step, that step may be highlighted on the screen to indicate the detection of a collision to the user.
    </p>
    <p num="245">
      The tool data that is used to detect for collisions may be actively taken out of a tool shape library based on the tooling selection(s) made by the user.
      <br/>
      Recalculation of a collision at any intermediate bending step may be performed based on a different tool shape or modification of the bending sequence.
      <br/>
      By providing such features, and displaying such information through a graphical user interface, such as that described herein, the potential for collisions may more easily be determined and corrected by the bending operator.
    </p>
    <p num="246">
      As described above, a joystick or mouse device may be provided at each of the station modules and locations throughout the manufacturing facility in order to permit the user to selectively activate and control various viewing functions (e.g., zoom, pan, rotate, etc.) when viewing the rendered model of the sheet metal part.
      <br/>
      The joystick device may be a multi-axis joystick and include select and control buttons.
      <br/>
      The joystick may be implemented through various commercially available joystick devices, including a Microsoft SideWinder joystick, and may be plugged into a game port of the computer of each of the station modules and/or other locations in the facility.
      <br/>
      The mouse may also be implemented by any commercially available mouse support software, such as Windows 95 or Windows NT, and any commercially available mouse device that is plugged into a game or mouse port of the computer at each of the facility locations
    </p>
    <p num="247">
      By way of non-limiting examples, FIGS. 36-41 illustrate various aspects of a system for manipulating 3-D geometrical shapes and renderings of the part by using a joystick or mouse device.
      <br/>
      The 3-D navigation system of the invention permits a user to control various viewing functions, such as rotation, zooming and panning.
      <br/>
      In accordance with an aspect of the present invention, the system may also use a dynamic rotation axis that is calculated based on the current zoom view when viewing the 3-D model.
      <br/>
      According to this aspect, the center of rotation may be dynamically changed and calculated based on the current view and zoom ratio or factor so that the zoomed area of the part will not disappear from the screen when the part is rotated with, for example, a high zoom ratio or factor.
    </p>
    <p num="248">
      In accordance with an aspect of the present invention, the 3-D manipulation and navigation system may be provided at the station modules and/or server module of the facility.
      <br/>
      The processes and operations of the 3-D navigation system may be implemented through software or programmed logic and by using any one of a wide variety of programming languages and techniques.
      <br/>
      For example, the system may be implemented by using a high level programming language such as C++ and using objected oriented programming techniques.
      <br/>
      Further, by way of a non-limiting example, VISUAL C++ may be utilized, which is a version of the C++ programming language provided by Microsoft Corporation for Windows based applications.
      <br/>
      The viewing functions (e.g., zoom, rotate, pan, etc.) may be defined and implemented as member functions of the view class of the bend model viewer of the present invention described above (see, e.g., FIG. 18 and the related disclosure provided above).
      <br/>
      Information concerning the current zoom factor and position of the part (e.g., the position of the part in 3-D space) may also be accessed from the bend model viewer to calculate the dynamic rotation axis and to provide the desired viewing functions.
    </p>
    <p num="249">
      Various hardware components and interfaces may also be provided in order to implement the 3-D navigation system of the present invention.
      <br/>
      For example, the software used to implement the system may be provided or reside in the computer or personal computer of the station modules and server module.
      <br/>
      As discussed above, the computer or personal computer may include a graphics card and a display screen or terminal, such as a high resolution monitor, to display 3-D renderings of the sheet metal part to the user.
      <br/>
      The computer or personal computer may also include a mouse or game port adapter card to connect and interface with the mouse or joystick device.
      <br/>
      Commercially available software may also be provided to interpret the command signals received by the mouse or game adapter card from the user-operated mouse or joystick device.
    </p>
    <p num="250">
      FIGS. 36A and 36B illustrate examples of rotation functions that may performed with a multi-axis joystick 112 to rotate, for example, a simple 3-D box shaped part.
      <br/>
      As noted above, a joystick may be provided and connected to a computer or equipment provided at the station modules and/or server module provided throughout the facility.
      <br/>
      As shown in FIGS. 36A and 36B, rotation of the part may be achieved by moving the joystick 112 forwardly or rearwardly, and to the left and the right.
      <br/>
      The orientation or direction of the rotation axis may be set based on the movement of the joystick 112 (or mouse).
      <br/>
      For example, moving the joystick 112 forwardly or rearwardly may cause the part to rotate in the clockwise or counter clockwise direction about a rotation axis defined along the X-coordinate axis (see, e.g., FIG. 36A).
      <br/>
      Further, moving the joystick 112, however, to the left or right may cause the part to rotate in the clockwise or counter clockwise direction about a rotation axis defined along the Y-coordinate axis (see, e.g., FIG. 36B).
    </p>
    <p num="251">
      When the zoom ratio or factor of the current view is low and the entire rendering of the part is provided on the screen, the rotation axis may be defined as passing through the geometric center or centroid of the part.
      <br/>
      As described above, the zoom factor and the visibility of the part on the screen may be determined based on the visibility function provided by the bend model viewer of the present invention.
      <br/>
      When it is determined that the entire part is displayed in the screen (such as that in FIGS. 36A and 36B), then coordinate geometry techniques may be used to define and set the rotation axis to the geometric center of the part.
      <br/>
      Rotation of the part may then be performed based on the user-defined movement of the joystick device and through the rotate member, viewing function of the bend model viewer of the present invention.
    </p>
    <p num="252">
      If, however, only part of the object is displayed on the screen and it is determined that portions of the part are not visible (e.g., a high zoom factor or ratio has been selected), the rotation axis should not be maintained at the geometric center or centroid of the part, since to do so may cause the zoomed portion of the part to disappear from the screen during rotation.
      <br/>
      Instead, according to the invention, when the zoom ratio is increased, the rotation axis is dynamically recalculated such that the rotation axis passes through the coordinate of the closest point to the viewpoint (or camera view) at the center of the screen.
      <br/>
      By dynamically recalculating the rotation axis based on changes in the zoom factor, the part may rotated about an axis that does not cause the visible portion of the part to go out of view during rotation.
    </p>
    <p num="253">
      In order to perform zooming and panning of the 3-D model, additional control buttons may be provided on a keypad that is provided separately or with the joystick or mouse device.
      <br/>
      For example, by pressing a zoom button 114, and moving the joystick 112 forwardly or rearwardly, the part may be zoomed in or out based on a predetermined rate, as shown in FIG. 37. As discussed above, the rotation axis may be recalculated within each zoom window to permit the user to view the zoomed portion of the part when rotation is performed.
      <br/>
      In addition, panning of the 3-D shape may be controlled by the user by pressing or activating a pan button 116 and moving the joystick 112, as shown in FIG. 38. As with the zoom button 114, the pan button 116 may be provided on a digital input pad that is provided separately or with the joystick or mouse device at each of the various locations of the facility.
    </p>
    <p num="254">
      In accordance with an exemplary embodiment of the invention, the various processes and operations that may be provided to implement the 3-D navigation and manipulation system will be described below with reference to FIGS. 39-41. As indicated above, the necessary processes and operations of the 3-D navigation system may be implemented through a combination of software or programmed logic, and hardware components and interfaces.
      <br/>
      Input signals from a user-controlled device, such as a joystick or mouse device, may be interpreted to determine the amount of movement and reorientation of the rendered part that is desired.
      <br/>
      In accordance with the invention, the rotation axis of the rendered part may be calculated dynamically, based on the current view and zoom factor, in order to prevent the zoomed area of the part from disappearing from the screen during rotation.
    </p>
    <p num="255">
      When updating the current view of the rendered part, input signals are received from the user based on the manipulation of the joystick or mouse device, as generally indicated at step S.301 in FIG. 39. Movement of the joystick or mouse device by the user in a particular direction, and/or in combination with the activation of special control buttons, may cause certain viewing functions (e.g., rotate, zoom, pan, etc.) and movement of the rendered part in predetermined directions (e.g., clockwise or counterclockwise; zoom-in or zoom-out; left or right; etc.) to be effectuated, as described for examples in FIGS. 36-38. The received signals, whether they are from a joystick or mouse device, may be mapped to cursor movement to define the amount of movement on the screen that is desired by the user.
      <br/>
      If the user is not within one of the viewing function modes (e.g., the user is selecting information on the screen or reviewing information in a dialog box or window) then mapping of the received signals may not be required.
    </p>
    <p num="256">
      As will be appreciated by those skilled in the art, the signals that are received from conventional joystick or mouse devices are based on different coordinate or reference systems than that of the screen space, and must be translated in order to provide meaningful information regarding cursor movement on the screen.
      <br/>
      Therefore, after receiving the input signals from the user, the received signals may be mapped to cursor movement, as indicated at step S.303, before calculating the rotation axis and updating the current view of the rendered part.
    </p>
    <p num="257">
      Different methods and processes may be used to translate and map the input signals from the user-controlled device to cursor movements in screen space.
      <br/>
      Traditionally, movements of a mouse device have been translated and mapped to cursor movements by commercially available software.
      <br/>
      For example, Windows 95 and Windows NT include software routines for translating mouse movements to cursor movements.
      <br/>
      As such, movements of a mouse device may be mapped to cursor movement by using such commercially available software.
      <br/>
      If, however, the user is provided with a joystick interface, then the joystick movements should also be translated and mapped to cursor movements in order to provide useful information.
      <br/>
      Various methods and techniques may be used to map the joystick movements within the joystick virtual space to cursor movements within the screen space.
      <br/>
      For example, the joystick movement signals may be first processed and translated to mouse movements before they are finally mapped to cursor movements.
      <br/>
      Alternatively, the joystick signals may be directly mapped to cursor movements as a function of the ratio of the screen space size to the size of the joystick virtual space.
    </p>
    <p num="258">
      FIG. 40 illustrates an example of mapping joystick movements to cursor movements in screen space, in accordance with an aspect of the present invention.
      <br/>
      As indicated above, a joystick device may include its own virtual coordinate system or space 218.
      <br/>
      The joystick virtual space 218 includes an origin J1 that corresponds to the position at which the joystick is in a center or neutral position (i.e., a position at which the joystick is not moved).
      <br/>
      When the joystick is moved to a new position (e.g., a current position J2 as shown in FIG. 40), the joystick device generates signals to indicate the new or current position within the virtual space of the joystick.
      <br/>
      Since the joystick virtual space 218 is often larger (in terms of pixels) than the screen space 212, the virtual coordinates and movements of the joystick must be translated to screen coordinates in order to determine the desired cursor movements and, thus, movement of the part on the screen.
    </p>
    <p num="259">
      Various methods and processes may be utilized to map and translate the virtual coordinate movements of the joystick to screen coordinate movements.
      <br/>
      For example, joystick movements may be mapped to screen cursor movements based on the ratio of the screen space size to the joystick virtual space size.
      <br/>
      More particularly, when it is determined that a viewing function mode (e.g., zoom, rotate, pan, etc.) is active and the joystick device has been manipulated by the user, the actual movement of the cursor from a previous point C1 to current point C2 may be determined by the following equation: current_point=previous_point+(scale_factor * V); wherein, "current_point" is the current point C2 of the cursor; "previous_point" is the previous point C1 of the cursor; "scale_factor" is the ratio of the screen size to the joystick virtual space size (both in pixels); and "V" is a vector representing the movement and direction of the joystick from the joystick origin J1 to the joystick current position J2.
      <br/>
      Thus, in order to map joystick movements to cursor movements, a vector "V" indicating the direction and movement of the joystick from the origin J1 to the current position J2 may first be calculated based on the signals received from the joystick device when it is manipulated by a user.
      <br/>
      After the vector "V" has been calculated, the joystick movement may be mapped to cursor movement by using the vector "V" amount and the "scale_factor" amount in the equation described above; that is, the new or current position C2 of the cursor may be calculated by multiplying the vector "V" by the ratio of the screen size to the joystick space size (i.e., the "scale factor"), and then adding the result of this computation to the previous cursor position C1.
    </p>
    <p num="260">
      Depending on the scale factor, it may be necessary to increase or decrease the rate of scaling or movement by a predetermined or user selected adjustment factor.
      <br/>
      In such a case, and depending on the preference of the user, the scale factor may be multiplied by the adjustment factor when calculating the current point of the cursor in order to increase or decrease the rate of scaling.
      <br/>
      For example, if the ratio of the screen size to the joystick space size provides a scale factor of 1/64, then it may be preferable to increase the rate of scaling in order to provide a more satisfactory relationship between movements of the joystick and the rate of movement of the rendered part on the screen.
      <br/>
      By way of a non-limiting example, with a scale factor of 1/64, an adjustment factor of 3 may be used when zooming or rotating the rendered part.
      <br/>
      Further, for a scale factor of 1/64, an adjustment factor of 6 may be used when panning of the rendered part is performed.
      <br/>
      Of course, the rate of scaling may be modified based on the particular needs of the user, and the adjustment factor may be predetermined or the user may be given the option to adjust or select the adjustment factor to modify the rate of scaling.
      <br/>
      Further, as indicated in the example discussed above, the adjustment factor may be set to the same amount for each of the viewing functions or may be individually set to the same or different amounts for each of the viewing functions provided.
    </p>
    <p num="261">
      After the received signals have been appropriately mapped and translated, the rotation axis of the part may be dynamically calculated, as generally shown at step S.305 in FIG. 39. Depending on the current view of the part, the rotation axis may be defined to pass through the center of the part or to pass through another point so that the zoomed area of the part will not disappear from the screen when the part is rotated with, for example, a high zoom ratio or factor.
      <br/>
      Various methods and processes may be utilized to dynamically recalculate the rotation axis of the part based on the current zoom view.
      <br/>
      In accordance with another aspect of the invention, FIG. 41 illustrates an exemplary logic flow and sequence of processes and steps that may be performed to calculate the rotation axis whenever the view of the part has been modified by the user.
    </p>
    <p num="262">
      As shown in FIG. 41, the current zoom factor or ratio and the part position and current view may be determined at steps S.311 and S.313. The zoom factor and orientation of the rendered part selected by the user will cause the entire part to be visible on the screen (i.e., a full view) or cause only a portion of the part to be made visible on the screen (i.e., a partial view).
      <br/>
      Thus, the current zoom factor and part orientation should be determined in order to properly set the rotation axis of the rendered part.
      <br/>
      Various methods and processes may be used in order to determine the current view of the part.
      <br/>
      As described above, a visibility function may be provided with the bend model viewer of the present invention to maintain and update the status of the current view orientation and zoom ratio whenever there is a change made to the displayed image.
      <br/>
      A function call may be made to the bend model viewer to determine what points or portions of the part are presently visible.
      <br/>
      Whether all of the part is displayed on the screen may be determined by comparing the view volume with the part's boundary base size.
    </p>
    <p num="263">
      If it is determined at step S.315 that a full view of the part is currently visible on the screen, then the rotation axis may be set to pass through the center of the part at step S.317. Setting the rotation axis to the center of the part when there is a full view is possible, since the entire rendered part will be visible on the screen when it is rotated by the user.
      <br/>
      With the entire part visible on the screen, the rotation axis may be defined so as to pass through the geometric center or centroid of the part.
      <br/>
      Conventional coordinate geometry techniques may be used to define and set the rotation axis to the geometric center of the part.
      <br/>
      In addition, the direction of the rotation axis may be defined as a vector that is perpendicular to the vector from the previous cursor position to the current cursor position.
    </p>
    <p num="264">
      If it is determined at step S.315 that only a partial view of the part is currently visible on the screen, then logic flow may continue to steps S.319-S.325 in order to calculate the rotation axis so that portions of the rendered part will not disappear from the screen when the zoomed part is rotated by the user.
      <br/>
      As described above, when a high zoom factor is selected by the user and only portions of the part are displayed on the screen, the rotation axis should not be set to pass through the geometric center of the part, since to do so may cause the zoomed portion(s) of the displayed part to disappear from the screen during rotation.
      <br/>
      In order to prevent the displayed portion of the part from being occluded or disappearing from the screen, the rotation axis should be set so as to pass through the coordinate of the closest point to the viewpoint (i.e., camera) at the center of the screen.
      <br/>
      In such a case, the direction of the rotation axis may be defined as a vector that is perpendicular to the vector from the previous cursor position to the current cursor position.
    </p>
    <p num="265">
      Thus, at step S.319, the center of the screen is located and the object or portion of the part at the center of the screen that is closest to the camera is selected.
      <br/>
      That is, the portion of the rendered part that is located at the center of the screen and that is closest to the camera or user viewpoint of the screen is picked.
      <br/>
      If it is determined at step S.321 that there is an object at the camera (e.g., that there is a solid portion of the part that is located at the center of the screen and that is closest to the camera), then at step S.325 the rotation axis may set to pass through the picked point.
      <br/>
      As discussed above, the direction of the rotation axis may be defined as a vector that is perpendicular to the vector from the previous cursor position to the current cursor position.
    </p>
    <p num="266">
      If it is determined at step S.321 that there is not an object at the camera (e.g., that the part includes a hole or opening that is located at the center of the screen and that is closest to the camera), then logic flow may continue to step S.323. At step S.323, the rotation axis may alternatively be define to pass through the center of the screen (e.g., the X and Y coordinate of the physical center of the screen) and at the Z-coordinate (i.e., depth) equal to the geometric center of the part.
      <br/>
      Thus, the rotation axis may be set to pass through the X, Y, and Z coordinates discussed above, with the direction of the rotation axis being defined as the vector that is perpendicular to the vector from the previous cursor position to the current cursor position.
    </p>
    <p num="267">
      Referring back to FIG. 39, after the dynamic rotation axis has been calculated, the selected viewing function (e.g., zoom, rotate, pan, etc.) may be called at step S.307. As discussed above, the various viewing functions of the 3-D manipulation system may be defined and implemented as member functions of the view class of the bend model viewer (see, e.g., FIG. 18 and the related disclosure provided above).
      <br/>
      In such a case, based on the viewing function selected by the user, a function call may be made to the bend model viewer to update the current view of the rendered part, at step S.309. The current view and orientation of the part may be updated based on the viewing function selected by the user and the mapped cursor movements received from the user-controlled input device (e.g., the mouse or joystick device).
      <br/>
      A graphics package, such as OpenGL or RenderWare, may be provided to facilitate the update of the current view provided to the user.
    </p>
    <p num="268">
      The logic flow and processes performed in the exemplary flowcharts of FIGS. 39 and 41 may be implemented by software and by using a wide variety of programming languages and techniques.
      <br/>
      For example, object oriented programming techniques and C++ may be used to implement the noted processes and operations.
      <br/>
      An exemplary code for implementing the 3-D manipulation system of the present invention is provided in Appendix L. The exemplary source code was written in C++ programming language and includes the various processes and operations for calculating the dynamic rotation axis.
      <br/>
      Comments are provided in the code of Appendix L to facilitate the analysis of the logic and algorithms used therein.
    </p>
    <p num="269">
      Although the 3-D manipulation system described above has been described with respect to the use of a joystick device and control buttons, the system may also be implemented by any other particular type of input means, including a mouse or keyboard.
      <br/>
      Further, in the above-described embodiments of FIGS. 37-38, boundaries may be defined to limit zooming or panning of the object in or out of the screen into infinity, since such continuous zooming or panning may cause the system to fail or crash.
    </p>
    <p num="270">
      In addition, various other features may be implemented in connection with the joystick interface.
      <br/>
      For example, movement in any of the viewing functions may not be effectuated unless the joystick is moved beyond a predetermined range or distance from the joystick center position.
      <br/>
      Requiring such a threshold of movement of the joystick before movement of the part is permitted prevents accidental movements of the rendered part based on inadvertent handling or pushing of the joystick from the center position.
      <br/>
      Other features may also be provided to improve the joystick interface and system interaction with the user.
      <br/>
      For instance, continuous or incremental (e.g., step-wise) movement in any one of the viewing functions (e.g., zoom, rotate, pan, etc.) may be provided based on the single operation of the joystick by the user.
      <br/>
      Selection of the continuous or incremental movements may also be provided based on the amount or duration of movement of the joystick in any single direction.
      <br/>
      If desired, the rate of scaling or movement of the rendered part may also be increased based on the degree or duration of movement of the joystick in any direction.
      <br/>
      Modification of the speed adjustment factor described above may also be implemented by permitting the user to manual insert the correction to the adjustment factor to increase or decrease the rate of scaling.
    </p>
    <p num="271">
      Various other features and embodiments may also be implemented in the present invention in order to aid in the design and manufacturing of components at the factory.
      <br/>
      For example, a bar code system may be implemented to keep track of and access information concerning each customer's order.
      <br/>
      A bar code with a predetermined reference or job number may be assigned to each part ordered by a customer.
      <br/>
      This bar code may be used for accessing and retrieving job information from database 30.
      <br/>
      A bar code reader or scanner, such as a Barcode Anything SCAN CCD sensor from Zebra Technologies VTI, Inc., Sandy, Utah, may be provided at each of the locations to permit users to scan the bar code for a particular job in to the server module or station module and to access and retrieve critical design and manufacturing information associated with that part that is stored in database 30.
      <br/>
      The bar code reader may be plugged into the computer of each of the station modules and/or the server module.
      <br/>
      The bar codes may be formatted in accordance with any conventional bar code formats, such as UPC-A, Codabar, Code 39, EAN/JAN-8 or Plessey, and the resultant bar code number may be translated in accordance with a lookup table to find the corresponding job reference number and/or file name in order to retrieve the job information from the database.
      <br/>
      Alternatively, the job number may be typed in or selected from a displayed directory at any of the stations located throughout the factory to instantaneously retrieve and display the job information at the user's location.
      <br/>
      The ability to instantaneously retrieve such information is aided by the use of communications network 26 and the storage of the design and information at a centrally located database, such as database 30.
    </p>
    <p num="272">
      In accordance with yet another aspect of the present invention, an apparatus and method for scheduling and assigning jobs may be provided in the proposed system.
      <br/>
      Conventionally, the scheduling and assignment of jobs throughout a manufacturing facility is performed by a shop or factory foreman who determines the current set-up and availability of machinery, as well as the status of current jobs.
      <br/>
      After gathering and analyzing this information, the shop or factory foreman may develop a schedule and distribute the assignments for the jobs (e.g., in the form of a job schedule sheet that is distributed to the factory floor) that are to be performed at the various locations in the factory.
      <br/>
      The scheduling and assignment of jobs is provided to ensure that each customer's job is completed in a timely fashion and by the specified delivery date.
      <br/>
      The conventional process of scheduling and assigning jobs is, however, often arduous and usually performed manually by the factory foreman.
    </p>
    <p num="273">
      In accordance with an aspect of the invention, a job assignment and scheduling system may be provided to assist a shop or factory foreman in establishing job schedules for the factory.
      <br/>
      The system may take advantage of communications network 26 and the bend model information that is stored in database 30 to automatically gather the necessary information so that the shop foreman may more easily develop a job schedule.
      <br/>
      The system may be implemented through software or programmed logic at the server module or station modules located throughout the factory.
      <br/>
      By entering the various jobs that need to be scheduled, the system software may analyze the design and part information and determine which machines are best suited for doing particular jobs.
      <br/>
      For this purpose, the current status and set-up of the machinery in the factory may be defined and stored in database 30 and accessed by the job scheduler software.
      <br/>
      Based on various criteria, the software may suggest to the foreman, in the form of a display, which machines are available to perform a particular job and which machines cannot perform other jobs.
      <br/>
      In this regard, a table may be displayed that ranks the availability of machines for particular jobs and that provides a proposed job schedule that may be implemented or modified by the shop foreman.
    </p>
    <p num="274">
      The criteria that may be used to set and recommend job schedules may include a wide variety of criteria including the current set-up of each machine in the factory, the types of bends and tooling required for each job and the other types of jobs that need to be performed within the same time frame or period.
      <br/>
      Information from the bend model file for each part may also be utilized, such as the bend angle, the flange length, and type of bending, in order to determine which machines can perform a particular job.
      <br/>
      A table stored at, for example, database 30, may include critical information as to the current set-up and capabilities of each of the punching and bending machines on the shop floor.
    </p>
    <p num="275">
      Based on the proposed job schedule, the foreman may assign jobs to various locations throughout the factory in order to optimize production and output capacity of the factory.
      <br/>
      The final job schedule or assignment may be entered electronically and routed to each of the machines through communications network 26.
      <br/>
      A pilot lamp, such as an LED, may be provided at each of the bending or machinery work stations to indicate and confirm that a job has been assigned or transferred to that station.
      <br/>
      The job assignment and schedule may be stored in a file of the server module that can be accessed instantaneously from any location within the factory.
    </p>
    <p num="276">
      In addition to the above features, other miscellaneous features may be implemented in accordance with the teachings of the present invention.
      <br/>
      For example, menu screens may be provided and displayed at the various station modules and locations to facilitate the user in selecting the various display and function modes of the present invention.
      <br/>
      For example, a main menu screen such as that shown in FIG. 42 may be provided to a user when the station module is initialized.
      <br/>
      The main menu window display may include icon images of each of the available window displays and viewing modes provided by the station module.
      <br/>
      The main menu screen may pop-up anytime a menu button (e.g., F1 key) is selected.
      <br/>
      The user may select a window by moving a highlighted block to the desired window icon and selecting the same.
      <br/>
      Such operations may be performed through the use of a keyboard, mouse or joystick.
    </p>
    <p num="277">
      Other window screens may also be provided and displayed to the user to facilitate the entry and display of the job information.
      <br/>
      For example, a part information window may be displayed to permit a user to enter or modify the part information.
      <br/>
      An example of a part information window display is provided in FIG. 43. The part information window may include all of the pertinent part information (e.g., part number, material type, dimensions, etc.) and may include a 2-D flat drawing and isometric view of the sheet metal part.
      <br/>
      A bendline information window, such as that illustrated in FIG. 44, may also be provided to allow a user to view the various bendline information, including the bend sequence and deduction amount for each bendline.
      <br/>
      The bendline information window may permit the user to enter or modify the bendline information for each bend, and may include both a 2-D flat drawing and isometric view of the sheet metal part.
    </p>
    <p num="278">
      Additional window display may also be provided to facilitate a bending operator's analysis of the bending sequence.
      <br/>
      For example, a bend sequence window display and a bend simulation window display may be provided to indicate the various bending stages of the part and to simulate the part orientation during bending operations.
      <br/>
      A bend sequence window, such as that shown in FIG. 45, may be selected from the main menu screen and displayed to the user to indicate the intermediate shapes of the part (in static form) at each stage of the bending sequence.
      <br/>
      A bend simulation window (see, e.g., FIG. 46) may also be selected by the user and provide both static information of the bending stages (in the form of part icons provided on the righthand side of the screen) and active simulation (in the center of the display) of the orientation and bending performed at each stage in the bend sequence.
      <br/>
      By intermittently selecting the part icons on the screen, the user may view an active simulation of the orientation of the part during bending at the stage represented by the selected part icon.
      <br/>
      The part may be flipped, translated and bent/rotated about the bendlines in order to actively simulate each bend sequence.
    </p>
    <p num="279">
      Each of the above-described window displays of FIGS. 43-46 may be selected and displayed to a user from the main menu window display of FIG. 42. In addition, a user at any of the station modules may select the appropriate window icons in the main menu window display to have the 2-D and/or 3-D representations of the part displayed in accordance with the viewing modes (e.g., 2-D flat, wire-frame, solid, orthographic) of the invention, as described in greater detail above with reference to FIGS. 19-22. Various menu windows may also be provided, for example, at the station modules to facilitate the operation of the features and functions of the present invention.
      <br/>
      FIGS. 47A nad 47B illustrate exemplary menus that may be displayed for the 2-D to 3-D operations.
      <br/>
      In addition, FIG. 48 illustrates an exemplary menu structure for the 2-D cleanup operation of the invention.
      <br/>
      The present invention, however, is not limited to these menu arrangement, and other menu screens and/or tool icon bars may be provided to facilitate a user's interaction with the system.
    </p>
    <p num="280">
      Other features may also be implemented in the present invention.
      <br/>
      For example, higher levels of automation may be provided to facilitate the development of the bending plan.
      <br/>
      For example, bending and tooling expert systems may be provided to develop and propose tooling set-up and bending sequences based on the part geometry and shape for each job, such as that disclosed in pending, U.S. patent application Ser.
      <br/>
      Nos. 08/386,369 and 08/338,115.
    </p>
    <p num="281">
      While the invention has been described with reference to several exemplary embodiments, it is understood that the words which have been used herein are words of description and illustration, rather than words of limitations.
      <br/>
      Changes may be made without departing from the scope and spirit of the invention and its various aspects.
      <br/>
      Although the invention has been described herein with reference to particular means, materials and embodiments, the invention is not intended to be limited to the particulars disclosed herein; rather, the invention extends to all functionally equivalent structures, methods and uses.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A system for developing a sheet metal bend sequence through the use of a graphical user interface, said bend sequence being adapted for use in the production of a part at a facility, said system comprising:</claim-text>
      <claim-text>a bend sequence display system for generating and displaying a bend sequence input window on a display device, said bend sequence input window comprising a 2-D flat image of said part, said 2-D flat image of said part including representations of each bendline of said part;</claim-text>
      <claim-text>and an input device for manually entering a bend sequence based on said 2-D flat image of said part, said bend sequence being entered by an operator using said input device by selecting each bendline displayed in said 2-D flat image of said part; wherein said bend sequence display system is further adapted to generate and display a plurality of images of said part based on said bend sequence entered by said input device, each of said plurality of images of said part relating to a representation of said part at a stage within said bend sequence.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. A system according to claim 1, wherein said input device is adapted to enter said bend sequence based on a sequence in which each said bendline is selected.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. A system according to claim 1, wherein said input device is adapted to enter said bend sequence based on a bend sequence number entered by said input device when each said bendline is selected.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. A system according to claim 1, wherein said input device comprises a joystick device.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. A system according to claim 1, further comprising a bend sequence number display system for displaying, on said display device, a bend sequence number for each said bendline based on said bend sequence entered by said input device.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. A system according to claim 1, further comprising an insert direction determination system for determining and displaying, on said display device, insert direction information for each said bendline of said part.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. A system according to claim 6, wherein each said bendline divides said part into two sides, and wherein said insert direction determination system determines said insert direction information for each said bendline based on the side that has a smaller predetermined dimension.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. A system according to claim 6, wherein said displayed insert determination information for each said bendline comprises an arrow relating to an insert direction for said bendline.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. A computer readable memory tangibly embodying a computer program, said computer program comprising instructions that are executable by a computer-based machine to perform a method for developing a sheet metal bending plan through the use of a graphical user interface, said bending plan being adapted for use in the production of a part at a facility, said method comprising: generating and displaying a bend sequence input window on a display device, said bend sequence input window comprising a 2-D flat image of said part; manually entering, in accordance with operation of an input device, a bend sequence based on said 2-D flat image of said part; generating and displaying tooling information on said display device, said tooling information relating to a plurality of tools; manually selecting, in accordance with operation of said input device, tooling based on said tooling information displayed on said display device;</claim-text>
      <claim-text>and storing, in a storage device, said bending plan for said part based on said entered bend sequence and said selected tooling; said method further comprising generating and displaying a plurality of images of said part on said display device based on said entered bend sequence, each of said plurality of images of said part relating to a representation of said part at a stage within said bend sequence.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. A computer readable memory according to claim 9, wherein said 2-D flat image of said part includes representations of each bendline of said part, and wherein said method further comprises displaying, on said display device, a bend sequence number for each said bendline of said 2-D flat image of said part based on said bend sequence that is entered.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. A computer readable memory according to claim 10, wherein said method further comprises determining and displaying, on said display device, insert direction information for each said bendline of said part.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. A computer readable memory according to claim 11, wherein each said bendline divides said part into two sides, and wherein said method further comprises determining said insert direction information for each said bendline based on the side of said part that has a smaller predetermined dimension.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. A computer readable memory according to claim 9, wherein said method further comprises displaying said plurality of images of said part in a sequence corresponding to said bend sequence.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. A computer readable memory according to claim 13, wherein said method further comprises providing drag and drop editing to modify said bend sequence based on a modification of said displayed sequence of said plurality of images on said display device.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. A computer readable memory according to claim 14, wherein said method further comprises regenerating and displaying said plurality of images and each said representation of said part based on said modified bend sequence.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. A computer readable memory according to claim 9, wherein said method further comprises displaying said tooling information through a series of successively displayed screen displays, at least one of said successively displayed screen displays being displayed based on a previous selection by said input device.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. A computer readable memory according to claim 16, wherein said method further comprises displaying, on said display device, a first screen display comprising a plurality of tool type icons, each of said tool type icons representing a tool type.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. A computer readable memory according to claim 17, wherein said method further comprises selecting one of said tool type icons in accordance with operation of said input device and displaying, in response to the selection of one of said tool type icons, a second screen display on said display device, said second screen display comprising a plurality of tool shape icons, each of said tool shape icons relating to said tool type icon selected in accordance with operation of said input device.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. A computer readable memory according to claim 18, wherein said method further comprises selecting one of said tool shape icons in accordance with operation of said input device and displaying, in response to the selection of one of said tool shape icons, a table of tool dimension data on said display device, said tool dimension data relating to a plurality of tools, each of said tools relating to said tool shape icon selected in accordance with operation of said input device.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. A computer readable memory according to claim 19, wherein said method further comprises selecting data from said table of tool dimension data in accordance with operation of said input device to select and enter at least a part of said tooling of said bending plan.</claim-text>
    </claim>
    <claim num="21">
      <claim-text>21. A computer readable memory according to claim 9, wherein said method further comprises displaying said 2-D flat image of said part and said plurality of images of said part simultaneously on said display device.</claim-text>
    </claim>
    <claim num="22">
      <claim-text>22. A computer readable memory tangibly embodying a computer program, said computer program comprising instructions that are executable by a computer-based machine to perform a method for developing a sheet metal bend sequence through the use of a graphical user interface, said bend sequence being adapted for use in the production of a part at a facility, said method comprising: generating and displaying a bend sequence input window on a display device, said bend sequence input window comprising a 2-D flat image of said part; manually entering, in accordance with operation of an input device, a bend sequence based on said 2-D flat image of said part;</claim-text>
      <claim-text>and generating and displaying a plurality of images of said part based on said bend sequence entered in accordance with operation of said input device, each of said plurality of images of said part relating to a representation of said part at a stage within said bend sequence.</claim-text>
    </claim>
    <claim num="23">
      <claim-text>23. A computer readable memory according to claim 22, wherein said method further comprises storing, in a database, said bending sequence for said part based on said bend sequence entered in accordance with operation of said input device.</claim-text>
    </claim>
    <claim num="24">
      <claim-text>24. A computer readable memory according to claim 22, wherein said method further comprises displaying said plurality of images of said part in a sequence corresponding to said bend sequence.</claim-text>
    </claim>
    <claim num="25">
      <claim-text>25. A computer readable memory according to claim 24, wherein said method further comprises providing drag and drop editing to modify said bend sequence based on a modification of said displayed sequence of said plurality of images on said display device.</claim-text>
    </claim>
    <claim num="26">
      <claim-text>26. A computer readable memory according to claim 25, wherein said method further comprises regenerating and displaying said plurality of images and each said representation of said part based on said modified bend sequence.</claim-text>
    </claim>
    <claim num="27">
      <claim-text>27. A computer readable memory according to claim 22, wherein said method further comprises displaying said 2-D flat image of said part and said plurality of images of said part simultaneously on said display device.</claim-text>
    </claim>
    <claim num="28">
      <claim-text>28. The computer readable medium of claim 22, wherein the plurality of images of the part are simultaneously displayed on the display device in a sequence corresponding to the bend sequence.</claim-text>
    </claim>
    <claim num="29">
      <claim-text>29. The system of claim 1, wherein the plurality of images of the part are simultaneously displayed on the display device in a sequence corresponding to the bend sequence.</claim-text>
    </claim>
    <claim num="30">
      <claim-text>30. The computer readable medium of claim 9, wherein the plurality of images of the part are simultaneously displayed on the display device in a sequence corresponding to the bend sequence.</claim-text>
    </claim>
  </claims>
</questel-patent-document>