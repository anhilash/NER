<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06178923B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06178923</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6178923</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="23216527" extended-family-id="38980880">
      <document-id>
        <country>US</country>
        <doc-number>09313644</doc-number>
        <kind>A</kind>
        <date>19990518</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1999US-09313644</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>39804433</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>31364499</doc-number>
        <kind>A</kind>
        <date>19990518</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1999US-09313644</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>A01K  29/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>01</class>
        <subclass>K</subclass>
        <main-group>29</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>A01K  27/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>01</class>
        <subclass>K</subclass>
        <main-group>27</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>119719000</text>
        <class>119</class>
        <subclass>719000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>119859000</text>
        <class>119</class>
        <subclass>859000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>A01K-027/00H</text>
        <section>A</section>
        <class>01</class>
        <subclass>K</subclass>
        <main-group>027</main-group>
        <subgroup>00H</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>A01K-027/00E</text>
        <section>A</section>
        <class>01</class>
        <subclass>K</subclass>
        <main-group>027</main-group>
        <subgroup>00E</subgroup>
      </classification-ecla>
      <classification-ecla sequence="3">
        <text>A01K-029/00</text>
        <section>A</section>
        <class>01</class>
        <subclass>K</subclass>
        <main-group>29</main-group>
        <subgroup>00</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>A01K-027/009</classification-symbol>
        <section>A</section>
        <class>01</class>
        <subclass>K</subclass>
        <main-group>27</main-group>
        <subgroup>009</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>A01K-027/006</classification-symbol>
        <section>A</section>
        <class>01</class>
        <subclass>K</subclass>
        <main-group>27</main-group>
        <subgroup>006</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>A01K-029/00</classification-symbol>
        <section>A</section>
        <class>01</class>
        <subclass>K</subclass>
        <main-group>29</main-group>
        <subgroup>00</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>20</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>2</number-of-drawing-sheets>
      <number-of-figures>2</number-of-figures>
      <image-key data-format="questel">US6178923</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">System and method for making live animals appear to talk</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>KIRSCHENBAUM DANIEL S, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5217379</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5217379</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>FRIEDMAN LORRI</text>
          <document-id>
            <country>US</country>
            <doc-number>5337041</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5337041</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>MISTRY RUPAL T</text>
          <document-id>
            <country>US</country>
            <doc-number>5355839</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5355839</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>HANSON MICHAEL C, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5955953</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5955953</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>PRINTZ ROBERT L</text>
          <document-id>
            <country>US</country>
            <doc-number>6003473</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US6003473</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="6">
          <text>ELLIS JOEL F</text>
          <document-id>
            <country>US</country>
            <doc-number>3870296</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US3870296</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="7">
          <text>GRASSANO VINCENT R</text>
          <document-id>
            <country>US</country>
            <doc-number>4681303</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4681303</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="8">
          <text>YARNALL SR ROBERT G, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4745882</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4745882</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="9">
          <text>TOBIAS SAMUEL</text>
          <document-id>
            <country>US</country>
            <doc-number>4967696</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4967696</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="10">
          <text>TARLOW KENNETH A, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5045327</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5045327</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>HYMAN GREG, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5316515</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5316515</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="12">
          <text>MARISCHEN JOSEPH E, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5351653</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5351653</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="13">
          <text>AVITAL NONI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5407376</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5407376</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="14">
          <text>GREENE TEDDY R</text>
          <document-id>
            <country>US</country>
            <doc-number>5494002</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5494002</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="15">
          <text>KLEES DANIEL J, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5509859</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5509859</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="16">
          <text>SHIMOGORI KOTARO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5752335</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5752335</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="17">
          <text>KLEES DANIEL J, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5775970</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5775970</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant app-type="applicant" sequence="1">
          <addressbook lang="en">
            <name>PLOTKIN ROBERT A.</name>
          </addressbook>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Plotkin, Robert A.</name>
            <address>
              <address-1>Reading, PA, 19612-4926, US</address-1>
              <city>Reading</city>
              <state>PA</state>
              <postcode>19612-4926</postcode>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Nixon &amp; Vanderhye P.C.</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Poon, Peter M.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>REVOKED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A system and method for making animals appear to talk is provided.
      <br/>
      The system includes a speaker mounted on an article (such as a collar) worn by the animal.
      <br/>
      A memory stores a plurality of pre-recorded messages.
      <br/>
      These pre-recorded messages may be generic phrases to be "spoken" by all types of animals or may be messages which are based on the characteristics of a particular animal.
      <br/>
      Using a selection circuit, a user is able to selectively output the pre-recorded messages from the memory to the speaker, thereby making the animal appear to talk.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="2">The present invention relates to a system and method for making live animals appear to talk.</p>
    <p num="3">2. Description of the Prior Art</p>
    <p num="4">
      Various arrangements are known in the art for producing sounds from toys such as stuffed animals.
      <br/>
      For example, U.S. Pat. No. 5,775,970 to Klees et al. discloses a toy leash with an adjustable harness, electronic sound and a light which is attachable to one of a number of toy animals.
      <br/>
      Housed within a handle connected to the leash are a battery and integrated circuit or chip for generating various electronic sound signals such as for a barking dog, a meowing cat, roaring lion or tiger, growling bear or the like.
      <br/>
      The appropriate sound signal is generated using one or more selector switches.
    </p>
    <p num="5">
      U.S. Pat. No. 5,509,859 to Klees et al. discloses a novelty item for creating the illusion of an imaginary pet.
      <br/>
      Mounted within the collar end of the leash is a micro speaker which is connected by wiring through a hollow leash to circuitry in the handle.
      <br/>
      The circuitry includes a conventional sound producing circuit for a plurality of simulated synthetic animal sounds such as a friendly dog bark, a mean dog growl, a friendly cat meow, and a scary cat hiss.
      <br/>
      One of these sounds is selected by appropriately depressing selector switches.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="6">
      The present invention relates to a system for making a live animal appear to talk.
      <br/>
      The system has particular utility with household pets such as dogs and cats, although the invention is not limited in this respect.
      <br/>
      The system includes a speaker mounted on an article (such as a collar) worn by the animal.
      <br/>
      A memory stores a plurality of pre-recorded messages.
      <br/>
      These pre-recorded mesages may be generic messages to be "spoken" by all types of animals or may be messages which are based on the characteristics (e.g., type, breed, size, age) of a particular animal.
      <br/>
      Using a selection circuit, a user is able to selectively output the pre-recorded messages from the memory to the speaker, thereby making the animal appear to talk.
      <br/>
      The selection circuit, the memory and a control circuit for causing the pre-recorded messages to be output from the memory to the speaker may be part of a system control panel.
      <br/>
      This control panel may be conveniently attached to the handle of a leash which is secured to a collar worn by the animal.
    </p>
    <p num="7">
      The system may be configured so that the memory stores two or more pre-recorded messages constituting a conversation.
      <br/>
      The system may also be provided with a second speaker.
      <br/>
      This speaker may be arranged, for example, in the control panel or on an article worn by another animal.
      <br/>
      Using the selection circuit, the user may select the messages constituting the conversation for output to the two speakers.
      <br/>
      The selection circuit may be arranged so that a single input results in the output of all of the messages constituting the conversation from the memory to the speakers and the control circuit may be arranged to direct each message to the appropriate one of the speakers.
      <br/>
      In this way, the animal can appear be involved in "conversations" either with its owner or with another animal.
    </p>
    <p num="8">
      The system may also be provided with one or more sensors for sensing a parameter such as air temperature.
      <br/>
      The sensed parameter may be used, at least in part, to select a pre-recorded message for output from the memory.
      <br/>
      Thus, for example, the animal can appear to be talking about current weather conditions.
    </p>
    <p num="9">
      The system may still further be provided with a timer.
      <br/>
      The control circuit is responsive to the timer for periodically (either at regular or irregular intervals) automatically outputting one of the pre-recorded messages from the memory.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="10">
      These, as well as other objects and advantages of this invention, will be more completely understood and appreciated by careful study of the following more detailed description of a presently preferred exemplary embodiment of the invention taken in conjunction with the accompanying drawings, of which:
      <br/>
      FIG. 1 is a block diagram showing the elements of the present invention; and
      <br/>
      FIG. 2 shows an implementation of an embodiment of the present invention.
    </p>
    <heading>DETAILED DESCRIPTION</heading>
    <p num="11">
      FIG. 1 is a block diagram showing a system in accordance with the present invention.
      <br/>
      The system includes a control circuit 10 such as a microprocessor, a memory 15, a selection circuit 20, a power supply 25, a speaker 30 and an optional serial port 42.
      <br/>
      Memory 15 is preferably a non-volatile memory and stores a plurality of pre-recorded spoken messages as will be explained in greater detail below.
      <br/>
      Selection circuit 20 permits a user to make selections including selections of one of the plurality of pre-recorded spoken messages from memory 15 for output by speaker 30 via a digital-to-analog converter (not shown).
    </p>
    <p num="12">
      The selection circuit 20 may comprise, for example, buttons or keys.
      <br/>
      These buttons or keys may be actuated individually or in combination to make selections including selections of a particular one of the pre-recorded spoken messages.
      <br/>
      The buttons or keys may include captions, labels or other indicia to assist the user in making selections.
      <br/>
      The selection circuit 20 may alternatively comprise a touch-sensitive display screen.
      <br/>
      In this case, the selections are made by touching a designated area or areas of the display screen.
      <br/>
      The designated area or areas may include captions, labels or other indicia to assist the user in making selections.
      <br/>
      The selection circuit 20 may comprise any combination of keys, buttons and a touch-sensitive display screen.
      <br/>
      Of course, the selection circuit 20 may be as simple as a single key or button that, in response to successive actuations, causes the output of the pre-recorded messages from memory 15 to speaker 30 in a random or in a pre-determined sequence.
    </p>
    <p num="13">Power supply 25 (such as one or more batteries) supplies power to the control circuit 10 and to any other components (e.g., a touch-sensitive display screen) requiring power.</p>
    <p num="14">
      FIG. 2 shows an implementation of the above system in accordance with an embodiment of the present invention.
      <br/>
      In this embodiment, the speaker 30 is attached to a collar 40 worn by a dog.
      <br/>
      One end of a leash 50 is attached to the collar 40.
      <br/>
      The other end of the leash 50 has a handle that is grasped by a person to restrain the dog when the dog is, for example, being walked.
      <br/>
      A control panel 60 is attached in any convenient manner to the handle 55.
      <br/>
      Control panel 60 accommodates the control circuit 10, memory 15, selection circuit 20 and power supply 25.
      <br/>
      Control panel 60 also includes a volume control (not shown) for controlling the volume of the speaker output.
      <br/>
      Other controls such as bass and treble may be provided, if desired, as is known in the art.
      <br/>
      Of course, various ones (or even all) of the components (e.g., control circuit 10 and memory 15) may be configured for attachment to collar 40 along with speaker 30 and the present invention is not limited in this respect.
    </p>
    <p num="15">
      Control panel 60 and speaker 30 are connected via a wired path.
      <br/>
      The wire may be located in the body of the leash or may be secured to or wrapped around the outside of the body of the leash.
      <br/>
      Alternatively, the control panel and the speaker may be connected via a wireless link.
      <br/>
      The use of a wireless link provides greater flexibility with respect to the positioning of the control panel, which of course is not limited to a position in which it is attached to handle 55.
    </p>
    <p num="16">
      The collar and leash combination may be unitary or the leash may be detachably coupled to the collar by using a coupling mechanism.
      <br/>
      In the case of the detachable coupling, the speaker and the control panel may be connected over a wireless link or the end of the wire that connects the control panel to the speaker may be provided, for example, with a plug which is plugged into a jack connected to the speaker.
    </p>
    <p num="17">
      Memory 15 may be configured in various ways.
      <br/>
      For example, memory 15 may be a memory which stores pre-recorded messages for a particular type or breed of animal.
      <br/>
      Thus, memory 15 may store a set of pre-recorded generic messages for a dog or a set of pre-recorded messages for a cat.
      <br/>
      Alternatively, memory 15 may store a set of pre-recorded messages created for a particular breed of animal such as a French poodle or a Siamese cat.
    </p>
    <p num="18">
      Memory 15 may also be configured to store pre-recorded messages for a plurality of different types and/or breeds of animals.
      <br/>
      Using the selection circuit 20, the user may initially select a particular type and/or breed of animal.
      <br/>
      After making this selection, the system allows the user to select from among the pre-recorded messages appropriate for use with an animal of the selected type and/or breed.
      <br/>
      Thus, the system is user configurable and the same system may be easily adapted for use with many different types and breeds of animals.
    </p>
    <p num="19">
      Memory 15 may also be configured as a portable memory module adapted to be removably attachable to the control panel 60 via a memory module port (not shown).
      <br/>
      The user uses the selection circuit 20 to selectively output pre-recorded messages from among the pre-recorded messages on the portable memory module.
      <br/>
      Different portable memory modules will store messages for animals of different types and breeds.
      <br/>
      For example, one portable memory module may store generic messages for any type of dog; another portable memory module may store generic messages for any type of cat; and still another portable memory module may store messages for a particular type of dog (e.g., a French poodle).
      <br/>
      It will be apparent that the use of portable memory modules provides a system which may be easily adapted for use with pets of different types (e.g., cats and dogs) or breeds (e.g., bulldogs and French poodles).
    </p>
    <p num="20">
      The system may also be configured for connection to a computer via serial port 42.
      <br/>
      Using this connection, memory 15 may be loaded or updated with pre-recorded messages stored by or accessible to the computer.
      <br/>
      For example, the memory of the computer may contain various pre-recorded messages.
      <br/>
      The pre-recorded messages may be loaded into the memory of the computer from a disk provided to the user when the system is purchased.
      <br/>
      Using the computer, the user may then select certain ones of these pre-recorded messages for loading into the memory 15 via serial port 42.
      <br/>
      In another implementation, the computer may be connected to a particular web site using conventional browser software.
      <br/>
      The web site provides various pre-recorded messages which may be selected for loading into the memory 15 via serial port 42.
      <br/>
      The pre-recorded messages on the web site may be organized according to animal type, breed, size, age, etc.
      <br/>
      This arrangement permits a user to select pre-recorded messages from among a large number of messages, as well as easy adaptation of the system to pets of different types or breeds and to the preferences of a particular user.
      <br/>
      The computer may also be used by the user to record his or her own messages using conventional equipment and software.
      <br/>
      These recorded messages may likewise be loaded into memory 15 via serial port 42.
    </p>
    <p num="21">
      The messages stored in memory 15 comprise of one or more spoken words and may be in any language, accent or voice type.
      <br/>
      It is also contemplated that the messages may comprise songs or parts of songs which can be accompanied or unaccompanied by appropriate background music.
      <br/>
      As noted above, the messages may be generic to all pets or may be tailored to specific types of pets or to specific breeds of a particular type of pet.
      <br/>
      An example of a generic message that may be pre-recorded in memory 15 for a pet dog is: "It's a dog eat dog world out there." An example of a generic message that may be pre-recorded for a pet cat is: "I want to be left alone." If desired, this message may be recorded with a Greta Garbo-like accent.
      <br/>
      Messages specific to a particular breed may also be pre-recorded.
      <br/>
      For example, a message for a boxer might be: "You should see the other guy." A message for a Doberman might be: "I'm not looking for any trouble." Messages for a French poodle may be recorded with a French accent.
    </p>
    <p num="22">
      It will be apparent that the content and characteristics (e.g., accents, high pitch voice, low pitch voice, etc.) of the pre-recorded messages are limited only by the imagination of the person making the recordings and by the intended audience.
      <br/>
      Thus, certain messages may be developed for a humorous or amusing effect while walking a dog around the neighborhood.
      <br/>
      In another implementation, certain messages may be developed for use with animals in a zoo.
      <br/>
      More particularly, a speaker may be attached to an article worn by an animal in a zoo.
      <br/>
      A visitor to the zoo may use a control panel (mounted for example adjacent to the animal's enclosure and configured for wireless transmissions to the speaker) to cause the speaker worn by the animal to selectively output pre-recorded messages.
      <br/>
      There may, for example, be a set of pre-recorded messages which are suitable for use with children.
      <br/>
      For example, the messages may include statements of the type of animal, the animal's name, how old the animal is, what the native habitat of the animal is, and the like.
      <br/>
      With appropriate inputs to the selection circuit, the user can select certain ones of these messages to be output from the speaker worn by the animal.
      <br/>
      Such a system would be particularly advantageous in a petting zoo for small children.
    </p>
    <p num="23">
      Those skilled in the art will readily understand that the functionality described herein can be achieved through the use of different components and the particularly circuitry associated with the control circuit 10, memory circuit 15, selection circuit 20 and/or control panel 60 can have many variations.
      <br/>
      Those skilled in the art will understand how the system of the present invention can be constructed in light of this disclosure and general knowledge in the industry.
      <br/>
      In addition, various technologies exist for recording spoken or sung messages in a format suitable for storage in a memory and those skilled in the art will readily understand how these technologies may be used in the system described herein.
    </p>
    <p num="24">
      In another implementation of the present invention, a second speaker is provided.
      <br/>
      This speaker may be provided, for example, in the leash handle or on the control panel.
      <br/>
      In this way, the pet can be involved in "conversations".
      <br/>
      In this implementation, the memory 15 may store pre-recorded messages that simulate a conversation (e.g., questions and answers or a series of comments about a particular topic).
      <br/>
      Using the selection circuit, the user may select the messages constituting the conversation for output to the speakers.
      <br/>
      The selection circuit may be arranged so that a single input results in the output of all of the messages of the conversation from the memory to the speaker and the control circuit may be arranged to direct each of the messages to the appropriate one of the speakers.
      <br/>
      In a variation of this implementation, the second speaker may be provided on an article worn by another animal or pet.
      <br/>
      In this way, two animals or pets can appear to be involved in a conversation.
    </p>
    <p num="25">
      In still another implementation, one or more sensors may be incorporated in or connected to control panel 60 for sensing parameters such as air temperature and the messages spoken by the pet may be determined, at least in part, based on the sensed parameter(s).
      <br/>
      For example, on a particularly cold day (e.g., one on which the temperature is below some predetermined temperature), the selection circuit may permit the user to select a pre-recorded message such as: "It's not fit for man nor beast." A sensor may also be provided to sense certain sounds or even words.
      <br/>
      For example, a sensor may be provided to sense a series of barks by a dog.
      <br/>
      In response to the sensing of this series of barks, the control circuit 10 may automatically cause the message "Don't make me come over there" to be output via speaker 20.
    </p>
    <p num="26">
      In a still further implementation, control circuit 10 may be responsive to a timer for periodically automatically outputting one of the pre-stored messages.
      <br/>
      The timer may be set by the user using the control panel 60 to thereby automatically output one of the pre-stored messages at regular or irregular intervals.
      <br/>
      The messages may be output randomly, in a predetermined sequence or in a sequence determined by the user.
    </p>
    <p num="27">While the invention has been described in connection with what is presently considered to be the most practical and preferred embodiment, it is to be understood that the invention is not to be limited to the disclosed embodiment, but on the contrary, is intended to cover various modifications and equivalent arrangements included within the spirit and scope of the appended claims.</p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A system for making a live animal appear to talk, the system comprising:</claim-text>
      <claim-text>a first speaker mounted on an article worn by the animal; a memory for storing pre-recorded phrases; a selection circuit configured to receive user-supplied inputs;</claim-text>
      <claim-text>and a control circuit responsive to the user-supplied inputs for selectively outputting the pre-recorded phrases from said memory to said first speaker thereby making the animal appear to talk.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The system according to claim 1, wherein the pre-recorded phrases stored in said memory are based on the characteristics of the animal.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The system according to claim 1, further comprising a second speaker.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The system according to claim 3, wherein said memory stores two or more phrases constituting a conversation and said control circuit is responsive to the user-supplied inputs for supplying the phrases constituting the conversation to said first and second speakers.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The system according to claim 1, wherein said first speaker is connected to said control circuit over a wireless communication link.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The system according to claim 1, further comprising: a sensor, wherein said control circuit is responsive to a parameter sensed by said sensor for automatically outputting a pre-recorded phrase from said memory to said first speaker.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. The system according to claim 6, wherein said parameter senses temperature.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The system according to claim 1, further comprising: a timer, wherein said control circuit is responsive to said timer for periodically automatically outputting a pre-recorded phrase from said memory to said first speaker.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. The system according to claim 1, wherein said selection circuit comprises a touch-sensitive display screen.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. The system according to claim 1, wherein said memory comprises a portable memory module.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. The system according to claim 1, wherein said memory is adapted to have its contents updated by connection to a computer.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. A system for making a pet appear to talk, the system comprising: a leash member for restraining the pet; a collar attached to one of said leash; a speaker mounted on said collar; a control panel including a memory for storing a plurality of pre-recorded phrases, a selection circuit for receiving user-supplied inputs and a control circuit responsive to the user-supplied inputs for selectively outputting the pre-recorded phrases from said memory to said speaker thereby making the pet appear to talk.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. The system according to claim 12, wherein a handle is disposed at the other of said leash and said control panel is secured to said handle.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. The system according to claim 12, wherein said control panel is connected to said speaker via a wireless link.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. The system according to claim 12, wherein said memory comprises a portable memory module.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. The system according to claim 12, wherein the pre-recorded phrases stored in said memory are based on the characteristics of the pet.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. The system according to claim 12, further comprising: a sensor, wherein said control circuit is responsive to a parameter sensed by said sensor for automatically outputting a pre-recorded phrase from said memory to said speaker.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. The system according to claim 12, further comprising: a timer, wherein said control circuit is responsive to said timer for periodically automatically outputting a pre-recorded phrase from said memory to said first speaker.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. A method of making an animal appear to talk, comprising: storing in a memory a plurality of pre-recorded phrases, the pre-recorded phrases being based on characteristics of the animal; attaching a speaker to the animal; using a selection circuit configured to receive user supplied inputs to select one of the pre-recorded phrases from said memory for output to the speaker, whereby the animal appears to talk.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. The method according to claim 19, further comprising: storing in said memory two or more pre-recorded phrases constituting a conversation; attaching another speaker to another animal;</claim-text>
      <claim-text>and selecting the phrases constituting the conversation from said memory for output to the speakers, whereby the animals appear to converse with each other.</claim-text>
    </claim>
  </claims>
</questel-patent-document>