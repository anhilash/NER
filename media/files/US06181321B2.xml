<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06181321B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06181321</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6181321</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="25293998" extended-family-id="28434677">
      <document-id>
        <country>US</country>
        <doc-number>08844933</doc-number>
        <kind>A</kind>
        <date>19970423</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1997US-08844933</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>29090029</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>84493397</doc-number>
        <kind>A</kind>
        <date>19970423</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1997US-08844933</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G06T   5/00        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>00</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>H04N   1/46        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>46</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>H04N   1/60        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>60</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>345617000</text>
        <class>345</class>
        <subclass>617000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>348557000</text>
        <class>348</class>
        <subclass>557000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>H04N-001/60E</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>001</main-group>
        <subgroup>60E</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>H04N-001/60L</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>001</main-group>
        <subgroup>60L</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-001/6027</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>6027</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-001/6077</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>6077</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>24</number-of-claims>
    <exemplary-claim>15</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>9</number-of-drawing-sheets>
      <number-of-figures>14</number-of-figures>
      <image-key data-format="questel">US6181321</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Combined color cast removal and contrast enhancement for digital color images</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>YAMAKAWA YOSHIFUMI</text>
          <document-id>
            <country>US</country>
            <doc-number>4682231</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4682231</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>CASINI PIERANGELO</text>
          <document-id>
            <country>US</country>
            <doc-number>5201027</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5201027</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>EDGAR ALBERT D</text>
          <document-id>
            <country>US</country>
            <doc-number>5265200</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5265200</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>STONE MAUREEN C, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5596690</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5596690</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>SCHNAITTER WILLIAM N, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5638090</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5638090</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>STONE MAUREEN C, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5652851</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5652851</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>NUMAKURA TAKASHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5841897</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5841897</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>WATKINS SPRAGUE H</text>
          <document-id>
            <country>US</country>
            <doc-number>5896189</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5896189</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="9">
          <text>YONEZAWA YASUHARU</text>
          <document-id>
            <country>US</country>
            <doc-number>4984071</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4984071</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="10">
          <text>COLLETTE ROBERT P, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5172224</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5172224</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>HIBI YOSHIHARU, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5245417</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5245417</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="12">
          <text>MURAKAMI SHIGEO</text>
          <document-id>
            <country>US</country>
            <doc-number>5335097</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5335097</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="13">
          <text>MORAG GUY, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5343311</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5343311</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="14">
          <text>ZORTEA ANTHONY</text>
          <document-id>
            <country>US</country>
            <doc-number>5376962</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5376962</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="15">
          <text>WINKELMAN KURT-HELFRIED</text>
          <document-id>
            <country>US</country>
            <doc-number>5420704</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5420704</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="16">
          <text>TANAKA YUJI</text>
          <document-id>
            <country>US</country>
            <doc-number>5528388</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5528388</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Canon Kabushiki Kaisha</orgname>
            <address>
              <address-1>Tokyo, JP</address-1>
              <city>Tokyo</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>CANON</orgname>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Zhao, Jun</name>
            <address>
              <address-1>San Jose, CA, US</address-1>
              <city>San Jose</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Hui, Jonathan</name>
            <address>
              <address-1>Fremont, CA, US</address-1>
              <city>Fremont</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="3">
          <addressbook lang="en">
            <name>Kohler, Timothy L.</name>
            <address>
              <address-1>Moutain View, CA, US</address-1>
              <city>Moutain View</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Fitzpatrick, Cella, Harper &amp; Scinto</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Shankar, Vijay</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      An original image is processed while permitting a user to control an amount of color cast removal and an amount of color contrast enhancement performed on the original image.
      <br/>
      A user interface, which includes a control element having a single degree of freedom, is provided.
      <br/>
      User adjustment of the control element is responded to by simultaneously varying the degree of color cast removal and the amount of color contrast enhancement performed on the original image.
      <br/>
      In a further embodiment, an original image is processed so as to automatically remove color cast from the original image.
      <br/>
      According to this embodiment contrast is reduced for certain very dark pixels and very bright pixels, and enhanced for the remainder.
      <br/>
      In a still further embodiment, an original image is processed so as to automatically enhance color contrast in the original image.
      <br/>
      According to this embodiment, a first mapping of intensity levels is performed if the image is not both highkey and lowkey, and a second mapping is performed if the image is both highkey and lowkey.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="2">The present invention relates to computerized color image processing of digital color images, and more particularly to systems and techniques for automatic contrast enhancement, automatic color cast removal with contrast enhancement, and combined color cast removal and contrast enhancement where a user can adjust a single control for maximum color cast removal, maximum contrast enhancement, or any intermediate position.</p>
    <p num="3">2. Description of the Related Art</p>
    <p num="4">
      In many instances an original color image will include an undesirable color cast or tint.
      <br/>
      For example, as photographs age they often acquire a yellow cast.
      <br/>
      In addition, color casts may arise from a variety of circumstances, including the type of lighting or the quality/color sensitivity of photographic film used when taking a photograph.
    </p>
    <p num="5">
      Conventional techniques have been employed in order to reduce or eliminate color casts in original color images.
      <br/>
      However, in order to achieve good results, it has generally been necessary to have significant user input.
      <br/>
      This can be inconvenient in many instances, and can also lead to less than optimal results.
    </p>
    <p num="6">
      For example, in one conventional technique the user is required to identify the white point in the image, and then the image colors are adjusted accordingly.
      <br/>
      However, with such a technique, different users might disagree about which point in the image is the white point.
      <br/>
      Accordingly, the image processing parameters will generally be based upon a subjective determination, which might not always be desirable.
      <br/>
      Moreover, a user's determination of the white point might be skewed based on the color makeup of the image.
      <br/>
      For example, a point might erroneously appear to be the white point only because surrounding colors interfere with the user's perception of the point's true color.
      <br/>
      Finally, selecting the white point in each image can be very tedious and burdensome, particularly when many images are to be processed, and generally will be impractical if one wishes to process frame images on a real time basis.
    </p>
    <p num="7">
      Another common defect of color images is poor contrast.
      <br/>
      This problem can obscure image information, as well as negatively affect the general appearance of the image.
      <br/>
      Although conventional techniques exist for enhancing contrast, such conventional techniques generally do not provide optimal results in many situations.
      <br/>
      For example, many conventional contrast enhancement techniques do not provide acceptable results when the original image has both very dark and very bright pixels.
    </p>
    <p num="8">
      Moreover, it is often desirable to allow a user to have some control over the amount of contrast enhancement and color cast removal performed on the original image.
      <br/>
      For instance, a fully automatic color cast removal technique probably will be incapable of determining when a user subjectively wants the image to have a color cast, such as when a user has taken a photograph through a colored filter or when a user intentionally wishes to mimic an old and yellowed photograph.
      <br/>
      Similarly, a user might, for aesthetic reasons, want to vary the amount of color contrast in an image.
      <br/>
      Conventionally, however, in order to permit a user to adjust both the amount of contrast enhancement and the degree of color cast removal, at least two controls have been provided (one for color cast removal and one for contrast enhancement).
      <br/>
      Accordingly, simultaneous adjustment of both color cast removal and contrast enhancement using conventional techniques has not heretofore been possible.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="9">The present invention addresses these problems by providing techniques for automatic color cast removal, automatic contrast enhancement, and combined color cast removal and contrast enhancement where a user can adjust a single control for maximum color cast removal, maximum contrast enhancement, or any intermediate position.</p>
    <p num="10">
      In one embodiment of the invention, an original image is digitally processed so as to automatically enhance color contrast in the original image.
      <br/>
      According to this embodiment, the original image is designated as highkey only if, for each color component in the original image, there exists a sufficient percentage of pixels having a pixel intensity level for that color component which is greater than or equal to a first threshold intensity value.
      <br/>
      The original image is designated as lowkey only if, for each color component in the original image, there exists a sufficient percentage of pixels having a pixel intensity level for that color component which is less than or equal to a second threshold intensity value.
      <br/>
      A first mapping is performed for each color component of the original image if the original image is not both highkey and lowkey, and a second mapping is performed, for each color component of the original image if the original image is both highkey and lowkey.
      <br/>
      The second mapping, which is different than the first mapping, enhances contrast for a range of the brightest pixels and a range of the darkest pixels and reduces contrast for pixels having an intensity between the ranges of darkest and brightest pixels for which contrast is enhanced.
    </p>
    <p num="11">
      By virtue of this arrangement, contrast enhancement is provided automatically and without user input.
      <br/>
      Moreover, the foregoing arrangement is designed to specifically address the situation where an original image contains both very dark and very bright pixels.
      <br/>
      Accordingly, the foregoing embodiment can provide good results in situations where conventional systems typically fail.
    </p>
    <p num="12">
      In a further embodiment, an original image is digitally processed so as to automatically remove color cast from the original image.
      <br/>
      According to this embodiment, pixel intensity levels for each color component i in an original image are obtained.
      <br/>
      The pixel intensity levels for each color component i are separately mapped to new pixel intensity levels for that color component by (a) determining a value di ' based on the darkest di percent of pixels, (b) mapping pixels darker than di ' to a small first range of dark intensity levels, (c) determining a value bi ' based on the brightest bi percent of pixels, (d) mapping pixels brighter than bi ' to a small second range of bright intensity levels, and (e) mapping the remainder of the pixels to fall between the first and second ranges, where di and bi are numbers pre-selected for each color component i. Finally, a new image is created using the new pixel intensity levels for each of the color components.
    </p>
    <p num="13">
      The foregoing arrangement thus provides for fully automatic color cast removal and can provide good results under a variety of circumstances without any user input.
      <br/>
      For example, the foregoing embodiment can provide good results without the necessity of requiring the user to designate a white point.
    </p>
    <p num="14">
      In a further embodiment, an original image is digitally processed while permitting a user to control an amount of color cast removal and an amount of color contrast enhancement performed on the original image.
      <br/>
      According to this embodiment, a user interface, which includes a control element having a single degree of freedom, is provided.
      <br/>
      The original image is digitally processed.
      <br/>
      User adjustment of the control element is responded to by simultaneously varying the degree of color cast removal and the amount of color contrast enhancement performed on the original image during the digital processing.
    </p>
    <p num="15">
      By virtue of this arrangement, a user can easily and without significant training or experience simultaneously adjust the amount of contrast enhancement and the degree of color cast removal performed on an original image.
      <br/>
      Moreover, these adjustments can be made with a single control, and generally without the necessity of significant user action, such as locating a white point.
    </p>
    <p num="16">
      This brief summary has been provided so that the nature of the invention may be understood quickly. A more complete understanding of the invention can be obtained by reference to the following detailed description of the preferred embodiments thereof in connection with the attached drawings.
      <br/>
      BRIEF DESCRIPTION OF THE DRAWINGS
      <br/>
      FIG. 1 is a perspective view of computing equipment which embodies the present invention.
      <br/>
      FIG. 2 is a block diagram of the computer workstation shown in FIG. 1.
      <br/>
      FIG. 3 is a flow diagram illustrating automatic contrast enhancement according to the present invention.
      <br/>
      FIG. 4A is a histogram illustrating pixel intensity distributions for a single color component of an original image.
      <br/>
      FIG. 4B is a histogram corresponding to the histogram in FIG. 4A after processing according to the process steps illustrated in FIG. 3.
      <br/>
      FIG. 5A is a histogram of pixel intensities for a single color component of an original image which is both highkey and lowkey.
      <br/>
      FIG. 5B is a histogram corresponding to the histogram in FIG. 5A after processing according to the process steps illustrated in FIG. 3.
      <br/>
      FIG. 6 is a flow diagram illustrating process steps for performing automatic color cast removal with contrast enhancement according to the invention.
      <br/>
      FIG. 7A is a histogram illustrating the pixel intensity distribution for a single color component in an original image.
      <br/>
      FIG. 7B is a histogram corresponding to the histogram in FIG. 7A after processing according to the process steps illustrated in FIG. 6.
      <br/>
      FIGS. 8A through 8C are histograms for the red, green and blue color components, respectively, of an original image, and show pixel intensity distributions both before and after processing according to the process steps shown in FIG. 6.
      <br/>
      FIG. 9 is a view of a monitor display according to an embodiment of the invention.
    </p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
    <p num="17">
      FIG. 1 shows the outward appearance of a representative embodiment of the present invention.
      <br/>
      Shown in FIG. 1 is computing equipment 10, such as a Macintosh or an IBM PC-compatible computer having a windowing environment, such as Microsoft.RTM. Windows. Provided with computing equipment 10 is a color display screen 11, such as a color monitor, keyboard 12 for entering text data and user commands, and pointing device 14, such as a mouse, for pointing to and manipulating objects displayed on display screen 12.
    </p>
    <p num="18">Computing equipment 10 includes a mass storage device, such as computer disk 15, for storing data files, which can include image data files, text data files, and other data files in compressed or uncompressed format, and for storing application programs such as image processing programs, including image processing programs for performing contrast enhancement and color cast removal according to the invention, and other information processing programs such as word and spreadsheet processing programs.</p>
    <p num="19">Such application programs contain stored program instructions by which computing equipment 10 manipulates and stores data files on disk 15 and presents data in those files to an operator via the display screen 11 or by printing to color printer 16.</p>
    <p num="20">
      Image data is input from color scanner 17 which scans documents or other images and provides bit map images for each of the red, green and blue color components of those documents to computing equipment 10.
      <br/>
      Document image data may also be input into computing equipment 10 from a variety of other sources, such as via local area network interface 18 or via facsimile/modem interface 19.
    </p>
    <p num="21">It should be understood that, although a programmable general-purpose computer arrangement is shown in FIG. 1, a dedicated or stand-alone computer or other types of data processing equipment can be used in the practice of the present invention.</p>
    <p num="22">
      FIG. 2 is a detailed block diagram showing the internal construction of computing equipment 10.
      <br/>
      As shown in FIG. 2, computing equipment 10 includes a central processing unit (CPU) 20 interfaced with computer bus 21.
      <br/>
      Also interfaced with computer bus 21 is scanner interface 22, printer interface 25, display interface 27, keyboard interface 28, mouse interface 29, main memory 30, ROM 24, and disk 15.
    </p>
    <p num="23">
      Main memory 30 interfaces with computer bus 21 so as to provide random access storage for use by CPU 20 when executing stored program instructions, such as programs for performing contrast enhancement and color cast removal, other image processing programs, and various other applications programs.
      <br/>
      More specifically, CPU 20 loads those programs from disk 15 into main memory 30 and executes those stored programs out of main memory 30.
    </p>
    <p num="24">
      The following embodiments are discussed with respect to a color image processing system which inputs and processes color images in the three color components red, green and blue.
      <br/>
      Moreover, in the preferred embodiments discussed below, the intensity level for each color component is represented by an eight bit binary number, which permits representation of intensity levels in the range of 0-255.
      <br/>
      However, it should be noted that the invention is not limited to any specific color space or to using eight bit words.
    </p>
    <p num="25">
      It should also be rioted that the invention is described as if it were a stand-alone image processing technique.
      <br/>
      Again, this should not be considered to limit the invention, since it is also possible to embody the invention as part of a more comprehensive image processing application program.
    </p>
    <p num="26">Automatic Contrast Enhancement</p>
    <p num="27">
      A method for automatic contrast enhancement will now be described with reference to FIG. 3.
      <br/>
      FIG. 3 is a flow diagram showing process steps for performing automatic contrast enhancement according to a representative embodiment of the invention.
      <br/>
      The process steps are stored on computer readable medium, such as disk 15, for execution by computing equipment 10.
    </p>
    <p num="28">
      Briefly, according to FIG. 3, an original image is input and then analyzed to determine whether it is both highkey and lowkey.
      <br/>
      If the image is not both highkey and lowkey, then for each color component i, (1) an intensity level x0 is determined based on the intensity level corresponding to the darkest di percent of the pixels, (2) an intensity level x1 is determined based on the intensity level corresponding to the brightest bi percent of the pixels, (3) pixels having an intensity level less than or equal to x0 are mapped to 0, (4) pixels having an intensity greater than or equal to x1 are mapped to an intensity level of 255, and (5) pixels having an intensity level between x0 and x1 are linearly mapped to the range 0 to 255.
      <br/>
      On the other hand, if the image is both highkey and lowkey, then for each color component, (1) the histogram of pixel intensities is segmented into five different intensity level ranges with the four dividing points being determined as the levels corresponding to: the darkest 3 percent of the pixels, the brightest 3 percent of the pixels, and the beginning and end points of a portion of the histogram where the histogram is likely to be relatively low and flat, and (2) the intensity levels for all pixels are mapped so that the darkest 3 percent are mapped to 0, the brightest 3 percent are mapped to 255, contrast in the low flat portion is reduced, and contrast in the remaining portions is enhanced.
      <br/>
      Finally, after all color components have been processed, a new image is formed using the new color components.
    </p>
    <p num="29">
      More specifically, in step S301 pixel intensity levels for each of the red, green and blue color components of an original image are input.
      <br/>
      This step might be performed by scanning a document containing the original image using color scanner 17 or by retrieving a file containing red, green and blue bit maps for the original image from disk 15, or by downloading from a computerized network or the internet.
      <br/>
      In any event each color pixel intensity is represented by 8 bits, providing a range of intensity values from 0 to 255 (0 being the darkest and 255 being the brightest).
    </p>
    <p num="30">
      In step S302, it is determined whether the image is highkey (i.e., whether it has a sufficient number of bright pixels) and whether it is lowkey (i.e., whether it has a sufficient number of dark pixels).
      <br/>
      In the preferred embodiment, the image is determined to be lowkey only if for each of the three color components (red, green and blue) the darkest 10 percent of the pixels have an intensity level from 0 to 35.
      <br/>
      Similarly, in the preferred embodiment, the image is determined to be highkey only if for each of the three color components the brightest 10 percent of the pixels have intensity levels from 230 to 255.
      <br/>
      The foregoing percentages and pixel ranges are not intended to be limiting.
      <br/>
      Moreover, it should be noted that a different percentage and/or different range can be used for each of the different color components.
      <br/>
      Similarly, these values can also be varied depending on other parameters.
    </p>
    <p num="31">
      Flow then proceeds to steps S303 through S330, in which pixel reference values are calculated in accordance with whether the image is highkey, lowkey or both (four reference values are calculated if both highkey and lowkey, whereas only two reference values are calculated if not), and the image is processed in accordance with the calculated reference values.
      <br/>
      Thus, in step S303, the first color component (i=1) is selected.
    </p>
    <p num="32">
      In step S304, if the image is both highkey and lowkey then processing proceeds to step S305.
      <br/>
      Otherwise, processing proceeds to step S320.
    </p>
    <p num="33">
      In steps S305 through S310, two pixel reference values, x0 and x1, are calculated for each color component, and the color components are mapped in accordance with the pixel reference values.
      <br/>
      Thus, in step S305, an intensity level x0 is determined.
      <br/>
      First, as an intermediate step, an intensity level x0 ' is determined as the lowest intensity level which is greater than or equal to the darkest di percent of the pixels.
      <br/>
      Preferably, di =0.5% for all color components.
      <br/>
      If x0 ' is less than or equal to Xd-safety (preferably, xd-safely =100), then x0 is set equal to x0 ' and processing proceeds to step S306.
      <br/>
      If, on the other hand, x0 ' is greater than xd-safety, then an intensity level x0 " is determined as the lowest intensity level which is greater than or equal to the darkest di ' percent of pixels.
      <br/>
      Preferably, di '=0.25% for all color components.
      <br/>
      If x0 " is also greater than xd-safety, then x0 is set equal to xd-safety and processing proceeds to step S306. otherwise, x0 is set equal to x0 ".
    </p>
    <p num="34">
      Similarly, in step S306 an intensity level x1 is determined.
      <br/>
      First, as an intermediate step, an intensity level x1 ' is determined as the highest intensity level which is less than or equal to the brightest bi percent of the pixels.
      <br/>
      Preferably, bi =0.5% for all color components.
      <br/>
      If x1 ' is greater than or equal to xb-safety (preferably, xb-safety =155), then x1 is set equal to x1 ' and processing proceeds to step S307.
      <br/>
      However, if x1 ' is less than xb-safety, an intensity level x1 " is determined as the highest intensity level which is less than or equal to the brightest bi ' percent of pixels.
      <br/>
      Preferably, bi '=0.25% for all color components.
      <br/>
      If x1 " is also less than xb-safety, then x1 is set equal to xb-safety and processing proceeds to step S307.
      <br/>
      Otherwise, x1 is set equal to x1 ".
    </p>
    <p num="35">In step S307 the pixel intensity levels for the current color component are mapped according to the following:  (Equation image '1' not included in text)</p>
    <p num="36">where x is an original pixel intensity and y is the corresponding new pixel intensity.</p>
    <p num="37">
      In step S309, if all color components have been processed then processing proceeds to step S330.
      <br/>
      Otherwise, the next color component is selected in step S312 and then processed beginning at step S304.
    </p>
    <p num="38">
      In step S330, a new image is formed using the new pixel intensities for each of the red, green and blue color components.
      <br/>
      For example, the new image might be displayed using color monitor 11 or printed using color printer 16.
    </p>
    <p num="39">
      For images which are both highkey and lowkey, steps S320 through S326 calculate four pixel reference values, x0 through X3, for each color component and map the color components in accordance with the pixel reference values.
      <br/>
      Thus, in step S320, x0 is determined as the lowest intensity level which is greater than or equal to the intensity levels of the darkest 3 percent of the pixels for the current color component.
    </p>
    <p num="40">In step S321, X3 is determined as the highest intensity level which is lower than or equal to the intensity levels of the brightest 3 percent of the pixels.</p>
    <p num="41">
      In step S322, x1 and x2 are determined as the end points of the portion of the intensity distribution histogram for the current color component which is likely to be relatively low and flat.
      <br/>
      In the preferred embodiment, x1 and x2 are determined as follows.
      <br/>
      First, segmentation points t1, t2, . . . t9 are located such that in each of the 10 intervals between 0 and t1, t1 and t2, . . . , and t9 and 255, the number of pixels is approximately 10 percent of the total number of pixels in the image.
      <br/>
      Next, starting from the left side, find the first interval which is more than 50 intensity levels long.
      <br/>
      If this interval is from tj to tj+1, then x1 =tj +10.
      <br/>
      Similarly, starting from the right side, locate the first interval which is greater than 50 intensity levels long.
      <br/>
      If this interval is from tj to tj+1, then x2 =tj+1 -10.
    </p>
    <p num="42">In step S324, the intensity levels are mapped according to the following:  (Equation image '2' not included in text)</p>
    <p num="43">where x is the pixel intensity of an original pixel and y is the corresponding new pixel intensity, y1 =x1 +(x2 -x1)/3, and y2 =x2.</p>
    <p num="44">In step S325, if all color components have been processed, then processing proceeds to step S330 where the new image is formed.</p>
    <p num="45">Otherwise, the next color component is selected in step S326 and processed beginning at step S320.</p>
    <p num="46">
      An example of the foregoing processing according to the preferred embodiment can be seen with reference to FIGS. 4A and 4B. FIG. 4A illustrates the envelope of an intensity distribution histogram for a single color component of an original image.
      <br/>
      It is assumed that the original image is not both highkey and lowkey.
      <br/>
      FIG. 4B illustrates a histogram for the same pixels shown in FIG. 4A, but after performing the contrast enhancement processing steps described above and shown in FIG. 3.
    </p>
    <p num="47">
      In FIG. 4A, the intensity level corresponding to the darkest 0.5 percent of the pixels (x0 '), which is shown as point 40, is greater than 100.
      <br/>
      Similarly, the intensity level corresponding to the darkest 0.25 percent of the pixels (x0 "), shown as point 41, is also greater than 100.
      <br/>
      Accordingly, x0 is set equal to 100.
      <br/>
      The intensity level corresponding to the brightest 0.5 percent of the pixels (x1 '), shown as point 44, is greater than 155.
      <br/>
      Accordingly, x1 is set equal to x1 '.
    </p>
    <p num="48">
      Thus, in FIG. 4B all pixels shown in FIG. 4A having an original intensity level lower than 100 (region 46) are mapped to 0 (shown in FIG. 4B as impulse 46' at intensity level 0).
      <br/>
      Similarly, all pixels in FIG. 4A having an intensity level greater than x1 (region 47) are mapped to level 255 (shown in FIG. 4B as impulse 47' at intensity level 255).
      <br/>
      Finally, pixels between 100 and x1 are linearly mapped to the range 0 to 255.
      <br/>
      Thus, point x0 in FIG. A, which originally was found at intensity level 100, is mapped to intensity level 0 in FIG. 4B. Likewise, point x1 in FIG. 4A, which was originally found at an intensity level corresponding to the brightest 0.5% of the pixels, is mapped to intensity level 255 in FIG. 4B.
    </p>
    <p num="49">
      FIGS. 5A and 5B depict a situation where the original image is both highkey and lowkey.
      <br/>
      Specifically, FIG. 5A shows a histogram for a single color component of the original image, and FIG. 5B shows a histogram for the same color component after applying the contrast enhancement process steps described above.
    </p>
    <p num="50">
      In FIG. 5A, x0 is the intensity level corresponding to the darkest 3 percent of the pixels, x3 is the intensity level corresponding to the brightest 3 percent of the pixels, and x1 and x2 are the intensity levels corresponding to the beginning and end of the low flat portion of the histogram.
      <br/>
      Also shown on FIG. 5A, y1 is located one-third of the distance between x1 and x2.
    </p>
    <p num="51">
      Comparing FIGS. 5A and 5B, pixels indicated in FIG. 5A as having an intensity level between 0 and x0 are mapped to 0 (shown in FIG. 5B by an impulse at 0).
      <br/>
      Similarly, pixels having an intensity level greater than x3 in FIG. 5A are mapped to level 255 (also shown in FIG. 5B by an impulse).
      <br/>
      Each of the remaining intervals A, B and C in FIG. 5A are linearly mapped to corresponding intervals A, B and C in FIG. 5B. That is, the interval in FIG. 5A from x0 to x1 is linearly mapped to the interval in FIG. 5B from 0 to y1.
      <br/>
      The interval from x1 to x2 is linearly mapped to the interval y1 to y2.
      <br/>
      Finally, the interval from x2 to x3 is linearly mapped to the interval y2 to 255.
      <br/>
      Thus, point x0 is mapped to the 0 intensity level, point x1 is mapped to intensity level y1, intensity level x2 is mapped to intensity level y2 (no intensity change), and intensity x3 is mapped to intensity level 255.
    </p>
    <p num="52">
      Thus, summarizing the results of the processing by comparing FIG. 5A with FIG. 5B, contrast is eliminated for intensity levels below x0 and above x3, contrast is enhanced between x0 and x1 (interval A) and between x2 and x3 (interval C), and contrast is reduced between x1 and x2 (interval B).
      <br/>
      Therefore, other than very dark and very bright levels, to which the human eye is not very sensitive, contrast is automatically enhanced for those intensity levels where most of the image information is concentrated and reduced for intensity levels which contain relatively little image information.
    </p>
    <p num="53">Automatic Color Cast Removal With Contrast Enhancement</p>
    <p num="54">
      A method for automatic color cast removal with contrast enhancement will now be discussed with reference to FIG. 6.
      <br/>
      FIG. 6 is a flow diagram showing process steps for performing color cast removal according to a representative embodiment of the invention.
      <br/>
      The process steps are stored on a computer readable medium, such as disk 15, for execution by computing equipment 10.
    </p>
    <p num="55">
      Briefly, according to FIG. 6, pixel intensities are obtained for each color component of an original image.
      <br/>
      Then, for each color component: (1) an intensity level x0 is determined based on the intensity level corresponding to the darkest di percent of the pixels, (2) an intensity level x1 is determined based on the intensity level corresponding to the brightest bi percent of the pixels, (3) pixels having an intensity level less than or equal to x0 are mapped to 0, (4) pixels having an intensity greater than or equal to x1 are mapped to an intensity level of 255, and (5) pixels having an intensity level between x0 and x1 are linearly mapped to the range 0 to 255.
    </p>
    <p num="56">
      More specifically, in step S601 pixel intensities corresponding to red, green and blue color components of an original image are input.
      <br/>
      This might be accomplished by scanning a document containing the image using color scanner 17, or by retrieving red, green and blue bit maps for the image from disk 15, or by downloading from a computerized network or the internet.
    </p>
    <p num="57">In step S602, the first of the three color components is selected.</p>
    <p num="58">
      In step S604, an intensity level x0 is determined.
      <br/>
      First, as an intermediate step, an intensity level x0 ' is determined as the lowest intensity level which is greater than or equal to the intensity levels of the darkest di percent of the pixels.
      <br/>
      Preferably, di =5% for all color components.
      <br/>
      If x0 ' is less than or equal to xd-safety (preferably, xd-safety =128), then x0 is set equal to x0 ' and processing proceeds to step S605.
      <br/>
      Otherwise, x0 is set equal to xd-safety.
    </p>
    <p num="59">
      Similarly, in step S605 an intensity level x1 is determined.
      <br/>
      First, as an intermediate step, an intensity level x1 ' is determined as the highest intensity level which is less than or equal to the intensity levels of the brightest bi percent of the pixels.
      <br/>
      Preferably, bi =3% for all color components.
      <br/>
      If x1 ' is greater than or equal to xb-safety (preferably, xb-safety =128), then x1 is set equal to x1 ' and processing proceeds to step S606.
      <br/>
      Otherwise, x1 is set equal to xb-safety.
    </p>
    <p num="60">In step S606, the pixel intensity levels for the current color component are mapped according to the following:  (Equation image '3' not included in text)</p>
    <p num="61">where x is an original pixel intensity and y is the corresponding new pixel intensity.</p>
    <p num="62">
      In step S607, if all color components have been processed, then processing proceeds to step S609.
      <br/>
      Otherwise, the next color component is selected in step S608 and then processed beginning with step S604.
    </p>
    <p num="63">
      In step S609, a new image is formed using the new pixel intensities for each of the red, green and blue color components.
      <br/>
      For example, the new image might be displayed using color monitor 11 or printed using color printer 16.
    </p>
    <p num="64">
      An example of the foregoing processing will now be discussed with reference to FIGS. 7A and 7B. FIG. 7A illustrates the envelope of a pixel intensity distribution histogram for a single color component of an original image.
      <br/>
      FIG. 7B illustrates the envelope of a histogram of the pixels depicted in FIG. 7A after processing according to the color cast removal processing steps described above and shown in FIG. 6.
    </p>
    <p num="65">
      In FIG. 7A, x0 ', the intensity level corresponding to the darkest 5% of the pixels, is less than 128.
      <br/>
      Accordingly, x0 =x0 '. Similarly, x1 ', the intensity level corresponding to the brightest 3% of the pixels, is greater than 128, so x1 =x1 '.
    </p>
    <p num="66">Thus, in FIG. 7B all pixels in FIG. 7A having an original intensity level lower than x0 (region 50) are mapped to 0 in FIG. 7B. Pixels having an intensity level greater than x1 (region 51) are mapped to 255 in FIG. 7B, and pixels between x0 and x1 in FIG. 7A are linearly mapped to the range 0 to 255 in FIG. 7B. Thus, intensity level x0 is mapped to intensity level 0 and intensity level x1 is mapped to intensity level 255.</p>
    <p num="67">
      Comparing FIGS. 7B to 7A, it can be seen that the color component represented by the histograms is intensified after processing.
      <br/>
      That is, the center of the intensity distribution for the color component is shifted from a low intensity level to a mid-level value.
      <br/>
      As will be seen from the next example, color cast can be removed by strengthening the weak color components, as well as by weakening the strong color components.
      <br/>
      In addition, other than the very darkest and brightest pixels, contrast is enhanced in the image.
      <br/>
      That is, the band of intensities in the original image from x0 to x1 is mapped to the interval from 0 to 255.
      <br/>
      Because information is mapped to a wider range of intensity levels, contrast within that region is enhanced.
    </p>
    <p num="68">
      FIGS. 8A through 8C show an example of the results of color cast removal according to the invention.
      <br/>
      Solid line histograms 101 (FIG. 8A), 102 (FIG. 8B) and 103 (FIG. 8C) respectively represent the envelopes of histograms showing pixel intensity distributions for the red, green and blue color components of an original image.
      <br/>
      As can be seen from FIGS. 8A through 8C, the original image has a strong red component, a weak green component and a medium blue component, resulting in an overall reddish cast in the image.
      <br/>
      Actually, due to the weak green component, the cast is somewhere between red and magenta.
    </p>
    <p num="69">
      However, after color cast removal processing as described above, the reddish cast is reduced.
      <br/>
      Specifically, after applying the above processing, the interval between x0 and x1 for each of histograms 101, 102 and 103 is linearly mapped to the interval 0 to 255.
      <br/>
      The results are shown as dashed line histograms 111, 112 and 113, respectively.
    </p>
    <p num="70">
      As a result of the mappings, peak 105 of histogram 101, which was originally in the very high intensity levels, is shifted toward the middle intensity levels to new peak 115.
      <br/>
      Similarly, after processing, peak 106 of histogram 102 for the green color component, which was originally in the lower intensity levels, is also shifted toward the middle intensity levels to new peak 116.
      <br/>
      However, because peak 106 was not originally as far from the middle intensity levels as peak 105, peak 106 is not shifted as much as peak 105.
      <br/>
      Finally, blue peak 107, which was originally very close to middle intensity level, moves only slightly toward the center, resulting in new peak 117.
    </p>
    <p num="71">
      Because each of the color components is shifted toward the center of the intensity scale, a better color balance is achieved, thereby reducing the reddish color cast of the original image.
      <br/>
      In this regard, the color cast is reduced not only by suppressing the red color component, but also by enhancing the green color component.
      <br/>
      That is, because color cast is caused by an imbalance in the color components (since overall color depends upon the intensities of the color components relative to each other), color cast reduction can be achieved by enhancing weak color components, as well as by attenuating strong color components.
      <br/>
      In addition, because in each case the pixel intensities are mapped to a wider range than in the original image, a certain amount of contrast enhancement also is provided.
    </p>
    <p num="72">
      In the above two embodiments, preferred values are given for certain variables.
      <br/>
      However, it should be noted that the invention is not limited to those values, except as expressly defined by the claims.
      <br/>
      For instance, the values need not be the same for each color component, and need not even be fixed, but might be made variable based on other parameters.
    </p>
    <p num="73">
      Moreover, the above preferred values apply when the foregoing technique is implemented in a fully automatic mode.
      <br/>
      However, when implemented in the adjustable combined contrast enhancement and color cast removal embodiment described below, different values are specified for certain of the above variables.
    </p>
    <p num="74">Adjustable Combined Contrast Enhancement and Color Cast Removal</p>
    <p num="75">The following describes combined contrast enhancement and color cast removal where the user can adjust the amount of contrast enhancement and the degree of color cast removal by adjusting a single control.</p>
    <p num="76">
      In this embodiment, a user is provided with a control having a single degree of freedom.
      <br/>
      Preferably, the control is a sliding bar included within a graphical user interface.
      <br/>
      However, the control might consist of a knob, a physical sliding bar, a pair of buttons (one for adjusting up and one for adjusting down), or any of the like.
    </p>
    <p num="77">
      By varying the control the user can select automatic contrast enhancement, automatic color cast removal with contrast enhancement, or an intermediate position.
      <br/>
      Specifically, adjusting the control causes a variable L to vary in the range between 0 and 100.
      <br/>
      When L&lt;50, automatic contrast enhancement is performed as described above in connection with FIGS. 3 through 5B.
      <br/>
      When L &gt;= 50, automatic color cast removal with contrast enhancement is performed as described above in connection with FIGS. 6 through 8C.
    </p>
    <p num="78">In addition to controlling which process steps are performed, L is used to control the values of the variables used in those processing steps as follows:</p>
    <p num="79">
      di =(0.5%)*(1-L/100)+(5%)*(L/100)
      <br/>
      di '=di /2
      <br/>
      bi =(0.5%)*(1-L/100)+(3%)*(L/100)
      <br/>
      bi '=bi /2  (Equation image '4' not included in text)
    </p>
    <p num="80">It should be noted that while the automatic contrast enhancement steps described above use all of the above variables, the automatic color cast removal discussed above uses all of them except di ' and bi '.</p>
    <p num="81">
      FIG. 9 illustrates a representative monitor display for this embodiment.
      <br/>
      Displayed on monitor 11 is an image to be processed and a GUI including various controls for adjusting image processing parameters, including control 81 which can be adjusted using a printing device such as mouse 14, and when so adjusted varies the value of L. More specifically, when control 81 is moved, the new position is sensed using conventional techniques, and the value of L is changed.
      <br/>
      At one extreme L is set equal to 0, and at the other extreme L is set equal to 100.
      <br/>
      In between, L varies continuously as the position of control 81 changes.
      <br/>
      According to this embodiment, a user can select within the range between maximum color cast removal and maximum contrast enhancement to be performed on image 80 merely by dragging sliding bar 81 using mouse 14.
    </p>
    <p num="82">
      The invention has been described with respect to particular illustrative embodiments.
      <br/>
      However, it is to be understood that the invention is not limited to the above described embodiments and that various changes and modifications may be made by those of ordinary skill in the art without departing from the spirit and scope of the invention.
    </p>
    <p num="83">
      For example, the above embodiments use linear mapping.
      <br/>
      However, except as defined in the claims, the invention is not limited to linear mapping.
      <br/>
      Other mapping techniques, such as cube root mapping to mimic human visual perception, might instead be employed.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15.</claim-text>
      <claim-text>A method for digitally processing each of multiple different color components of a digital image so as to automatically enhance color contrast in the digital image, said method comprising: designating the digital image as highkey only if, for each color component in the digital image, there exists a sufficient percentage of pixels having a pixel intensity level for that color component which is greater than or equal to a first threshold intensity value; designating the digital image as lowkey only if, for each color component in the digital image, there exists a sufficient percentage of pixels having a pixel intensity level for that color component which is less than or equal to a second threshold intensity value; performing a first mapping for each color component of the digital image if the digital image is not both highkey and lowkey;</claim-text>
      <claim-text>and performing a second mapping for each color component of the digital image if the digital image is both highkey and lowkey, wherein the second mapping is different than the first mapping, and wherein the second mapping enhances contrast for a range of the brightest pixels and a range of the darkest pixels and reduces contrast for pixels having an intensity between the ranges of darkest and brightest pixels for which contrast is enhanced.</claim-text>
      <claim-text>1. A method for digitally processing a digital image under control of a user so as to simultaneously control an amount of color cast removal and an amount of color contrast enhancement performed on the digital image, said method comprising:</claim-text>
      <claim-text>providing a user interface which includes a control element having a single degree of freedom, the single degree of freedom for permitting coupled control over color cast removal and contrast enhancement; digitally processing the digital image;</claim-text>
      <claim-text>and responding to user adjustment of the control element by simultaneous and coupled variation of a degree of color cast removal and an amount of color contrast enhancement performed on the digital image in said digital processing step.</claim-text>
      <claim-text>2. A method according to claim 1, wherein the user interface comprises a graphical user interface.</claim-text>
      <claim-text>3. A method according to claim 2, wherein the control element comprises a sliding bar.</claim-text>
      <claim-text>4. A method according to claim 1, wherein at one extreme setting of the control element a maximum amount of contrast enhancement is performed, and at the other extreme setting a maximum degree of color cast removal is performed.</claim-text>
      <claim-text>5. A method according to claim 1, wherein color cast removal processing is performed when the control element is set below a predetermined setting level and contrast enhancement is performed when the control element is set above the predetermined setting level.</claim-text>
      <claim-text>6. A method according to claim 5, wherein the color cast removal processing includes contrast enhancement.</claim-text>
      <claim-text>7. A method according to claim 6, wherein the amount of contrast enhancement and the degree of color cast removal are simultaneously varied by varying a cutoff point at which contrast enhancement is performed.</claim-text>
      <claim-text>8. A method for digitally processing an original image so as to automatically remove color cast from the original image, said method comprising: obtaining pixel intensity levels for each color component i in an original image; separately mapping the pixel intensity levels for each color component i to new pixel intensity levels for that color component by (a) determining a value x0 based on the darkest di percent of pixels, (b) mapping pixels darker than x0 to a small first range of dark intensity levels, (c) determining a value x1 based on the brightest bi percent of pixels, (d) mapping pixels brighter than x1 to a small second range of bright intensity levels, and (e) mapping the remainder of the pixels to fall between the first and second ranges, where di and bi are numbers pre-selected for each color component i;</claim-text>
      <claim-text>and creating a new image using the new pixel intensity levels for each of the color components.</claim-text>
      <claim-text>9. A method according to claim 8, wherein each di is approximately equal to 5%.</claim-text>
      <claim-text>10. A method according to claim 8, wherein each bi is approximately equal to 3%.</claim-text>
      <claim-text>11. A method according to claim 8, wherein all the di s are approximately equal to 5% and all the bi s are approximately equal to 3%.</claim-text>
      <claim-text>12. A method according to claim 8, wherein all pixels brighter than x1 are mapped to the brightest intensity level available and all pixels darker than x0 are mapped to zero intensity level.</claim-text>
      <claim-text>13. A method according to claim 8, wherein the mapping of the remainder of the pixels is linear.</claim-text>
      <claim-text>14. A method according to claim 8, wherein each di and each bi is set in accordance with the setting of a user-adjustable control having a single degree of freedom.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. A method according to claim 15, wherein the original image is designated as highkey only if, for each color component in the original image, there are at least approximately 10% of the pixels having a pixel intensity level for that color component which is greater than or equal to approximately 90% of the maximum intensity level available.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. A method according to claim 15, wherein the original image is designated as lowkey only if, for each color component in the original image, there are at least approximately 10% of the pixels having a pixel intensity level for that color component which is less than or equal to approximately 14% of the maximum intensity level available.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. A method according to claim 15, wherein the first mapping enhances contrast for all pixels in the original image other than small ranges of the darkest and brightest pixels in the original image.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. A method according to claim 18, wherein the first mapping includes:</claim-text>
      <claim-text>(a) mapping the darkest di percent of pixels to a small first range of dark intensity levels, (b) mapping the brightest bi percent of pixels to a small second range of bright intensity levels, and (c) linearly mapping the remainder of the pixels to fall between the first and second ranges, where di and bi are numbers pre-selected for each color component i.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. A method according to claim 15, wherein the second mapping includes:</claim-text>
      <claim-text>(a) mapping the darkest di percent of pixels to a small first range of dark intensity levels, (b) mapping the brightest bi percent of pixels to a small second range of bright intensity levels.</claim-text>
    </claim>
    <claim num="21">
      <claim-text>21. A method according to claim 20, wherein each di and each bi is approximately equal to 0.5%.</claim-text>
    </claim>
    <claim num="22">
      <claim-text>22. A method according to claim 20, wherein the second mapping step further includes a step of locating an interval t on a pixel intensity distribution histogram for the current color component which is likely to be low and flat, reducing contrast for the interval t, and enhancing contrast for the portions between di and the beginning of the interval t and between bi and the end of the interval t.</claim-text>
    </claim>
    <claim num="23">
      <claim-text>23. A method according to claim 15, wherein each of the first and second mappings includes at least one linear mapping.</claim-text>
    </claim>
    <claim num="24">
      <claim-text>24. A method according to claim 20, wherein each di and each bi is set in accordance with the setting of a user-adjustable control having a single degree of freedom.</claim-text>
    </claim>
  </claims>
</questel-patent-document>