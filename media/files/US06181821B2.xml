<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06181821B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06181821</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6181821</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="25304435" extended-family-id="42108507">
      <document-id>
        <country>US</country>
        <doc-number>08848845</doc-number>
        <kind>A</kind>
        <date>19970430</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1997US-08848845</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>43164984</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>84884597</doc-number>
        <kind>A</kind>
        <date>19970430</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1997US-08848845</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>H04N   7/50        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>7</main-group>
        <subgroup>50</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>H04N  21/2365      20110101A I20140524RMEP</text>
        <ipc-version-indicator>
          <date>20110101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>21</main-group>
        <subgroup>2365</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20140524</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>H04N  21/262       20110101A I20140524RMEP</text>
        <ipc-version-indicator>
          <date>20110101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>21</main-group>
        <subgroup>262</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20140524</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>H04N  21/434       20110101A I20140524RMEP</text>
        <ipc-version-indicator>
          <date>20110101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>21</main-group>
        <subgroup>434</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20140524</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>382232000</text>
        <class>382</class>
        <subclass>232000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>375E07139</text>
        <class>375</class>
        <subclass>E07139</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>375E07155</text>
        <class>375</class>
        <subclass>E07155</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>375E07157</text>
        <class>375</class>
        <subclass>E07157</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>375E07167</text>
        <class>375</class>
        <subclass>E07167</subclass>
      </further-classification>
      <further-classification sequence="5">
        <text>375E07170</text>
        <class>375</class>
        <subclass>E07170</subclass>
      </further-classification>
      <further-classification sequence="6">
        <text>375E07176</text>
        <class>375</class>
        <subclass>E07176</subclass>
      </further-classification>
      <further-classification sequence="7">
        <text>375E07181</text>
        <class>375</class>
        <subclass>E07181</subclass>
      </further-classification>
      <further-classification sequence="8">
        <text>375E07183</text>
        <class>375</class>
        <subclass>E07183</subclass>
      </further-classification>
      <further-classification sequence="9">
        <text>375E07211</text>
        <class>375</class>
        <subclass>E07211</subclass>
      </further-classification>
      <further-classification sequence="10">
        <text>375E07218</text>
        <class>375</class>
        <subclass>E07218</subclass>
      </further-classification>
      <further-classification sequence="11">
        <text>375E07268</text>
        <class>375</class>
        <subclass>E07268</subclass>
      </further-classification>
    </classification-national>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-021/4347</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>21</main-group>
        <subgroup>4347</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130830</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/124</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>124</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/149</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>149</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/15</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>15</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/152</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>152</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="6">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/154</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>154</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="7">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/159</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>159</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="8">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/172</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>172</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="9">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/176</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>176</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="10">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/179</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>179</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="11">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/61</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>61</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="12">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-021/2365</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>21</main-group>
        <subgroup>2365</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130830</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="13">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-021/23655</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>21</main-group>
        <subgroup>23655</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130830</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="14">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-021/26275</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>21</main-group>
        <subgroup>26275</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130830</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>19</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>4</number-of-drawing-sheets>
      <number-of-figures>7</number-of-figures>
      <image-key data-format="questel">US6181821</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Predictive source encoding and multiplexing</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>NISHIHARA EITARO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4903317</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4903317</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>MORIMOTO EIICHI</text>
          <document-id>
            <country>US</country>
            <doc-number>5168374</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5168374</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>GOLIN STUART J</text>
          <document-id>
            <country>US</country>
            <doc-number>5265180</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5265180</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>GONZALES CESAR A, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5301242</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5301242</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>REININGER DANIEL J, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5426463</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5426463</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>YOKOYAMA YOSHIHIRO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5452102</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5452102</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>LANEY STUART T, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5467134</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5467134</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>PETERS ERIC C</text>
          <document-id>
            <country>US</country>
            <doc-number>5577190</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5577190</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="9">
          <text>KOHIYAMA TOMOHISA, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5666161</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5666161</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="10">
          <text>PAIK WOO H, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5216503</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5216503</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>KRAUSE EDWARD A, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5877812</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5877812</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="12">
          <text>YANG CHAO-KUNG, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>6005620</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US6005620</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Massachusetts Institute of Technology</orgname>
            <address>
              <address-1>Cambridge, MA, US</address-1>
              <city>Cambridge</city>
              <state>MA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>MIT - MASSACHUSETTS INSTITUTE OF TECHNOLOGY</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Lim, Jae S.</name>
            <address>
              <address-1>Winchester, MA, US</address-1>
              <city>Winchester</city>
              <state>MA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Fish &amp; Richardson, P.C.</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Couso, Jose L.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      Variable-rate encoding of a signal by processing the signal to determine the data rate demand over a time period for multiple values of an encoding parameter, such as a quantization parameter which affects the encoded data rate, and selecting a value for the encoding parameter with which to encode a segment of the time period.
      <br/>
      Determining the data rate demands of a set of image sequences and selecting a subset of the sequences based on the data rate demands, for example, to satisfy a storage volume constraint, and then encoding each of the selected subset of sequences for transmission or storage.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">This invention relates to encoding and multiplexing multiple signals for transmission or storage, and in particular relates to statistically multiplexing of multiple image sequences.</p>
    <p num="2">
      An image sequence encoded at a fixed image quality using a variable-rate encoder produces data at a time varying rate.
      <br/>
      The data rate, in general, depends on the characteristics of images being encoded, and with some encoding techniques, on the relationships of images being encoded to images nearby in the sequence.
      <br/>
      For example, images of a fast-moving scene will typically produce a higher data rate than those of a still scene.
      <br/>
      In addition different encoding techniques, producing different amounts of data, may be used for different images in the sequence.
      <br/>
      For example, some images may be encoded independently of other images, producing relative more data than other images encoded based on prediction from nearby images.
      <br/>
      The Motion Picture Expert Group MPEG-2 video encoding standard specifies such a variable-rate image encoding technique.
    </p>
    <p num="3">
      In addition to producing data at time varying rates at a fixed image quality, some image encoding techniques allow control over an encoding parameter such as a quantization parameter, thereby, indirect control over the image quality and the average output data rate.
      <br/>
      Reducing the quantization parameter in general reduces average data rate and image quality.
      <br/>
      For transmission over a capacity constrained channel, variable-rate output from an encoder is stored in a buffer before transmission.
      <br/>
      The quantization parameter can then be adjusted to control the average data rate.
      <br/>
      If the buffer contains a large backlog of data, the quantization parameter is reduced thereby resulting in the buffer being filled less quickly by the encoder.
      <br/>
      If there is a small backlog, the quantization parameter is increased.
      <br/>
      This type of feedback prevents exceeding the capacity of the buffer or emptying the buffer while using a relatively high image quality.
    </p>
    <p num="4">
      Multiplexing multiple encoded image sequences on a capacity constrained channel can be done by preallocating portions of the total capacity to individual image sequences.
      <br/>
      For example, in the case of a fixed-rate channel, each image sequence can be allocated a fixed fraction of the total capacity.
      <br/>
      However, if the fixed fraction is too small, an encoded image sequence may at times demand a higher data rate than its allocated fraction.
      <br/>
      If the fixed fraction is too large, there may be times when an encoded image sequence does not need its entire allocated capacity leaving unused channel capacity not available to other image sequences.
    </p>
    <p num="5">
      When multiple variable-rate encoded image sequences are multiplexed on a single channel, there may be times when one sequence needs a high data rate while another sequence may only need a relatively low data rate.
      <br/>
      Statistical multiplexing takes advantage of this phenomenon by not allocating fixed portions of the total channel capacity to particular image sequences.
      <br/>
      The overall sum of the data rates will be time varying.
      <br/>
      A control mechanism is generally needed to prevent exceeding the capacity of the channel.
    </p>
    <p num="6">
      FIG. 1 shows a statistical multiplexing arrangement in which image sequences 112, 114 are encoded by variable-rate image encoders 116, 118, fed to a bounded capacity buffer 122, and multiplexed in multiplexor 120, before passing through a fixed-data-rate communication path 124.
      <br/>
      An encoding controller 130 is responsive to the amount of data in buffer 122 and controls the data rates produced by encoders 116, 118 in a feedback arrangement in order to keep the amount of data in buffer 122 near a target value and not allowing the amount of data to exceed the capacity of the buffer or allowing the buffer to empty.
      <br/>
      The encoded data produced by encoders 116, 118 includes control information sufficient to decode the data even with a time-varying data-rate control.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="7">
      In a first aspect, the invention provides an improved technique for variable-rate encoding a signal by processing the signal to determine the data rate demand over a time period for multiple values of an encoding parameter, such as a quantization parameter which affects the encoded data rate, and selecting a value for the encoding parameter with which to encode a segment of the time period.
      <br/>
      An advantage of the invention over a buffer feedback arrangement is that there may be times when the buffer has a large backlog resulting in feedback control to reduce a quantization parameter, when in fact future image sequences would have naturally produced sufficiently low data rates to allow a larger quantization parameter and therefore, indirectly, a higher image quality to be maintained.
      <br/>
      Thus, the invention can avoid unnecessary reduction in image quality.
    </p>
    <p num="8">In general, in the first aspect, the invention features encoding a first signal, wherein the encoding produces a first stream of encoded data having a variable data rate generally dependent on values of an encoding parameter, by processing the first signal to determine the data rate demand over a time period for each of a plurality of values of the encoding parameter, selecting a first value of the encoding parameter from the plurality of values based on the determined data rate demands, and encoding the first signal over a segment of the time period using the first value.</p>
    <p num="9">Preferred implementations may include one or more of the following features:</p>
    <p num="10">The processing, selecting, and encoding steps may be repeated for a plurality of time segments, with different values of the encoding parameter being selected for at least some time segments.</p>
    <p num="11">A second signal may be encoded, producing a second stream of encoded data having a variable data rate generally dependent on values of an encoding parameter, and the first and second data streams may be combined to form a combined data stream for transmission or storage, by processing the second signal to determine the data rate demand over the time period for each of a plurality of values of the encoding parameter, selecting a second value of the encoding parameter from the plurality of values based on the determined data rate demands, and encoding the second signal over the segment of the time period using the second value.</p>
    <p num="12">The first and second data streams may be multiplexed to form the combined data stream.</p>
    <p num="13">A relative delay between the first and the second data streams may be provided to reduce peaks in data rate demand of the combined data stream.</p>
    <p num="14">The combined data stream may be stored in a buffer of limited data volume.</p>
    <p num="15">The first and second data values may be selected to maintain a desired volume of data in the buffer.</p>
    <p num="16">The volume of data currently stored in the buffer may also be used in selecting the values of the encoding parameter.</p>
    <p num="17">The first and second signals may be prerecorded image sequences.</p>
    <p num="18">The combined data stream may be transmitted over a communication channel of limited data rate capacity.</p>
    <p num="19">The step of processing a signal to determine the data rate demand may include presenting each image in the sequence to a variable-rate encoder and recording the amount of data produced for that image for each of a plurality of values of the encoding parameter.</p>
    <p num="20">The encoding may include predictive encoding and the time segments over which the same value of the encoding parameter is used may be chosen so that the amounts of data produced by images in one segment are independent of the choice of quantization parameter in another segment.</p>
    <p num="21">At least some of the data rate demands may be approximations of the actual data rate demands.</p>
    <p num="22">
      In a second aspect of the invention, the data rate demands of a set of image sequences is determined and a subset of the sequences is selected based on the data rate demands, for example, to satisfy a storage volume constraint.
      <br/>
      Each of the selected subset of sequences is then encoded for transmission or storage.
    </p>
    <p num="23">In general, the second aspect features encoding for transmission or storage a set of image sequences, by processing the image sequences to determine the data rate demand of each over a time period, selecting a subset of the image sequences based on the determined data rate demands; and encoding each of the selected image sequences to form an encoded data stream for each, and combining the encoded data streams to form a combined data stream.</p>
    <p num="24">Preferred implementations may include one or more of the following features:</p>
    <p num="25">The combined data stream may be transmitted over a data rate constrained communication channel or stored on a data volume constrained storage medium, and the step of selecting a subset of image sequences may include selecting image sequences that produce a data rate or data volume consistent with the constraints of the communication channel or storage medium.</p>
    <p num="26">Processing the image sequences to determine the data rate demand of each may be done for each of a plurality of values of an encoding parameter, and selections of values of the encoding parameters may be made for the selected image sequences, with the selections being made to make the data rate or data volume consistent with the constraints of the communication channel or storage medium.</p>
    <p num="27">
      Other features and advantages of the invention will become apparent from the following description of preferred embodiments, including the drawings, and from the claims.
      <br/>
      BRIEF DESCRIPTION OF THE DRAWINGS
      <br/>
      FIG. 1 shows a prior art buffer feedback arrangement used to control the data rates produced by multiple encoders for multiplexing over a communication channel;
      <br/>
      FIG. 2 shows a predictive arrangement for encoding two image sequences for multiplexing over a communication channel;
      <br/>
      FIG. 3a and FIG. 3b illustrate precomputed data rate demands for two image sequences;
      <br/>
      FIG. 3c and FIG. 3d illustrate the combination of precomputed data rates with and without a time delay; and
      <br/>
      FIG. 4 shows a combined predictive and feedback arrangement for encoding multiple image sequences including a sequence without a precomputed data rate demand.
    </p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
    <p num="28">
      FIG. 2 shows a first embodiment in which two image sequences 212, 232 are encoded, buffered and multiplexed for transmission over a communication channel 258.
      <br/>
      A buffer 257 which accepts the outputs of the encoders has a bounded capacity and can accept data at a variable rate.
      <br/>
      Multiplexor 252 accepts data from the buffer at a fixed data rate and passes it to fixed-rate channel 258.
      <br/>
      In order to not exceed the input capacity of the buffer, encoding controller 210 controls the data rates produced by variable-rate image encoders 228, 248 such that when their outputs are combined in multiplexor 252, the data rate on data path 254 does not result in the buffer overflowing or emptying.
    </p>
    <p num="29">
      Variable-rate image encoders 228, 248 each have two inputs.
      <br/>
      Image data is provided on data paths 224, 244.
      <br/>
      Control paths 226, 246 are used to select from a discrete set of "quantization parameter" values.
      <br/>
      The data rate output from encoders 228, 248 depend indirectly on a selected quantization parameter Q. In general, the lower the quantization parameter selected, the smaller the amount of data produced for each image, on average, and also the poorer the image quality.
      <br/>
      In this embodiment, the image encoding technique implemented in encoders 228, 248 includes a quantization step followed by a lossless variable-rate encoding step.
      <br/>
      The selected quantization parameter Q affects the resolution of the quantization step.
      <br/>
      The variable-rate encoding step is such that if a lower resolution is used for quantization, less data (i.e., a smaller number of bits) is produced on average by the lossless variable-rate encoding step.
      <br/>
      Therefore, the amount of data that is produced in encoding any particular image depends on both the selected quantization parameter Q and characteristics of the image.
    </p>
    <p num="30">
      Image sequences 212, 232 are presented to variable-rate image encoders 228, 248 at fixed image rates (i.e., at a fixed number of images per second).
      <br/>
      Delay elements 222, 242 control fixed time offsets for each sequence by accessing image sequences 212, 232 over data paths 218, 238 and then presenting the sequences over data paths 224, 244 at the fixed image rates.
      <br/>
      The fixed time offsets of delay elements 222, 242 are controlled over a delay control paths 220, 240 by encoding controller 210.
    </p>
    <p num="31">
      In order to control the amount of data in buffer 257, encoding controller 210 controls the overall encoding process of both image sequences using delay control paths 220, 240 and image quality control paths 226, 246.
      <br/>
      In order to determine appropriate controls, encoding controller 210 must be able to predict their effect on the data rates on data paths 230 and 250.
      <br/>
      This determination is based on a precomputed data rate demand 216 associated with image sequence 212 and a precomputed data rate demand 236 associated with image sequence 232.
    </p>
    <p num="32">
      FIG. 3a and 3b illustrate precomputed data rate demands 216, 236.
      <br/>
      Each data rate demand includes predictions of the amount of data that would be produced by an encoder for each image in the corresponding sequence for several values of quantization parameter, indicated as Q=Q1, Q=Q2, and Q=Q3.
      <br/>
      FIG. 3c shows the combined data rate demand if the two signals are multiplexed without any relative delay (for illustration assuming the buffer has zero capacity and that both encoders use the same value of quantization parameter).
      <br/>
      For a particular value of Q, the data rates shown in FIG. 3c are the algebraic sums of the data rates in FIG. 3a and FIG. 3b. FIG. 3d shows the data rate demand when the two signals multiplexed after delaying the second sequence by a fixed number of images.
      <br/>
      Note that the peak data rate for the highest quantization parameter (Q=Q1) is lower in FIG. 3d than in FIG. 3c. Introducing the delay allows use of a larger quantization parameter and therefore a higher image quality, while not exceeding the constraints of the communication channel by avoiding times when both image sequences have high data rate demands.
      <br/>
      In practice with a non-zero capacity buffer, the effect of a delay on the amount of buffered data is more complex.
    </p>
    <p num="33">
      Referring again to FIG. 2, encoding controller 210 chooses the largest possible quantization parameter without exceeding the capacity of buffer 257.
      <br/>
      If the controller predicts that uses of the largest quantization parameter would indeed exceed the capacity of the buffer on the next or some future image, the planned quantization parameter for one or more images in one or more of the image sequences is reduced so that the predicted data rate no longer exceeds the capacity of the buffer.
    </p>
    <p num="34">
      Data rate demand is typically precomputed for recorded image sequences such as movies, scheduled shows, and even some news broadcasts.
      <br/>
      The precomputation is equivalent to, for each value of the quantization parameter, presenting each image in the sequence to a variable-rate image encoder and recording the amount of data produced for that image with that value of the quantization parameter.
      <br/>
      The amount of data recorded is relatively small compared to the original image sequence.
    </p>
    <p num="35">
      Some image sequence encoding approaches, such as the MPEG-2 standard approach, use prediction from the encoded representation of one or more images to reduce the amount of data produced in encoding another image.
      <br/>
      In order that encoding controller 210 can accurately predict the amount of data that will be produced by encoding an image with a particular choice of quantization parameter, the amount of data produced by encoding that image cannot depend on a second variable, such as the selected quantization parameter for another image used for prediction.
      <br/>
      Although the amount of data could in principle be recorded for all combinations of quantization parameters for the image being encoded and for all the images used for prediction, this may result in excessive storage for the data rate demand.
      <br/>
      The solution chosen in this embodiment is to divide the image sequence into segments.
      <br/>
      A quantization parameter is chosen for an entire segment.
      <br/>
      The segments are chosen such that the amounts of data produced by images in one segment are independent of the choice of quantization parameter in another segment.
      <br/>
      In this embodiment, the same quantization parameter is selected by controller 210 for all images in a segment.
      <br/>
      The segments are formed to satisfy the constraint that any image whose encoding depends on the encoding of an image in a segment must also be in that same segment.
    </p>
    <p num="36">
      A second embodiment of the invention addresses the situation in which the data rate demand information is available for some but not all of the image sequences.
      <br/>
      FIG. 4 shows an arrangement in which three image sequences 412, 422, 432 are encoded, buffered in a finite capacity buffer 450, and multiplexed over a fixed-data-rate transmission path 460.
      <br/>
      As in the first embodiment, encoding controller 410 is responsive to data rate demands 414, 424 precomputed for image sequences 412, 424.
      <br/>
      A precomputed data rate demand is not available for image sequence 432, owing, for example, to the images being from a live video source such as a sporting event.
      <br/>
      In addition to being responsive to the precomputed data rate demands, controller 410 is also responsive to the amount of data in buffer 450 in a feedback arrangement.
      <br/>
      In this embodiment, data rate demands 414, 424 are used to estimate rather than predict exactly the amount of data in buffer 450.
      <br/>
      The feedback arrangement then compensates for the error in the estimated data rate and controls the amount of data in the buffer to not exceed the capacity of the buffer and to not empty the buffer.
    </p>
    <p num="37">
      In other embodiments the data rate demand may not be known exactly.
      <br/>
      For example, the future data rate demand available to the encoding controller may be an approximation of the true data rate demand.
      <br/>
      An encoding controller and a data buffer are used as in the second embodiment.
      <br/>
      A feedback connection between the buffer and the encoding controller is used to deal with the uncertainty in the prediction of the multiplexed data rate in a similar arrangement as shown in FIG. 4.
      <br/>
      In the second embodiment, the uncertainty in the multiplexed data rate resulted from one of the image sequences not having a precomputed data rate demand.
      <br/>
      In this embodiment, the uncertainty results from having approximations of the true data rate demand for all the image sequences.
    </p>
    <p num="38">
      In another embodiment, one or more image sequences are encoded and recorded on a bounded capacity storage device.
      <br/>
      For example, one or more prerecorded movies are stored on a storage disk such as a CD-ROM.
      <br/>
      In order to make use of as much of the available storage on the device as possible, the precomputed data rate demands for all of the image sequences are used to select sequences of quantization parameters for the image sequences.
      <br/>
      Each image sequence is then encoded and recorded in turn using its selected sequence of quantization parameters.
    </p>
    <p num="39">
      The encoding controllers in the preferred embodiments can implement a variety of optimization algorithms to choose the sequence of encoder controls.
      <br/>
      In addition, the encoding control strategy does not necessarily have to reduce the image quality for all sequences in a "fair" manner.
      <br/>
      Some sequences, such as a high fidelity movie, may have higher priority for data rate than other sequences.
    </p>
    <p num="40">
      In a related embodiment of the invention, in addition to determining the delays and quantization parameters for a set of image sequences, the particular set of sequences for encoding and multiplexing over a communication channel is selected from a larger set of possible sequences.
      <br/>
      The selection is based on the precomputed data rate demands for each of the set of possible image sequences.
    </p>
    <p num="41">
      Other embodiments are within the scope of the following claims.
      <br/>
      For example, other types of signals than image sequences can be encoded and multiplexed in similar arrangements.
      <br/>
      In addition, various techniques for controlling the output rate of variable-rate encoders, other than controlling a quantization resolution, can be used.
      <br/>
      Also, there may not be a "hard" capacity constraint in the communication channel or storage device.
      <br/>
      The data rate demand information can be used to optimize any of a number of criteria.
      <br/>
      In addition, the quantization parameter for a variable-rate image encoder does not necessarily have to be chosen to be uniform over an entire image, such as by choosing Q on a block-by-block basis.
      <br/>
      Also, different image quality values could be chosen for different types of images, for example images encoded with prediction could use a different image quality control than images not coded with prediction.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A method of encoding a first sequence of image frames to produce a first stream of encoded data representing the image frames,</claim-text>
      <claim-text>wherein the amount of encoded data generally depends on the value of an encoding parameter used in the encoding process, the method comprising:</claim-text>
      <claim-text>- computing the amount of encoded data that would be produced by encoding a plurality of the image frames for each of a plurality of values of the encoding parameter;</claim-text>
      <claim-text>and - selecting a value of the encoding parameter to be used for encoding of the plurality of image frames based on the amount of encoded data produced for the selected value.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The method of claim 1, wherein the steps of claim 1 are followed for a second sequence of image frames, wherein the second sequence of image frames is encoded to produce a second stream of encoded data representing the image frames, and wherein the first and second streams of encoded data are combined to form a combined stream of encoded data.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The method of claim 2, wherein the first stream of encoded data is multiplexed with the second stream of encoded data.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The method of claim 3, further comprising selecting a relative delay between the first and second streams of encoded data to reduce peaks in the data rate of the combined stream.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The method of claim 2, wherein the combined stream of encoded data is stored in a buffer of limited data volume.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The method of claim 5, wherein the values of the encoding parameter used for final encoding are selected to maintain a desired amount of data in the buffer.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. The method of claim 6 wherein the volume of data currently stored in the buffer is also used in selecting the values of the encoding parameter.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The method of claim 1 or 2, wherein the encoding parameter is a quantization parameter.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. The method of claim 1 or 2, wherein the first and second sequences of image frames are prerecorded sequences.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. The method of claim 2, wherein the combined first and second data streams are transmitted over a communication channel of limited data rate capacity.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. The method of claim 2, wherein the encoding comprises predictive encoding and the frames over which the same value of the encoding parameter is used are chosen so that the amounts of data produced by images from one sequence of frames is independent of the choice of encoding parameter for another sequence of frames.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. The method of claim 1, wherein the step of computing the amount of encoded data comprises preliminarily encoding the plurality of image frames for each of a plurality of values of the encoding parameter.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. The method of claim 1, wherein the step of computing the amount of encoded data comprises computing an approximation of the amount of encoded data.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. The method of claim 1, wherein each sequence of image frames comprises a plurality of frames.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. The method of claim 2, wherein at least a third sequence of image frames is encoded to produce a third stream of encoded data, and a selection is made of a plurality, but fewer than all, of the streams of encoded data to form the combined stream of encoded data, and wherein the combined stream is transmitted over a data rate constrained communication channel or stored on a data volume constrained storage medium, and wherein the selection of a plurality of streams of encoded data is made so that the combined stream has a data rate or data volume consistent with the constraints of the communication channel or the storage medium.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. The method of claim 1, wherein the step of computing the amount of encoded data for each value of an encoding parameter is performed in advance for each of a plurality of sequences of image frames making up a first motion picture segment, and the amounts of encoded data for each sequence of image frames are stored as a first set of data rate values.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. The method of claim 15, wherein the first motion picture segment is encoded by reading the first set of data rate values for a sequence of image frames, selecting a value of the encoding parameter based on the first set of data rate values, encoding the sequence of image frames using the selected value, and repeating the process for the next sequence of image frames.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. The method of claim 16, further comprising buffering the outputs of the encoding in a buffer, and transmitting the contents of the buffer over a capacity limited communication channel, and wherein the selection of the value of the encoding parameter includes selecting the value based on both the data rate values and the amount of data stored in the buffer.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. The method of claim 16, wherein the step of computing the amount of encoded data is performed in advance for each of a plurality of sequences of image frames making up a second motion picture segment to be encoded along with the first motion picture segment, and the amounts of encoded data for each sequence of image frames are stored as a second set of data rate values, and wherein the step of selecting a value of the encoding parameter is based on both the first and second sets of data rate values.</claim-text>
    </claim>
  </claims>
</questel-patent-document>