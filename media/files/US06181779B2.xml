<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06181779B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06181779</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6181779</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="21626156" extended-family-id="42108454">
      <document-id>
        <country>US</country>
        <doc-number>08785781</doc-number>
        <kind>A</kind>
        <date>19970121</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1997US-08785781</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>43164911</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>TW</country>
        <doc-number>85217286</doc-number>
        <kind>U</kind>
        <date>19961111</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1996TW-U217286</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>H04M   1/65        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>M</subclass>
        <main-group>1</main-group>
        <subgroup>65</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>H04M   1/654       20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>M</subclass>
        <main-group>1</main-group>
        <subgroup>654</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>379067100</text>
        <class>379</class>
        <subclass>067100</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>379072000</text>
        <class>379</class>
        <subclass>072000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>379088040</text>
        <class>379</class>
        <subclass>088040</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>379088180</text>
        <class>379</class>
        <subclass>088180</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>379093010</text>
        <class>379</class>
        <subclass>093010</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>H04M-001/65</text>
        <section>H</section>
        <class>04</class>
        <subclass>M</subclass>
        <main-group>1</main-group>
        <subgroup>65</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>H04M-001/654</text>
        <section>H</section>
        <class>04</class>
        <subclass>M</subclass>
        <main-group>1</main-group>
        <subgroup>654</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04M-001/654</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>M</subclass>
        <main-group>1</main-group>
        <subgroup>654</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04M-001/65</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>M</subclass>
        <main-group>1</main-group>
        <subgroup>65</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>2</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>7</number-of-drawing-sheets>
      <number-of-figures>8</number-of-figures>
      <image-key data-format="questel">US6181779</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Rationalized automated answering machine</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>NAKAMURA KEIICHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4617425</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4617425</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>MATTHEWS GORDON H, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4757525</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4757525</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>BERNARD JOHN K, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4922520</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4922520</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>LADD DAVID J, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5117451</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5117451</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>DUGDALE WILLIAM P, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5128982</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5128982</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>BERGSMAN BARRY, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5146487</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5146487</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>KNUTH STEPHEN B, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5400393</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5400393</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>KLAUSNER JUDAH, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5524140</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5524140</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="9">
          <text>BERGSMAN BARRY, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5568539</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5568539</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="10">
          <text>FITCH TODD M</text>
          <document-id>
            <country>US</country>
            <doc-number>5633909</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5633909</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="11">
          <text>GOLDBERG DAVID, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5692213</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5692213</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="12">
          <text>WOLF RICHARD J</text>
          <document-id>
            <country>US</country>
            <doc-number>5771276</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5771276</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="13">
          <text>ASTARABADI SHAUN</text>
          <document-id>
            <country>US</country>
            <doc-number>5822405</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5822405</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Winbond Electronics Corporation</orgname>
            <address>
              <address-1>Hsinchu, TW</address-1>
              <city>Hsinchu</city>
              <country>TW</country>
            </address>
          </addressbook>
          <nationality>
            <country>TW</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>WINBOND ELECTRONICS</orgname>
          </addressbook>
          <nationality>
            <country>TW</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Hwang, Bar-Chung</name>
            <address>
              <address-1>Taoyuan, TW</address-1>
              <city>Taoyuan</city>
              <country>TW</country>
            </address>
          </addressbook>
          <nationality>
            <country>TW</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Ladas &amp; Parry</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Zele, Krista</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>LAPSED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A rationalized automated answering machine which can distinguish sentence intervals in the Out Going Message (OGM) left by a host by using a microcomputer and record the space position between adjacent sentences of the Out Going Message.
      <br/>
      When the rationalized automated answering machine receives a call and plays the Out Going Message left by the host, the rationalized automated answering machine also monitors the sound of a caller simultaneously.
      <br/>
      If the caller interrupts in the OGM playback at any point, the Out Going Message playback stops immediately and the rationalized automated answering machine records the sound of the caller.
      <br/>
      After talk from the caller finishes, the Out Going Message playback continues.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="2">The invention relates to an automated answering machine, in particular to a rationalized automated answering machine which can adjust the playback of an Out Going Message (OGM) left by a host according to the talk pattern of a caller.</p>
    <p num="3">2. Description of Related Art</p>
    <p num="4">
      In a conventional automated answering machine, a pre-recorded Out Going Message (OGM) is played before which the caller can be prompted to leave a message following a "beep".
      <br/>
      When the caller calls in and a host/user can not answer the phone, the caller's left message is recorded by an magnetic tape or a digital IC.
      <br/>
      FIG. 1 presents a schematic view showing the question-answer situation of a prior automated answering machine in which the left side of the schematic depicts a typical prerecorded voice prompt or Out Going Massage (OGM) from the automated answering machine, while the right side depicts talk from the caller.
      <br/>
      Typically, the caller may feel impatient and irritated when hearing the Out Going Message left by the host after the telephone is on line.
      <br/>
      The caller may also be not familiar with leaving messages after a beep sound.
      <br/>
      Moreover, since the caller can not interrupt the OGM at all before a beep sound in prior automated answering machines, many callers unfamiliar with such machines tend to hang up the phone after realizing that the voice prompt is just an Out Going Message from the automated answering machine.
      <br/>
      Other callers cannot be bothered to wait until the completion of the OGM.
      <br/>
      This prevents the automated answering machine from being utilized to accomplish its purpose in relaying messages.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="5">
      Therefore, the object of the invention is to provide a rationalized automated answering machine that distinguishes each sentence interval in the Out Going Message (OGM) by using a microcomputer and records space positions between adjacent sentences.
      <br/>
      When the rationalized automated answering machine receives a call and plays the Out Going Message, the sound of a caller may be monitored simultaneously.
      <br/>
      If the caller interrupts at any point during the playing of the OGM, the Out Going Message playing stops immediately and a message left by the caller is recorded.
      <br/>
      And yet, the Out Going Message is played continuously after talk from the caller finishes.
      <br/>
      In this way, the caller does not have to wait until the Out Going Message finishes playing before talking, thereby avoiding caller irritation and impatience.
    </p>
    <p num="6">
      Another object of the invention is to provide the function of filtering select so that the users can set the rationalized automated answering machine to only record messages left by the caller or record all messages after the telephone is on line.
      <br/>
      To the caller who is not familiar with leaving a message, the host can recognize the sound of the caller, such as "hello, hello . . . " to distinguish the caller and then call back later.
    </p>
    <p num="7">The rationalized automated answering machine of the invention includes a telephone line interface circuit which services as the interface between a ring line and a tip line and an internal circuit; a ringing detector which checks the number of rings; a hybrid circuit dividing connecting ends of the telephone line interface circuit into an input end and an output end; a sound input selector connected to the output end of the hybrid circuit and a microphone, for selecting a source of sound input; a sound output selector connected to the input end of the hybrid circuit and an amplifier for selecting output position of sound; a sound coder connected to the sound input selector to code input sound; a memory for saving sound data coded by the sound coder; a sound decoder for decoding sound data inside the memory and then delivering the sound data to the sound output selector; a signal input detector for checking sound situations from the caller; and a processor for distinguishing each sentence position of the Out Going Message left by a host and controlling the playback modes of the Out Going Message according to the checking result of the signal input detector;</p>
    <p num="8">
      The rationalized automated answering machine of the invention mentioned above can simply distinguish the discrete sentences of the Out Going Message left by the host by using a microcomputer and record space positions between adjacent sentences.
      <br/>
      When the rationalized automated answering machine receives a call and plays the Out Going Message left by the host, the rationalized automated answering machine also monitors the sound from the caller simultaneously.
      <br/>
      If the caller interrupts the playing of the Out Going Message, the playback of the Out Going Message stops immediately and the rationalized automated answering machine records the sound of the caller.
      <br/>
      After the caller finishes talking, the Out Going Message playing is restarted.
      <br/>
      Moreover, when each sentence of Out Going Message finishes playing, the rationalized automated answering machine will wait for a message from the caller and if no message from the caller is received over a period time, the Out Going Message will continue playing.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="9">
      The objectives, characteristics and advantages of the invention will be explained by using a preferred embodiment with pertinent drawings as follows:
      <br/>
      FIG. 1 is a schematic chart showing a question-and-answer situation between a prior automated answering machine with Out Going Message (OGM) and a caller;
      <br/>
      FIG. 2 is a block diagram showing the rationalized automated answering machine structure of the invention;
      <br/>
      FIG. 3a is a schematic view showing a signal input detector circuit of the embodiment of the invention;
      <br/>
      FIG. 3b is a schematic view showing a signal input detector circuit of the other embodiment of the invention;
      <br/>
      FIG. 4 (4a and 4b) is a flow chart of the rationalized automated answering machine of the invention;
      <br/>
      FIG. 5 is a schematic chart showing the question-and-answer situations of the embodiment of the invention; and
      <br/>
      FIG. 6 is a schematic chart showing the question-and-answer situations of the other embodiment of the invention.
    </p>
    <heading>DETAILED DESCRIPTION OF THE INVENTION</heading>
    <p num="10">
      Referring to FIG. 2, the rationalized automated answering machine of the present invention is shown.
      <br/>
      Telephone line interface circuit 10 serves as the interface between a ring line and a tip line and an internal circuit.
      <br/>
      Ringing detector 15 checks a ringing number.
      <br/>
      Hybrid circuit 20 divides connecting ends of the telephone line interface circuit into input end 22 and output end 21.
      <br/>
      Sound input selector 25 is connected to output end 21 of the hybrid circuit and microphone 26 respectively for electing a source of the sound input.
      <br/>
      Sound output selector 30 is connected to input end 22 of hybrid circuit and amplifier 31 for selecting a position of the sound output to speaker 33.
      <br/>
      Analog-to-digital converter 35 is connected to sound input selector 25 to digitize the input sound and then transfer the input sound by u-law or a-law.
      <br/>
      Compressor 38 compresses digitized data resulting in the memory capacity saving.
      <br/>
      Memory 40, for example, a Random Access Memory, saves sound data processed by compressor 38.
      <br/>
      Decompressor 42 decompresses the sound data saved in memory 40.
      <br/>
      Digital-to-analog converter 45 restores the decompressed sound data from the decompressor by u-law or a-law, converts the sound data to analog sound, and then delivers the sound data to sound output selector 30.
      <br/>
      Signal input detector 50 checks the sound situation of the caller.
      <br/>
      Processor 55, for example, a 8051 chip, distinguishes each sentence position of the Out Going Message left by the host and controls the playing modes of the Out Going Message according to the checking result of signal input detector 50.
      <br/>
      Analog-to-digital converter 35 and digital-to-analog converter 45 may be a TP 3054 chip manufactured by National Semiconductor Company in U.S.A. Compressor 38 and decompressor 42 may be a W62401 chip manufactured by Winbond Electronic Corporation in Taiwan.
    </p>
    <p num="11">
      Based upon the description of the rationalized automated answering machine structure of the invention above, signal input detector 50 checks whether the caller is talking or not.
      <br/>
      Sound input selector 25 is switched to the microphone only when the host/user records an Out Going Message.
      <br/>
      Sound output selector 30 is switched to a speaker only when the host/user plays a left message.
    </p>
    <p num="12">
      Referring to FIGS. 3a and 3b, FIG. 3a is a schematic view showing an embodiment of the invention in which signal input detector circuit 50 has a unipolar signal input, while FIG. 3b is a schematic view showing an embodiment of the invention in which signal input detector circuit 50 has a balanced differential signal input.
      <br/>
      The two circuits each include operational amplifier 51 and output amplifier 52, wherein amplifier 51 can work under a signal power source and R1 and R2 are used to adjust the checking point of signal input detector 50.
      <br/>
      When the signals are inputted, V0 becomes 0 volt.
      <br/>
      Otherwise, V0 still remains high.
    </p>
    <p num="13">Referring to FIGS. 4a and 4b, the flow chart of the rationalized automated answering machine of the present invention includes the following steps:</p>
    <p num="14">
      (1) Step 100: The rationalized automated answering machine is in a waiting condition.
      <br/>
      (2) Step 102: Check if ringing is taking place and then proceed to next step if yes, otherwise return to step 100.
      <br/>
      (3) Step 104: Count the number of rings.
      <br/>
      (4) Step 106: Check if the ringing number is larger than a predetermined number and then proceed to step 108 if yes, otherwise proceed to step 110.
      <br/>
      (5) Step 108: The rationalized automated answering machine answers the phone and proceeds to step 114.
      <br/>
      (6) Step 110: Check if telephone handset is picked up and then return to step 100 if yes, otherwise proceed to step 102.
      <br/>
      (7) Step 114: Reset the pointer of the Out Going Message.
      <br/>
      (8) Step 116: The pointer of Out Going Message increases as the Out Going Message is played sentence by sentence.
      <br/>
      (9) Step 118: Check if the Out Going Message playing is stopped and then proceed to step 120 if yes, otherwise proceed to step 132.
      <br/>
      (10) Step 132: Check if non-noise talk from the caller is detected and then proceed to step 134 if yes, otherwise return to step 116.
      <br/>
      (11) Step 134: The playback of the Out Going Message playing is interrupted.
      <br/>
      (12) Step 136: Count an interrupt number.
      <br/>
      (13) Step 138: Check if the interrupt number is larger than a predetermined value and then proceed to step 140 if yes, otherwise proceed to step 142.
      <br/>
      (14) Step 140: Set a noise flag and then return to step 116.
      <br/>
      (15) Step 142: Point the Out Going Message to the beginning of current sentence and then proceed to step 144.
      <br/>
      (16) Step 120: Check if the Out Going Message playing has finished and then proceed to step 122 if yes, otherwise proceed to step 126.
      <br/>
      (17) Step 122: Set a recorded signal flag to indicate the recording position.
      <br/>
      (18) Step 124: Check if the phone has been hung up and then return to step 100 if yes, otherwise proceed to step 124.
      <br/>
      (19) Step 126: Set the beginning point of next sentence of the Out Going Message and clear an accumulated interrupted number of the previous sentence.
      <br/>
      (20) Step 128: Check if there is any sound input from the caller and then proceed to step 144 if yes, otherwise proceed to step 130.
      <br/>
      (21) Step 130: Clear the noise flag and then proceed to step 144.
      <br/>
      (22) Step 144: Wait for a period of time and then proceed to step 146.
      <br/>
      (23) Step 146: Check if there is any sound input from the caller and then proceed to step 148 if yes, otherwise return to step 116.
      <br/>
      (24) Step 148: Check if the time of sound input from the caller is larger than the predetermined time and then proceed to step 150 if yes, otherwise returns to step 144.
      <br/>
      (25) Step 150: Set the noise flag.
    </p>
    <p num="15">In the flow chart mentioned above, the rationalized automated answering machine will return to a waiting condition if the phone is hung up.</p>
    <p num="16">Furthermore, the rationalized automated answering machine has the following characteristics according to the flow chart:</p>
    <p num="17">
      (1) In steps 126 and 142, the processor can control the reading of the memory and thereby the Out Going Message can be played from the beginning of each sentence. (2) In steps 118, 132, 134, 136, 138,142,144 and 146, when talk from the caller is checked by the signal input detector, the processor will stop playing the Out Going Message and record the message left by the caller.
      <br/>
      After talk from the caller finishes, the interrupted sentence of the Out Going Message is played continuously from the beginning. (3) In step 128, 130, 144, and 146, the processor controls playing speed of the Out Going Message, i.e., the Out Going Message playing stops during a period of time between adjacent sentences of the Out Going Message, but the playing will be continuous when a waiting time exceeds the period of time. (4) Using steps 136, 138, and 140, the processor can set a predetermined number and if the replaying number of the same interrupted sentence of the Out Going Message is larger than the predetermined number, the processor may ignore the influence of the signal input detector and keep playing the interrupted sentence. (5) In steps 148 and 150, the processor can set a predetermined time.
      <br/>
      If background noise is too loud, the input signal detector may keep checking sound input from the caller and if the time of the continuous sound input is larger than the predetermined time, the processor may continue to complete playing the sentence of the Out Going Message.
      <br/>
      After the sentence playing finishes, the processor will distinguish if the signal input is background noise.
    </p>
    <p num="18">
      The rationalized automated answering machine can record all sound input from the caller according to the checking result of the signal input detector or only record messages left by the caller according to predetermined processes.
      <br/>
      When the host/user sets the recording mode as "Recording All", the recording will start, once the caller begins to talk.
      <br/>
      Otherwise, the recording does not start until the Out Going Message playing finishes.
    </p>
    <p num="19">
      Referring to FIG. 5, there is presented a schematic view showing the question-answer situation of the automated answering machine in which the left side of the schematic depicts talk from the automated answering machine, while the right side depicts talk from the caller.
      <br/>
      When the Out Going Message is played, if the caller interrupts in at any point, the playback of the Out Going Message stops and after talk from the caller finishes, Out Going Message continues playback.
      <br/>
      This makes the caller feel respected and prevents an conflict between the Out Going Message and talk from the caller.
    </p>
    <p num="20">
      Referring to FIG. 6, there is similarly presented a schematic view showing the question-answer situation of the automated answering machine of the present invention.
      <br/>
      The host/user can pre-record the Out Going Message by using a simple question-and-answer routine, thereby allowing the caller to hold a conversation with the rationalized automated answering machine.
      <br/>
      The caller may come to realize that he is merely talking to an automated answering machine.
      <br/>
      Based on the description above, the rationalized automated answering machine can accomplish the objective of having the caller leave messages and raise public acceptance of such automated machines.
      <br/>
      Having described the invention in connection with a preferred embodiment thereof, modification will now suggest itself to those skilled in the art.
      <br/>
      As such, the invention is not to be limited to the disclosed embodiment except as is specifically required by the appended claims.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A rationalized automated answering machine comprising:</claim-text>
      <claim-text>a signal input detector for sensing sounds provided by a caller; a memory for recording a message left by the host and storing sound data;</claim-text>
      <claim-text>and a processor for controlling the playback of sentences included in the message prerecorded in memory and stopping the playback of the sentences a soon as said signal input detector determines that the caller has emitted a sound and then recording the sound emitted by the caller, said processor counting a number of times that a given interrupted sentence is replayed to said caller and if said number exceeds a predetermined number then said processor ignores said signal input detector and allows the given interrupted sentence to be played without further interruption by the caller.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. A rationalized automated answering machine comprising: a signal input detector for sensing sounds provided by a caller; a memory for recording a message left by the host and storing sound data;</claim-text>
      <claim-text>and a processor for controlling the playback of sentences included in the message prerecorded in memory and stopping the playback of the sentences a soon as said signal input detector determines that the caller has emitted a sound and then recording the sound emitted by the caller and if background noise is too loud, said input signal detector continues to sense for sounds from the caller and, if the noise continues for a period of time longer than a predetermined period of time, then said processor ignores said signal input detector and allows the message sentence to continue playing.</claim-text>
    </claim>
  </claims>
</questel-patent-document>