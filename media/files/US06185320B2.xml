<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06185320B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06185320</doc-number>
        <kind>B2</kind>
        <date>20010206</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6185320</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="23574882" extended-family-id="1171696">
      <document-id>
        <country>US</country>
        <doc-number>08982282</doc-number>
        <kind>A</kind>
        <date>19971201</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1997US-08982282</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>1211200</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>98228297</doc-number>
        <kind>A</kind>
        <date>19971201</date>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1997US-08982282</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>US</country>
        <doc-number>39830795</doc-number>
        <kind>A</kind>
        <date>19950303</date>
        <priority-linkage-type>B</priority-linkage-type>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1995US-08398307</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010206</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>A61B   6/00        20060101AFI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>6</main-group>
        <subgroup>00</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G06K   9/48        20060101A I20080531RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>9</main-group>
        <subgroup>48</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20080531</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>G06T   1/00        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>1</main-group>
        <subgroup>00</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>G06T   5/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="5">
        <text>G06T   5/30        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>30</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="6">
        <text>G06T   7/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>7</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="7">
        <text>G06T   7/60        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>7</main-group>
        <subgroup>60</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>382132000</text>
        <class>382</class>
        <subclass>132000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>382173000</text>
        <class>382</class>
        <subclass>173000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>382209000</text>
        <class>382</class>
        <subclass>209000</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>382260000</text>
        <class>382</class>
        <subclass>260000</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>382308000</text>
        <class>382</class>
        <subclass>308000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G06K-009/48B</text>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>009</main-group>
        <subgroup>48B</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>G06T-007/00B2</text>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>007</main-group>
        <subgroup>00B2</subgroup>
      </classification-ecla>
      <classification-ecla sequence="3">
        <text>G06T-007/00S1</text>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>007</main-group>
        <subgroup>00S1</subgroup>
      </classification-ecla>
      <classification-ecla sequence="4">
        <text>G06T-007/00S2</text>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>007</main-group>
        <subgroup>00S2</subgroup>
      </classification-ecla>
      <classification-ecla sequence="5">
        <text>G06T-007/00S5</text>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>007</main-group>
        <subgroup>00S5</subgroup>
      </classification-ecla>
      <classification-ecla sequence="6">
        <text>G06T-007/00S6</text>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>007</main-group>
        <subgroup>00S6</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06K-009/482</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>9</main-group>
        <subgroup>482</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170105</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-007/0012</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>7</main-group>
        <subgroup>0012</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170105</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20170101</date>
        </classification-scheme>
        <classification-symbol>G06T-007/11</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>7</main-group>
        <subgroup>11</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170102</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20170101</date>
        </classification-scheme>
        <classification-symbol>G06T-007/12</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>7</main-group>
        <subgroup>12</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170102</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="CPC">
          <date>20170101</date>
        </classification-scheme>
        <classification-symbol>G06T-007/149</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>7</main-group>
        <subgroup>149</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170102</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="6">
        <classification-scheme office="EP" scheme="CPC">
          <date>20170101</date>
        </classification-scheme>
        <classification-symbol>G06T-007/155</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>7</main-group>
        <subgroup>155</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170102</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="7">
        <classification-scheme office="EP" scheme="CPC">
          <date>20170101</date>
        </classification-scheme>
        <classification-symbol>G06T-007/187</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>7</main-group>
        <subgroup>187</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170102</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="8">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2207/20056</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2207</main-group>
        <subgroup>20056</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170105</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="9">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2207/20156</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2207</main-group>
        <subgroup>20156</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170105</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="10">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2207/30068</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2207</main-group>
        <subgroup>30068</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170105</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="11">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2207/30096</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2207</main-group>
        <subgroup>30096</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170105</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="12">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>S06T-207/20056</classification-symbol>
      </patent-classification>
      <patent-classification sequence="13">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>S06T-207/20141</classification-symbol>
      </patent-classification>
      <patent-classification sequence="14">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>S06T-207/20156</classification-symbol>
      </patent-classification>
      <patent-classification sequence="15">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>S06T-207/30068</classification-symbol>
      </patent-classification>
      <patent-classification sequence="16">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>S06T-207/30096</classification-symbol>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>55</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>26</number-of-drawing-sheets>
      <number-of-figures>38</number-of-figures>
      <image-key data-format="questel">US6185320</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Method and system for detection of lesions in medical images</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>DENISON KENNETH S, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4761819</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4761819</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>KRICH DAVID M</text>
          <document-id>
            <country>US</country>
            <doc-number>4797806</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4797806</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>MERICKEL MICHAEL B, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4945478</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4945478</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>KENET ROBERT O, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5016173</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5016173</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>GRENIER LEONARD E, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5079698</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5079698</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>SAXENA KRIPA C</text>
          <document-id>
            <country>US</country>
            <doc-number>5212637</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5212637</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>FORSLUND DONALD C, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5237626</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5237626</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>KANO AKIKO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5359513</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5359513</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="9">
          <text>KASDAN HARVEY L, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5432865</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5432865</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="10">
          <text>GREGGAIN LANCE, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5440653</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5440653</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="11">
          <text>BICK ULRICH, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5452367</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5452367</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="12">
          <text>MULLER SERGE, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5544219</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5544219</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="13">
          <text>LOCE ROBERT P, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5579445</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5579445</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="14">
          <text>JANG BEN K</text>
          <document-id>
            <country>US</country>
            <doc-number>5757953</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5757953</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="15">
          <text>SCHMIDT ROBERT C, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5781667</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5781667</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="16">
          <text>YAMADA MASAHIKO</text>
          <document-id>
            <country>US</country>
            <doc-number>5911014</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5911014</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="17">
          <text>KASDAN HARVEY L, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5121436</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5121436</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="18">
          <text>STEREOMETRIX CORP</text>
          <document-id>
            <country>WO</country>
            <doc-number>9107135</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>WO9107135</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="1">
          <text>Maragos, Petros, "Tutorial on Advances in Morphological Image Processing and Analysis", 1987 Society of Photo-Optical Instrumentation Engineers, vol. 26, No. 7, pp. 623-632.</text>
        </nplcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="2">
          <text>P. Nickolls, Pattern Recognition Society, vol. 14, Nos. 1-6, 1981, "Pre-Processing of Images in an Automated Chromosome Analysis System", pp. 219-229.</text>
        </nplcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="3">
          <text>Kobatake, Hidefumi, Faculty of Technology, Tokyo University, "Computer Diagnosis of Breast Cancer by Mammogram Processing", 1992, pp. 626-629.</text>
        </nplcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="4">
          <text>Press et al., Cambridge University Press, "Numerical Recipes, The Art of Computing", 1992, pp. 326-333.</text>
        </nplcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="5">
          <text>Sammon, John W., IEEE Transactions on Computers, vol. C-19, No. 7, Jul. 1970, "Interactive Pattern Analysis and Classification", pp. 594-615..</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="6">
          <text>Eric Persoon, IEEE Transactions on Systems, Man, and Cybernetics, vol. SMC-7, No. 3, pp. 170 to 179, "Shape Discrimination Using Fourier Descriptors", Mar. 3, 1997.</text>
        </nplcit>
      </citation>
    </references-cited>
    <related-documents>
      <continuation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>39830795</doc-number>
              <kind>A</kind>
              <date>19950303</date>
            </document-id>
            <parent-status>ABANDONED</parent-status>
          </parent-doc>
        </relation>
      </continuation>
    </related-documents>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Arch Development Corporation</orgname>
            <address>
              <address-1>Chicago, IL, US</address-1>
              <city>Chicago</city>
              <state>IL</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>ARCH DEVELOPMENT</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Bick, Ulrich</name>
            <address>
              <address-1>Muenster, DE</address-1>
              <city>Muenster</city>
              <country>DE</country>
            </address>
          </addressbook>
          <nationality>
            <country>DE</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Giger, Maryellen L.</name>
            <address>
              <address-1>Elmhurst, IL, US</address-1>
              <city>Elmhurst</city>
              <state>IL</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Oblon, Spivak, McClelland, Maier &amp; Neustadt, P.C.</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Patel, Jay</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A method and system for the automated detection of lesions in medical images.
      <br/>
      Medical images, such as mammograms are segmented and optionally processing with peripheral enhancement and/or modified median filtering.
      <br/>
      A modified morphological open operation and filtering with a modified mass filter are performed for the initial detection of circumscribed lesions.
      <br/>
      Then, the lesions are matched using a deformable shape template with Fourier descriptors.
      <br/>
      Characterization of the match is done using simulated annealing, and measuring the circularity and density characteristics of the suspected lesion.
      <br/>
      The procedure is performed iteratively at different spatial resolution in which at each resolution step a specific lesion size is detected.
      <br/>
      The detection of the lesion leads to a localization of a suspicious region and thus the likelihood of cancer.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <p num="1">
      The present invention is a continuous application of application Ser.
      <br/>
      No. 08/398,307, filed on Mar. 3, 1995 and now abandoned.
    </p>
    <p num="2">
      The present invention was made in part with U.S. Government support under grant numbers CA48985 (National Institute of Health), DAMD17-93-J-3021 (Army Research Office), and FRA-390 (American Cancer Society).
      <br/>
      The Government has certain rights in the invention.
    </p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="3">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="4">
      The invention relates generally to a method and system for an improved computerized, automatic detection and characterization of lesions in medical images, and more particularly to the detection of circumscribed masses in digital mammograms.
      <br/>
      Novel techniques in the localization (segmentation) and detection of masses in mammograms, include initially processing with peripheral equalization (correction), a modified median filter, a modified morphological open operation, filtering with a modified mass filter for the initial detection of circumscribed densities, matching using a deformable shape template with Fourier descriptors, optimization of the match using simulated annealing, and measuring the circularity and density characteristics of the suspected lesion to distinguish true positives from false positives and malignant lesions from benign lesions.
      <br/>
      The procedure is performed iteratively at different spatial resolution in which at each resolution step a specific lesion size is detected.
      <br/>
      The detection of the mass leads to a localization of a suspicious region and thus the likelihood of cancer.
    </p>
    <p num="5">2. Discussion of the Background</p>
    <p num="6">
      Although mammography is currently the best method for the detection of breast cancer, between 10-30% of women who have breast cancer and undergo mammography have negative mammograms.
      <br/>
      In approximately two-thirds of these false-negative mammograms, the radiologist failed to detect the cancer that was evident retrospectively.
      <br/>
      The missed detections may be due to the subtle nature of the radiographic findings (i.e., low conspicuity of the lesion), poor image quality, eye fatigue or oversight by the radiologists.
      <br/>
      In addition, it has been suggested that double reading (by two radiologists) may increase sensitivity.
      <br/>
      It is apparent that the efficiency and effectiveness of screening procedures could be increased by using a computer system, as a "second opinion or second reading", to aid the radiologist by indicating locations of suspicious abnormalities in mammograms.
      <br/>
      In addition, mammography is becoming a high volume x-ray procedure routinely interpreted by radiologists.
    </p>
    <p num="7">
      If a suspicious region is detected by a radiologist, he or she must then visually extract various radiographic characteristics.
      <br/>
      Using these features, the radiologist then decides if the abnormality is likely to be malignant or benign, and what course of action should be recommended (i.e., return to screening, return for follow-up or return for biopsy).
      <br/>
      Many patients are referred for surgical biopsy on the basis of a radiographically detected mass lesion or cluster of microcalcifications.
      <br/>
      Although general rules for the differentiation between benign and malignant breast lesions exist, considerable misclassification of lesions occurs with current radiographic techniques.
      <br/>
      On average, only 10-20% of masses referred for surgical breast biopsy are actually malignant.
      <br/>
      Thus, another aim of computer use is to extract and analyze the characteristics of benign and malignant lesions in an objective manner in order to aid the radiologist by reducing the numbers of false-positive diagnoses of malignancies, thereby decreasing patient morbidity as well as the number of surgical biopsies performed and their associated complications.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="8">Accordingly, an object of this invention is to provide a method and system for detecting, classifying, and displaying masses in medical images of the breast.</p>
    <p num="9">Another object of this invention is to provide an automated method and system for the detection and/or classification of masses based on a multi-resolution analysis of mammograms.</p>
    <p num="10">Another object of this invention is to provide an automated method and system for the detection and/or classification of masses based on a modified morphological open operation, filtering with a modified mass filter for the initial detection of circumscribed densities, matching using a deformable shape template with Fourier descriptors, optimization of the match using simulated annealing, and measuring the circularity and density characteristics of the suspected lesion.</p>
    <p num="11">These and other objects are achieved according to the invention by providing a new and improved automated method and system in which a segmentation of densities (masses) within a mammogram is performed followed by optimal characterization.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="12">
      A more complete appreciation of the invention and many of the attendant advantages thereof will be readily obtained as the same becomes better understood by the reference to the following detailed description when considered in connection with the accompanying drawings, wherein:
      <br/>
      FIGS. 1A-1C are schematic diagram illustrating embodiments of the automated method for the detection of lesions according to the invention;
      <br/>
      FIG. 2 is a graph illustrating the step of peripheral enhancement according to the invention;
      <br/>
      FIG. 3A is a schematic diagram of the modified median filtering according to the invention;
      <br/>
      FIG. 3B is a schematic diagram of the modified morphological open operation according to the invention;
      <br/>
      FIGS. 3C and 3D are graphs illustrating the criteria used in the modified morphological open operation of FIG. 3B;
      <br/>
      FIG. 4 is a diagram illustrating the circular kernel used in the modified mass filter;
      <br/>
      FIG. 5 is a diagram illustrating a gradient vector in the modified mass filtering;
      <br/>
      FIG. 6 is a diagram illustrating examples of the deformable templates corresponding to the possible shapes assigned to localized densities from the Fourier descriptors analysis;
      <br/>
      FIG. 7 is a diagram of calculating a gradient in a region of interest;
      <br/>
      FIG. 8 is a schematic diagram illustrating the analysis of a suspected lesion;
      <br/>
      FIGS. 9A and 9B are tables illustrating the relationship between pixel size of the image and the lesion size being detected, and the relationship between kernel size and the lesion size being detected, respectively;
      <br/>
      FIG. 10 is a schematic diagram of the changing of the kernel size in mass filtering;
      <br/>
      FIG. 11 is a diagram of two detected lesions;
      <br/>
      FIGS. 12A-12F illustrate examples of (12A) an original mammogram, (12B) after border segmentation, (12C) after the modified open operation, (12D) after the modified mass filter, (12E) after template matching and (12F) after feature extraction;
      <br/>
      FIGS. 13A-13F illustrate examples of (13A) a mammogram, after peripheral enhancement, (13B) after morphological filtering, (13C) a image of the difference of the images of FIGS. 13A and 13B, and (13D-13F) after morphological filtering with pixel sizes of 1, 2 and 4 mm;
      <br/>
      FIGS. 14A-14C illustrate (14A) an artificial lesion, (14B) its detection results, and (14C) the edge maps used in the detection;
      <br/>
      FIG. 15A shows the location of a region of interest (ROI) used for feature analysis;
      <br/>
      FIGS. 15B-15D show enlargement of the ROI of FIG. 15A, a truth margin, and detection results, respectively;
      <br/>
      FIG. 16 is a graph illustrating the performance of the method in the detection of malignant lesions in a screening mammographic database; and
      <br/>
      FIG. 17 is a schematic block diagram illustrating a system for implementing the automated method for the detection of lesions in medical images.
    </p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
    <p num="13">
      Referring now to the drawings, and more particularly to FIGS. 1A-1C thereof, schematic diagrams of the automated method for the detection and classification of lesions in breast images is shown.
      <br/>
      In FIG. 1A a first embodiment of the overall scheme includes an initial acquisition of a mammogram and digitization (step 100).
      <br/>
      Next, the breast border is segmented from the rest of the image area (step 101) and peripheral density enhancement is performed on the image (step 102).
      <br/>
      The image is processed (step 103) and then subjected to a modified morphological open operation using different filter sizes (steps 104-106).
      <br/>
      The image after the open operation is mass filtered (steps 107-109) and template matched (steps 110-112).
      <br/>
      Feature extraction is then performed (step 113) followed by integration (step 114) and classification (step 115) of the detected lesions.
    </p>
    <p num="14">
      The method of detecting circumscribed masses according to the invention uses an automatically segmented mammographic image indicating only the actual breast region (step 101) after an optional application of the peripheral density equalization (step 102).
      <br/>
      Segmentation of a mammogram is described in application Ser.
      <br/>
      No. 08/158,320 to Bick et al, the disclosure of which is herein incorporated by reference.
    </p>
    <p num="15">
      In the segmentation process, noise filtering is applied to the digital mammogram followed by application of the gray-value range operator.
      <br/>
      Using information from the local range operator a modified global histogram analysis is performed.
      <br/>
      Region growing is performed on the threshold image using connectivity (counting pixels), followed by a morphological erosion operation.
      <br/>
      The distance map of the image is determined and the boundary of the segmented object (breast) in the image is then tracked to yield its contour.
      <br/>
      The contour can then be output onto the digital image or passed to other computer algorithms.
    </p>
    <p num="16">
      Note that there is an inverse relationship between gray level and optical density.
      <br/>
      A low optical density (white region) on the mammogram (high anatomic density) corresponds to a high gray level (1023), whereas a high optical density (black region) on the mammogram corresponds to a low gray level (0).
    </p>
    <p num="17">
      The image after segmenting can be processed (step 103) or peripheral density enhancement can be performed.
      <br/>
      Peripheral density enhancement is described in application Ser.
      <br/>
      No. 08/158,320.
      <br/>
      The average gray values of the pixels as a function of distance from the breast border is determined.
      <br/>
      An enhancement curve is determined by fitting, such as polynomial fitting, a curve of the average gray values as a function of distance, and then reversing the fit.
      <br/>
      The enhancement curve is added to the curve of the average gray values as a function of distance to produce an enhanced gray value curve.
      <br/>
      This results in a peripherally enhanced image where the center and the portion near the border are simultaneously displayed without loss in contrast.
      <br/>
      FIG. 2 shows the curve of the average gray values as a function of distance, the reversed fitted curve and the peripherally enhanced curve.
    </p>
    <p num="18">
      The segmented image, with or without peripheral density enhancement, is then optionally processed (step 103).
      <br/>
      An initial modified median filter of size nxn may be used to eliminate isolated aberrant (very dark, low gray level) pixel values in the segmented image, since this would disturb the erosion step.
      <br/>
      The modified median filtering is shown in FIG. 3A. The median filter can be of 3 * 3 size, for example.
      <br/>
      The conventional median filter is described in, for example, "The Image Processing Handbook," 2nd Ed., by John Russ (CRC Press 1995).
    </p>
    <p num="19">
      At a beginning pixel location l(x,y) in the image (step 300), which can be either the segmented or the peripherally enhanced segmented image, the local minimum is determined (step 301) in the surrounding neighborhood (nxn pixels).
      <br/>
      If the gray level at pixel location l(x,y) is smaller than the local minimum by a certain number of gray levels (M) in step 302, then that gray level is corrected by the median filter (step 303).
      <br/>
      An example of M is 5 gray levels, but other values are possible.
      <br/>
      In the embodiment, the gray level of the pixel at l(x,y) is updated to the median pixel value of the neighborhood.
    </p>
    <p num="20">
      It is checked whether the pixel is the last pixel for processing ( step 304).
      <br/>
      If no, the next pixel is selected (step 305) and step 301 is repeated.
      <br/>
      If the answer in step 302 is no, the process moves to step 304.
      <br/>
      When the last pixel location is reached (step 304), the filtering is completed for all of the pixels in the image.
    </p>
    <p num="21">
      Two criteria are then used to control which pixels are used as seed pixels for the morphological operation, to preserve the gray value characteristics of larger lesions as far as possible.
      <br/>
      As shown in FIG. 3B, beginning at pixel location l(x,y) (step 310) a check is made to determine whether pixel l(x,y) is a seed pixel.
      <br/>
      The local maximum of the neighborhood is calculated (step 311).
    </p>
    <p num="22">
      To qualify as a seed pixel the following criteria must be fulfilled.
      <br/>
      First, there must be a negative Laplacian (gray value of the pixel in question minus the local minimum gray value must be less than the local maximum gray value minus the gray value of the pixel in question, (step 312).
      <br/>
      This, as demonstrated in FIGS. 3C and 3D, prevents erosion of the center of a small mass.
      <br/>
      In FIG. 3C the gray value I(x,y)=MAX, so no change is made to pixel value and the center is preserved.
      <br/>
      In FIG. 3D, I(x,y)-MIN&lt;MAX-I(x,y), so the gray value of pixel at location l(x,y) is changed.
    </p>
    <p num="23">
      Second, only pixels with a small distance from the local minimum are used as erosion centers (step 313).
      <br/>
      That is, the location of the seed pixel must be close to the location of the local MIN.
      <br/>
      This preserves the gray value slope in the periphery of larger lesions.
      <br/>
      An example of the distance is 3 pixels, and other values may be chosen.
    </p>
    <p num="24">
      If the answer is no at either of steps 312 and 313, the next pixel is selected (step 314) and the process is repeated.
      <br/>
      For those pixels which qualify as a seed pixel, the morphological open operation is performed (step 315).
    </p>
    <p num="25">
      The morphological open (erosion followed by dilation) shown in FIG. 3B is performed on the segmented image, with or without modified median filtering, as shown in FIG. 1A. The morphological open operation is also described in Russ, supra.
      <br/>
      Only the erosion processing can be performed, omitting the dilation procedure.
      <br/>
      The main effect of the erosion is smoothing of the image while keeping lesions that are of interest.
      <br/>
      The main effect of the dilation is to return masses to roughly their original size.
      <br/>
      The dilation is optional.
    </p>
    <p num="26">
      The structuring element in the embodiment for the morphological operation is a circle with a diameter of 7 pixels, e.g. for a pixel size of 0.5 mm. The structuring eliminates small circular and thin linear structures up to a diameter of 3.5 mm (for a 0.5 mm pixel size).
      <br/>
      If larger structuring elements are used, the subsequently used mass filter size is changed (as discussed below).
      <br/>
      At the same time irregular densities are rounded by this process.
    </p>
    <p num="27">
      This morphological operation is different from the conventional operation in the sense that a threshold E is used to control how much structure is eroded.
      <br/>
      If the difference, i.e. the gray level value of a pixel in the image prior to the morphological operation, I(x,y), minus the gray level value after the morphological operation, P(x,y), is larger than the threshold E (step 316), then the gray level value of the pixel is replaced by the output of the morphological operation (step 317).
      <br/>
      Examples of E can range from 0-10 in terms of gray levels.
      <br/>
      When dilation is performed, if the gray level after dilation exceeds the original gray level of the pixel, the original gray level value is used for the pixel.
      <br/>
      This is repeated for all pixels.
    </p>
    <p num="28">
      Referring to FIG. 1A, the morphological step is performed at different image resolutions.
      <br/>
      For example, resolution 1 (step 104) can use an image having a 0.5 mm pixel size (resolution 1), with the image being 512 * 512 pixels.
      <br/>
      The process is repeated in parallel for images having 1 mm, 1.5 mm, 2.5 mm, etc. pixel size with a corresponding decrease in image size as the pixel size increase (for 1.0 mm pixel size, the image is 256 * 256, etc.).
    </p>
    <p num="29">
      The process can also be conducted serially with a change in the resolution for each iteration.
      <br/>
      A second embodiment of the method according to the invention is shown in FIG. 1B. After steps 100-103, the morphological operation is performed at a beginning resolution (step 104), followed by mass filtering (step 107) and template matching (step 110).
      <br/>
      The image resolution is changed in step 116 and the results of the matching are stored in step 117.
      <br/>
      It then determined whether the maximum resolution has been exceeded (step 118).
      <br/>
      If no, the process is repeated at the new resolution.
      <br/>
      If yes, feature extraction, integration and classification (steps 113-115) are performed the same as in FIG. 1A.
    </p>
    <p num="30">
      FIG. 1C shows a third embodiment of the invention.
      <br/>
      The method shown in FIG. 1C differs from the method shown in FIG. 1B in that a thresholding operation 119 is performed using the output of the mass filtering step.
      <br/>
      The mass filtered image identifies areas suspected of containing a lesion that can be further processed by gray-level thresholding.
      <br/>
      After thresholding the image with the remaining suspected lesions is input to step 113 for feature analysis, followed by steps 114 and 115, as in the method of FIG. 1B.
    </p>
    <p num="31">
      FIG. 4 is a diagram illustrating the circular kernel used in the mass filter.
      <br/>
      For detection of circumscribed densities a mass filter with a circular base is used (this mass filter is a modified IRIS filter; for a description of the IRIS filter see Kobatake et al., CAR 1993: pp 624-629).
      <br/>
      The kernel is ring-shaped (pixels 402) around a center pixel 400.
      <br/>
      Note in this kernel that the center pixel locations 401 are absent since they would not contribute useful values to the overall filter value (as described below).
      <br/>
      A ring-shaped filter rather than just a solid circular filter is thus used.
    </p>
    <p num="32">
      The mass filter value is based on the local gradient (in the embodiment a 7 * 7 kernel is used) in x- (Dx) and y- (Dy) directions.
      <br/>
      Differences from the description of the IRIS filter in Kobatake et al. include use of a ring-shaped filter, second derivative instead of the gradient, and edge orientation bins.
      <br/>
      Gradient values smaller than a gradient threshold (e.g., 10) are not used in the calculation of the filter value.
    </p>
    <p num="33">
      The edge orientation at a specific image point is equivalent to the gradient vector and the edge strength is calculated as the second derivative in edge orientation.
      <br/>
      FIG. 5 shows a gradient 500 at point 501.
      <br/>
      This assures that regions with a constant gradual slope do not contribute to the mass filter value.
      <br/>
      The gradient is oriented at an angle  PHI  relative to a radial line from point 501 to point (x,y).
      <br/>
      The filter value is calculated separately for a specific number of edge orientation bins, such as 16 (B1, B2 . . . B16).
      <br/>
      Orientation bins are radial sectors of the circular area.
      <br/>
      For example, each of 16 bins would cover an angle of  PI /8.
      <br/>
      A bin 502, shown for a sector of  PI /8, is made of the pixels 402 between lines 503.
    </p>
    <p num="34">
      The calculation for a given pixel location (x,y) is given for the calculation of each orientation bin by:
      <br/>
      f(Bi)=(1/N) SIGMA P in K MAX(0, cos  PHI )*Edge Strength (at P)
    </p>
    <p num="35">where:</p>
    <p num="36">
      f(Bi) filter value for edge orientation bin
      <br/>
      K filter kernel
      <br/>
      P neighbor point in K
      <br/>
      N number of points in K
      <br/>
      PHI  angle between gradient vector and connection line center point/neighbor point
    </p>
    <p num="37">
      Edge strength is obtained from the second derivative of P calculated in edge orientation.
      <br/>
      The final filter value is calculated as sum of the individual orientation bins, where a specified number of bins j, for example 4, with the highest values are ignored.
      <br/>
      That is:
      <br/>
      filter value at pixel l(x,y)= SIGMA i-j f(Bi)
    </p>
    <p num="38">
      for Bi not equal to the j highest bins.
      <br/>
      This prevents an influence of straight edges (e.g. the pectoralis muscle border) on the filter value, since all points along this edge are within the same orientation bin without changing the filter value for ideal circular lesions.
    </p>
    <p num="39">
      Usually the filter value is highest in the center of a lesion.
      <br/>
      The highest filter values are found for round or slightly oval shaped lesions.
      <br/>
      The neighborhood used in calculation of the filter value is empirically determined to be around 10 pixels (outer radius); this could be increased to improve the detection of oval shaped masses.
      <br/>
      In addition, a gradient threshold can be employed so that pixels in the neighborhood that have a gradient smaller than the threshold (e.g., 10) do not contribute to the calculation of the filter value.
    </p>
    <p num="40">
      The image outputted by the mass filter is then subjected to template matching.
      <br/>
      Local maxima of the filter value define potential center points of mass lesions, which are used in steps 111-113, the matching of a deformable template on to the lesion border.
      <br/>
      The edges of the suspect lesion can be obtained from the derivative or second derivative of the image output from the mass filtering.
      <br/>
      The deformable shape template is defined using Fourier descriptors.
      <br/>
      An initial shape is selected and the Fourier descriptors are varied to dynamically fit the shape of the lesion.
      <br/>
      Fourier descriptors are described in, for example Arbter et al., Application of Affine-invariant Fourier Descriptors to Recognition of 3-D Objects, IEEE Trans.
      <br/>
      Pattern Analysis Machine Intelligence 12:640-647 (1990); Kuhl et al., Elliptic Fourier Features of a Closed Contour, Computer Graphics Image Processing 18:236-258 (1982); Wallace et al., An Efficient Three-dimensional Aircraft Recognition Algorithm Using Normalized Fourier Descriptors, ibid., 13:99-126 (1980); Granlund, Fourier Preprocessing for Hand Print Character Recognition, IEEE Trans.
      <br/>
      Computers 21:195-201 (1972); Zahn et al., Fourier Descriptors for Plane Closed Curves. ibid., 21:269-281 (1972); Crimmins, A Complete Set of Fourier Descriptors for Two-dimensional Shape, IEEE Trans.
      <br/>
      Sys. Man Cybernetics 12:848-855 (1982); Persoon et al., Shape Discrimination Using Fourier Descriptors, ibid., 7:170-179 (1977); and Richard et al., Identification of Three-dimensional Objects Using Fourier Descriptors of the Boundary Curve, ibid., 4:371-378 (1974).
    </p>
    <p num="41">
      In the template matching step the object contour is generated as an inverse Fourier transform of a limited number of complex Fourier terms.
      <br/>
      The following relationship exists between a closed planar curve g(l) and Fourier descriptors ck : g(l) planar curve and Fourier descriptors:  (Equation image '1' not included in text)
    </p>
    <p num="42">
      where:
      <br/>
      g(l) is a planar curve with a runlength l; the real of part of g=x coordinate, the imaginary part of g=y coordinate
      <br/>
      ck Fourier descriptors with -N/2 &lt;= k &lt;= N/2, N --&gt;  (infinity)
    </p>
    <p num="43">
      By variation of the terms -2, -1, 0, 1, and 2 arbitrary elliptical or kidney shape contours can be generated.
      <br/>
      The terms -2 to 2 were selected since the lesions are of simple shape.
      <br/>
      However, one can modify the terms using a priori knowledge of the lesions to be detected.
      <br/>
      The term 0 defines the position and the terms -1 and 1 define size and orientation of the main ellipse.
    </p>
    <p num="44">
      In the mass detection the following fourier descriptors are used:
      <br/>
      ck =0 for k &lt;=  &lt;= -2 or k&gt;2
      <br/>
      c-1 =sp1 ej ALPHA
      <br/>
      c0 =x+jy
      <br/>
      c1 =sej ALPHA
      <br/>
      c2 =sp2 ej( ALPHA + PI )
      <br/>
      x x center position
      <br/>
      y y center position
      <br/>
      s size
      <br/>
      ALPHA  orientation (angle between main ellipse and x-axis)
      <br/>
      p1 : variable parameter to describe the short/long axis ratio of the main ellipse with 0 &lt;= p1 &lt;= 0.5 (long axis: s+sp1, short axis: s-sp1, for P1 =0, the Fourier descriptors define a circle as a special case of an ellipse)
      <br/>
      p2 variable parameter to describe the degree of asymmetry (kidney shape) with 0 &lt;= p2 &lt;= 0.3
    </p>
    <p num="45">
      FIG. 6 is a diagram illustrating examples of the deformable templates corresponding to the possible shapes assigned to localized densities from the Fourier descriptors analysis discussed above, with the p1 and p2 values indicated for each shape.
      <br/>
      Note that the center position and the angle (orientation) and the size of each can be varied.
      <br/>
      FIG. 6 is an example of possible shapes, and the invention is not limited to these particular shapes or this number of shapes.
    </p>
    <p num="46">
      The lesion contour is generated by variation of the Fourier terms within a certain range with minimization of a cost function using lesion contrast, edge strength and deviation from the ideal circular shape.
      <br/>
      This process is performed on the output from the mass filter.
      <br/>
      Simulated annealing is used for minimization.
    </p>
    <p num="47">
      Simulated annealing is a technique for optimization, which involves a description of possible system configurations, a generator of random changes in the configuration (i.e., the "options"), a function for minimization and a control parameter (temperature) that controls the increments of the random changes.
      <br/>
      It is described in, for example, Numerical Recipes by Press, et al., Cambridge Press (1988).
    </p>
    <p num="48">
      The configuration in the embodiment is the "correct" Fourier descriptor of an extracted contour.
      <br/>
      This configuration could be obtained as an entire curve or in radial segments of the curve using different Fourier descriptors for each segment.
      <br/>
      Once "fit", the inverse of the Fourier descriptors is performed yielding the contour.
      <br/>
      With the radial segments, only a limited number of points are generated in the inverse transformation.
      <br/>
      The changes in the configuration (i.e., the contour shape, that is the Fourier descriptor coefficients ck) are changed by changes in the center location, the size of the "lesion", the orientation ( ALPHA ), the long/short axis ratio (indicating the degree of being oval) and the degree of asymmetry.
      <br/>
      The method limits the changes to these in the Fourier descriptors.
      <br/>
      Examples of the range of variation for each parameter include increments in center position by one pixel, a size range of 5 to 80 pixels in diameter with an increment of 2 pixels, and a range in a from -360 (degree)  to 360 (degree) . The function to be minimized includes a center cost index of 20 (in each direction), a size cost index of 10 and an angle cost index of 10.
      <br/>
      The starting temperature was set at 30.
      <br/>
      Upon minimizing the cost function, the difference between the "lesion" center and the "fit" center, the difference between the size of the "lesion" and the size of the "fit", the Euclidean difference between x-y position of the lesion contour and the x-y position of the fit contour, etc. are minimized.
      <br/>
      The temperature is modified (cooled) as the iterations increase so that after a specified number of iterations a downward step in the temperature is taken.
    </p>
    <p num="49">
      In the template matching the following can be varied: the shape in terms of Fourier descriptors, the penalty factor for deviations from the mean, the center, the angle and the size.
      <br/>
      The penalty factor is a measure based on standard deviation, i.e. a limit on the amount of deformation during the template matching.
    </p>
    <p num="50">
      An example of the parameter file used in the deformable template matching is shown below:
      <br/>
      a shape file giving which part of the curve is used
      <br/>
      start temperature for the simulated annealing
      <br/>
      number of iterations
      <br/>
      increments such as for incrementing the center position, the size, the angle during the simulated annealing
      <br/>
      number of points generated in the inverse transformation.
    </p>
    <p num="51">
      Note that after the matching is successful, the final coefficients of the Fourier descriptors are used to return to the x,y domain.
      <br/>
      Thus, discontinuous margin pixels along a "mass" will be connected.
      <br/>
      The output of the template matching is contour or a partial contour of the suspect lesion.
    </p>
    <p num="52">
      Sixteen edge maps can be used in the shape matching.
      <br/>
      Edge maps are obtained from the second derivative, as described above.
      <br/>
      Edge maps are used since sometimes there is only one good edge in the suspected lesion.
      <br/>
      The lesion contour is generated by variation of the Fourier terms within a certain range with minimization of a cost function using lesion contrast, edge strength and deviation from the ideal circular shape.
      <br/>
      Simulated annealing is used for minimization.
      <br/>
      In the matching one can have varied the following: the shape in terms of Fourier descriptors, the penalty factor deviations from the mean, the center, the angle and the size.
    </p>
    <p num="53">
      For further characterization a rectangular ROI containing the suspected lesion identified in the open, mass filtering and template matching operations is extracted from the original peripheral density enhanced image.
      <br/>
      Feature extraction and analysis is performed on the suspected lesion.
      <br/>
      Feature extraction and is described in application Ser.
      <br/>
      No. 08/158,389 to Giger et al., the disclosure of which is herein incorporated by reference.
    </p>
    <p num="54">
      This is shown in more detail in FIG. 8.
      <br/>
      The suspected lesion from the template matching is obtained (step 800).
      <br/>
      Note that a suspected lesion from another method, by a computer or manually by an observer, can also be used as input (step 801).
      <br/>
      A region of interest (ROI) containing the suspected lesion is selected (automatically or manually) in step 802.
      <br/>
      The gradient and orientation of the ROI is calculated in step 803, followed by a calculation of the gradient index R, contrast and elongation factor in step 804.
      <br/>
      This is shown in more detail in FIG. 7, where in an ROI 700 a gradient 701 is calculated at a point 702 in a suspected lesion 703 having a center point (x,y).
      <br/>
      The pixels in the area enclosed by dashed line 704 are those pixels that do not contribute much to the gradient index (the gray value varies more towards the edge of the suspected lesion), and may be excluded.
    </p>
    <p num="55">The radial gradient index R, defined as follows:  (Equation image '2' not included in text)</p>
    <p num="56">
      where:
      <br/>
      R radial gradient index -1 &lt;= R &lt;= 1
      <br/>
      P image point
      <br/>
      (x,y) center of suspected lesion from template matching
      <br/>
      L detected lesion excluding the center part
      <br/>
      Dx gradient in x-direction
      <br/>
      Dy gradient in y-direction
      <br/>
      PHI  angle between gradient vector and connection line center (x,y) to P
    </p>
    <p num="57">
      The radial gradient index is a measure of circularity and density characteristics of the lesion.
      <br/>
      The radial gradient index approaches 1 for ideal circular lesions.
      <br/>
      This radial gradient index can be viewed as the average gradient in the radial direction normalized by the average gradient.
      <br/>
      The suspected lesion size is given by the difference between the gray level at the center to that at the margin of the suspected lesion.
    </p>
    <p num="58">
      To limit the number of false positives, thresholding is performed in step 805.
      <br/>
      For example, lesions with a diameter less than some preset value (e.g. &lt;4 mm), a contrast less than some preset value (e.g. &lt;0.1 optical density) or a radial gradient less that a preset value (e.g., 0.5) are eliminated.
    </p>
    <p num="59">
      The features after thresholding are indicated in step 806 and can be merged using, for example, rule-based methods or an artificial neural network trained to detect and classify lesions (step 807) to eliminate further more false positives or to distinguish between malignant and benign lesions.
      <br/>
      Malignant and benign lesions will possess different R values if the maglinant lesion is highly spiculated.
    </p>
    <p num="60">
      The open, mass filtering and template matching are performed repeatedly with different resolutions.
      <br/>
      In each resolution step a specific lesion size is detected.
      <br/>
      FIG. 9A is a table illustrating the relationship between pixel size of the image and the lesion size being detected.
      <br/>
      The number and size of resolutions chosen depends upon the type of lesions to be detected and the amount of processing time available for detection.
    </p>
    <p num="61">
      The kernel size in the mass filtering can also be varied.
      <br/>
      FIG. 9B is a table showing the relationship between kernel size and the size of the lesion being detected.
      <br/>
      In the embodiments described above, a single mass filter can be chosen for the different resolutions of the open filter.
      <br/>
      In a modification of theses embodiments, the kernel size in the mass filtering can be varied, for example as shown in FIG. 9B. The modified mass filtering step is shown in FIG. 10. The image resolution is kept constant while the kernel size is varied, the kernel size is kept constant while the image resolution is varied, or both can be varied.
    </p>
    <p num="62">
      In step 1000, the image from the morphological operation is obtained.
      <br/>
      The initial kernel size is set (step 1001) and the mass filtering is performed at the initial kernel size (step 1002).
      <br/>
      The image after mass filtering is stored (step 1003).
      <br/>
      Next, it is checked whether the maximum kernel size has been reached in step 1004.
      <br/>
      If no, then a new kernel size is selected (step 1005) and the mass filtering is performed again.
      <br/>
      After the last kernel size is used, the images are output (step 1006).
    </p>
    <p num="63">
      After features analysis has been performed, in step 116 of FIG. 1A the different detected lesions from all of the outputs obtained from different resolution images, different size kernels, or both, are integrated.
      <br/>
      Locations indicating the same lesion may show up in more than one image.
    </p>
    <p num="64">
      If two lesions overlap, the lesion with the smaller radial gradient index is eliminated.
      <br/>
      The amount of acceptable overlap can be varied by specifying the percent of overlap allowed.
      <br/>
      In the embodiment, 30% was chosen, but other values can be used.
      <br/>
      Referring to FIG. 11, two lesions 1100 and 1101 are shown.
      <br/>
      The smaller lesion, having the larger gradient index is kept.
    </p>
    <p num="65">
      FIGS. 12A-12F illustrate example of (12A) an original mammogram, (12B) after border segmentation, (12C) after the modified open operation, (12D) after the mass filtering, (12E) after template matching and (12F) after feature extraction in which the suspect lesions are prioritized by number (with one being the most suspicious).
      <br/>
      In this case lesion 1 was an intramammary lymph node with a radial gradient index of 0.92, lesion 2 was a 10 mm invasive ductal cancer (R=0.90), lesion 3 was a 7 mm invasive ductal cancer (R=0.85), and lesions 4 through 7 were false positive with R ranging from 0.78 to 0.52.
    </p>
    <p num="66">
      In FIG. 12D the suspected lesions are evidently highlighted, allowing their extraction through thresholding as described above.
      <br/>
      FIG. 12E contains many contrast features not evident from a visual inspection of FIG. 12D. The template matching is sensitive to subtle variations in the mass-filtered image.
    </p>
    <p num="67">
      FIGS. 13A-13F show examples of a mammogram (13A) after peripheral enhancement and (13B) after morphological filter with a pixel size of 0.5 mm. FIG. 13C shows the difference image of FIG. 13A minus FIG. 13B, illustrating the small detail, non-lesion like structures that are eliminated by the morphological operation.
      <br/>
      The effect of morphological operations with different pixel sizes is shown in FIGS. 13D-13F for pixel sizes of 1.0 mm, 2.0 mm and 4.0 mm, respectively.
    </p>
    <p num="68">
      FIGS. 14A-14C illustrates (14A) an artificial ideal spherical lesion and (14B) its detection results.
      <br/>
      FIG. 14C shows the 16 directional edge maps used in the method.
      <br/>
      The 16 edge maps correspond to 16 equal radial sectors making up the circular lesion.
      <br/>
      Other numbers of edge maps can be chosen.
    </p>
    <p num="69">
      FIG. 15A shows the location of the ROI used for feature analysis within the original mammogram after peripheral enhancement.
      <br/>
      FIGS. 15B-15D show enlargements of the ROI, the truth margin as marked by a radiologists and the detection result for lesions 1 and 2 from FIG. 12F, respectively.
    </p>
    <p num="70">
      FIG. 16 is a graph illustrating the performance of the method in the detection of malignant lesions in a screening mammographic database in terms of FROC (free response operating characteristic) curve.
      <br/>
      For this performance evaluation, 45 invasive cancers less than 10 mm in size were used.
    </p>
    <p num="71">
      FIG. 17 is a schematic block diagram illustrating a system for implementing the automated method for the detection of lesions in medical images.
      <br/>
      The system of FIG. 17 operates and carries out functions as described above.
      <br/>
      A data input device 1700, such as a x-ray mammography device with a laser scanner and digitizer, produces a digitized mammogram.
      <br/>
      The digitized mammogram is segmented by segmenting circuit 1701 and then input to a peripheral enhancement circuit 1702 or sampling circuit 1703.
      <br/>
      Either the digitized mammogram or the peripherally enhanced is sampled by the sampling circuit 1703 (to select a pixel size) and then optionally processed by a modified median filter 1704.
      <br/>
      Either the output of the sampling circuit 1703 or the filter 1704 is input to and processed by morphological circuit 1705.
      <br/>
      The output of circuit 1705 is fed to mass filter circuit 1706 for mass filtering.
      <br/>
      Next, the mass-filtered image is fed to a Fourier descriptors generating circuit 1707, edge images generating circuit 1708 and simulated annealing circuit 1709 for template matching.
      <br/>
      The image(s) are then fed to a feature analysis circuit 1710 for feature extraction and analysis.
      <br/>
      Memory 1711 is available to store images.
      <br/>
      The features are merged for classification and integration in feature merging circuit 1712, and can be displayed on display 1713, such as a video display terminal.
    </p>
    <p num="72">
      The images can also be transferred from memory 1711 via transfer circuit 1714 to a feature analysis circuit 1715 to perform feature extraction and analysis.
      <br/>
      The features are fed to a rule-based circuit or neural network 1716 to perform detection and classification of lesions.
      <br/>
      Superimposing circuit 1717 allows the detected lesions to be displayed on the images.
    </p>
    <p num="73">
      The elements of the system of FIG. 17 can be carried out in software or in hardware, such as a programmed microcomputer.
      <br/>
      The neural network can also be carried out in software or as a semiconductor layout.
    </p>
    <p num="74">
      Obviously, numerous modifications and variations of the present invention are possible in light of the above technique.
      <br/>
      It is therefore to be understood that within the scope of the appended claims, the invention may be practiced otherwise than as specifically described herein.
      <br/>
      Although the current application is focussed on the detection and classification of mass lesions in mammograms, the concept can be expanded to the detection and classification of abnormalities in other organs in the human body, such as the lungs and the liver.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed as new and desired to be secured by Letters Patent of the United States is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A method for the automated detection of a mass lesion in mammographic images, comprising:</claim-text>
      <claim-text>generating a mammogram; segmenting said mammogram to produce a segmented mammogram; performing a modified morphological operation on said segmented mammogram;</claim-text>
      <claim-text>and detecting whether said lesion is present in said mammogram; wherein said modified morphological operation comprises:</claim-text>
      <claim-text>- determining a first gray-level value of a pixel in said segmented mammogram using morphological processing; - determining a difference between a second gray level value of said pixel before performing said morphological operation and said first value;</claim-text>
      <claim-text>and - substituting said first value for said second value in said segmented mammogram if said difference is greater than a threshold value.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. A method as recited in claim 1, comprising performing said modified morphological operation using a plurality of filter sizes.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. A method as recited in claim 1, wherein segmenting said mammogram comprises segmenting a breast border from said mammogram.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. A method as recited in claim 1, wherein segmenting said mammogram comprises: performing noise analysis on said mammogram; applying a gray value range operator; performing global gray-level histogram analysis to provide a thresholded image; region growing using said thresholded image; performing a morphological erosion operation;</claim-text>
      <claim-text>and determining a distance map.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. A method as recited in claim 1, comprising: peripherally enhancing said segmented image to produce an enhanced image;</claim-text>
      <claim-text>and performing said modified morphological operation using said enhanced image.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. A method as recited in claim 5, wherein said peripherally enhancing said segmented image comprises: determining average gray-level values of pixels as a function of distance from a border of a breast in said mammogram; fitting an enhancement curve to said gray-level values; reversing a fit of said enhancement curve to obtain a second enhancement curve;</claim-text>
      <claim-text>and adding said second enhancement curve to a curve of said average gray-level values as a function of distance.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. A method as recited in claim 1, comprising: processing said segmented image to produce a processed image;</claim-text>
      <claim-text>and performing said modified morphological operation using said processed image.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. A method as recited in claim 7, wherein processing said segmented image comprises: obtaining a gray-level value in said segmented image at a first pixel; determining a local gray-level minimum in said segmented image in a neighborhood of pixels disposed around said first pixel; substituting said local gray-level minimum for said gray-level value of said first pixel when a first difference between said minimum and said gray-level value is greater than a first gray-level threshold value;</claim-text>
      <claim-text>and repeating said obtaining, determining and substituting steps for selected pixels of said segmented image to obtain a processed image.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. A method as recited in claim 8, comprising: determining whether a pixel in said processed image is a seed pixel;</claim-text>
      <claim-text>and performing said modified morphological operation using said seed pixel.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. A method as recited in claim 9, wherein determining whether said pixel is said seed pixel comprises: determining a local gray-level maximum of said neighborhood; a first step of determining whether a first difference between said gray-level value and said local gray level minimum is less than a second difference between said local gray-level maximum and said gray-level value;</claim-text>
      <claim-text>and a second step determining whether said pixel is within a predetermined distance of a pixel having said local minimum gray-level value.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. A method as recited in claim 9, comprising: performing said modified morphological operation at a selected seed pixel in said segmented image; determining whether a second difference of a first gray-level value of said selected seed pixel before performing said modified morphological operation and a second gray-level value of said selected seed pixel after performing said morphological operation is less than a second gray-level threshold value; replacing said first gray-level value with said second gray-level value when said second difference is greater than said second gray-level threshold value.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. A method as recited in claim 1, wherein said detecting step comprises: extracting features using a result of said morphological operation, said mass filtering and said template matching; integrating said features;</claim-text>
      <claim-text>and classifying said features.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. A method as recited in claim 1, comprising: performing mass filtering after performing said modified morphological operation to produce a filtered image performing template matching using said filtered image; performing thresholding using said filtered image;</claim-text>
      <claim-text>and detecting said lesions using said template matching and said thresholding.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. A method as recited in claim 1, comprising: performing mass filtering;</claim-text>
      <claim-text>and performing template matching.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. A method as recited in claim 14, comprising: performing said modified morphological operation, said mass filtering and said template matching serially at a plurality of morphological resolutions; wherein said modified morphological operations performed at said plurality of resolutions are conducted in parallel.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. A method as recited in claim 14, comprising: performing said modified morphological operation, said mass filtering and said template matching serially at a plurality of morphological resolutions; wherein said modified morphological operations performed at said plurality of resolutions are conducted iteratively.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. A method as recited in claim 16, further comprising thresholding a mass filtered image obtained from said mass filtering.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. A method as recited in claim 14, further comprising: thresholding a mass filtered image obtained from said mass filtering to obtained a threshold image; using said threshold image in detecting said lesions.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. A method as recited in claim 18, wherein: said detecting step comprises performing feature extraction;</claim-text>
      <claim-text>and said threshold image is used in said feature extraction.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. A method as recited in claim 14, wherein performing said mass filtering comprises: using a ring-shaped kernel;</claim-text>
      <claim-text>and determining a filter value based upon a second derivative of edge orientation.</claim-text>
    </claim>
    <claim num="21">
      <claim-text>21. A method as recited in claim 14, wherein said template matching comprises: determining a deformable shape template;</claim-text>
      <claim-text>and fitting said shape template to a shape of a suspected lesion.</claim-text>
    </claim>
    <claim num="22">
      <claim-text>22. A method as recited in claim 21, comprising: determining said deformable shape template using Fourier descriptors;</claim-text>
      <claim-text>and varying said descriptors to dynamically fit said shape template to said shape of said suspected lesion.</claim-text>
    </claim>
    <claim num="23">
      <claim-text>23. A method as recited in claim 21, comprising: determining said shape template as an inverse Fourier transform having a plurality of Fourier terms; varying said Fourier terms to fit said shape template to said shape of said suspected lesion;</claim-text>
      <claim-text>and outputting a contour of said suspected lesion.</claim-text>
    </claim>
    <claim num="24">
      <claim-text>24. A method as recited in claim 23, wherein varying said Fourier terms comprises minimizing a cost function using simulated annealing.</claim-text>
    </claim>
    <claim num="25">
      <claim-text>25. A method as recited in claim 23, comprising: varying a center location, a size, an orientation, a ratio of a long axis to a short axis, and a degree of asymmetry of said inverse Fourier transform.</claim-text>
    </claim>
    <claim num="26">
      <claim-text>26. A method as recited in claim 21, comprising: determining a center of a suspected lesion as a maximum mass filter value; determining edges of said suspected lesion as one of a derivative and a second derivative of said image after mass-filtering;</claim-text>
      <claim-text>and fitting said template using said center and said edges.</claim-text>
    </claim>
    <claim num="27">
      <claim-text>27. A method as recited in claim 14, wherein performing said mass filtering comprises: selecting an initial kernel size of a mass filter; performing mass filtering using said initial kernel size to produce a mass-filtered image; varying said kernel size up to a maximum kernel size;</claim-text>
      <claim-text>and performing mass filtering at each kernel size and producing corresponding mass-filter images.</claim-text>
    </claim>
    <claim num="28">
      <claim-text>28. A method as recited in claim 27, comprising: performing said template matching on each of said mass-filter images; detecting suspected lesions in said mass-filtered images;</claim-text>
      <claim-text>and integrating said suspected lesions.</claim-text>
    </claim>
    <claim num="29">
      <claim-text>29. A method as recited in claim 28, wherein integrating said suspected images comprises: determining whether suspected lesions in said mass-filtered images spatially overlap;</claim-text>
      <claim-text>and eliminating selected ones of overlapping suspected lesions.</claim-text>
    </claim>
    <claim num="30">
      <claim-text>30. A method as recited in claim 29, comprising: determining a radial index for each of said overlapping suspected lesions;</claim-text>
      <claim-text>and eliminating one of said overlapping suspected lesions having a smaller radial index.</claim-text>
    </claim>
    <claim num="31">
      <claim-text>31. A method as recited in claim 1, comprising: selecting a region of interest containing said lesion;</claim-text>
      <claim-text>and performing feature extraction using said region of interest.</claim-text>
    </claim>
    <claim num="32">
      <claim-text>32. A method as recited in claim 31, comprising: selecting said region of interest containing a lesion identified using template matching.</claim-text>
    </claim>
    <claim num="33">
      <claim-text>33. A method as recited in claim 31, wherein performing feature extraction comprises: determining a gradient of said region of interest; determining an orientation of said region of interest; determining a gradient index of said region of interest; determining a contrast of said region of interest;</claim-text>
      <claim-text>and determining an elongation factor of said region of interest.</claim-text>
    </claim>
    <claim num="34">
      <claim-text>34. A method as recited in claim 33, comprising: thresholding at least one of said gradient, orientation, gradient index, contrast and elongation factor.</claim-text>
    </claim>
    <claim num="35">
      <claim-text>35. A method as recited in claim 34, comprising: determining a final filter value as a sum of said filter values.</claim-text>
    </claim>
    <claim num="36">
      <claim-text>36. A method as recited in claim 35, comprising: determining said final filter value using a plurality of said orientation bins excluding a predetermined number of said orientation bins having highest values.</claim-text>
    </claim>
    <claim num="37">
      <claim-text>37. A method for the automated detection of mass lesions in mammographic images, comprising: generating a mammogram; segmenting said mammogram to produce a segmented mammogram; performing a morphological operation on said segmented mammogram; performing mass filtering;</claim-text>
      <claim-text>and detecting whether a lesion is present in said image; wherein performing said mass filtering comprises: - determining a filter value for a plurality of edge orientation bins;</claim-text>
      <claim-text>and - wherein determining said filter value comprises:</claim-text>
      <claim-text>-  calculating said filter value using: -   where:</claim-text>
      <claim-text>-    f(Bi) is said filter value at an orientation bin; -    K is a filter kernel; -    P is a neighbor point in K; -    N is a number of points in K;</claim-text>
      <claim-text>and -     PHI  is an angle between a gradient vector and a connection line between said neighbor point and a center point.</claim-text>
    </claim>
    <claim num="38">
      <claim-text>38. A system for detecting lesions in a medical image, comprising: a data input device; a segmenting circuit connected to said input device; a modified morphological circuit connected to receive an output of said segmenting circuit;</claim-text>
      <claim-text>and a lesion detecting circuit operably connected to the modified morphological circuits; wherein said modified morphological circuit comprises: - a gray level value determining circuit adapted to determine a first gray-level value of a pixel in said segmented mammogram using morphological processing; - a difference circuit adapted to obtain a difference between a second gray level value of said pixel before performing said morphological operation and said first value;</claim-text>
      <claim-text>and - a pixel substitution circuit adapted to substitute said first value for said second value in said segmented mammogram if said difference is greater than a gray-level threshold value.</claim-text>
    </claim>
    <claim num="39">
      <claim-text>39. A system as recited in claim 38, comprising: a peripheral enhancement circuit connected to said segmenting circuit; wherein said morphological circuit is further connected to receive an output of said peripheral enhancement circuit.</claim-text>
    </claim>
    <claim num="40">
      <claim-text>40. A system as recited in claim 39, comprising: a sampling circuit connected to said segmenting, peripheral enhancement and morphological circuits; wherein said sampling circuit is connected to receive said outputs of said segmenting and peripheral enhancement circuits;</claim-text>
      <claim-text>and said morphological circuit is connected to receive an output of said sampling circuit.</claim-text>
    </claim>
    <claim num="41">
      <claim-text>41. A system as recited in claim 38, wherein said morphological circuit comprises: means for performing a modified morphological operation using a plurality of filter sizes.</claim-text>
    </claim>
    <claim num="42">
      <claim-text>42. A system as recited in claim 38, wherein said morphological circuit comprises: means for determining whether a pixel in said medical image is a seed pixel;</claim-text>
      <claim-text>and means for performing a modified morphological operation using said seed pixel.</claim-text>
    </claim>
    <claim num="43">
      <claim-text>43. A system as recited in claim 38, wherein: said gray level value determining circuit comprises means for obtaining a gray-level value in said medical image at a first pixel; said difference circuit comprises means for determining a local gray-level minimum in said segmented image in a neighborhood of pixels disposed around said first pixel;</claim-text>
      <claim-text>and said pixel substitution circuit comprises means for substituting said local gray-level minimum for said gray-level value of said first pixel when a difference between said minimum and said gray-level value is greater than said gray-level threshold value.</claim-text>
    </claim>
    <claim num="44">
      <claim-text>44. A system as recited in claim 43, comprising: means for determining a local gray-level maximum of said neighborhood of pixels; first means for determining whether a first difference between said gray-level value and said local gray level minimum is less than a second difference between said local gray-level maximum and said gray-level value;</claim-text>
      <claim-text>and second means for determining whether said pixel is within a predetermined distance of a pixel having said local minimum gray-level value.</claim-text>
    </claim>
    <claim num="45">
      <claim-text>45. A system as recited in claim 38, comprising: a mass filter circuit connected to said modified morphological circuit; a template matching circuit connected to said mass filter circuit;</claim-text>
      <claim-text>and a feature analysis circuit connected to said template matching circuit; wherein said lesion detecting circuit is connected to the feature analysis circuit.</claim-text>
    </claim>
    <claim num="46">
      <claim-text>46. A system as recited in claim 45, wherein said template matching circuit comprises: a Fourier descriptor generating circuit; an edge generating circuit connected to said Fourier descriptor generating circuit;</claim-text>
      <claim-text>and a simulated annealing circuit connected to said edge generating circuit.</claim-text>
    </claim>
    <claim num="47">
      <claim-text>47. A system as recited in claim 45, wherein said mass filter circuit comprises: means for determining a filter value for a plurality of edge orientation bins;</claim-text>
      <claim-text>and means for determining a final filter value as a sum of said filter values.</claim-text>
    </claim>
    <claim num="48">
      <claim-text>48. A system as recited in claim 45, wherein said template matching circuit comprises: means for determining a deformable shape template;</claim-text>
      <claim-text>and means for fitting said shape template to a shape of a suspected lesion.</claim-text>
    </claim>
    <claim num="49">
      <claim-text>49. A system as recited in claim 48, wherein said template matching circuit further comprises: means for determining said deformable shape template using Fourier descriptors;</claim-text>
      <claim-text>and means for varying said descriptors to dynamically fit said shape template to said shape of said suspected lesion.</claim-text>
    </claim>
    <claim num="50">
      <claim-text>50. A system as recited in claim 48, wherein said template matching circuit further comprises: means for determining said shape template as an inverse Fourier transform having a plurality of Fourier terms; means for varying said Fourier terms to fit said shape template to fit said shape template to said shape of said suspected lesion;</claim-text>
      <claim-text>and means for outputting a contour of said suspected lesion.</claim-text>
    </claim>
    <claim num="51">
      <claim-text>51. A system as recited in claim 50, wherein said template matching circuit further comprises: means for varying a center location, a size, an orientation, a ratio of a long axis to a short axis, and a degree of asymmetry of said inverse Fourier transform.</claim-text>
    </claim>
    <claim num="52">
      <claim-text>52. A system as recited in claim 45, wherein said template matching circuit further comprises: means for determining a center of a suspected lesion as a maximum mass filter value; means for determining edges of said suspected lesion;</claim-text>
      <claim-text>and means for fitting said template using said center and said edges.</claim-text>
    </claim>
    <claim num="53">
      <claim-text>53. A system as recited in claim 45, wherein said feature extraction circuit comprises: means for determining a gradient of said region of interest; means for determining an orientation of said region of interest; means for determining a gradient index of said region of interest; means for determining a contrast of said region of interest;</claim-text>
      <claim-text>and means for determining an elongation factor of said region of interest.</claim-text>
    </claim>
    <claim num="54">
      <claim-text>54. A system as recited in claim 45, wherein said feature extraction circuit further comprises a thresholding circuit.</claim-text>
    </claim>
    <claim num="55">
      <claim-text>55. A system as recited in claim 45, wherein said mass filter circuit comprises: means for selecting an initial kernel size of a mass filter; means for performing mass filtering using said initial kernel size to produce a mass-filtered image; means for varying said kernel size up to a maximum kernel size;</claim-text>
      <claim-text>and means for performing mass filtering at each kernel size and producing corresponding mass-filter images.</claim-text>
    </claim>
  </claims>
</questel-patent-document>