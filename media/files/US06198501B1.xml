<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06198501B1.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as first publication">
      <document-id>
        <country>US</country>
        <doc-number>06198501</doc-number>
        <kind>B1</kind>
        <date>20010306</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6198501</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B1</original-publication-kind>
    <application-reference is-representative="YES" family-id="26691178" extended-family-id="58675449">
      <document-id>
        <country>US</country>
        <doc-number>09323578</doc-number>
        <kind>A</kind>
        <date>19990601</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1999US-09323578</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>59974091</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>32357899</doc-number>
        <kind>A</kind>
        <date>19990601</date>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1999US-09323578</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>US</country>
        <doc-number>86485197</doc-number>
        <kind>A</kind>
        <date>19970529</date>
        <priority-linkage-type>1</priority-linkage-type>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1997US-08864851</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="3">
        <country>US</country>
        <doc-number>1848996</doc-number>
        <kind>P</kind>
        <date>19960530</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="3">
        <doc-number>1996US-60018489</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010306</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <term-of-grant>
      <disclaimer/>
    </term-of-grant>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>F41J   5/08        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>F</section>
        <class>41</class>
        <subclass>J</subclass>
        <main-group>5</main-group>
        <subgroup>08</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>348135000</text>
        <class>348</class>
        <subclass>135000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>348139000</text>
        <class>348</class>
        <subclass>139000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>348211600</text>
        <class>348</class>
        <subclass>211600</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>F41J-005/08</text>
        <section>F</section>
        <class>41</class>
        <subclass>J</subclass>
        <main-group>5</main-group>
        <subgroup>08</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>F41J-005/08</classification-symbol>
        <section>F</section>
        <class>41</class>
        <subclass>J</subclass>
        <main-group>5</main-group>
        <subgroup>08</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>6</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>32</number-of-drawing-sheets>
      <number-of-figures>35</number-of-figures>
      <image-key data-format="questel">US6198501</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Military range scoring system</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>NEMIROFF ROBERT V, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5999210</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5999210</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="2">
          <text>STOLLER MILTON</text>
          <document-id>
            <country>US</country>
            <doc-number>3624401</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US3624401</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="3">
          <text>RIPLEY J, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>3793481</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US3793481</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="4">
          <text>MICHELSEN P</text>
          <document-id>
            <country>US</country>
            <doc-number>3798795</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US3798795</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="5">
          <text>FINCH C</text>
          <document-id>
            <country>US</country>
            <doc-number>3807858</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US3807858</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="6">
          <text>ROBERTSSON HANS R</text>
          <document-id>
            <country>US</country>
            <doc-number>3955292</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US3955292</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="7">
          <text>BEAUREGARD JOHN G, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4155096</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4155096</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="8">
          <text>ALLEN DONNIE E, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4222564</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4222564</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="9">
          <text>GELL HAROLD A</text>
          <document-id>
            <country>US</country>
            <doc-number>4225867</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4225867</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="10">
          <text>GODA WILFRIED</text>
          <document-id>
            <country>US</country>
            <doc-number>4315689</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4315689</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>LOEWE GUENTER</text>
          <document-id>
            <country>US</country>
            <doc-number>4333106</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4333106</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="12">
          <text>DANIEL JEAN P</text>
          <document-id>
            <country>US</country>
            <doc-number>4349838</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4349838</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="13">
          <text>KNIGHT LINDSAY C, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4350881</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4350881</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="14">
          <text>MARSHALL ALBERT H, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4439156</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4439156</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="15">
          <text>GODA WILFRIED</text>
          <document-id>
            <country>US</country>
            <doc-number>4478581</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4478581</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="16">
          <text>BROWN C DAVID</text>
          <document-id>
            <country>US</country>
            <doc-number>4611993</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4611993</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="17">
          <text>BOECK HANS-JOACHIM, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4622458</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4622458</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="18">
          <text>PLANTE ROBERT, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4672438</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4672438</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="19">
          <text>EICHWEBER KURT</text>
          <document-id>
            <country>US</country>
            <doc-number>4689016</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4689016</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="20">
          <text>EICHWEBER KURT</text>
          <document-id>
            <country>US</country>
            <doc-number>4695256</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4695256</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="21">
          <text>WARD RICHARD L, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4739329</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4739329</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="22">
          <text>HILL BANFORD R</text>
          <document-id>
            <country>US</country>
            <doc-number>4955812</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4955812</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="23">
          <text>ROHRBAUGH GEORGE W</text>
          <document-id>
            <country>US</country>
            <doc-number>5025424</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5025424</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="24">
          <text>HARRIS GORDON L</text>
          <document-id>
            <country>US</country>
            <doc-number>5141175</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5141175</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="25">
          <text>ELDRIDGE MORTON T</text>
          <document-id>
            <country>US</country>
            <doc-number>5228854</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5228854</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="26">
          <text>HEIER HELMUT, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5285397</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5285397</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="27">
          <text>DUNNE JEREMY G</text>
          <document-id>
            <country>US</country>
            <doc-number>5291262</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5291262</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="28">
          <text>MUIRHEAD JAMES O, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5359920</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5359920</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="29">
          <text>BEARD III BRYCE P, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5393064</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5393064</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="30">
          <text>CARGILL LEE B</text>
          <document-id>
            <country>US</country>
            <doc-number>5432546</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5432546</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="31">
          <text>MCGARY DOUG</text>
          <document-id>
            <country>US</country>
            <doc-number>5521634</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5521634</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="32">
          <text>BRADSHAW MARK, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5528518</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5528518</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="33">
          <text>JENKINS GARY KIM, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5644386</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5644386</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="34">
          <text>VOGT MARK A, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5689445</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5689445</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <related-documents>
      <continuation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>86485197</doc-number>
              <kind>A</kind>
              <date>19970529</date>
            </document-id>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>5999210</doc-number>
              <kind>A</kind>
              <date>19991207</date>
            </document-id>
          </parent-doc>
        </relation>
      </continuation>
      <related-publication>
        <document-id>
          <country>US</country>
          <doc-number>60/018,849</doc-number>
          <date>19960530</date>
        </document-id>
        <document-id>
          <country>US</country>
          <doc-number>60/018849</doc-number>
          <date>19960530</date>
        </document-id>
      </related-publication>
    </related-documents>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Proteus Corporation</orgname>
            <address>
              <address-1>Albuquerque, NM, US</address-1>
              <city>Albuquerque</city>
              <state>NM</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>PROTEUS</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Nemiroff, Robert V.</name>
            <address>
              <address-1>Las Vegas, NV, US</address-1>
              <city>Las Vegas</city>
              <state>NV</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>McGoohan, Kevin P.</name>
            <address>
              <address-1>Las Vegas, NV, US</address-1>
              <city>Las Vegas</city>
              <state>NV</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="3">
          <addressbook lang="en">
            <name>Siebold, Pete A.</name>
            <address>
              <address-1>Las Vegas, NV, US</address-1>
              <city>Las Vegas</city>
              <state>NV</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="4">
          <addressbook lang="en">
            <name>Hutson, III, Henry R.</name>
            <address>
              <address-1>Las Vegas, NV, US</address-1>
              <city>Las Vegas</city>
              <state>NV</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <name>Myers, Jeffrey D.</name>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Britton, Howard</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>LAPSED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A military range scoring system with a plurality of imagers capable of viewing reference points and impact points for ordinance aimed at the reference points, imager position controllers, and data processors and video monitors for processing and viewing data received from said imagers; and communication links between the components.
      <br/>
      The imagers are preferably infrared or near-infrared, and the system manually and/or automatically scores impacts by digital signal processing of imager data.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>CROSS-REFERENCE TO RELATED APPLICATIONS</heading>
    <p num="1">
      This application is a continuation of U.S. patent application Ser.
      <br/>
      No. 08/864,851, filed on May 29, 1997, issued as U.S. Pat. No. 5,999,210, on Dec. 7, 1999.
    </p>
    <p num="2">This application claims the benefit of the filing of Provisional Application Serial No. 60/018,849, entitled "Tactical Range Infrared Scoring System", filed on May 30, 1996, the specification of which is incorporated by reference.</p>
    <heading>COPYRIGHTS</heading>
    <p num="3">
      A portion of the disclosure of this patent document and of the provisional patent application to which it claims priority, contains material which is subject to copyright protection.
      <br/>
      The owner has no objection to the facsimile reproduction of the patent document or the patent disclosure, as it appears in the Patent and Trademark Office patent file or records, but otherwise reserves all copyright rights whatsoever.
    </p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="4">
      1.
      <br/>
      Field of the Invention (Technical Field)
    </p>
    <p num="5">The present invention relates to scoring systems for military ranges.</p>
    <p num="6">2. Background Art</p>
    <p num="7">
      The armed services are required to continuously train and test the capability of troops to accurately and effectively deliver various types of ordinance to targets under battlefield conditions.
      <br/>
      Current methods used by the various services are limited in scope and capability.
      <br/>
      The shift to more extensive use of nighttime engagements has heretofore required the use in training of low level explosives (spotting charges) to determine points of impact.
      <br/>
      These charges are expensive and present both safety and environmental hazards.
      <br/>
      Many types of munitions cannot at present be scored in training scenarios.
    </p>
    <p num="8">
      The prior art in this area includes the following: U.S. Pat. No. 4,155,096, to Thomas et al, relates to laser bore-sighting of sensors. U.S. Pat. No. 4,222,564, to Alan et al, relates to vibration sensing of impacts. U.S. Pat. No. 4,315,689, to Goda, relates to simulated firings of sight-guided missiles employing painting of the target with laser light for a period of time. U.S. Pat. No. 4,333,106, to Love, relates solely to airborne targets. U.S. Pat. No. 4,349,838, to Daniel, relates to laser bore-sighting of sensors. U.S. Pat. No. 4,350,881, to Knight et al, relates to detection of the pressure wave of a projectile. U.S. Pat. No. 4,439,156, to Marshall et al, relates to simulated environments and weapons firings. U.S. Pat. No. 4,622,458, to Boeck et al, relates to a system which determines trajectories of objects employing a plurality of mobile data acquisition systems connected to a central station. U.S. Pat. No. 4,478,581, to Goda, relates to simulation of firings of ballistic ammunition using lasers. U.S. Pat. No. 4,611,993, to Brown, relates to a system requiring a vertical projection screen. U.S. Pat. No. 4,689,016, to Eichweber, relates only to simulations of firearms. U.S. Pat. No. 4,695,256, to Eichweber, relates only to firearms simulations requiring a retro-reflector. U.S. Pat. No. 4,739,329, to Ward et al, relates to a system requiring radar. U.S. Pat. No. 4,955,812, to Hill, relates only to firearms simulations. U.S. Pat. No. 5,025,424, to Rohrbaugh, relates to sensing of shockwaves. U.S. Pat. No. 5,228,854, to Eldridge, relates to a pure simulation system. U.S. Pat. No. 5,359,920, to Muirhead, relates to detection of radio frequencies generated by impacts. U.S. Pat. No. 5,432,546, to Cargill, relates to a sensor attached to the projectile itself.
      <br/>
      Finally, U.S. Pat. No. 5,521,634, to McGary, relates to an algorithm for compressing image data in a target sensing system.
    </p>
    <p num="9">
      The present invention provides a scoring system capable of detecting and reporting delivery of a wide variety of ordinance in real time under daytime and nighttime conditions.
      <br/>
      Once calibrated, the system is straightforward to set up and use, including automatic selection of targets.
    </p>
    <p num="10">SUMMARY OF THE INVENTION (DISCLOSURE OF THE INVENTION)</p>
    <p num="11">
      The present invention is of a military range scoring apparatus comprising: a plurality of imagers capable of viewing a plurality of reference points and impact points for ordinance aimed at the reference points; a remote imager controller and a processor for processing and viewing data received from the imagers; and control information and data communicating devices for interchange between the imagers and the remote imager controller.
      <br/>
      In the preferred embodiment, the controller and processor comprises a video monitor and the data comprise video images calibrated for angular displacement across a horizontal axis.
      <br/>
      A device to measure the calibrated angular displacement between the reference point and the impact point without a requirement for detailed survey data is preferably employed, as is a device for calculating the displacement (X and Y and/or azimuth and distance) between the reference point and the impact point.
      <br/>
      The data communicating devices may including microwave, radio, fiber optic line, and wire line.
      <br/>
      The controller preferably comprises a positioner used to aim an imager at a reference point by changing azimuth and elevation of the imager.
      <br/>
      A database of reference points and imager locations allows rapid and accurate calculation of impact points.
      <br/>
      The imagers are preferably sensitive to infrared radiation, and preferably are capable of sensing laser radiation used to target and guide smart weapons.
      <br/>
      The imagers may include flux gate compasses used to sense imager horizontal pointing angle, to allow accurate horizontal positioning and status information provided to the controller, as well as inclinometers used to sense imager vertical pointing angle, to allow accurate vertical positioning and status information provided to the controller.
      <br/>
      The controller preferably includes a computer storing imager pointing, setup, and calibration data for multiple reference points, and means for setting imager parameters including field of view, zoom, focus, sensitivity, and contrast.
      <br/>
      The system preferably employs a computer for automatically scoring proximities of impact points to reference points and a device causing the controller to direct imagers to point at a reference point, reading back calibration data from the imagers, and entering the calibration data into scoring calculations so that manual calibration is not required.
      <br/>
      The processor includes a video image digitizer and a digital signal processor for determining angular offsets and scoring an impact point from the digitized video image, which can detect multiple impacts and score impact points without user intervention, as well as storage and retrieval mechanisms for the digitized video images.
    </p>
    <p num="12">A primary object of the present invention is to provide a scoring system capable of detecting and accurately reporting delivery of a wide variety of ordinance.</p>
    <p num="13">Another object of the present invention is to provide a scoring system capable of functioning under both daytime and nighttime conditions.</p>
    <p num="14">A primary advantage of the present invention is that it provides for automatic selection of targets.</p>
    <p num="15">
      Other objects, advantages and novel features, and further scope of applicability of the present invention will be set forth in part in the detailed description to follow, taken in conjunction with the accompanying drawings, and in part will become apparent to those skilled in the art upon examination of the following, or may be learned by practice of the invention.
      <br/>
      The objects and advantages of the invention may be realized and attained by means of the instrumentalities and combinations particularly pointed out in the appended claims.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="16">
      The accompanying drawings, which are incorporated into and form a part of the specification, illustrate several embodiments of the present invention and, together with the description, serve to explain the principles of the invention. The drawings are only for the purpose of illustrating a preferred embodiment of the invention and are not to be construed as limiting the invention. In the drawings:
      <br/>
      FIG. 1 is a flowchart of the top-level functionality provided by the preferred scoring system of the invention;
      <br/>
      FIG. 2 is a flowchart of the mission preparation function of the scoring system;
      <br/>
      FIG. 3 is a flowchart of the scoring and report function;
      <br/>
      FIG. 4 is a schematic of the preferred controller of the invention;
      <br/>
      FIG. 5 is a schematic of an exemplary scoring system deployed and in use;
      <br/>
      FIG. 6 is a schematic of the long range infrared imager preferred for use in the system;
      <br/>
      FIG. 7 is a schematic of the long range laser infrared imager preferred for use in the system;
      <br/>
      FIG. 8 is a schematic of the preferred imager site of the invention;
      <br/>
      FIG. 9 is a schematic of the preferred scoring position of the invention;
      <br/>
      FIG. 10 is a window of the preferred software enabling input and selection of a mission;
      <br/>
      FIG. 11 is a window of the preferred software enabling settings for targets;
      <br/>
      FIG. 12 is a window of the preferred software showing mission information and a real-time view of the target area while a mission is in progress, including functions to control imagers, select targets, and carry out scoring;
      <br/>
      FIG. 13 is a window of the preferred software enabling setup of imager parameters;
      <br/>
      FIG. 14 is a window of the preferred software enabling setup of target parameters;
      <br/>
      FIG. 15 is a window of the preferred software enabling setup of the communications interface between the computer and the video digitizer;
      <br/>
      FIG. 16 is a window of the preferred software enabling control of display characteristics of the digitized video on the computer screen;
      <br/>
      FIG. 17 is a window of the preferred software enabling control of position and refresh rate of digitized video on the computer screen;
      <br/>
      FIG. 18 is a window of the preferred software enabling mission creation and naming;
      <br/>
      FIG. 19 is a window of the preferred software enabling mission selection from a panel of previously created missions;
      <br/>
      FIG. 20 is a window of the preferred software enabling selection of ordinance;
      <br/>
      FIG. 21 is a window of the preferred software enabling selection of method of ordinance delivery;
      <br/>
      FIG. 22 is intentionally omitted;
      <br/>
      FIG. 23 is a trace view of the bottom of the preferred configuration of the remote controller mother board of the invention;
      <br/>
      FIG. 24 is a trace view of the top of the preferred configuration of the remote controller mother board of the invention;
      <br/>
      is FIG. 25 is a schematic of the preferred compass controller and video data inserter of the invention;
      <br/>
      FIG. 26 is a bottom trace diagram for FIG. 25;
      <br/>
      FIG. 27 is a schematic of the preferred mother board of the invention;
      <br/>
      FIG. 28 is a continuation schematic from FIG. 27;
      <br/>
      FIG. 29 is intentionally omitted; and
      <br/>
      FIGS. 30-34 are schematics of the wiring harness connections for video, microwave, power, imager, and pan and tilt subsystems, respectively, that connect to the controller ports of FIG. 4.
    </p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
    <p num="17">(BEST MODES FOR CARRYING OUT THE INVENTION)</p>
    <p num="18">
      The present invention is of an ordinance scoring system employing, preferably, both optical and thermal imagers which can operate in multiple lighting conditions.
      <br/>
      The imagers sense visible light, near infrared, infrared, and military laser designators simultaneously with the ability to overlay each onto the others.
      <br/>
      The output of the sensor is a video-like presentation displaying different energy levels rather than light levels.
      <br/>
      By sensing the energy levels of each object in the field of view, the imager works as well in the absence of light as it does in visibly bright conditions.
      <br/>
      Accordingly, the sensor will operate under all day and night ambient conditions and can detect the impact of every type of ordinance now in use as well as a laser spot designator illuminating targets for smart weapons.
      <br/>
      The sensor can also track the "fly in" path of many weapons that are adequately heated by air resistance during delivery.
    </p>
    <p num="19">
      The present invention also incorporates a control system which, when calibrated, will automatically position the imager on any selected target with high azimuth and inclination accuracy, such as of 0.05% error or less.
      <br/>
      The miss distance between the target and the weapon impact can then be calculated using multiple sensor azimuth triangulation or single sensor azimuth and inclination differences.
    </p>
    <p num="20">
      The operator interfaces to the scoring system through a computer, preferably an IBM-PC compatible system running a Windows (trademark of Microsoft Corporation) operating system.
      <br/>
      During normal operations, scoring ordinance and repositioning the system to different targets is accomplished by a simple series of two or three clicks of the mouse, trackball, touch screen, or like input device.
    </p>
    <p num="21">
      The video from the sensor or sensors is digitized and displayed on the same computer screen used to control the system's operation and to score the weapon.
      <br/>
      The video can be frozen at the point of ordinance impact to allow very accurate cursor positioning and scoring.
      <br/>
      The digitized video can be saved and retrieved on a frame-by-frame basis and re-processed, if required.
      <br/>
      The use of digital signal processing on the digitized video facilitates the implementation of automated scoring methods.
      <br/>
      A fully automated version of the invention senses the moment of impact and scores its location with no operator intervention.
    </p>
    <p num="22">
      Referring to FIGS. 1-3, these provide flowcharts of the high level logic of the scoring and control computer 24 of the invention, which is shown in FIG. 5.
      <br/>
      The preferred controller, diagramed on FIG. 4, comprises microcomputer 10, supplied by power 16 and power supply voltage regulators, filters, and reset circuitry 18.
      <br/>
      Via serial port 22, the microcomputer communicates with modem 14 to provide two-way communication with the scoring and control computer via radio transceiver 12 and antenna 11.
      <br/>
      Serial port 20 provides communication to flux gate compass and inclinometer 36, which provides both digital 26 and analog 28 inputs back to the microcomputer.
      <br/>
      Communication with microwave units 38, video switcher and control 40, imager control 42, and pan and tilt control 44 is provided via analog input 28, buffered analog input 30, buffered digital output 32, and power driver 34.
    </p>
    <p num="23">
      FIG. 5 illustrates a typical system of the invention.
      <br/>
      Scoring and control computer 24 receives via microwave 46 and communicates via VHF radio antenna/modem 12,14,11 to, in this case, two imaging sites sending transmissions by microwave 50,60 and receiving communications by VHF antennas 51,61.
      <br/>
      Each site comprises a system controller 55,65, photoelectric and battery power supply means 52,62, a positioner 54,64, and an infrared imager 53,63.
      <br/>
      The imagers at the sites are controlled by the system controller on commands from the scoring and control computer as needed to observe target(s) 99.
    </p>
    <p num="24">
      FIG. 6 illustrates a long range infrared imager system of the invention, with controller 55, positioner 54, infrared imager 53, compass position sensor 56, and sunshade 57.
      <br/>
      FIG. 7 illustrates a second type long range laser infrared imager system of the invention, with controller 65, positioner 64, infrared imager 63, compass position sensor 66, and sunshade 67.
      <br/>
      FIG. 8 illustrates an imager site, showing the interconnections to and the central role of the controller 65, with the photoelectric generator, regulator, and batteries 62, VHF antenna 61, microwave antenna 60, flux gate compass and inclinometer 69, infrared imager 63, and pan and tilt positioner 68.
      <br/>
      FIG. 9 illustrates a scoring position, with scoring and control computer 88, preferably having high speed and high resolution graphics controller 90, high speed video digitizer and overlay processor 92, high capacity digital video storage and playback system 94, interface controller 96, 166 MHz or faster Intel Pentium, Pentium Pro, or Pentium II processor 98, large format high resolution monitor 82, keyboard 84, and mouse/trackball 86.
      <br/>
      Input is received from microwave unit 81 and video switch and processor 83 and output is through VHF antenna 87, VHF transceiver 89, and control modem 91.
      <br/>
      Optionally, video input may be simultaneously stored on VHS format video recorder 85 or the like.
    </p>
    <p num="25">
      Software, such as that disclosed in the provisional patent application from which priority is claimed, is employed to control the entire system during a mission.
      <br/>
      FIGS. 10-21 illustrate the types of screens useful in any software according to the invention.
      <br/>
      Attention is particularly drawn to FIG. 12, which illustrates one embodiment of the main control screen during a mission.
      <br/>
      In this example, two remote imagers are being viewed and controlled simultaneously, while other setups will allow varying numbers of imagers.
      <br/>
      Specialized hardware useful in the present invention are shown in FIGS. 23-34.
    </p>
    <p num="26">The following are preferred requirements of the integrated controller for infrared imager sites of the invention:</p>
    <p num="27">
      --
      <br/>
      -- Power Input:
      <br/>
      -- Imager Power          12VDC 2A
      <br/>
      -- Pan &amp; Tilt Power  12VDC to 28VDC 2A
      <br/>
      -- Controller power      12VDC 0.18A
      <br/>
      -- Radio Power           12VDC 0.06A Receive
      <br/>
      --                       12VDC 0.90A Transmit
      <br/>
      -- Auxiliary Power       220VDC/AC 10.0A
      <br/>
      -- Position Control
      <br/>
      -- Azimuth Motor Control Variable from 0% to 100%
      <br/>
      -- Azimuth Motor Drive   6VDC to 28VDC 2A
      <br/>
      -- Elevation Motor Control Variable from 0% to 100%
      <br/>
      -- Elevation Motor Drive 6VDC to 28VDC 2A
      <br/>
      -- Position Sensing
      <br/>
      -- Coupled Potentiometer 1.5 (degree)  Resolution from Rotational Stop
      <br/>
      --                       1.0 (degree)  Inclination from Horizontal
      <br/>
      -- Standard Compass      1.0 (degree)  Resolution from Magnetic North
      <br/>
      --                       1.0 (degree)  Inclination from Horizontal
      <br/>
      -- High Resolution Compass 0.1 (degree)  Resolution from Magnetic North
      <br/>
      --                       0.1 (degree)  Inclination from Horizontal
      <br/>
      -- Imager Control
      <br/>
      -- Power                 Off On (switchable)
      <br/>
      -- Cool Down             Status Indication Reportable
      <br/>
      -- Sensitivity           -5VDC to +5VDC (continuously variable)
      <br/>
      -- Field of View         Narrow or Wide (switchable)
      <br/>
      -- Electro-optical Zoom  X1 X2 X4 or continuous zoom (switchable)
      <br/>
      -- Width Calibration     -5VDC to +5VDC (absolute sewing)
      <br/>
      -- Phase Calibration     -5VDC to +SVDC (absolute setting)
      <br/>
      -- Contrast              Low Medium High (switchable) or
      <br/>
      --                       -5VDC to +5VDC (continuously variable)
      <br/>
      -- Polarity              Black Hot / White Hot (switchable)
      <br/>
      -- Focus                 Wide FOV Near / Far (relative setting)
      <br/>
      --                       Narrow FOV Near / Far (relative setting)
      <br/>
      -- Case Temperature      Status Indication Reportable
      <br/>
      -- Control Addressability
      <br/>
      -- Discrete Addresses    225 individually addressable controllers
      <br/>
      -- Broadcast             To all 225 controllers at the same time
      <br/>
      -- Group Address         25 assignable subgroup addresses
      <br/>
      -- Preset Locations
      <br/>
      -- Stored Presets        50 presets stored in non-volatile memory
      <br/>
      -- Download              Real time down load of Azimuth, Elevation,
      <br/>
      --                       Field of View, Contrast, Polarity,
      <br/>
      --                       Sensitivity, and Focus
      <br/>
      -- Status (read back when a bi-directional communication link is used)
      <br/>
      -- The following status conditions may preferably be read back on
      <br/>
      -- command: Azimuth, Elevation, Field of View, Contrast, Polarity,
      <br/>
      -- Sensitivity, Focus, Power Supply Voltage, Temperature, Ambient
      <br/>
      -- Light Condition, User Designated Alarm Conditions
      <br/>
      -- Communications Link
      <br/>
      -- Direct Interface      RS-232
      <br/>
      --                       RS-422/485 (optional)
      <br/>
      -- Modem (optional)      Internal 300 Baud to 2400 Baud
      <br/>
      -- Radio (optional)      VHF or UHF Transceiver
    </p>
    <p num="28">
      Although the invention has been described in detail with particular reference to these preferred embodiments, other embodiments can achieve the same results.
      <br/>
      Variations and modifications of the present invention will be obvious to those skilled in the art and it is intended to cover in the appended claims all such modifications and equivalents.
      <br/>
      The entire disclosures of all references, applications, patents, and publications cited above, are hereby incorporated by reference.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A method of military range scoring, the method comprising the steps of:</claim-text>
      <claim-text>a) providing a plurality of imagers capable of viewing a plurality of reference points and impact points for ordinance aimed at the reference points; b) remotely controlling the imagers via a positioner used to aim an imager at a reference point by changing azimuth and elevation of the imager; c) remotely processing and viewing data received from the imagers;</claim-text>
      <claim-text>and d) communicating control information and data between the imagers and remote control means.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. A method of military range scoring, the method comprising the steps of: a) providing a plurality of imagers capable of viewing a plurality of reference points and impact points for ordinance aimed at the reference points, wherein the imagers comprise flux gate compasses used to sense imager horizontal pointing angle, to allow accurate horizontal positioning and status information provided to remote control means; b) remotely controlling the imagers; c) remotely processing and viewing data received from the imagers;</claim-text>
      <claim-text>and d) communicating control information and data between the imagers and the remote control means.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. A method of military range scoring, the method comprising the steps of: a) providing a plurality of imagers capable of viewing a plurality of reference points and impact points for ordinance aimed at the reference points, wherein the imagers comprise inclinometers used to sense imager vertical pointing angle, to allow accurate vertical positioning and status information provided to remote control means; b) remotely controlling the imagers; c) remotely processing and viewing data received from the imagers;</claim-text>
      <claim-text>and d) communicating control information and data between the imagers and the remote control means.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. A method of military range scoring, the method comprising the steps of: a) providing a plurality of imagers capable of viewing a plurality of reference points and impact points for ordinance aimed at the reference points; b) remotely controlling the imagers via a positioner used to aim an imager at a reference point by changing azimuth and elevation of the imager; c) remotely processing and viewing data received from the imagers;</claim-text>
      <claim-text>and d) communicating control information and data between the imagers and remote control means comprising a computer storing imager pointing, setup, and calibration data for multiple reference points, and means for setting imager parameters including field of view, zoom, focus, sensitivity, and contrast.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. A method of military range scoring, the method comprising the steps of: a) providing a plurality of imagers capable of viewing a plurality of reference points and impact points for ordinance aimed at the reference points; b) remotely controlling the imagers; c) remotely processing and viewing data received from the imagers; d) communicating control information and data between the imagers and remote control means;</claim-text>
      <claim-text>and e) automatically scoring proximities of impact points to reference points by causing the remote control means to direct imagers to point at a reference point, reading back calibration data from the imagers, and entering the calibration data into scoring calculations so that manual calibration is not required.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. A method of military range scoring, the method comprising: a) providing a plurality of imagers capable of viewing a plurality of reference points and impact points for ordinance aimed at the reference points; b) remotely controlling the imagers c) processing and viewing data received from the imagers by digitizing a video image and digitally signal processing to determine angular offsets and scoring an impact point from the digitized video image, and without user intervention detecting multiple impacts and scoring impact points;</claim-text>
      <claim-text>and d) communicating control information and data between the imagers and remote control means.</claim-text>
    </claim>
  </claims>
</questel-patent-document>