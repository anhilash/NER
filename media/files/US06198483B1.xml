<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06198483B1.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as first publication">
      <document-id>
        <country>US</country>
        <doc-number>06198483</doc-number>
        <kind>B1</kind>
        <date>20010306</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6198483</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B1</original-publication-kind>
    <application-reference is-representative="YES" family-id="26713330" extended-family-id="42109495">
      <document-id>
        <country>US</country>
        <doc-number>08964655</doc-number>
        <kind>A</kind>
        <date>19971105</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1997US-08964655</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>43166298</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>96465597</doc-number>
        <kind>A</kind>
        <date>19971105</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1997US-08964655</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>US</country>
        <doc-number>3661997</doc-number>
        <kind>P</kind>
        <date>19970130</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1997US-60036619</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010306</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G06F   3/033       20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>3</main-group>
        <subgroup>033</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G06F   3/048       20060101A I20070721RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>3</main-group>
        <subgroup>048</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20070721</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>715848000</text>
        <class>715</class>
        <subclass>848000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>715781000</text>
        <class>715</class>
        <subclass>781000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>715977000</text>
        <class>715</class>
        <subclass>977000</subclass>
      </further-classification>
    </classification-national>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06F-003/0481</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>3</main-group>
        <subgroup>0481</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06F-003/04815</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>3</main-group>
        <subgroup>04815</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06F-003/0485</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>3</main-group>
        <subgroup>0485</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06F-2203/04803</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>2203</main-group>
        <subgroup>04803</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>Y10S-715/977</classification-symbol>
        <section>Y</section>
        <class>10</class>
        <subclass>S</subclass>
        <main-group>715</main-group>
        <subgroup>977</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130518</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>55</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>63</number-of-drawing-sheets>
      <number-of-figures>68</number-of-figures>
      <image-key data-format="questel">US6198483</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Motion user interface</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>ROBERTSON GEORGE G, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5339390</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5339390</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>HOARTY WILLIAM LEO</text>
          <document-id>
            <country>US</country>
            <doc-number>5485197</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5485197</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>LUCAS PETER, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5499330</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5499330</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>ROBERTSON GEORGE G, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5670984</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5670984</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>MACKINLAY JOCK D, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5689287</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5689287</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>HUSICK LAWRENCE A, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5717914</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5717914</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>BARBER RONALD JASON, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5751286</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5751286</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>GANDRE JERRY D</text>
          <document-id>
            <country>US</country>
            <doc-number>5754809</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5754809</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="9">
          <text>HARA HIROYUKI</text>
          <document-id>
            <country>US</country>
            <doc-number>5781175</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5781175</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="10">
          <text>HORVITZ ERIC J, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5880733</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5880733</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>SCANDURA JOSEPH M, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5262761</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5262761</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="12">
          <text>ROBERTSON GEORGE G</text>
          <document-id>
            <country>US</country>
            <doc-number>5333254</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5333254</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="13">
          <text>MILLS MICHAEL, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5513306</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5513306</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="1">
          <text>Cognitive Systems, Ken Launaais, 1995.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="2">
          <text>Video Search Engine/Operating System: A Cognitive Approach to Interface Design, Data Structures &amp; Informational Transfer to the Mind, Ken Launaisl 1995, 1996.</text>
        </nplcit>
      </citation>
    </references-cited>
    <related-documents>
      <related-publication>
        <document-id>
          <country>US</country>
          <doc-number>60/036,619</doc-number>
          <date>19970130</date>
        </document-id>
        <document-id>
          <country>US</country>
          <doc-number>60/036619</doc-number>
          <date>19970130</date>
        </document-id>
      </related-publication>
    </related-documents>
    <parties>
      <applicants>
        <applicant app-type="applicant" sequence="1">
          <addressbook lang="en">
            <name>LAUNAIS KEN</name>
          </addressbook>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Launais, Ken</name>
            <address>
              <address-1>San Francisco, CA, 94122, US</address-1>
              <city>San Francisco</city>
              <state>CA</state>
              <postcode>94122</postcode>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Bayerl, Raymond J.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A data viewing terminal for displaying graphical indices pointing to elements of a database of information in a way that takes into account properties of the human visual perception system so as to maximize the amount of information that the user can absorb.
      <br/>
      The system has an interface with a processor that displays the graphical indices as images moving across a viewing screen.
      <br/>
      The screen is divided into viewing segments, each of which displays graphical indices in motion in a direction predetermined for that segment where the information in at least one pair of adjacent viewing segments moves in anti-parallel directions.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>RELATED APPLICATION DATA</heading>
    <p num="1">The present application claims priority from U.S. Provisional Application No. 60/036,619 filed Jan. 30, 1997 pending, entitled MOTION USER INTERFACE the entirety of which is incorporated herein by reference for all purposes.</p>
    <heading>FIELD OF THE INVENTION</heading>
    <p num="2">This invention relates to the use of a visual interface to enable a user to access data located on computer servers.</p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="3">
      Today's principal commercial computer user interface is the GUI (Graphical User Interface).
      <br/>
      It is based upon two simple user interface elements: the mouse controlled cursor and the pull-down menu.
      <br/>
      These elements have also been used in tandem to enable hypertext linking.
    </p>
    <p num="4">
      The current implementations of a GUI has serious limitations when used to navigate through large databases.
      <br/>
      It presents tree-like structures of file names, file contents and links on the Web.
      <br/>
      In doing so, 95% of the time it presents lists as vertical or horizontal screen displays.
      <br/>
      Just as the graphical format display of telephone books, GUI's tree-structures relegates the user to a tedious search through lists, and lists of lists, reached through only two features: scroll up and down buttons and links.
      <br/>
      In either case, the complete content of the database is not effectively presented and the format soon exhausts the user's attention span, making GUI inefficient at best for speedy navigation and location of desired content.
    </p>
    <p num="5">
      Numerous hierarchical tree-like structures, branching and sub-branching methodologies have been developed to ease this limitation.
      <br/>
      Their common flaw lies in the method of data presentation.
      <br/>
      The method of presentation has but one purpose: the communication of information to the user's mind.
      <br/>
      Thus, the presentation problem should be approached from the point of view of the mind's "information acquirement" abilities.
      <br/>
      A step towards higher cognitive processing should not ignore such information acquirement factors as differentiation, elimination, in-depth analysis and context identification with formal commitment to memory.
    </p>
    <heading>BRIEF DESCRIPTION OF THE INVENTION</heading>
    <p num="6">The present invention does not supplant the usual user interface elements, but provides arrangements of elements presented on the GUI to facilitate the acquisition of information from a small or large database.</p>
    <p num="7">
      The present invention utilizes features of the mind's acquirement patterns to improve the ability to navigate through large databases of images, text or a combination of both.
      <br/>
      In enabling this approach, the inventor avoids having all information presented in a static form, in which once accessed it remains immobile on the page and the screen.
      <br/>
      Hence, navigation for the purpose of a fast visual fly-over analysis of a database's content-terrain is effectuated in the present invention by particular motion of graphical elements on a console.
      <br/>
      Mere motion is not sufficient, however, but as enabled in this invention it takes into account basic principles of the user's mind's viewing patterns.
      <br/>
      The invention avoids the prior art, which merely had the user clicking on a scroll button to pull-down a list or stack-up an array of windows.
      <br/>
      In essence, this motion carefully feeds data to the user in an easily digestible form rather than having the user feeding the data to himself/herself.
      <br/>
      Eliminating this self-feeding process as implemented in the present invention by particular formats designed for easy assimilation is a unique and unprecedented approach.
    </p>
    <p num="8">
      In making the invention, it was found that several categories of information could be viewed simultaneously once the information was put in motion and the self feeding eliminated during a fast visual fly-over analysis.
      <br/>
      Concurrent viewing of two or more sets of information greatly increases the speed with which information acquirement can occur, beyond that already expected by the velocity by the motion.
      <br/>
      Where the increase persists as multiple layers of information are presented to the user, the increase in speed greatly exceeds the speed of data access of conventional methods.
    </p>
    <p num="9">
      Applications for the invention are wide ranging.
      <br/>
      These include any applications where navigation (or browsing) through a large database for the purpose of locating a single piece of data or samples of data is necessary and where the search process calls for selection from strings of data. (Strings of data is defined for our purposes as numerous pieces of information pertaining to a defining category.)
    </p>
    <p num="10">
      A medical imaging application using the invention, as a case in point, might help a student looking for video clips of two specific surgical procedures.
      <br/>
      He/She could utilize the invention to display (in data cells) clips pertaining to key images of each case scenario.
      <br/>
      Those relating to the first procedure could be displayed in motion on a left quadrant and those relating to the second procedure on the right quadrant (FIG. 1).
      <br/>
      Along with the still image of each case scenario, a key title would be superimposed on the image in each data cell.
      <br/>
      The student, with the aid of this invention, can visually skim through 1,000 images for each procedure in just a few minutes� As soon as a data cell arouses his/her attention, the student need only interrupt the flow and through a click of the mouse, enlarge the image, access an in-depth textual description and view the surgical procedure's video clip.
    </p>
    <p num="11">
      The invention can also be applied to electronic shopping where a user wants to search through the hundreds of VCR's and TV sets available at a cybermall.
      <br/>
      The invention can be applied to Video On Demand where a consumer in the near future may browse through an entire video library of a large video store in about 45 minutes, a feat not feasible by physically walking the aisles of an actual large Store.
      <br/>
      The invention can also be used to help a car purchaser search through hundreds or even thousands of options on the World Wide Web.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="12">
      FIG. 1 shows and embodiment in which a screen is divided into quadrants as the location where images are displayed in a Bi-Mode.
      <br/>
      FIG. 2. Shows a Quad-Mode display and the four quadrants location.
      <br/>
      FIG. 3 shows four possible streaming directions for images.
      <br/>
      FIG. 4 shows possible directional flow configurations of image streams in a Bi-Mode display.
      <br/>
      FIG. 5 shows how directional flow settings split a total field of view into two separate fields A &amp; B, or two input channels for the visual cortex.
      <br/>
      FIG. 6 shows an incorrect Bi-Mode directional flow configurations.
      <br/>
      FIG. 7 shows how incorrect Bi-Mode directional flow configurations do not split the total field of view into separate input channels for effective concurrent viewing.
      <br/>
      FIG. 8 shows Quad Mode Directional flow configurations and the resulting split input channels. Config. 11 and Config. 12 show incorrect directional flow settings and the resulting emergence of three input channels.
      <br/>
      FIG. 9 shows a Multiple Cell Mode in a twin channel configuration, Bi-Modal Multiple Cell 1 with central quadrants and cells, adjacent cells, the location of a central field of view, a central window and the correct directional flow configurations for that particular display.
      <br/>
      FIG. 10 is a drawing of the Bi-Modal Multiple Cell 1 display and shows the natural zoom positions that aid in the visual interception of images.
      <br/>
      FIG. 11 is a drawing of a Bi-Modal Multiple Cell 2 display having Parametric Repeat Patterns and Aligned Proximity. The drawing also shows the inverted positioning of an original and duplicate row, adjacent fields of view as established by the Aligned Proximity of image data, and a central field of view.
      <br/>
      FIG. 12 is a drawing of the Bi-Modal Multiple Cell 2 display which shows how a single horizontal input channel is established through a combination of directional flow configurations and original and duplicate row positioning.
      <br/>
      FIG. 13 shows a Bi-Modal Multiple Cell 2 display with incorrect positioning of rows and correct directional flow configurations.
      <br/>
      FIG. 14 shows the confusing array of visual fields established by incorrect positioning of rows and correct directional flow configurations, namely two pair of vertical input channels (A;B, C;D) and two pairs of vertical input channels (I;I, II;II).
      <br/>
      FIG. 15 shows the initial Parametric Mode Lay-out.
      <br/>
      FIG. 16 shows the directional flow configurations for Quad-Mode Multiple Cell 1.
      <br/>
      FIG. 17 shows the directional flow configurations for Quad-Mode Multiple Cell 2 and Quad-Mode Multiple Cell 2A displays along with the correct positioning of original and duplicate rows for each directional flow configuration.
      <br/>
      FIG. 18 shows a Bi-Modal Multiple Cell display with a Visual Tag Search (VST) along with the explicit manifestation of a Visual Tag as inserted in bounded channels.
      <br/>
      FIG. 19 shows a Visual Tag Search (VST) in a "Tag User-Induced Access Mode" with the establishment of a third horizontal image channel.
      <br/>
      FIG. 20 shows the Initial Piano Quad-Mode Layout.
      <br/>
      FIG. 21 shows an 8-step "jump-flip" sequence within a Quad-Mode Piano Sequence.
      <br/>
      FIG. 22 shows a Quad-Mode Multiple Cell 1 display with Dim Luminance Zones.
      <br/>
      FIG. 23 shows the initial Bi-Mode layout along with a slide-view of individual image cells.
      <br/>
      FIG. 24 shows a half panel view corresponding to FIG. 23.
      <br/>
      FIG. 25 shows a Bi-Mode layout when a picture on the right channel is selected.
      <br/>
      FIG. 26 shows a bi-Mode layout when the Text Description button is pressed (Right Channel picture selected).
      <br/>
      FIG. 27 shows a Bi-Mode layout when a picture on the left channel is selected.
      <br/>
      FIG. 28 shows a Bi-Mode layout when the Text Description button is pressed (Left Channel picture selected).
      <br/>
      FIG. 29, Bi-Mode--Main Routine: shows the overview of how the Bi-mode works.
      <br/>
      This is where execution begins.
      <br/>
      FIG. 30, Initialize: shows the preparations needed to run the Bi-Mode.
      <br/>
      FIG. 31, Stream Pictures: shows the overview of how streaming works in the Bi-Mode.
      <br/>
      FIG. 32, Initialize Left Side for Stream Motion: shows the necessary preparations to stream the left channel.
      <br/>
      FIG. 33, Initialize Right Side for Stream Motion: shows the necessary preparations to stream the right channel.
      <br/>
      FIG. 34, Stream Left Slide View: shows how the left channel slide view is streamed.
      <br/>
      FIG. 35, Stream Right Slide View: shows how the right channel slide view is streamed.
      <br/>
      FIG. 36, Stream Left Main Warped View: shows how the left channel perspective is streamed.
      <br/>
      FIG. 37, Stream Right Main Warped View: shows how the right channel perspective is streamed.
      <br/>
      FIG. 38, Initialize NLTPI &amp; LCCP (up): shows how to determine the next picture to show when the right channel slide view is streaming up.
      <br/>
      FIG. 39, Initialize NRTPI &amp; RCCP (up): shows how to determine the next picture to show when the left channel slide view is streaming down.
      <br/>
      FIG. 40, Initialize NLTPI &amp; LCCP (down): shows how to determine the previous picture to show when the right channel slide view is streaming down.
      <br/>
      FIG. 41, Initialize NRTPI &amp; RCCP (down): shows how to determine the previous picture to show when the right channel slide view is streaming down.
      <br/>
      FIG. 42, Poll User Input: shows the overview of polling for user inputs, such as double clicking on a picture to enter full view and text view.
      <br/>
      FIG. 43, Process Left Channel Inputs: shows how user inputs on the left channel are processed.
      <br/>
      FIG. 44, Process Right Channel Inputs: shows how user inputs on the right channel are processed.
      <br/>
      FIG. 45, Process Left Full View Inputs: shows how user inputs are processed when the user has clicked on a picture on the right channel and entered full view mode.
      <br/>
      FIG. 46, Process Right Full View Inputs: shows how user inputs are processed when the user has clicked on a picture on the left channel and entered full view mode.
      <br/>
      FIG. 47, Process Left Text View Inputs: shows how user inputs are processed when the user has clicked on the Show Text Description button on the right channel and entered the full view mode on the left channel.
      <br/>
      FIG. 48, Process Right Text View Inputs: shows how user inputs are processed when the user has clicked on the Show Text Description button on the left channel and entered the full view mode on the right channel.
      <br/>
      FIG. 49, Set LCCP to Previous Picture: shows how to determine the previous picture to display on the left channel.
      <br/>
      FIG. 50, Set LCCP to Next Picture: shows how to determine the next picture to display on the left channel.
      <br/>
      FIG. 51, Set RCCP to Previous Picture: shows how to determine the previous picture to display on the right channel.
      <br/>
      FIG. 52, Set RCCP to Next Picture: shows how to determine the next picture to display on the right channel.
      <br/>
      FIG. 53, Quad Mode Piano Sequenced: shows how the Quad Mode Piano Sequenced works overall. This is where execution begins.
      <br/>
      FIG. 54, Initialize Piano Sequenced Quad Mode: shows the preparations for the Quad Mode Piano Sequenced.
      <br/>
      FIG. 55, Display Picture in a Quadrant: shows how pictures are displayed in the Quad Mode Piano Sequenced.
      <br/>
      FIG. 56, Parametric Mode Definitions: shows the Parametric Mode Definitions.
      <br/>
      FIG. 57, Parametric Mode Main Routine: shows how the overall view of the Parametric Mode, where execution begins.
      <br/>
      FIG. 58, Initialize Parametric Mode: shows the preparations necessary to enter the Parametric Mode.
      <br/>
      FIG. 59, Initialize Data Cells with Pictures: shows all data cells filled with pictures.
      <br/>
      FIG. 60, Stream Left Channel: shows how the left channel is streamed overall.
      <br/>
      FIG. 61, Stream Right Channel: shows how the right channel is streamed overall.
      <br/>
      FIG. 62, Prepare to Stream Left Channel: shows the preparations needed to stream the left-channel.
      <br/>
      FIG. 63, Prepare to Stream Right Channel: shows the preparations needed to stream the right channel.
      <br/>
      FIG. 64, Stream Central Data Cell (Left Channel): shows how the right most picture on the bottom left channel is streamed into central view.
      <br/>
      FIG. 65, Stream Bottom Left Channel: shows how a new picture is streamed into the bottom left channel.
      <br/>
      FIG. 66, Stream Top Left Channel: shows how the same new picture is streamed into the top left channel.
      <br/>
      FIG. 67, Stream Top Right Channel: shows how a new picture is streamed into the top right channel.
      <br/>
      FIG. 68, Stream Bottom Right Channel: shows how the same new picture is streamed into the bottom right channel.
    </p>
    <heading>DETAILED DESCRIPTION OF A PREFERRED EMBODIMENT OF THE PRESENT INVENTION</heading>
    <p num="13">
      The invention, named "MUI" or "Motion User Interface", is a visual interface for action by a user, based on basic cognitive viewing patterns of the mind to allow for faster registration of visual stimuli by the mind.
      <br/>
      The first aspect of the present invention is based on the premise that the mind can assimilate larger quantities of information when differentiated by motion as opposed to a static presentation on paper or on screen.
      <br/>
      Furthermore, when information is presented in motion, not only can larger quantities of data be assimilated, but assimilation also occurs at much higher speed than possible when static.
      <br/>
      The motion used in MUI is based on a continuous and smooth stream, allowing the mind to seamlessly and effortlessly assimilate the data being presented.
      <br/>
      Data can either be pictures, text (images of words) or a combination of both.
    </p>
    <p num="14">
      A second aspect of the MUI invention facilitates simultaneous viewing of concurrent channels of streaming information.
      <br/>
      Several viewing configurations are offered with MUI, wherein each configuration relies on the user's visual cortex interpreting the received images as if only two main input channels are presented.
      <br/>
      This is achieved by setting the stream directions of each quadrant.
      <br/>
      A quadrant refers to a position on the screen where an image is seen (FIG. 1).
    </p>
    <p num="15">
      Preferably the MUI allows two, three and up to four quadrants to be displayed simultaneously (FIGS. 1 &amp; 2).
      <br/>
      These quadrants are displayed simultaneously, and can each hold one picture at a time.
      <br/>
      Each quadrant can stream images in different directions (up, down, left to right or right to left).
      <br/>
      By setting the directional flow of each stream motion in relation to the others (FIG. 3), the user's mind will only acknowledge two main viewing areas (visual cortex input channels) even if there are in fact 2, 3, or 4 concurrent streaming images.
      <br/>
      The MUI's display is preferably rendered in perspective, allowing a reduced width of the field of view through the Y-axis and added depth through the Z-axis.
      <br/>
      Depth via perspective eases the visual separation of streaming images as it is similar to one's physical experience in the real world.
    </p>
    <p num="16">
      There are two Beginner's Modes, the bi-mode and the quad-mode.
      <br/>
      A tri-mode can also be used but for purposes of the invention's description, only bi-modal and quad-mode configurations will be described.
      <br/>
      The principle for a tri-mode or configurations higher than quad-mode remains the same.
      <br/>
      There are also six advanced modes: Bi-Mode Multiple Cell 1, 2 and 2.A.; Quad-Mode Multiple Cell 1, 2 and 2.A; as well as a seventh mode that uses a different motion pattern, the Quad-Mode Piano-Sequence.
      <br/>
      The detailed description of the invention focuses for the most part on illustrating its functioning through the Bi-Mode.
    </p>
    <heading>BI-MODE</heading>
    <p num="17">
      The Bi-mode is preferably implemented on a computer monitor by a digital computer capable of graphical display and presents two quadrants in perspective to the viewer.
      <br/>
      The data displayed may be present on a server or other data storage medium.
      <br/>
      The display is controlled by a processor implementing a user interface algorithm.
      <br/>
      This is the simplest of the viewing modalities and the easiest for viewing-by the untrained user.
    </p>
    <p num="18">Directional flow can be set in four main configurations as shown in FIG. 4:</p>
    <p num="19">Configuration 1: The right quadrant streams from right to left while the left quadrant streams from left to right, in both instances towards the center.</p>
    <p num="20">Configuration 2: The right quadrant streams from left to right while the left quadrant streams from right to left, in both instances away from the center.</p>
    <p num="21">Configuration 3: The right quadrant streams from top to bottom while the left quadrant streams from bottom to top.</p>
    <p num="22">Configuration 4: The right quadrant streams from bottom to top while the left quadrant streams from top to bottom.</p>
    <p num="23">
      The above directional flow configurations result in the user identifying two viewing areas or two input channels A &amp; B (FIG. 5).
      <br/>
      This separation of the field of view allows the user to view two images simultaneously for a short period of time (stream motion speed can be set by the user) before two more images are loaded into the respective quadrants for a same duration.
      <br/>
      Each setting efficiently achieves concurrent viewing--but different users will feel more comfortable with different configurations.
    </p>
    <p num="24">Incorrect configurations of Directional Flow (FIG. 6):</p>
    <p num="25">Configuration 5: Both right and left quadrant stream upward.</p>
    <p num="26">Configuration 6: Both right and left quadrant stream downward.</p>
    <p num="27">Configuration 7: Both right and left quadrant stream from left to right.</p>
    <p num="28">Configuration 8: Both right and left quadrant stream from right to left.</p>
    <p num="29">
      These incorrect settings will not have the effect of splitting the field of view into two viewing areas or two input channels for the user but will instead lead to the user acknowledging two sets of information--2 images--in a single viewing area (FIG. 7).
      <br/>
      Since the information is moving, the user must struggle to identify each set separately (one after the other) and the greater the speed, the more difficult it becomes.
      <br/>
      After a while, the mind loses the benefit of the stream and for every ten pictures, only three are effectively identified.
      <br/>
      A good example is the NYSE stock quote display or Cable TV's Preview Channel.
      <br/>
      The average-viewer gets lost in the flow of information.
      <br/>
      However, these displays are somewhat effective when the viewer is looking for specific information--either a specific quote or show rather than viewing the overall content of an entire database.
    </p>
    <p num="30">
      Configuration 5 through 7 have some value if the speed is sufficiently slow and there are only two quadrants presented.
      <br/>
      They are not preferable and are presented merely to illustrate the unique solutions that Configuration 1 through 4 present as concurrent viewing results in a faster registration of higher quantities of data.
    </p>
    <p num="31">
      Additionally, setting the directional flow as per configuration 1 through 4 allows the user to separate the field of view into two distinct viewing areas (FIG. 5), while smoothly assimilating the stream of one image to another in each quadrant.
      <br/>
      This results in the possibility of the user being presented with 2, 3 or 4 concurrent channels of information even though as far as the user is concerned, it is as if he/she was still dealing with just two separate input channels.
    </p>
    <heading>QUAD-MODE</heading>
    <p num="32">
      Just as with the Bi-mode, the Quad-mode (FIG. 2) allows concurrent viewing of several channels of information.
      <br/>
      However, instead of two quadrants, the user is presented with four quadrants, each simultaneously streaming an image into another.
      <br/>
      The principle is the same as previously since each quadrant is set to stream in a particular direction in relation to the others (FIG. 8).
      <br/>
      These settings also result in the user concentrating on just two main viewing areas or input channels.
    </p>
    <p num="33">
      There are 12 directional flow configurations of which 10 effectively result in two main viewing areas while two result in three distinct viewing areas (FIG. 8, Configuration 11 &amp; 12) and are thus less preferable for the user.
      <br/>
      The 12 possible configurations, are depicted in FIG. 8.
    </p>
    <heading>MULTIPLE CELL MODES</heading>
    <p num="34">Multiple Cell Modes are advanced viewing configurations that exponentially increase the number of images that can be seen in the same amount of time as with the regular Bi and Quad-Mode.</p>
    <p num="35">
      Multiple Cell Modes can also be configured in a Bi-Mode, Tri-Mode or Quad-Mode.
      <br/>
      The central quadrants are extended into rows of 3 or 5 cells each revealing an image (FIG. 9) presented in a perspective view,. Hence, a picture "A" would stream into cell 3--the cell furthest away from the central quadrant or cell 1--and remain in that position for a determined amount of time (stream motion speed can be set by the user) before streaming into cell 2.
      <br/>
      This action will continue until the image has reached cell 1.
      <br/>
      By the time picture A has entered cell 1, picture C will be in cell 3 and as it streams into cell 2, picture D will have entered cell 3.
    </p>
    <p num="36">
      The perspective view also plays a significant role in facilitating the identification of data.
      <br/>
      This is true with rows that contain 3 cells or 5 cells. (However, once one starts streaming 2, 3, or 4 rows with 5 cells each, the speed can become overwhelming and embodiments termed "Parametric Repeat Patterns" and "Aligned Proximity" have been developed to solve the problem.
      <br/>
      These embodiments are addressed under "Parametric Repeat Patterns and Aligned Proximity" and it is the third main preferred embodiment of MUI and perhaps the most-useful.)
    </p>
    <p num="37">
      In the case of rows affording a three cell presentation (FIG. 9), the central field of view (located at the center of the overall display) is the focal point where the viewer will be naturally prompted to direct his/her attention. (This natural prompting is enhanced through a feature referred to as "Luminance Zones".) In order to see the whole and acknowledge the images coming in from the furthest point of the 2, 3 or 4 rows, the viewer simply retracts his viewing.
      <br/>
      In essence, the user perceives an enlarged total field of view (FIG. 10).
      <br/>
      It is preferable to retract by zooming out one's eyesight than to zoom in.
      <br/>
      MUI was designed to prompt this action as images entering the central cells 1 of each respective row will then disappear.
      <br/>
      Hence, if one has already identified the images in cell 1 and 2 it is far more logical to zoom out to glimpse at the image in cell 3.
      <br/>
      Furthermore, as the images in cells 3 have already been identified, the viewer already knows from the overall flow of data that those images will instantly find themselves in cells 2 before proceeding to cells 1.
      <br/>
      Hence, the overall flow naturally directs the viewer to zoom out, zoom in, zoom out etc. at will, whenever a particular image has caught his/her interest.
      <br/>
      This action remains valid in the directional flow setting of configuration 2 (FIG. 9, Config.2) as the viewing reflexive methodology is merely inverted from the center to the borders of the display, though it is not preferable from a cognitive standpoint.
    </p>
    <heading>PARAMETRIC REPEAT PATTERNS</heading>
    <p num="38">
      Parametric Repeat Patterns and Aligned Proximity is the third aspect of the MUI invention.
      <br/>
      Parametric Repeat Patterns are applicable to all Multiple Cell Modes but are used mostly in 5 cells per row configurations and are based on duplicating data cells when presented in a display.
      <br/>
      Hence, if an image or set of images streams onto the screen, the same image or set of images will appear simultaneously on the screen at another location.
      <br/>
      Since a Multiple Cell Mode is presented as a row (referred to as the original row), MUI arranges the duplication as a second row (the duplicate row) placed below or above the original row.
      <br/>
      Furthermore, if the original row presents images A through E, the duplicate row would present images E through A. The streams would also run in opposite direction (FIG. 11).
    </p>
    <heading>ALIGNED PROXIMITY</heading>
    <p num="39">
      Aligned Proximity is a direct result of a Parametric Repeat Pattern arrangements and manifests itself when, through the action of streaming images, the images from both original and duplicate row interconnect through a visual alignment in cell 3 of each respective row.
      <br/>
      This has the advantage of enhanced exposure to the specific data cell carried by images that align (FIG. 11).
    </p>
    <p num="40">
      The reasoning behind Parametric Repeat Patterns and Aligned Proximity is as follows.
      <br/>
      In the case where rows of 5 cells are displayed irrespective of the number of channels (2, 3 or 4), the same problem occurs as discussed under "Incorrect Directional Flow" settings in Bi-mode (FIG. 7).
      <br/>
      Although the directional flow for a row runs in relation to the other rows' directional flow, the sheer number of images streaming simultaneously in one row, a number multiplied in a Bi, Tri and Quad Mode, can be overwhelming.
      <br/>
      Indeed, the user will quickly find itself relegated to focusing on a single row's stream of images.
      <br/>
      Hence, the viewer chases a stream of images in one row, desperately attempting to identify every image and focuses on just one single field of view.
      <br/>
      Concurrent viewing of streaming information is no longer achieved and within a short time, the viewer will only identify, for argument's sake, 3 out of 10 images.
    </p>
    <p num="41">
      The solution found was to duplicate the original number of rows.
      <br/>
      MUI still presents the original Bi, Tri and Quad-Mode solutions--not 4, 6 and 8 individual rows--but merely takes the content of each cell in a single row and duplicates it immediately below it or above it depending on the directional flow chosen by the user (FIG. 11).
    </p>
    <p num="42">
      If a row is streaming images A through E in cell 5 through 1, the duplicate row below it will also stream images A through E. However this implementation does not result in any improvement as the viewer is still chasing a stream of images in a single field of view.
      <br/>
      Hence, rather than merely streaming images A through E, the invention inverts the order of the images so that images E through A will stream from cell 1 to cell 5.
      <br/>
      The order of the cells has also been inverted.
      <br/>
      This novel solution achieves two goals (FIG. 11):
    </p>
    <p num="43">
      1. By setting the directional flow in the duplicated row to stream in the opposite direction, MUI has reinstated 2 fields of view for the user.
      <br/>
      Note that in all cases of a Bi-mode, Tri-mode or Quad-mode with five multiple cells, two vertical visual fields A &amp; B have been established along with a single horizontal visual field C and this number is still easily handled by the user as all it need do is switch back and forth at will between the logical input channels to identify the streaming data or zoom out and focus on the total display.
      <br/>
      What the MUI has achieved at this level is essentially to establish a reflexive methodology for the user to switch back and forth between fields of view (FIG. 12).
    </p>
    <p num="44">
      2. Since there is an odd number of cells, inverting the order of images streaming in a pair of rows will lead to the images aligning at the central point of the rows or cell 3 (FIG. 12).
      <br/>
      The MUI's purpose is to further establish an additional point for the viewer to select, an adjacent central field of view, that will naturally call attention to the viewer.
      <br/>
      Hence if image X has caught the attention of the viewer but he/she is more focused on another image, the viewer intuitively knows that he/she can further glimpse and identify the detailed nature of image X when it aligns� parametrically in the position of cell 3, in both the original row and its duplicate, placed below or above, depending on the directional flow chosen.
    </p>
    <heading>BI-MODE MULTIPLE CELL CONFIGURATIONS</heading>
    <p num="45">BI-MODE MULTIPLE CELL 1</p>
    <p num="46">In this embodiment only 3 cells are displayed in each row (FIG. 9).</p>
    <p num="47">Configuration 1: The left row streams from left to right while the right row streams from right to left, both streaming towards the center.</p>
    <p num="48">Configuration 2: The left row streams from right to left while the right row streams from left to right, both streaming away from the center.</p>
    <p num="49">BI-MODE MULTIPLE CELL 2</p>
    <p num="50">This is the most complex of embodiments (FIG. 11 &amp; 12) where each row displays 5 cells and where use of Parametric Repeat Patterns and Aligned Proximity is necessary for concurrent viewing. (This same configuration is also applied to a Tri and Quad-Multiple Cell mode.)</p>
    <p num="51">
      Configuration 1: The right channel comprises two rows, an original placed on top and a duplicate placed below.
      <br/>
      The top "original row"--streaming images A through E positioned in cell 5 through 1 with cell 5 being the furthest away from the center--is set to stream from right to left while the "duplicate row below streams images E through A from left to right through cell 1 through 5, with cell 1 being the furthest away from the center (FIG. 12).
      <br/>
      Conversely, the left channel also comprises two rows with the original row placed below and the duplicate placed above.
      <br/>
      The bottom "original row"--streaming images A through E via cell 5 through 1 with cell 5 being the furthest way from the center is set to stream from right to left while the "duplicate row" above streams the same images E through A from left to right via cell 5 through 1 with cell 1 being the furthest away from the center. (Note that the images A-E in the right row are different than the images A-E in the left row)
    </p>
    <p num="52">Configuration 2: The opposite of configuration 1 (FIG. 12).</p>
    <p num="53">
      It is important to note at this point that with Bi-Mode Multiple Cell 2, the directional flow configurations above achieve concurrent viewing by splitting the total field of view into two vertical pairs of input channels A &amp; B for the visual cortex.
      <br/>
      This is done by placing the original row in one channel directly opposite the other channel original row's position (FIG. 12).
      <br/>
      Hence if the original channel in the left row is the top one, then the original channel in the right row will the be the bottom one and vice versa.
      <br/>
      This establishes the vertical input channels A &amp; B to the visual cortex.
      <br/>
      Since there are two rows per channel, setting the directional flow as per configuration 1 and 2 above, with both original channels in the top position (FIG. 13), would, in effect, result in the viewer having to gaze back and forth between 4 vertical fields of view (FIG. 14, A, B, C and D), one pair above the other while the two horizontal fields of view become the gaze's travel between the top and bottom levels (FIG. 14, 1 and 11).
      <br/>
      Within those two levels, concurrent viewing is achieved by the correct setting of directional flow but complete concurrent viewing for the total display/field of view is not achieved, as shown in the abstracted schematic (FIG. 14).
      <br/>
      By inverting the positions of both original and duplicate channels, the MUI is crisscrossing the paths of two horizontal fields of view, forcing the user to assimilate it as one complete horizontal visual field (FIG. 12).
      <br/>
      Within the context of this complete viewing area, both left and right channels are correctly split into two concurrent pairs of viewing areas or two input channels and not three.
    </p>
    <p num="54">BI-MODE MULTIPLE CELL 1.A.</p>
    <p num="55">
      Bi-Mode Multiple Cell 1.A: Directional flow settings and row positioning follows the logic above, but one difference exists.
      <br/>
      The stream of images in the left channel (or vice versa) will start at time x while the opposite channel, the right channel in this example will start streaming at time y, with time x earlier than time y. This configuration will lead image A of the left channel reaching cell 1--within the original rows--before the right channel's image A reaches cell 1.
      <br/>
      Hence this timing sequence will also allow the viewer to focus his/her attention back and forth between the right and left sides of the display.
    </p>
    <p num="56">
      Finally, as all Multiple Cell modes contain a central window placed in the center of each quadrant, the MUI uses this central window to feed into it each image that reaches cell 1.
      <br/>
      This technique provides an enhanced focal point allowing the viewer to further identify the nature of the image or data, in essence extending the time for visual acquisition.
      <br/>
      Due to the streams starting at different times, reverting to the above scenario would lead the left channel's image Al to reach cell 1 before the right channel's image A2 while feeding image A1 into the central window--allowing for an extra opportunity--just before image A2 coming in from the right channel enters the central window leaving the position of cell 1.
    </p>
    <heading>OUAD-MODE MULTIPLE CELL EMBODIMENTS</heading>
    <p num="57">
      All elements of the Bi-Mode Multiple Cell display features are retained in the Quad-Mode Multiple Cell: Parametric Repeat Patterns are also necessary through the inversion of data cell order, the specific target, positioning of original and duplicate rows is utilized, as is the Aligned Proximity of data cells with all configurations having five cells per row.
      <br/>
      Differential Luminance zones is offered and in the case of Quad-Mode Multiple Cell 2, a configuration whereby the images reaching the central quadrants can enter the central window at timed increments is also offered (Quad-Mode Multiple Cell 2.A).
    </p>
    <p num="58">QUAD-MODE MULTIPLE CELL 1</p>
    <p num="59">
      In this embodiment, three cells per row are utilized and there are no Parametric Repeat Patterns and Aligned Proximity.
      <br/>
      There are 14 directional flow configurations.
      <br/>
      See FIG. 16.
    </p>
    <p num="60">QUAD-MODE MULTIPLE CELL 2</p>
    <p num="61">
      As with the Bi-Mode Multiple Cell 2, this configuration calls for the use of Parametric Repeat Patterns and Aligned Proximity.
      <br/>
      There are four original rows and corresponding duplicate rows, all presenting five data cells and a central window to the viewer.
    </p>
    <p num="62">Positioning of rows follows the same logic as the Bi-Mode Multiple Cell 2, as does the directional flow settings.</p>
    <p num="63">For Directional Flows, please refer to FIG. 17.</p>
    <p num="64">QUAD-MODE MULTIPLE CELL 2.A.</p>
    <p num="65">All settings are the same as those of Quad-Mode Multiple Cell 2 except that a timed sequence is used, as with Bi-Mode Multiple Cell 1.A.</p>
    <heading>QUAD-MODE-PIANO-SEQUENCED</heading>
    <p num="66">
      This particular display methodology is unlike all the others as it utilizes a distinctly different motion pattern, does not require that split fields of views (visual cortex input channels) be established for concurrent viewing--concurrence does not play a role in this particular methodology--and is presented in a flat 2-dimensional display rather than using perspective (FIG. 20).
      <br/>
      The motion is based on a continuous and interconnecting "flip-jump" of images and is effective in a tri-mode, quad-mode and higher configurations.
    </p>
    <p num="67">Four images are presented on a screen in near proximity and laid out so that each image corresponds to the four quadrants set by splitting a square in four.</p>
    <p num="68">
      Image 1 flips-on in the upper left hand quadrant, flip-jumping to the second image on the bottom right quadrant, then proceeding to the bottom left corner and finally flip-jumping back to the upper right quadrant.
      <br/>
      Image 5 flips-on at the starting point of image I--the-upper left quadrant--, flip-jumping to the bottom left quadrant following to the next set position, the upper right quadrant and finalizing the eight step sequence in the bottom right quadrant.
      <br/>
      The sequence will loop again with image 9 until all images in the database have been exhausted or the user has interrupted the motion (FIG. 21).
    </p>
    <p num="69">
      The establishing of these 8 step sequences (which could also be 16 steps or any multiple of the number of quadrants) changes the visual path so that the user is kept naturally alert and attempts to commit the sequence to memory while undergoing the sequence process.
      <br/>
      Eventually, the user knows precisely and almost by second nature where on the screen to set his/her sight.
    </p>
    <p num="70">This process also results in an exponential browsing speed for large numbers of images, such images being pictures, text (images of text) or a combination of both.</p>
    <heading>LUMINANCE ZONES</heading>
    <p num="71">
      The luminance zone feature may be utilized in all cases of a Multiple Cell Mode display at the user's option.
      <br/>
      It simply calls for the central cells to be highlighted by a higher level of luminance than the cells adjoining them in all rows.
      <br/>
      The adjacent cells 2 through 5 are dimmed by a shaded zone (FIG. 22).
      <br/>
      By differentiating the central cell with a higher level of luminance, the MUI directs the user's attention to the central field of view where central quadrants are located and where images will be afforded a last chance for identification. (Note however, that the user may revert to classic scroll features to backtrack a stream or an "Interrupt Flow" button should his/her attention to a specific image warrant a complete interruption or a backtracking motion of the stream.)
    </p>
    <p num="72">
      In the case of Multiple Cell Mode configurations where five cells per row are displayed and where the setting is in "Parametric Repeat Pattern and Aligned Proximity", a third and intermediate level of luminance is used.
      <br/>
      It differentiates the field of view at the center of the display, the positions of image alignment in each row--adjacent central field of views--and the total overall display which would be the dimmest of all luminance zones.
    </p>
    <heading>VISUAL TAG SEARCH</heading>
    <p num="73">
      In searching through large databases, a user may be offered the use of a textual search engine to filter the data by the computer so that only information of particular interest is either returned or accessed for viewing and analysis.
      <br/>
      Visual Tag Search incorporates the idea of further defining a search but does so in a strictly visual format.
      <br/>
      It differs significantly from the textual search engine since unlike the textual search engine it actively involves the user in the search of specific information in a MUI environment.
    </p>
    <p num="74">Textual search engines rely on one or several text boxes for entry of user-defined parameters (in certain cases those parameters are pre-defined) after which the search process is autonomous until data that matches the parameters is located by the engine and displayed for the user to analyze.</p>
    <p num="75">
      Visual Tag searches also rely at the initial user setting level on user defined or pre-defined parameters.
      <br/>
      Once this step is taken, motion based visual tags displayed on a bounded channel will appear above data cells that match the parameters, thus visually signaling the user (FIG. 18).
      <br/>
      Once the visual tag has entered the visual field's orbit, the specific motion used inside the bounded channel will distinguish itself from the regular stream motion, communicating to the user that further action may be taken, an action herein described as "Tag user induced access mode" (FIG. 19).
    </p>
    <p num="76">
      To further understand how a Visual Tag Search operates, a case scenario is presented: A user elects to view a shopping catalog through the Bi-Mode Multiple Cell 1 configuration to look for TV's and VCR'S.
      <br/>
      In choosing all of the assignment settings--directional flow of stream motion, speed, assignment of categories to left and right row--the MUI offers the user the possibility of further refining the search in the categories chosen.
      <br/>
      The user assigns a Visual Tag to the definition of "TV's &amp; VCR's in the less than $500 range".
      <br/>
      When, as described above, the Visual Tag enters the visual field's orbit, i.e., above the right row, the user's perception of a VCR image in cell 2 indicates that this particular product falls under the parameter of "less than $500".
      <br/>
      At this juncture, the user may click on the image to interrupt the flow and access the in-depth textual description of the product--model -, order -, features etc.--or the user may click on the Visual Tag itself launching it into "Tag User Induced Access Mode", an action which summons the MUI to open a vertical row below cell 2 and present an image stream of all other VCR's that pertain to the set parameter (FIG. 19).
      <br/>
      Note that the regular stream motion of the right and left horizontal rows is at a standstill allowing the user to focus instead on the newly opened vertical row of streaming images.
    </p>
    <p num="77">DESCRIPTION OF MOTION IN VISUAL TAG SEARCH (VTS) CHANNEL</p>
    <p num="78">
      The motion utilized in the VTS channel depends on a streak motion effect.
      <br/>
      Thin lines streak at very high speed, running parallel to the channels bounding (enclosing) frame.
      <br/>
      When an image below the VTS channel matches the VTS defining parameter, the actual tag also reveals its own and distinctive stream motion while surrounded by the streak of thin lines.
      <br/>
      The tag itself may display frantically zigzagging lines, streaming perpendicular to the original streak motion effect (FIG. 18).
    </p>
    <p num="79">
      Such dramatic visual motions-are not to be mistaken for mere special effects, since their visual communicative values are calculated.
      <br/>
      The MUI presents an environment where most elements are in perpetual motion, motions that become effective for the user at very high speeds.
      <br/>
      As images occupy a prominent if not the most prominent position in the overall display, the VTS channel must rely on a visual methodology that is unobtrusive most of the time except when it must signal the user.
      <br/>
      The frantically zigzagging lines running perpendicular to the streak motion lines represent a striking opposite of value, thus rendering them effective.
    </p>
    <heading>SLIDE VIEW</heading>
    <p num="80">
      Slide View (FIG. 23) is a feature used in the beginner's Bi and Quad Mode which displays a slide view on the side of the respective quadrants with 4 or 5 mini-data cells, each equivalent to an image that is either in position in a quadrant, has just left the quadrant's position or is about to enter the quadrant's position.
      <br/>
      It allows the user to see the outgoing or incoming images and further establish a visual location of an image in relation to others.
      <br/>
      A Slide View will also move the mini-data cells in relation to the streaming images inside the quadrants.
    </p>
    <p num="81">
      Although the invention has been described in terms of its preferred embodiments, it is not intended that it be limited to these specific embodiments.
      <br/>
      Instead the invention is to be construed as broadly as is legally permitted as defined by the following claims.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>I claim:</claim-text>
      <claim-text>1. A data viewing terminal for displaying graphical indices corresponding to elements of a database of information, said terminal interfacing with a processor that displays said graphical indices as images moving across a viewing screen,</claim-text>
      <claim-text>said screen divided into a plurality of viewing segments, each viewing segment displaying said graphical indices in motion in a direction predetermined for said segment, such that the graphical indices in at least one pair of adjacent viewing segments move in opposing directions;</claim-text>
      <claim-text>and means for selecting one of said graphical indices; wherein said viewing segments are configured and said graphical indices are moving such that two input channels are presented to a visual cortex of a user.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The data viewing terminal for displaying graphical indices of claim 1, wherein each viewing segment has an apparent perspective vanishing point such that the motion of each image moves towards and decreases in size as it approaches the vanishing point of the segment.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The data viewing terminal for displaying graphical indices of one of claims 1 or 2 in which there are at least four viewing segments arranged of which three have graphical indices flowing in parallel directions and a fourth opposing direction.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The data viewing terminal for displaying graphical indices of one of claims 1 or 2 in which there are at least four viewing segments arranged so that there are two pairs of viewing areas having graphical indices flowing parallel within each pair and in opposing directions as between pairs.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. A data viewing terminal for displaying graphical indices corresponding to elements of a database of information, said terminal interfacing with a processor that displays said graphical indices as images moving across a viewing screen, said screen divided into a plurality of viewing segments comprising left and right rows narrowing in perspective towards a central region, each viewing segment displaying graphical indices in motion towards said central region, such that the graphical indices in each viewing segment are present for a predetermined time before moving into the next adjacent segment;</claim-text>
      <claim-text>and means for selecting one of said graphical indices.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The data viewing terminal of claim 5, wherein the viewing terminal has an outer edge and motion of the segments towards a central vanishing point causes the viewer to view the outer edges of the data viewing terminal, whereby graphical indices at the outer edges are focused upon by the user.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. The data viewing terminal for displaying graphical indices of claim 5 wherein each of said viewing segments comprises a parametric repeat pattern of identical pairs of graphical indices in reverse linear order, each pair comprising two elements moving in anti-parallel motion.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. A data viewing terminal for displaying graphical indices corresponding to elements of a database of information, said terminal interfacing with a processor that displays said graphical indices as images moving across a viewing screen, said screen divided into a plurality of viewing segments comprising left and right rows broadening in perspective towards a central region, each viewing segment displaying graphical indices in motion towards said central region, such that the graphical indices in each viewing segment are present for a predetermined time before moving into the next adjacent segment;</claim-text>
      <claim-text>and means for selecting one of said graphical indices; wherein said viewing segments are configured and said graphical indices are moving such that two input channels are presented to a visual cortex of a user.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. A data viewing terminal for displaying graphical indices corresponding to elements of a database of information, said terminal interfacing with a processor that displays said graphical indices as images moving across a viewing screen, said screen divided into at least four quadrants of viewing segments in which said graphical indices stream in parallel or anti-parallel directions, wherein at least one pair of adjacent elements moves antiparallel to an adjacent stream;</claim-text>
      <claim-text>and means for selecting one of said graphical indices; wherein said viewing segments are configured and said graphical indices are moving such that two input channels are presented to a visual cortex of a user.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. The data viewing terminal of claim 9 in which only one quadrant has a graphical stream that move antiparallel to the remaining graphical streams.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. The data viewing terminal of claim 9 in which two quadrants have graphical streams that move antiparallel to the remaining graphical streams.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. A data viewing terminal for displaying graphical indices corresponding to elements of a database of information, said terminal interfacing with a processor that displays said graphical indices as images moving across a viewing screen, said screen divided into multiple cells of viewing segments having a perspective converging to a central portion of the screen, wherein the graphical images within each segment move toward said central portion;</claim-text>
      <claim-text>and means for selecting one of said graphical indices.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. A data viewing terminal for displaying graphical indices corresponding to elements of a database of information, said terminal interfacing with a processor that displays said graphical indices as images moving across a viewing screen, said screen divided into multiple cells of viewing segments, wherein a plurality of said graphical indices are repeated in different cells and the motion of streams of said indices brings identical indices together during a portion of their motion;</claim-text>
      <claim-text>and means for selecting one of said graphical indices.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. The data viewing terminal for displaying graphical indices of one of claims 1,2 and 5-13, wherein said viewing screen comprises one or more regions comprising luminance zones in which images are distinguished by color from indices outside said luminance zones.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. A data viewing terminal for enabling a user to display graphical indices corresponding to elements of a database of information, said terminal interfacing with a processor that displays said graphical indices as images moving across a viewing screen, said screen divided into multiple cells of viewing segments, wherein each cell is associated with a visual tag region moving in opposite directions, said tag regions each comprising one of at least first and second types, said second type being associated with cells having content that matches predefined parameters;</claim-text>
      <claim-text>and said visual tag regions being associated with said second tag type being selectable by the user.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. The data viewing terminal of claim 15, wherein said first type of tag comprises streaming lines and said second type of tag comprises a zig-zag pattern.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. The data viewing terminal of claim 15, wherein said second tag type upon selection by the user acts as a trigger to expand its associated visual segment to open further visual segments.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. The data viewing terminal of claim 17, wherein said further visual segments comprise a vertical row of segments.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. A data viewing terminal for enabling a user to display graphical indices corresponding to elements of a database of information, said terminal interfacing with a processor that displays said graphical indices as images moving across a viewing screen, said screen divided into a piano view of multiple cells of viewing segments that converge to a central portion of the screen, wherein said segments display information in a preset temporal sequence such that the order in which information is displayed to the different segments repeats in a regular sequence or series of sequences, wherein said regular sequence or series of sequences are configured such that the visual cortex of a user can recognize the visual pattern of the regular sequence or series of sequences.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. A data viewing terminal for enabling a user to display graphical indices corresponding to elements of a database of information, said terminal interfacing with a processor that displays said graphical indices as images moving across a viewing screen, said screen divided into quadrants and aligned mini-data cells, each mini-data cell comprising a reduced copy of a corresponding image present in a quadrant or adjacent to a quadrant, and such that the central mini-cell is equivalent to an image in a quadrant, and the central cell's adjacent mini-cells are equivalent to images that have already been displayed or are about to be displayed in a quadrant.</claim-text>
    </claim>
    <claim num="21">
      <claim-text>21. The data viewing terminal for enabling a user to display graphical indices of claim 20, wherein said mini-data cells contain information corresponding to streaming information within the quadrants.</claim-text>
    </claim>
    <claim num="22">
      <claim-text>22. A computer program product for presenting a plurality of images on a display, comprising: at least one computer readable medium; computer program instructions embodied in the at least one computer readable medium for a causing a computer to:</claim-text>
      <claim-text>- present a first subset of the plurality of images in a first viewing area of the display, each of the first subset of images moving in a first direction;</claim-text>
      <claim-text>and - present a second subset of the plurality of images in a second viewing area of the display, each of the second subset of images moving in a second direction; - wherein the first and second viewing areas are configured and the images are moving such that two input channels are presented to a visual cortex of a user.</claim-text>
    </claim>
    <claim num="23">
      <claim-text>23. The computer program product of claim 22 wherein the first and second directions are opposite each other.</claim-text>
    </claim>
    <claim num="24">
      <claim-text>24. The computer program product of claim 23 wherein the first and second directions are toward a central region of the display.</claim-text>
    </claim>
    <claim num="25">
      <claim-text>25. The computer program product of claim 23 wherein the first and second directions are away from a central region of the display.</claim-text>
    </claim>
    <claim num="26">
      <claim-text>26. The computer program product of claim 23 wherein the first direction is toward a top edge of the display and the second direction is toward a bottom edge of the display.</claim-text>
    </claim>
    <claim num="27">
      <claim-text>27. The computer program product of claim 22 wherein the computer program instructions further cause the computer to: present a third subset of the plurality of images in a third viewing area of the display, each of the third subset of images moving in a third direction;</claim-text>
      <claim-text>and present a fourth subset of the plurality of images in a fourth viewing area of the display, each of the fourth subset of images moving in a fourth direction; wherein the first, second, third and fourth viewing areas are configured such that two input channels are presented to a user's visual cortex.</claim-text>
    </claim>
    <claim num="28">
      <claim-text>28. The computer program product of claim 27 wherein the first and second directions are opposite each other and the third and fourth directions are opposite each other.</claim-text>
    </claim>
    <claim num="29">
      <claim-text>29. The computer program product of claim 27 wherein the first and second directions are opposite each other and the third and fourth directions are the same.</claim-text>
    </claim>
    <claim num="30">
      <claim-text>30. The computer program product of claim 22 wherein each of the first and second viewing areas comprises an image region which narrows in aspect toward a central region of the display, the first and second subsets of images moving in their respective image regions.</claim-text>
    </claim>
    <claim num="31">
      <claim-text>31. The computer program product of claim 30 wherein each image region provides perspective views of the images therein, selected ones of the plurality of images being further toward the central region than others of the plurality of images and therefore appearing farther away than the others of the plurality of images.</claim-text>
    </claim>
    <claim num="32">
      <claim-text>32. The computer program product of claim 22 wherein each of the first and second viewing areas comprises an image region which is two-dimensional in appearance.</claim-text>
    </claim>
    <claim num="33">
      <claim-text>33. The computer program product of claim 22 wherein movement of the first and second subsets of images appears smooth to the user's visual cortex.</claim-text>
    </claim>
    <claim num="34">
      <claim-text>34. The computer program product of claim 22 wherein each of the first and second viewing areas comprises a plurality of image regions which move across the display in the first and second viewing areas in the first and second directions, respectively.</claim-text>
    </claim>
    <claim num="35">
      <claim-text>35. The computer program product of claim 34 wherein the computer program instructions further cause the computer to present each of the first and second subsets of images in a corresponding image region in the first and second viewing areas, each of the image regions periodically stopping for a predetermined period of time.</claim-text>
    </claim>
    <claim num="36">
      <claim-text>36. The computer program product of claim 34 wherein the computer program instructions further cause the computer to present each of the first and second subsets of images in a corresponding image region in the first and second viewing areas, each of the image regions appearing to the user's visual cortex to move smoothly across the display.</claim-text>
    </claim>
    <claim num="37">
      <claim-text>37. The computer program product of claim 22 wherein the computer program instructions further cause the computer to: present first duplicates of the first subset of images in the first viewing area, each of the first duplicates moving in a third direction opposite the first direction;</claim-text>
      <claim-text>and present second duplicates of the second subset of images in the second viewing area, each of the second duplicates moving in a fourth direction opposite the second direction.</claim-text>
    </claim>
    <claim num="38">
      <claim-text>38. The computer program product of claim 37 wherein movement of the images and their duplicates causes each image to be presented adjacent its duplicate in a central portion of the viewing area in which each image is presented.</claim-text>
    </claim>
    <claim num="39">
      <claim-text>39. The computer program product of claim 22 wherein each of the first and second viewing areas comprises a first region having an increased luminance relative to a remaining portion of the viewing area thereby highlighting images in the first region.</claim-text>
    </claim>
    <claim num="40">
      <claim-text>40. The computer program product of claim 22 wherein the computer program instructions further cause the computer to visually identify at least one of the plurality of images in at least one of the first and second viewing areas according to at least one user specified criterion.</claim-text>
    </claim>
    <claim num="41">
      <claim-text>41. The computer program product of claim 40 wherein visual identification of the at least one of the plurality of images is effected by augmenting the at least one of the plurality of images.</claim-text>
    </claim>
    <claim num="42">
      <claim-text>42. The computer program product of claim 40 wherein the computer program instructions further cause the computer to present a visual tag region adjacent the images in each of the first and second viewing areas, the visual tag region having a particular characteristic when adjacent the at least one of the plurality of images.</claim-text>
    </claim>
    <claim num="43">
      <claim-text>43. The computer program product of claim 42 wherein the computer program instructions further cause the computer to enable the user to view an additional stream of images relating to the at least one of the plurality of images.</claim-text>
    </claim>
    <claim num="44">
      <claim-text>44. The computer program product of claim 43 wherein the additional stream of images is presented in response to the user selecting the at least one of the plurality of images.</claim-text>
    </claim>
    <claim num="45">
      <claim-text>45. The computer program product of claim 22 wherein the computer program instructions further cause the computer to: provide a first image region in the first viewing area in which the first subset of images moves and second image region in the second viewing area in which the second subset of images moves; provide a first slide view region in the first viewing area, the first slide view region presenting selected ones of the first subset of images;</claim-text>
      <claim-text>and provide a second slide view region in the second viewing area, the second slide view region presenting selected ones of the second subset of images.</claim-text>
    </claim>
    <claim num="46">
      <claim-text>46. The computer program product of claim 45 wherein the selected ones of the first subset of images comprises images currently moving through the first image region, images about to enter the first image region, and images which recently left the first image region, and wherein the selected ones of the second subset of images comprises images currently moving through the second image region, images about to enter the second image region, and images which recently left the first second region.</claim-text>
    </claim>
    <claim num="47">
      <claim-text>47. The computer program product of claim 45 wherein the first slide view region presents more of the first subset of images than the first image region, and wherein the second slide view region presents more of the second subset of images than the second image region.</claim-text>
    </claim>
    <claim num="48">
      <claim-text>48. A method for transmitting computer program instructions from a server to a remote device via a wide area network, comprising: storing computer program instructions in a memory associated with the server, the computer program instructions being for causing a computer to: - present a first subset of the plurality of images in a first viewing area of the display, each of the first subset of images moving in a first direction;</claim-text>
      <claim-text>and - present a second subset of the plurality of images in a second viewing area of the display, each of the second subset of images moving in a second direction; - wherein the first and second viewing areas are configured and the images are moving such that two input channels are presented to a user's visual cortex;</claim-text>
      <claim-text>and transmitting the computer program instructions from the server to the remote device.</claim-text>
    </claim>
    <claim num="49">
      <claim-text>49. A computer implemented method for presenting a plurality of images on a display, comprising: presenting a first subset of the plurality of images in a first viewing area of the display, each of the first subset of images moving in a first direction;</claim-text>
      <claim-text>and presenting a second subset of the plurality of images in a second viewing area of the display, each of the second subset of images moving in a second direction; wherein the first and second viewing areas are configured and the images are moving such that two input channels are presented to a user's visual cortex.</claim-text>
    </claim>
    <claim num="50">
      <claim-text>50. The method of claim 49 wherein the plurality of images are transmitted to a computer associated with the display from a remote platform via a wide area network, the computer having a computer readable medium in which computer program instructions for performing the method are stored.</claim-text>
    </claim>
    <claim num="51">
      <claim-text>51. The method of claim 49 wherein the plurality of images are transmitted to a computer associated with the display from a remote platform via a wide area network, the remote platform having a computer readable medium in which computer program instructions for performing the method are stored.</claim-text>
    </claim>
    <claim num="52">
      <claim-text>52. A computer, comprising: memory; a processor;</claim-text>
      <claim-text>and a display; wherein computer program instructions are stored in the memory for causing the processor to: - present a first plurality of images in a first viewing area of the display, each of the first plurality of images moving in a first direction;</claim-text>
      <claim-text>and - present a second plurality of images in a second viewing area of the display, each of the second plurality of images moving in a second direction; - wherein the first and second viewing areas are configured and the images are moving such that two input channels are presented to a user's visual cortex.</claim-text>
    </claim>
    <claim num="53">
      <claim-text>53. A computer program product for presenting a plurality of images on a display, comprising: at least one computer readable medium; computer program instructions embodied in the at least one computer readable medium for a causing a computer to: - present a first subset of the plurality of images in a first viewing area of the display, each of the first subset of images moving within a first image region in a first direction;</claim-text>
      <claim-text>and - present a second subset of the plurality of images in a second viewing area of the display, each of the second subset of images moving within second image region in a second direction opposing the first direction; - wherein each of the first and second image regions narrows in aspect toward a central region of the display and provides perspective views of the images therein, and wherein the first and second viewing areas are configured and the images are moving such that two input channels are presented to a visual cortex of a user.</claim-text>
    </claim>
    <claim num="54">
      <claim-text>54. A computer program product for presenting a plurality of images on a display, the display being divided into a plurality of viewing regions, the computer program product comprising: at least one computer readable medium; computer program instructions embodied in the at least one computer readable medium for a causing a computer to: - sequentially presenting a first subset of the plurality of images in the viewing regions according to a first pattern; - after presenting the first subset, sequentially presenting a second subset of the plurality of images in the viewing regions according to a second pattern;</claim-text>
      <claim-text>and - alternating between the first and second patterns for successive subsets of the images.</claim-text>
    </claim>
    <claim num="55">
      <claim-text>55. The computer program product of claim 54 wherein the display is divided into four viewing regions including an upper and lower left viewing regions and upper and lower right viewing regions, the first, second and successive sets each including four of the plurality of images, the first pattern being upper left, lower right, lower left, upper right, and the second pattern being upper left, lower left, upper right, lower right.</claim-text>
    </claim>
  </claims>
</questel-patent-document>