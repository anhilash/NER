<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06184915B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06184915</doc-number>
        <kind>B2</kind>
        <date>20010206</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6184915</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="16141883" extended-family-id="21392013">
      <document-id>
        <country>US</country>
        <doc-number>08890648</doc-number>
        <kind>A</kind>
        <date>19970709</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1997US-08890648</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>21939888</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>JP</country>
        <doc-number>18378496</doc-number>
        <kind>A</kind>
        <date>19960712</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1996JP-0183784</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010206</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>B41J  29/38        20060101AFI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>B</section>
        <class>41</class>
        <subclass>J</subclass>
        <main-group>29</main-group>
        <subgroup>38</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>B41J   2/525       20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>B</section>
        <class>41</class>
        <subclass>J</subclass>
        <main-group>2</main-group>
        <subgroup>525</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>G06T   7/00        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>7</main-group>
        <subgroup>00</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>H04N   1/00        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>00</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="5">
        <text>H04N   1/46        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>46</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="6">
        <text>H04N   1/60        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>60</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>347251000</text>
        <class>347</class>
        <subclass>251000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>347240000</text>
        <class>347</class>
        <subclass>240000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>347247000</text>
        <class>347</class>
        <subclass>247000</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>358001900</text>
        <class>358</class>
        <subclass>001900</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>358504000</text>
        <class>358</class>
        <subclass>504000</subclass>
      </further-classification>
      <further-classification sequence="5">
        <text>358534000</text>
        <class>358</class>
        <subclass>534000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>H04N-001/60F3B</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>001</main-group>
        <subgroup>60F3B</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-001/6055</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>6055</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>25</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>18</number-of-drawing-sheets>
      <number-of-figures>22</number-of-figures>
      <image-key data-format="questel">US6184915</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Image processing apparatus and method</invention-title>
    <references-cited>
      <citation srep-phase="applicant">
        <patcit num="1">
          <text>ABE SHUNICHI</text>
          <document-id>
            <country>US</country>
            <doc-number>4888636</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4888636</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="2">
          <text>HANEDA SATOSHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4959669</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4959669</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="3">
          <text>JOHNSON STEPHEN E</text>
          <document-id>
            <country>US</country>
            <doc-number>5053866</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5053866</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="4">
          <text>MORI TETSUZO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5060059</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5060059</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="5">
          <text>CHAN C S</text>
          <document-id>
            <country>US</country>
            <doc-number>5107332</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5107332</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="6">
          <text>SAVATIER TRISTAN, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5136371</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5136371</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="7">
          <text>USAMI AKIHIRO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5142356</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5142356</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="8">
          <text>SAKAI MASANORI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5166786</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5166786</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="9">
          <text>COLLETTE ROBERT P, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5172224</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5172224</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="10">
          <text>SAITO HIROYUKI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5175633</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5175633</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>ABE SHUNICHI</text>
          <document-id>
            <country>US</country>
            <doc-number>5191361</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5191361</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="12">
          <text>MORONAGA KENJI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5229864</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5229864</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="13">
          <text>KOIKE KEIICHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5237401</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5237401</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="14">
          <text>SASANUMA NOBUATSU, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5258783</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5258783</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="15">
          <text>AKUZAWA YOSHIHIDE, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5331441</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5331441</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="16">
          <text>SETO KAORU, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5379126</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5379126</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="17">
          <text>KASHIHARA ATSUSHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5386302</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5386302</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="18">
          <text>AMEMIYA KOJI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5414531</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5414531</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="19">
          <text>USAMI AKIHIRO</text>
          <document-id>
            <country>US</country>
            <doc-number>5434645</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5434645</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="20">
          <text>MAEKAWA SHINICHIRO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5446550</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5446550</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="21">
          <text>NAKAZAWA TAMOTSU</text>
          <document-id>
            <country>US</country>
            <doc-number>5463700</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5463700</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="22">
          <text>YAMADA OSAMU, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5489998</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5489998</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="23">
          <text>IKEDA YUICHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5566372</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5566372</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="24">
          <text>SASANUMA NOBUATSU</text>
          <document-id>
            <country>US</country>
            <doc-number>5572330</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5572330</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="25">
          <text>USAMI AKIHIRO</text>
          <document-id>
            <country>US</country>
            <doc-number>5608549</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5608549</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="26">
          <text>NEC CORP</text>
          <document-id>
            <country>JP</country>
            <doc-number>S61248668</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP61248668</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Canon Kabushiki Kaisha</orgname>
            <address>
              <address-1>Tokyo, JP</address-1>
              <city>Tokyo</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>CANON</orgname>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Atsumi, Tetsuya</name>
            <address>
              <address-1>Susono, JP</address-1>
              <city>Susono</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Sasanuma, Nobuatsu</name>
            <address>
              <address-1>Mishima, JP</address-1>
              <city>Mishima</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="3">
          <addressbook lang="en">
            <name>Ikeda, Yuichi</name>
            <address>
              <address-1>Numazu, JP</address-1>
              <city>Numazu</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="4">
          <addressbook lang="en">
            <name>Saito, Yasuhiro</name>
            <address>
              <address-1>Susono, JP</address-1>
              <city>Susono</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Fitzpatrick, Cella, Harper &amp; Scinto</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Le, N.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      An image forming apparatus forms an image on a medium by using an output device.
      <br/>
      A pattern signal for forming a predetermined pattern image on the medium is generated, and image forming parameters for the output device are determined on the basis of the density of the pattern image formed on the medium.
      <br/>
      The determined image forming parameters are transmitted via bidirectional communication to an external computer or other image forming apparatus.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">The present invention relates to an image processing apparatus having a function for compensating for characteristics of an output device and an image processing method.</p>
    <p num="2">
      Recently, a color image forming apparatus which forms a color image on a recording medium on the basis of information of a color original image displayed on a color CRT display has been used in computerized offices.
      <br/>
      As examples of color image forming apparatuses, there are a copying machine and a printer adopting an electrophotographic method.
      <br/>
      Such copying machine and printer have excellent color reproduction, therefore, they are widely used in a field which requires faithful color reproduction of an original image, such as the field of designing and the field of image processing.
    </p>
    <p num="3">
      Further, the color gamut in chromaticness and lightness of an original image displayed on a color CRT display generally does not match the color gamut of a printed image formed by the above image forming apparatuses.
      <br/>
      Therefore, in order to match the color gamut of a color image inputted to a color image forming apparatus to the color gamut of an output color image, several techniques have been suggested.
      <br/>
      According to one technique, a test pattern which is outputted from a color image forming apparatus is read,-And characteristics of the image forming apparatus are compensated for.
      <br/>
      According to another technique, when the color gamut of an input color image signal is broader than that of a color image forming apparatus, the color gamut of the input color image signal is compressed within the color gamut of the image forming apparatus.
      <br/>
      By using the above techniques, an attempt is made to faithfully reproduce an original image.
    </p>
    <p num="4">
      There is no problem in a case where a single color image forming apparatus for outputting an image is used, however, a problem exists when a plurality of color image forming apparatuses are connected to a single computer by a computer network system.
      <br/>
      In such a network system, when an image is outputted from the plurality of color image forming apparatuses, each of the plurality of color image forming apparatuses may independently adjusted its output characteristics, however, the color image forming apparatuses may not be adjusted to each other and the computer.
      <br/>
      As a result, the plurality of color image forming apparatuses may form images having different color gamuts from each other.
    </p>
    <p num="5">Further, since an external device, such as a computer, can not determine the output characteristics of an image forming apparatus, there is a problem such that image processing suitable for the output characteristics of the image forming apparatus to be used is not performed.</p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="6">The present invention has been made in consideration of the above situation, and has as its object to provide an image processing apparatus and method capable of providing parameters representing output characteristics of an image forming apparatus to an external device.</p>
    <p num="7">According to the present invention, the foregoing object is attained by providing an image processing apparatus for an output device which forms an image, the processing apparatus comprising: generation means for generating a pattern signal for forming a predetermined pattern image on a medium; determination means for determining an image forming parameter for the output device on the basis of density of the pattern image formed on the medium; and communication means for outputting the determined image forming parameter to an external computer, the communication means being capable of performing bidirectional communication.</p>
    <p num="8">According to the present invention, the foregoing object is also attained by providing an image processing method for an output device which forms an image, the method comprising: a generation step of generating a pattern signal for forming a predetermined pattern image on a medium; a determination step of determining an image forming parameter for the output device on the basis of density of the pattern image formed on the medium; and a communication step of performing bidirectional communication for outputting the determined image forming parameter to an external computer.</p>
    <p num="9">It is another object of the present invention to improve the calibration function of an output device of an image processing apparatus.</p>
    <p num="10">It is still another object of the present invention to improve efficiency of calibration processing of an output device of an image processing apparatus in a network system.</p>
    <p num="11">Other features and advantages of the present invention will be apparent from the following description taken in conjunction with the accompanying drawings, in which like reference characters designate the same or similar parts throughout the figures thereof.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="12">
      The accompanying drawings, which are incorporated in and constitute a part of the specification, illustrate embodiments of the invention and, together with the description, serve to explain the principles of the invention.
      <br/>
      FIG. 1 is a block diagram illustrating a configuration of an optical system and an image processing system in an image forming apparatus according to an embodiment of the present invention;
      <br/>
      FIG. 2 is a schematic cross-sectional view of an image forming apparatus according to a first embodiment;
      <br/>
      FIG. 3 is a flowchart showing a processing sequence of maximum density correction and tone correction according to the first embodiment;
      <br/>
      FIG. 4 is a view showing a patch pattern used for the maximum density correction;
      <br/>
      FIG. 5 is a graph showing the relationship between relative potential on the surface of an electrostatic drum and image density;
      <br/>
      FIG. 6 is a graph showing the relationship between grid potential and the potential on the surface of the electrostatic drum;
      <br/>
      FIG. 7 is a graph showing density characteristic compensation curves;
      <br/>
      FIG. 8 is a view showing a tone pattern used for tone correction;
      <br/>
      FIG. 9A is a schematic representation showing a system including a computer and a plurality of printers connected via., a communication network;
      <br/>
      FIG. 9B is a graph showing input-output characteristics of a printer A;
      <br/>
      FIG. 9C is a graph showing input-output characteristics of a printer B;
      <br/>
      FIG. 10 is a block diagram illustrating a signal processing system including a photosensor in an apparatus according to a second embodiment;
      <br/>
      FIG. 11 is a flowchart showing a processing sequence of maximum density correction and tone correction when using the photosensor according to the second embodiment;
      <br/>
      FIG. 12A is a view showing a patch pattern outputted from a pattern generator;
      <br/>
      FIG. 12B is a view showing the patch pattern shown in FIG. 12A developed on an electrostatic drum;
      <br/>
      FIG. 13A is a view showing another patch pattern outputted from the pattern generator;
      <br/>
      FIG. 13B is a view showing the patch pattern shown in FIG. 13A developed on the electrostatic drum;
      <br/>
      FIG. 14 is a graph showing spectral characteristics of a yellow toner;
      <br/>
      FIG. 15 is a graph showing spectral characteristics of a magenta toner;
      <br/>
      FIG. 16 is a graph showing spectral characteristics of a cyan toner;
      <br/>
      FIG. 17 is a graph showing spectral chracteristics of a black toner; and
      <br/>
      FIG. 18 is a graph showing the relationship between the output from the photosensor and the density of an image outputted on an electrostatic drum.
    </p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
    <p num="13">Preferred embodiments of the present invention will be described in detail in accordance with the accompanying drawings.</p>
    <p num="14">&lt;First Embodiment&gt;</p>
    <p num="15">
      First, an overall configuration of an image forming apparatus according to the first embodiment is explained.
      <br/>
      Note, in the first embodiment, a case where the present invention is applied to a digital copying machine adopting an electrophotographic method is explained, however, the present invention is not limited to this, and is also applicable to image forming apparatuses adopting a variety of methods, such as an electrostatic printing method and ink-jet printing method.
    </p>
    <p num="16">(Configuration of an Image Forming Apparatus)</p>
    <p num="17">
      FIG. 1 is a block diagram illustrating a configuration of the image forming apparatus according to the first embodiment of the present invention, and FIG. 2 is a schematic cross-sectional view of the image forming apparatus.
      <br/>
      The configuration of the image forming apparatus and image forming processes in the image forming apparatus are explained in detail below.
    </p>
    <p num="18">
      The digital copying machine shown in FIG. 2 includes a reading unit for reading an original image and a printing unit for reproducing the original image on a recording paper sheet, which is as a recording medium, on the basis of image signals of the original image read by the reading unit.
      <br/>
      The operation of the reading unit and the printing unit which will be explained below is controlled by controllers 100 and 200, respectively.
      <br/>
      Note, the controller 100 has a CPU (not shown) and controls the reading unit in accordance with a program stored in advance in a ROM, or the like.
      <br/>
      Further, the controller 200 includes a CPU 214 as shown in FIG. 1, and controls the printing unit in accordance with a program stored in advance in ROM 213.
    </p>
    <p num="19">
      In the apparatus shown in FIG. 2, when a copy key (not shown) is pressed by an operator, the controller 100 controls the reading unit so that an exposure lamp 32 emits light to scan an original 30 placed on a platen glass 31.
      <br/>
      The reflected light from the original 31 is directed to a full-color sensor 34, such as a CCD (charge-coupled device), to obtain color component image signals.
      <br/>
      The full-color sensor 34 decomposes an image of the original 30 into a number of pixels, and generates signals, obtained by photoelectric conversion, corresponding to the density of each pixel.
    </p>
    <p num="20">
      Referring to FIG. 1, image signals (red, green and blue (referred as "R, G and B", hereinafter) analog signals) outputted from the full-color sensor 34 are inputted to an analog signal processor 201 where gain and offset of the image signals are adjusted.
      <br/>
      Thereafter, the image signals are converted into R, G and B digital signals of eight bits (each 0 to 255 levels, capable of expressing 256 tones), for example, by an analog-digital (A/D) converter 202 for each color component.
      <br/>
      Then, a shading correction unit 203 performs a known shading correction for each color component for optimizing gain in correspondence with each cell of a CCD sensor (referred as "CCD sensor cell", hereinafter), arranged in a line, on the basis of signals of a reference white board 35 in order to correct unevenness in sensitivity of CCD sensor cells.
    </p>
    <p num="21">
      A line-delay unit 204 corrects the spatial gap included in the image signals outputted from the shading correction unit 203.
      <br/>
      The spatial gap is due to the arrangement of line sensors of the full-color sensor 34, that is, the line sensors are separated from each other at a predetermined distance in the sub-scanning direction.
      <br/>
      More specifically, the line-delay unit 204 delays R and G component signals by line in the sub-scanning direction with respect to a B component signal, thereby synchronizing the phase of the three color component signals.
    </p>
    <p num="22">
      An input masking unit 205 transforms the color space of the image signals outputted from the line-delay unit 204 into an NTSC standard color space by performing the matrix operation shown in the following equation (1).
      <br/>
      In other words, a color space of the color component signals outputted from the full-color sensor 34 is determined by the spectral characteristics of a filter of each color component, and the color space is then transformed into the NTSC standard color space.  (Equation image '1' not included in text)
    </p>
    <p num="23">R0, G0 and B0 are image signals outputted from the input masking unit 205, and Ri, Gi and Bi are image signals inputted to the input masking unit 205.</p>
    <p num="24">
      A logarithmic (LOG) conversion unit 206 has a look-up table (LUT) stored in a ROM (not shown), or the like, for example, and converts R, G and B luminance signals outputted from the input masking unit 205 into C, M and Y density signals.
      <br/>
      A line-delay memory 207 provided next to the LOG conversion unit 206 delays the image signals outputted from the LOG conversion unit 206 for a period (for one line period) in which a black character determination unit (not shown) generates a control signal, UCR, for controlling a masking/under color removal (UCR) unit 208 (will be explained later), a control signal, FILTER, used for edge enhancement, and a control signal, SEN, used for increasing resolution of an image when the black character determination unit determines the image is composed of black characters, for example, from the output of the input masking unit 205.
    </p>
    <p num="25">
      A masking/under color removal (UCR) unit 208 extracts a black component signal K from the image signals outputted from the line-delay memory 207.
      <br/>
      Further, it applies a matrix operation to Y, M, C and K image signals in order to correct color haziness of color recording material in the printing unit and outputs frame-sequential color component image signals of eight bits, for example, in the order of M, C, Y and K, each time the reading unit performs a reading operation.
      <br/>
      Note, matrix coefficients used in the matrix operation are set by the CPU 214 in the controller 200.
    </p>
    <p num="26">
      A  GAMMA  correction unit 209 applies density correction on image signals outputted from the masking/UCR unit 208 so as to fit the image signals to ideal toning characteristics of the printing unit.
      <br/>
      Then, an output filter (spatial filtering unit) 210 performs edge enhancement or smoothing processing on the image signals outputted from the  GAMMA  correction unit 209 in accordance with control signals from the CPU 214.
    </p>
    <p num="27">
      A look-up table (LUT) 211 is used for matching the density of an original image and the density of an output image.
      <br/>
      It is stored in a RAM (not shown), or the like, for example, and data of the LUT 211 by the CPU 214 (details will be explained later).
      <br/>
      Further, a pulsewidth modulator (PWM) 212 outputs a pulse signal having a pulsewidth corresponding to a level of an input image signal, and the pulse signal is inputted to a laser driver 41 which drives a laser emitter 42, such as a semi-conductor laser (refer to FIG. 2).
    </p>
    <p num="28">Note, the image forming apparatus has a pattern generator 215, and can directly pass the image signals corresponding to a predetermined pattern image, which will be explained later, on the basis of data stored in the ROM 213 in advance, to the pulsewidth modulator 212 (details will be explained later).</p>
    <p num="29">
      Referring to FIG. 2, a laser beam E emitted from the laser emitter 42 is directed by a rotating polygon mirror 3a so as to sweep an electrostatic drum 1 in the main scanning direction, passes through a lens 3b, such as a f/ THETA  lens, then is reflected by a fixed mirror 3c which is used for directing the laser beam E toward the electrostatic drum 1 where the laser beam E makes a light spot.
      <br/>
      Thereby, the laser beam E scans the electrostatic drum 1 in a direction approximately parallel to a rotation axis of the electrostatic drum 1 (i.e., main scanning direction), and repeats scanning the electrostatic drum 1 in the main scanning direction by shifting in the direction of rotation of the electrostatic drum (i.e., sub-scanning direction), thereby forming a latent image on the electrostatic drum 1.
    </p>
    <p num="30">
      In the printing unit, the electrostatic drum 1 on which a latent image and a toner image are formed has amorphous silicon, selenium, organic photo conductor (OPC), and so on, on its surface, and is supported so as to freely rotate in the direction of an arrow shown in FIG. 2.
      <br/>
      Around the electrostatic drum 1, a pre-exposure lamp 11, a corona charger 2 as a charging means, a laser exposing optical system 3, a surface potential sensor 12, four developing units, 4y, 4c, 4m and 4bk, having different color recording materials, a photo sensor 13 as a quantity-of-light detecting means for the electrostatic drum, a transfer unit 5, and a cleaning unit 6 are provided.
    </p>
    <p num="31">
      In the printing unit, the controller 200 controls the electrostatic drum 1 to rotate in the direction of the arrow when forming an image.
      <br/>
      After charges on the electrostatic drum 1 are uniformly removed by using the pre-exposure lamp 11, the electrostatic drum 1 is uniformly charged by the corona charger 2.
      <br/>
      Thereafter, the electrostatic drum 1 is scanned and exposed by the laser beam E which is generated in accordance with the image signals in PWM 212, thereby a latent image corresponding to the image signals is formed on the electrostatic drum 1.
    </p>
    <p num="32">
      Next, the controller 200 operates a predetermined developing unit to reversal-develop the latent image formed on the electrostatic drum 1 by using a double-component developer consisting of toner and carrier.
      <br/>
      Accordingly, a visible image (toner image) of resin as a base substance which is charged to negative is formed.
      <br/>
      Here, a controller 200 controls eccentric cams, 24y, 24c, 24m and 24bk, so that the four developing units 4y, 4c, 4m and 4bk approach the electrostatic drum one by one in accordance with signals of the color to be developed.
      <br/>
      Note, "reversal-develop" indicates a developing method for visualizing a latent image by clinging a toner, charged to the same polarity as that of the latent image, to an area on the electrostatic drum 1 exposed by light (laser beam E).
    </p>
    <p num="33">
      Further, the toner image on the electrostatic drum 1 is transferred onto a recording medium provided by a conveying system 250 from a recording medium feed tray 7 at a position facing to the electrostatic drum 1 by the transfer unit 5.
      <br/>
      The transfer unit 5 has a transfer drum 5a for conveying a recording medium, a brush transfer charger 5b as transfer means, a brush attracting charger 5c and an attracting roller 5g facing the brush attracting charger 5c for electrostatically attracting the recording medium, an inner charger 5d, an outer charger 5e, and a transfer separation sensor 5h.
      <br/>
      Further, a recording medium holding sheet 5f, made of a dielectric, having a cylindrical shape is integrally put around the lateral face of the transfer drum 5a supported by an axis so as to be operated to rotate.
      <br/>
      Note, a dielectric sheet, such as a polycarbonate sheet, is used as the recording medium holding sheet 5f.
    </p>
    <p num="34">
      In the transfer unit 5, as the controller 200 controls the transfer drum 5a to rotate, the toner image on the electrostatic drum 1 is transferred onto the recording medium, held by the recording medium holding sheet 5f, by the brush transfer charger 5b.
      <br/>
      Then, after toner images of a desired numbers of colors are transferred on the recording medium, the recording medium is separated from the transfer drum 5a by a claw separator 8a, a separation push-up roller 8b, and a separation charger 5h.
      <br/>
      The toner image on the separated recording medium is fixed by a thermal roller fixing device 9, then the recording medium is discharged to a tray 10, thereby a full-color image is provided.
    </p>
    <p num="35">
      Meanwhile, after a toner image is transferred from the electrostatic drum 1, residual toner on its surface is cleaned by the cleaning unit 6 having a cleaning blade and a raked gear sheet, and the electrostatic drum 1 serves the next image forming processes.
      <br/>
      Further, in order to prevent toner from scattering and clinging to the recording medium holding sheet 5f on the transfer drum 5a and to prevent oil from clinging on a recording medium, the transfer drum 5a is cleaned by a cleaning brush 14 and a back-up brush 15 which faces the cleaning brush 14 via the recording medium holding sheet.
      <br/>
      Such cleaning is performed before or after image forming processing, and whenever jamming occurs.
    </p>
    <p num="36">(Maximum Density Correction Processing and Tone Correction Processing)</p>
    <p num="37">
      Next, maximum density correction processing and tone correction processing performed in the reading unit and the printing unit are explained with reference to the flowchart shown in FIG. 3.
      <br/>
      These processings are performed as a calibration function (self-adjusting function) of the image forming apparatus.
    </p>
    <p num="38">
      FIG. 3 is a flowchart showing a sequence of maximum density correction processing and tone correction processing performed in the image forming apparatus according to the first embodiment.
      <br/>
      Referring to FIG. 3, after the processing starts in response to an operation by an operator, a test print P1 on which a predetermined pattern image (test pattern image I1) is formed is outputted at step S101 by performing the image forming processes described above.
    </p>
    <p num="39">
      The test pattern image I1 was registered in the ROM 213 in advance, and the pattern generator 215 generates image signals corresponding to the test pattern image I1 under control of the CPU 214.
      <br/>
      Then, the image signals are processed by the PWM 212 and the laser driver 41 drives the laser emitter 42 in accordance with the processed image signals, as described above, the test pattern image I1 as shown in FIG. 4 is outputted.
      <br/>
      Note, when the test pattern image I1 shown in FIG. 4 is outputted, the LUT 211 is not used.
    </p>
    <p num="40">
      At this time, the CPU 214 determines whether or not there is a recording paper sheet which is necessary for outputting the test pattern image I1.
      <br/>
      If there is not, a predetermined warning message is displayed.
      <br/>
      Further, as for contrast potential (explained later) when outputting the test print P1, an initial value under predetermined environment (standard state) was registered in advance and used.
      <br/>
      Regarding the test pattern image I1 (patch pattern), a belt-shape pattern 61 showing half tone densities of yellow (Y), magenta (M), cyan(C) and black (Bk) and a patch pattern 62 showing maximum densities (e.g., image density signal level is 255) of Y, M, C and Bk are formed.
    </p>
    <p num="41">After the output test print P1 is placed on the platen glass 31, the test pattern image I1 is read at step S102, and correction coefficients kc, km, ky and kbk are adjusted so that the obtained values become the same as those of a densitometer on the market by using the following equations (2), for converting the R, G and B values obtained by reading the test pattern image I1 into density values.</p>
    <p num="42">
      C=-kc * log10 (R/255)
      <br/>
      M=-km * log10 (G/255)
      <br/>
      Y=-ky * log10 (B/255)
      <br/>
      Bk=-kbk * log10 (G/255)  (2)
    </p>
    <p num="43">Next, a method for correcting the maximum reproducible density of the image forming apparatus on the basis of the density information obtained by performing the aforesaid processes will be explained.</p>
    <p num="44">
      FIG. 5 is a graph showing the relationship between relative potential of the electrostatic drum surface (referred as "surface relative potential", hereinafter) and the image density obtained in accordance with the aforesaid calculation.
      <br/>
      Note, the value of the image density shown in FIG. 5 is measured by the Macbeth method.
      <br/>
      Here, the surface relative potential is the relative potential of the surface of the electrostatic drum 1 after a latent image is formed on it with reference to the potential to be applied to the electrostatic drum 1 when developing a latent image (called "developing bias potential", hereinafter).
    </p>
    <p num="45">
      Referring to FIG. 5, the potential a shows the contrast potential when the test print 1 is outputted.
      <br/>
      Note, the contrast potential is a relative potential of the electrostatic drum surface with respect to the developing bias potential when the semi-conductor laser is controlled to emit a laser of the maximum level after the electrostatic drum is primary charged.
      <br/>
      Here, a case where Da, shown in FIG. 5, is the maximum density obtained when the relative surface potential is the contrast potential a is considered.
      <br/>
      In the maximum density region shown by oblique stripes in FIG. 5, basically density of an output image linearly changes, as shown by a line L, with respect to the relative surface potential.
      <br/>
      However, when a double-component developer including toner and carrier is used, in a case where the toner density in the developer decreases, the relationship between the density of the output image and the relative surface potential occasionally becomes non-linear in the maximum density region, as shown by a dotted line N. Therefore, although the desired value of the maximum density of an output image is 1.6 in the first embodiment, 0.1 is added in order to overcome the above non-linear problem, and a value 1.7 is used as the desired value of the maximum density.
    </p>
    <p num="46">A method for calculating a contrast potential of b for obtaining the desired maximum density of 1.7, as shown in FIG. 5, and controlling a grid potential and the developing bias potential so as to make the contrast potential be the calculated value b is explained below.</p>
    <p num="47">First the contrast potential b is calculated.</p>
    <p num="48">
      In the first embodiment, the contrast potential b is calculated in accordance with the following equation (3).
      <br/>
      b=(a+ka) * 1.7/Da  (3)
    </p>
    <p num="49">where ka is a correction coefficient, and preferably is optimized depending upon the developing method (step S103).</p>
    <p num="50">
      Next, a method for obtaining the grid potential and the developing bias potential Vdc for controlling charge on the electrostatic drum 1 on the basis of the contrast potential b obtained by the equation (3) is briefly explained.
      <br/>
      Note, control operation for obtaining the grid potential and the potential of the developing bias is called "potential measuring control" below.
    </p>
    <p num="51">
      FIG. 6 is a graph showing the relationship between the grid potential and the potential on the surface of the electrostatic drum 1.
      <br/>
      With the grid potential set to -300V, potential Vd on the surface of the electrostatic drum 1 when the electrostatic drum 1 is scanned with a laser beam of the minimum pulse level emitted from the laser emitter 42, and the potential VI on the surface of the electrostatic drum when the electrostatic drum 1 is scanned with a laser beam of maximum pulse level are measured by the surface potential sensor 12.
      <br/>
      Similarly, the potentials Vd and VI are measured when the grid potential is set to -500V.
      <br/>
      Thereafter, the data obtained when the grid potentials are -300V and -500V is interpolated.
      <br/>
      Thereby, it is possible to obtain the relationship between the grid potential and the potential on the surface of the electrostatic drum 1.
    </p>
    <p num="52">
      A developing bias potential Vdc is set to a potential which is different from the potential Vd by a potential difference of Vback (set to 150V in the first embodiment) so that excess toner does not cling to the electrostatic drum 1.
      <br/>
      Further, a contrast potential Vcont, shown in FIG. 6, indicates the potential difference between the developing bias potential Vdc and the potential VI, and as the contrast potential Vcont is larger, a larger maximum density can be outputted.
    </p>
    <p num="53">In order to match the contrast potential b to the value obtained in accordance with the aforesaid equation (3), the grid potential and the developing bias potential Vdc are to be calculated based on the relationship shown in FIG. 6.</p>
    <p num="54">For example, the contrast potential is calculated so that the obtained maximum density of an output image becomes the desired value of 1.7, then the grid potential and the developing bias potential Vdc are set so that the calculated contrast potential is obtained as a result (step S104).</p>
    <p num="55">How the LUT 211 and processing sequence of tone correction according to the first embodiment are used is explained below.</p>
    <p num="56">
      FIG. 7 is a graph used for compensating output characteristics of the image forming apparatus when reproducing the density of an original image.
      <br/>
      In FIG. 7, quadrant I shows characteristics of the reading unit for converting density of the original image into a density signal; quadrant II shows characteristics of the LUT 211 for converting the density signal into a laser output signal; quadrant III shows characteristics of density of an image outputted by the printing unit on the basis of the laser output signal; and quadrant IV shows the relationship between the density of the original image and density of the output image.
      <br/>
      Note, in FIG. 7, the density of original image and density of the output image are measured by the Macbeth method.
      <br/>
      These characteristics show overall toning characteristics of the image forming apparatus according to the first embodiment.
    </p>
    <p num="57">
      Note, the number of tones used in the first embodiment is 256, since tone is processed as an eight-bit digital signal.
      <br/>
      Further, because of the aforesaid maximum density correction processing in which the desired maximum density is set to include an allowance of 0.1 in consideration of a case where toner density in a double-component developer drops, the characteristics of the printing unit shown in the quadrant III is as the curve J. Note, when such allowance is not included, the characteristics of the printing unit may be as shown by a broken line H which does not reach the actually desired density of 1.6. Therefore, if the characteristics of the printing unit is as shown by the broken line H, no matter how the LUT 211 is set, the density between the density DH and the desired value 1.6 is not reproducible, since the LUT 211 does not have an ability of increasing the maximum density of an output image.
    </p>
    <p num="58">
      In the image forming apparatus according to the first embodiment, non-linear characteristics of the printer unit as shown in the quadrant III are compensated by the LUT 211 whose characteristics are shown in the quadrant II, so as to make the relationship between the density of the original image and the density of the output image (i.e., tone characteristics between the original image and the output image) shown in the quadrant IV linear.
      <br/>
      The LUT 211 can be easily generated on the basis of the input-output characteristics of the printing unit shown the quadrant III.
    </p>
    <p num="59">
      Next at step S105, a test print P2 is outputted.
      <br/>
      A predetermined pattern image (test pattern image I2) on the test print P2 was also registered in the ROM 213 in advance, similarly to the test pattern image I1, and after the same processes performed on the test pattern image I1 by using the pattern generator 215 are applied to the test pattern image I2, the test print P2 as shown in FIG. 8 is outputted.
      <br/>
      Note, the test print P2 is outputted without using the LUT 211.
    </p>
    <p num="60">
      The test pattern image I2 is formed of patches of each color, Y, M, C and Bk, and each patch shows gradually changing 64 tones arranged in four rows and sixteen columns.
      <br/>
      Among reproducible 256 tones, the relatively large number of the low density tones are printed as a part of the 64 tones.
      <br/>
      By doing so, it is possible to adjust tone characteristics of a light color.
    </p>
    <p num="61">
      In FIG. 8, reference numeral 71 denotes patches printed in a resolution of 200 lpi (lines/inch), and 72 denotes patches printed in a resolution of 400 lpi.
      <br/>
      For forming images in these different resolutions, a plurality of triangular waves, used for converting image data by the PWM 212, having different periods are prepared.
      <br/>
      Note, the image forming apparatus forms a tone image in the resolution of 200 lpi, and forms a line image, such as a character, in the resolution of 400 lpi.
      <br/>
      Further, the image forming apparatus outputs two sets of patches in the two different resolutions by using the identical tone levels.
      <br/>
      However, in the case where the tone characteristics of the two sets of patches outputted on the test print P2 are much different depending upon the resolutions, the 64 tone levels to be outputted are preferably set depending upon the resolution.
    </p>
    <p num="62">Note, the output test print P2 is read by the reading unit similarly to the case of the maximum density correction processing, and the density values are corrected.</p>
    <p num="63">After the reading unit reads the test print P2 and the density values are corrected, the relationship between the laser output levels and the densities is stored in RAM 216 in correspondence to the laser output levels and tone pattern formation positions (step S106).</p>
    <p num="64">
      Accordingly, characteristics of the printing unit shown in the quadrant III in FIG. 7 are obtained.
      <br/>
      Then, by updating the input-output relationship of the characteristics of the printing unit, i.e., by exchanging the ordinate and the abscissa of the input-output characteristics, data to be set in the LUT 211 in the printing unit is obtained and set to the LUT 211 (step S107).
    </p>
    <p num="65">The data set to the LUT 211 in step S107 is used in the subsequent normal printing operation as parameters when forming an image by the image forming apparatus.</p>
    <p num="66">
      Note, when obtaining input-output characteristics data, to set LUT 211, of the printing unit by calculation, the density data which can be used is based only on the tones in the test pattern image I2, namely 64 tones, as shown in FIG. 8.
      <br/>
      Therefore, missing data is interpolated so that the laser output levels correspond to all the levels (tones), from 0 to 255, of the density signals.
    </p>
    <p num="67">After the aforesaid processes are completed, a message, such as "ready for copying", is displayed on an operation panel (not shown), for example, and the apparatus is ready for a copying operation.</p>
    <p num="68">
      By performing the aforesaid processes, as the contrast potential calculated in the method as described above is set as well as the data is set to the LUT 211, stable tone reproduction of an image on a recording medium is realized in the subsequent normal copying operation.
      <br/>
      Further, the image forming apparatus having good and linear toning characteristics with respect to image density signals can be obtained.
    </p>
    <p num="69">(Correction Control of Output Characteristics via the Bidirectional Communication)</p>
    <p num="70">Next, a method of compensating output characteristics of output devices (printers) of image forming apparatuses having the aforesaid self-adjusting function via bidirectional communication with a platform (computer) is explained.</p>
    <p num="71">
      FIG. 9A is a schematic representation showing a system including a computer and a plurality of printers as copying machines (aforesaid image forming apparatuses) connected via a communication network system.
      <br/>
      In FIG. 9A, a computer 1000 is connected to a printer A and a printer B via a local area network (LAN) 2000 as communication means.
      <br/>
      Further, input-output characteristics (i.e., toning characteristics represented in the quadrant IV in FIG. 7) of the printer A and that of the printer B differ from each other.
      <br/>
      In such case, in order to adjust the input-output characteristics of a printer (printer B) to that of the printer A, input-output characteristic setting values (correspond to the content of data set in the LUT 211, signal L200) are transmitted from the printer A to the printer B. Or, the input-output characteristic setting values (signal L100) are received by the computer 1000, then they (signal L101) are transferred to the printer B for changing the input-output characteristics of the printer B, then the received input-output characteristic setting values are used in processing of input-output characteristic compensation in the printer B.
    </p>
    <p num="72">
      According to the first embodiment as described above, correction values of image forming parameters used in an output device are generated on the basis of the density values of test prints, and transmitted to other image forming apparatus via an external device (e.g., computer), or directly transmitted to another image forming apparatus.
      <br/>
      Accordingly, substantially the same reproduction quality of an image is achieved even when different output devices are used.
    </p>
    <p num="73">Further, by setting output characteristics from the computer 1000 as a user desires, it is possible to achieve the same advantages.</p>
    <p num="74">Further, by transmitting the adjusting value, such as the F value of each color, set by a user for each printer directly to another printer or via the computer 1000, it is possible to substantially obtain the same image reproduction quality when an image is outputted from different printers or copying machines.</p>
    <p num="75">Note, by providing means for independently switching the settings of the output characteristics in a printer, it is possible to substantially realize the same image reproduction quality as a user desires by using a printer originally having the different output characteristics with a simple operation.</p>
    <p num="76">&lt;Second Embodiment&gt;</p>
    <p num="77">
      A second embodiment of the present invention is described below.
      <br/>
      In the second embodiment, a case where each printer performs maximum density correction processing and tone correction processing by itself is explained.
      <br/>
      Note, an image forming-apparatus according to the second embodiment has the same configuration as that described in the first embodiment, therefore, explanation of it is omitted.
    </p>
    <p num="78">
      FIG. 10 illustrates a configuration of a processing circuit for processing signals from the photosensor 13 having an LED and a photodiode provided at a position facing the electrostatic drum 1.
      <br/>
      Near infrared rays reflected by the electrostatic drum 1 impinges on a photosensor 13 in FIG. 10 and is converted to electrical signals by the photosensor 13.
      <br/>
      Output voltage of each electrical signal which is between 0V and 5V is converted into a digital signal of between 0 to 255 levels by an analog-digital (A/D) converter 221, and is then converted into density data by a density converting circuit 222 provided in the downstream of the A/D converter 221.
    </p>
    <p num="79">
      Color toners, i.e., yellow, magenta and cyan toners, used in the image forming apparatus according to the second embodiment are compounds of styrene resin as a binder and color material of each color distributed in the binder.
      <br/>
      Spectral characteristics of these yellow, magenta and cyan toners (see FIGS. 14 through 17) are such that the reflectance of a near infrared ray (960 nm) is about 80%.
      <br/>
      Further, since carbon black is used as color material for expressing pure black, the reflectance of a near infrared ray is about 10%.
      <br/>
      Further, OPC is used in the electrostatic drum 1, and its reflectance of a near infrared ray is about 40%.
      <br/>
      Other drums, such as one using amorphous silicon, may be used since the reflectance is about the same.
    </p>
    <p num="80">
      FIG. 18 is a graph showing the relationship between the output from the photosensor 13 and density of an image outputted on the electrostatic drum 1 when the density of each color toner on the electrostatic drum is stepwise changed by area toning.
      <br/>
      Here, as shown in FIG. 18, the output of the photosensor 13 when no toner is clinging to the electrostatic drum 1 is set to 2.5 V, namely, the 128th level.
    </p>
    <p num="81">As seen from FIG. 18, for the yellow, magenta and cyan toners, as area covering rate, namely an amount of toner used per unit area, becomes larger and as the density of an image becomes higher, the output of the photosensor 13 increases compared to when no toner is clinging to the electrostatic drum 1.</p>
    <p num="82">
      In contrast, the black toner, as the area covering rate becomes larger and as the density of an image becomes higher, the output of the photosensor 13 decreases compared to when no toner is clinging to the electrostatic drum 1.
      <br/>
      Therefore, a table 223, made in consideration of the aforesaid characteristics, for converting an output signal of the photosensor 13 into a density signal is provided.
      <br/>
      Accordingly, it is possible to obtain a density signal for each color in correspondence with the state of the electrostatic drum 1.
    </p>
    <p num="83">(Maximum Density Correction Processing and Tone Correction Processing)</p>
    <p num="84">According to the second embodiment, on the basis of density signals obtained by the aforesaid processing circuit, the contrast potential Vcont for each color, M, C, Y and Bk, is calculated and the LUT 211 is made for each color, and the maximum density correction processing and the tone correction processing, similarly to those explained in the first embodiment, are performed.</p>
    <p num="85">FIG. 11 is a flowchart showing a processing sequence of the maximum density correction processing and the tone correction processing using a photosensor according to the second embodiment.</p>
    <p num="86">First, maximum density correction processing is explained.</p>
    <p num="87">
      Similarly to the first embodiment as described above, after the potential measuring control for measuring the grid potential and the potential of the developing bias is performed, a patch pattern image of the maximum density (test pattern image I3), as shown in FIG. 12A, is generated by the pattern generator 215 for the maximum density correction processing and formed on the electrostatic drum 1 (step S201).
      <br/>
      The test pattern image I3 and a test pattern image I4, which will be explained later, were registered in the ROM 213 in advance, similarly to the case explained in the first embodiment, and the pattern generator 215 generates image signals corresponding to the pattern image under control of the CPU 214.
      <br/>
      Then, reflected light from the patch pattern image I3 on the electrostatic drum 1 is detected by the photosensor 13 (step S202), the obtained result is converted into density by the density converting circuit 222 and a contrast potential for each color is set so that the maximum density becomes 0.1 higher than a predetermined desired value (step S203).
    </p>
    <p num="88">
      Note, in the second embodiment, an electrostatic drum of large caliber is used in the printing unit.
      <br/>
      Therefore, for obtaining precise density data, decentering of the rotation axis of the electrostatic drum 1 is considered, and patches of the same color are formed in the opposite positions with respect to the rotation axis on the electrostatic drum 1, and predetermined measurement and a plurality of sampling operations are performed, and the obtained results are averaged.
      <br/>
      Note, FIG. 12B shows patch patterns shown in FIG. 12A when they are developed on the electrostatic drum 1.
    </p>
    <p num="89">Next, the tone correction processing is explained.</p>
    <p num="90">
      In the second embodiment, a tone pattern (test pattern image I4) is formed on the electrostatic drum 1 (step S204).
      <br/>
      FIG. 13A shows the tone pattern (test pattern image I4) of each color generated by the pattern generator 215.
      <br/>
      Further, FIG. 13B shows the tone pattern shown in FIG. 13A when it is developed on the electrostatic drum 1 (step S204).
      <br/>
      After reflected light from the patch pattern image I4 on the electrostatic drum 1 is detected by the photosensor 13 (step S202), the obtained result is converted to density by the density converting circuit 222, and the relationship between the laser output level and the obtained density are stored in the RAM 216 (step S205).
      <br/>
      Thereafter, on the basis of the relationship between the laser output level and the density, the content of the LUT 211 for each color is determined and set (step S206).
    </p>
    <p num="91">(Correction Control of Output Characteristics via the Bidirectional Communication)</p>
    <p num="92">Next, a method of compensating output characteristics of output devices (printers) of image forming apparatuses having the aforesaid self-adjusting function via bidirectional communication with a platform (computer) is explained.</p>
    <p num="93">
      In the second embodiment, assume that the input-output characteristics (toning characteristics in the quadrant IV in FIG. 7) of the printer A and those of the printer B, shown in FIG. 9, differ.
      <br/>
      In such case, in order to adjust the input-output characteristics of a printer (printer B) to the output characteristics of the printer A, input-output characteristic setting values (correspond to the content of data set in the LUT 211) of the printer A is directly transmitted to the printer B, or a computer receives the input-output characteristic setting values of the printer A, then transmits them to the printer B for changing the input-output characteristics of the printer B. The printer B uses the received input-output characteristic setting values for correcting the input-output characteristics of itself.
    </p>
    <p num="94">By performing as described above, it is possible to provide substantially identical image reproductivity when different output devices are used according to the second embodiment.</p>
    <p num="95">
      It should be noted that output characteristics may be set by a user to desired ones via a computer.
      <br/>
      Similarly, it is possible to change the maximum density to the desired value.
      <br/>
      Furthermore, the predetermined pattern images may be formed on a recording paper sheet as in the first embodiment, or may be formed on a medium, such as an electrostatic drum and a transfer drum, as in the second embodiment.
    </p>
    <p num="96">Further, by transmitting an adjusting value, such as the F value of each color, set by a user for each printer to another printer directly or via a computer, it is possible to obtain substantially the same image reproduction quality when an image is outputted from different printers or copying machines.</p>
    <p num="97">Note, by providing means for independently switching the settings of the output characteristics in a printer, it is possible to realize substantially the same image reproduction quality as a user desires by using a printer originally having different output characteristics with a simple operation.</p>
    <p num="98">
      The present invention can be applied to a system constituted by a plurality of devices (e.g., host computer, interface, reader, and printer) or to an apparatus comprising a single device (e.g., copying machine and facsimile machine).
      <br/>
      Furthermore, the invention is applicable also to a case where the object of the invention is attained by supplying a program to a system or apparatus.
    </p>
    <p num="99">
      According to the embodiments as described above, image forming parameters representing reproduction characteristics of an image of an output device of the apparatus are generated on the basis of densities of pattern images formed on a recording medium, and the generated parameters are transmitted to other image forming apparatus by communication.
      <br/>
      Accordingly, even when a plurality of image forming apparatuses are used,  GAMMA  characteristics of output devices are corrected to desired ones, thereby a difference in output characteristics between the image forming apparatuses is reduced.
    </p>
    <p num="100">
      The present invention is not limited to the above embodiments and various changes and modifications can be made within the spirit and scope of the present invention.
      <br/>
      Therefore to appraise the public of the scope of the present invention, the following claims are made.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>An image processing apparatus for adjusting a color process condition to be applied to a first color image forming apparatus for forming a color image on a medium by using image forming means, said processing apparatus comprising:</claim-text>
      <claim-text>setting means for setting an image forming condition in accordance with a detected result of a first pattern image formed by said image forming means;</claim-text>
      <claim-text>and transmitting means for transmitting, to an external device, information according to a detected result of a second pattern image formed by said image forming means which is controlled by the image forming condition and an adjusting value set by a user, wherein the external device adjusts a color process condition of a second color image forming apparatus, which is different from the first color image forming apparatus, on a basis of the transmitted information and the transmitted adjusting value.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The image processing apparatus according to claim 1, wherein the second pattern image is a tone pattern image, and the information represents a condition of tone conversion.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The image processing apparatus according to claim 2, wherein the condition of tone conversion is generated by an interpolation operation.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The image processing apparatus according to claim 2, wherein the condition of tone conversion is data of a look-up table.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The image processing apparatus according to claim 1, wherein said transmitting means transmits the information and also a user adjusted value arbitrarily set by a user.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The image processing apparatus according to claim 1, wherein the medium is recording paper.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. The image processing apparatus according to claim 1, wherein said transmitting means performs bidirectional communication with the external device.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The image processing apparatus according to claim 7, wherein the external device is an image processing apparatus for the second color image forming apparatus.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. The image processing apparatus according to claim 1, further comprising a scanner for scanning an original image.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. The image processing apparatus according to claim 1, wherein the transmitted adjusting value is a F-value of each color.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. The image processing apparatus according to claim 1, wherein the image forming condition is a condition regarding a contrast potential.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. The image processing apparatus according to claim 1, wherein the first pattern image and the second pattern image are formed on the medium.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. The image processing apparatus according to claim 1, wherein the first pattern image is formed on an electrostatic drum.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. A color process condition adjusting method of an image processing apparatus, said method comprising: a setting step of setting an image forming condition in accordance with a detected result of a first pattern image formed by image forming means of a first color image forming apparatus which forms a color image on a medium by using said image forming means; a transmitting step of transmitting, to an external device, information according to a detected result of a second pattern image formed by said image forming means which is controlled by the image forming condition and an adjusting value set by a user;</claim-text>
      <claim-text>and an adjusting step of adjusting, in the external device, a color process condition of a second color image forming apparatus, which is different from the first color image forming apparatus, on a basis of the transmitted information and the transmitted adjusting value.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. The color process condition adjusting method according to claim 14, wherein the second pattern image is a tone pattern image, and the information represents a condition of tone conversion.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. The color process condition adjusting method according to claim 15, wherein the condition of tone conversion is generated by an interpolation operation.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. The color process condition adjusting method according to claim 15, wherein the condition of tone conversion is data of a look-up table.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. The color process condition adjusting method according to claim 14, wherein said transmitting means transmits the information and also a user adjusted value arbitrarily set by a user.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. The color process condition adjusting method according to claims 14, wherein the medium is recording paper.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. The color process condition adjusting method according to claim 14, wherein in said transmitting step, bidirectional communication is performed with the external device.</claim-text>
    </claim>
    <claim num="21">
      <claim-text>21. The color process condition adjusting method according to claim 20, wherein the external device is an image processing apparatus for the second color image forming apparatus.</claim-text>
    </claim>
    <claim num="22">
      <claim-text>22. An image processing method of adjusting a color process condition of a second image outputting device having second image forming means in accordance with an adjusting result of a first image outputting device having a first image forming means, said method comprising: a setting step of setting an image forming condition, of the first image outputting device, in accordance with a detected result of a first pattern image formed by said first image forming means; an inputting step of inputting information according to a detected result of a second pattern image formed by said first image forming means which is controlled by the image forming condition and an adjusting value set by a user;</claim-text>
      <claim-text>and an adjusting step of adjusting a color process condition of the second image outputting device on a basis of the inputted information and the inputted adjusting value.</claim-text>
    </claim>
    <claim num="23">
      <claim-text>23. The image processing method according to claim 22, wherein the second pattern image is a tone pattern image, and the inputted information represents a condition of tone conversion.</claim-text>
    </claim>
    <claim num="24">
      <claim-text>24. The image processing method according to claim 23, wherein the condition of tone conversion is data of a look-up table.</claim-text>
    </claim>
    <claim num="25">
      <claim-text>25. The image processing method according to claim 13, wherein the inputted adjusting value is a F-value of each color regarding the first image outputting device.</claim-text>
    </claim>
  </claims>
</questel-patent-document>