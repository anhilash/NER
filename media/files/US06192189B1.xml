<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06192189B1.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as first publication">
      <document-id>
        <country>US</country>
        <doc-number>06192189</doc-number>
        <kind>B1</kind>
        <date>20010220</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6192189</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B1</original-publication-kind>
    <application-reference family-id="26467964" extended-family-id="3855884">
      <document-id>
        <country>US</country>
        <doc-number>09132159</doc-number>
        <kind>A</kind>
        <date>19980810</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1998US-09132159</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>3986702</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>13215998</doc-number>
        <kind>A</kind>
        <date>19980810</date>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1998US-09132159</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>JP</country>
        <doc-number>19781695</doc-number>
        <kind>A</kind>
        <date>19950802</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1995JP-0197816</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="3">
        <country>JP</country>
        <doc-number>13366496</doc-number>
        <kind>A</kind>
        <date>19960528</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="3">
        <doc-number>1996JP-0133664</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="4">
        <country>US</country>
        <doc-number>69087396</doc-number>
        <kind>A</kind>
        <date>19960801</date>
        <priority-linkage-type>1</priority-linkage-type>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="4">
        <doc-number>1996US-08690873</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010220</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <term-of-grant>
      <disclaimer/>
    </term-of-grant>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>H04N   5/928       20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>928</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>H04N   5/781       20060101AFI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>781</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>G11B  19/12        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>19</main-group>
        <subgroup>12</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>G11B  20/10        20060101ALI20060101BMKR</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>20</main-group>
        <subgroup>10</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>KR</country>
        </generating-office>
        <classification-status>B</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20060101</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="5">
        <text>G11B  20/12        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>20</main-group>
        <subgroup>12</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="6">
        <text>G11B  27/034       20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>27</main-group>
        <subgroup>034</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="7">
        <text>G11B  27/10        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>27</main-group>
        <subgroup>10</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="8">
        <text>G11B  27/30        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>27</main-group>
        <subgroup>30</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="9">
        <text>G11B  27/32        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>27</main-group>
        <subgroup>32</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="10">
        <text>H04N   5/765       20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>765</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="11">
        <text>H04N   5/85        20060101A N20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>85</subgroup>
        <classification-value>N</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="12">
        <text>H04N   5/91        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>91</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="13">
        <text>H04N   5/92        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>92</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="14">
        <text>H04N   7/52        20110101A I20120414RMEP</text>
        <ipc-version-indicator>
          <date>20110101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>7</main-group>
        <subgroup>52</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20120414</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="15">
        <text>H04N   9/804       20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>9</main-group>
        <subgroup>804</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="16">
        <text>H04N   9/806       20060101A N20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>9</main-group>
        <subgroup>806</subgroup>
        <classification-value>N</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="17">
        <text>H04N   9/82        20060101A N20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>9</main-group>
        <subgroup>82</subgroup>
        <classification-value>N</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="18">
        <text>H04N  21/845       20110101A I20140524RMEP</text>
        <ipc-version-indicator>
          <date>20110101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>21</main-group>
        <subgroup>845</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20140524</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>386248000</text>
        <class>386</class>
        <subclass>248000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>375E07004</text>
        <class>375</class>
        <subclass>E07004</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>375E07267</text>
        <class>375</class>
        <subclass>E07267</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>386318000</text>
        <class>386</class>
        <subclass>318000</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>386324000</text>
        <class>386</class>
        <subclass>324000</subclass>
      </further-classification>
      <further-classification sequence="5">
        <text>386337000</text>
        <class>386</class>
        <subclass>337000</subclass>
      </further-classification>
      <further-classification sequence="6">
        <text>386E09013</text>
        <class>386</class>
        <subclass>E09013</subclass>
      </further-classification>
      <further-classification sequence="7">
        <text>G9B019017</text>
        <class>G9B</class>
        <subclass>019017</subclass>
      </further-classification>
      <further-classification sequence="8">
        <text>G9B027012</text>
        <class>G9B</class>
        <subclass>027012</subclass>
      </further-classification>
      <further-classification sequence="9">
        <text>G9B027019</text>
        <class>G9B</class>
        <subclass>027019</subclass>
      </further-classification>
      <further-classification sequence="10">
        <text>G9B027033</text>
        <class>G9B</class>
        <subclass>027033</subclass>
      </further-classification>
      <further-classification sequence="11">
        <text>G9B027050</text>
        <class>G9B</class>
        <subclass>027050</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>H04N-009/804B</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>009</main-group>
        <subgroup>804B</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>G11B-019/12</text>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>19</main-group>
        <subgroup>12</subgroup>
      </classification-ecla>
      <classification-ecla sequence="3">
        <text>G11B-027/034</text>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>27</main-group>
        <subgroup>034</subgroup>
      </classification-ecla>
      <classification-ecla sequence="4">
        <text>G11B-027/10A1</text>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>027</main-group>
        <subgroup>10A1</subgroup>
      </classification-ecla>
      <classification-ecla sequence="5">
        <text>G11B-027/30C</text>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>027</main-group>
        <subgroup>30C</subgroup>
      </classification-ecla>
      <classification-ecla sequence="6">
        <text>G11B-027/32D2</text>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>027</main-group>
        <subgroup>32D2</subgroup>
      </classification-ecla>
      <classification-ecla sequence="7">
        <text>H04N-007/52</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>7</main-group>
        <subgroup>52</subgroup>
      </classification-ecla>
      <classification-ecla sequence="8">
        <text>H04N-021/845P</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>021</main-group>
        <subgroup>845P</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-009/8042</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>9</main-group>
        <subgroup>8042</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G11B-019/12</classification-symbol>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>19</main-group>
        <subgroup>12</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G11B-027/034</classification-symbol>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>27</main-group>
        <subgroup>034</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G11B-027/105</classification-symbol>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>27</main-group>
        <subgroup>105</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G11B-027/3027</classification-symbol>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>27</main-group>
        <subgroup>3027</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="6">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G11B-027/329</classification-symbol>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>27</main-group>
        <subgroup>329</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="7">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G11B-2220/2562</classification-symbol>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>2220</main-group>
        <subgroup>2562</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="8">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-005/85</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>85</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="9">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-007/52</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>7</main-group>
        <subgroup>52</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="10">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-009/8063</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>9</main-group>
        <subgroup>8063</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="11">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-009/8233</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>9</main-group>
        <subgroup>8233</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="12">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-021/8455</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>21</main-group>
        <subgroup>8455</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="13">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>S11B-220/25D3</classification-symbol>
      </patent-classification>
      <patent-classification sequence="14">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>T04N-005/85</classification-symbol>
      </patent-classification>
      <patent-classification sequence="15">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>T04N-009/806S</classification-symbol>
      </patent-classification>
      <patent-classification sequence="16">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>T04N-009/82N6</classification-symbol>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>10</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>14</number-of-drawing-sheets>
      <number-of-figures>17</number-of-figures>
      <image-key data-format="questel">US6192189</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Data recording method and apparatus, data recorded medium and data reproducing method and apparatus</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>VAN LUYT BALTHASAR A G, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4794465</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4794465</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>COOKSON CHRISTOPHER J, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5400077</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5400077</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>COOKSON CHRISTOPHER J, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5598276</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5598276</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>CHOI HAE-MIN</text>
          <document-id>
            <country>US</country>
            <doc-number>5617386</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5617386</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>TSUGA KAZUHIRO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5691972</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5691972</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>FUJINAMI YASUSHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5881203</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5881203</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <related-documents>
      <continuation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>69087396</doc-number>
              <kind>A</kind>
              <date>19960801</date>
            </document-id>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>5881203</doc-number>
              <kind>A</kind>
            </document-id>
          </parent-doc>
        </relation>
      </continuation>
    </related-documents>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Sony Corporation</orgname>
            <address>
              <address-1>Tokyo, JP</address-1>
              <city>Tokyo</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>SONY</orgname>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Fujinami, Yasushi</name>
            <address>
              <address-1>Kanagawa, JP</address-1>
              <city>Kanagawa</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Kawamura, Makoto</name>
            <address>
              <address-1>Kanagawa, JP</address-1>
              <city>Kanagawa</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Frommer Lawrence &amp; Haug, LLP.</orgname>
          </addressbook>
        </agent>
        <agent sequence="2" rep-type="agent">
          <addressbook lang="en">
            <name>Frommer, William S.</name>
          </addressbook>
        </agent>
        <agent sequence="3" rep-type="agent">
          <addressbook lang="en">
            <name>Smid, Dennis M.</name>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Garber, Wendy</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A data recording method is provided in which video data and plural channels of language data are divided into packets as units, and the video data and the plural channels of language data are recorded on a record medium along with the control information containing a flag designating a reproducing channel of the language data matched to a reproducing pattern of the video data.
      <br/>
      Thus it becomes possible to record video data and plural channels of language data on a record medium so that a reproducing channel for the language data matched to the reproducing pattern of the video data will be selected and the plural channels of language data matched to the reproducing pattern and the video data will be reproduced by a reproducing system.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <p num="1">
      This application is a continuation of Ser.
      <br/>
      No. 08/690,873 Aug. 1, 1996, now U.S. Pat. No. 5,881,203.
    </p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="2">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="3">This invention relates to a data recording method and apparatus, a data record (recording/recordable/recorded) medium and a data reproducing method and apparatus employed with advantage for compressing and time-divisionally multiplexing digital moving picture data and digital speech data and for recording/reproducing the data on or from, for example, an optical disc.</p>
    <p num="4">2. Description of the Related Art</p>
    <p num="5">
      In video works, such as motion pictures, there are occasions wherein plural works having basically the same contents and slightly different in details, that is different in version, under variable circumstances.
      <br/>
      For example, a so-called directors cut edition, later edited by a director, may exist in addition to the first edition shown in a theater.
      <br/>
      Specifically, although part of the photographed scenes are cut or modified in the first edition from reasons related to management or under political or cultural backgrounds, these cut or modified scenes may be revived in reediting for taking changes in the backgrounds or the author's intentions into account.
      <br/>
      These are identified as director's cut editions, complete editions, special editions and so forth.
      <br/>
      Three or more different versions may be occasionally derived from one and the same work.
    </p>
    <p num="6">In addition to the versions for showing in a theater, an original work may be edited for matching to the broadcasting time for e.g., television broadcasting or matching to a recording/reproducing apparatus of relatively short play time for household entertainment.</p>
    <p num="7">
      In addition, motion pictures or video works shown for indefinite audience are designated for being shown only for adults (rating).
      <br/>
      The rating is voluntarily applied by the maker to a motion picture for prohibiting the nonage from viewing it if the motion picture includes inappropriate expressions for nonage.
      <br/>
      Similarly, a rated video disc, for example, is prohibited from being sold or assigned to the nonage.
    </p>
    <p num="8">
      The rating in US is not provided by law but is a voluntary process followed by the maker inclusive of the distributer and seller.
      <br/>
      According to a literature "THE MOVIE BUSINESS BOOK, pp. 396 to 406, "THE VOLUNTARY MOVIE RATING SYSTEM", the motion picture is classed into five categories, namely G (General Audiences; All Ages Admitted), PG (Parental Guidance Suggested); some material may not be suitable for children); PG-13 (Parents Strongly Cautioned, Some material may be inappropriate for children under 13; R (Restricted, under 17 requires accompanying parent or adult guardian); and NC-17 (No Children under 17 admitted).
    </p>
    <p num="9">
      Therefore, under these designations, admittance to a theater or the sale of video tapes or the like is restricted.
      <br/>
      Heretofore, a sole rating level is set for a given motion picture and referred to in a theater or a video shop for taking the age of the admitted or purchasing persons into account.
      <br/>
      In contrast to these voluntary process, there is also an idea of compulsorily prohibiting a rated video disc from being viewed by the nonage on the side of a reproducing apparatus.
      <br/>
      In this case, a flag for discriminating the possible rating is written on a video disc for detection by the reproducing apparatus for prohibiting reproduction.
      <br/>
      This function is termed a rating system, referred to hereinafter simply as rating.
    </p>
    <p num="10">
      In an European digital broadcasting system, there is a description "Parental Rating" in the definition of the service information.
      <br/>
      This broadcasting system provides a method for describing the age based on which the rating is allowed to come into operation by a receiving apparatus.
      <br/>
      In the above-mentioned rating system, if only a certain scene in a program is objectionable, an identification code is recorded at a position directly before the program starting.
      <br/>
      If the reproducing apparatus is in a rating mode, this identification code is read and the program is discontinued without being reproduced.
      <br/>
      In this case, the program in its entirety cannot be viewed.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="11">It is therefore an object of the present invention to provide a data recording method and apparatus, a data record medium and a data reproducing method and apparatus for coping with plural versions or rating modes in such a manner that the reproducing system selects a reproducing channel of speech data matched to the reproducing pattern of video data for reproducing the speech data and video data matched to the reproducing pattern.</p>
    <p num="12">
      A data recording method according to the present invention divides video data and plural channels of language data into packets as units, and records the video data and the plural channels of language data on a record medium along with the control information containing a flag designating a reproducing channel of the language data matched to a reproducing pattern of the video data.
      <br/>
      Thus it becomes possible to record video data and plural channels of language data on a record medium so that a reproducing channel for the language data matched to the reproducing pattern of the video data will be selected and the plural channels of language data matched to the reproducing pattern and the video data will be reproduced by a reproducing system.
    </p>
    <p num="13">
      With the data recording method according to the present invention, the video data and the plural channels of language data are multiplexed and recorded on a record medium along with the control information containing a flag designating a reproducing channel of the language data matched to a reproducing pattern of the video data.
      <br/>
      Thus it becomes possible to record video data and plural channels of language data on a record medium so that a reproducing channel for the language data matched to the reproducing pattern of the video data will be selected and the plural channels of language data matched to the reproducing pattern and the video data will be reproduced by a reproducing system.
    </p>
    <p num="14">
      With the data recording method according to the present invention, the video data and the plural channels of the language data are multiplexed and recorded on a record medium, and the control information containing a flag designating the reproducing channel of the language data matched to the reproducing pattern of video data is recorded in a pre-set area on the record medium.
      <br/>
      Thus it becomes possible to record video data and plural channels of language data on a record medium so that a reproducing channel for the language data matched to the reproducing pattern of the video data will be selected and the plural channels of language data matched to the reproducing pattern and the video data will be reproduced by a reproducing system.
    </p>
    <p num="15">
      With the data recording method according to the present invention, speech data, for example, is recorded as the language data on the record medium.
      <br/>
      Thus it becomes possible to record video data and plural channels of speech data on a record medium so that a reproducing channel for the speech data matched to the reproducing pattern of the video data will be selected and the plural channels of speech data matched to the reproducing pattern and the video data will be reproduced by a reproducing system.
    </p>
    <p num="16">
      With the data recording method according to the present invention, speech data and/or title data, for example, is recorded as the language data on the record medium.
      <br/>
      Thus it becomes possible to record video data and plural channels of speech data and/or title data on a record medium so that a reproducing channel for the speech data and/or title data matched to the reproducing pattern of the video data will be selected and the plural channels of speech data and/or title data matched to the reproducing pattern and the video data will be reproduced by a reproducing system.
    </p>
    <p num="17">
      Thus, with the data recording method according to the present invention, video data and plural channels speech data and/or plural channels of title data are divided into packets as units and recorded on a record medium in a multiplexed or separate form along with the control information containing a flag designating a reproducing channel for the speech data and the title data matched to the reproducing pattern of the video data.
      <br/>
      Thus it becomes possible to record video data and plural channels of speech data and plural channels of title data on a record medium so that a reproducing channel for the speech and title data matched to the reproducing pattern of the video data will be selected and the speech and title data matched to the reproducing pattern and the video data will be reproduced by a reproducing system.
    </p>
    <p num="18">
      With a data recording apparatus according to the present invention, packet dividing means divides video data and plural channels of language data into packets as units, and control information generating means generates the control information containing a flag designating a reproducing channel of language data matched to a reproducing pattern of the video data, while recording means records the video data and the plural channels of language data along with the control information generated by the control information generating means on a record medium.
      <br/>
      Thus it becomes possible to record video data and plural channels of language data on a record medium so that a reproducing channel for the language data matched to the reproducing pattern of the video data will be selected and the plural channels of language data matched to the reproducing pattern and the video data will be reproduced by a reproducing system.
    </p>
    <p num="19">
      With the data recording apparatus according to the present invention, the video data and the plural channels of language data are multiplexed and recorded on a record medium along with the control information containing a flag designating a reproducing channel of the language data matched to a reproducing pattern of the video data.
      <br/>
      Thus it becomes possible to record video data and plural channels of speech data on a record medium so that a reproducing channel for the speech data matched to the reproducing pattern of the video data will be selected and the plural channels of language data matched to the reproducing pattern and the video data will be reproduced by a reproducing system.
    </p>
    <p num="20">
      With the data recording apparatus according to the present invention, the video data and the plural channels of the language data are multiplexed and recorded on a record medium, and the control information containing a flag designating the reproducing channel of the language data matched to the reproducing pattern of video data is recorded in a pre-set area on the record medium.
      <br/>
      Thus it becomes possible to record video data and plural channels of speech data on a record medium so that a reproducing channel for the speech data matched to the reproducing pattern of the video data will be selected and the plural channels of language data matched to the reproducing pattern and the video data will be reproduced by a reproducing system.
    </p>
    <p num="21">
      With the data recording apparatus according to the present invention, speech data, for example, is recorded as the language data on the record medium.
      <br/>
      Thus it becomes possible to record video data and plural channels of speech data on a record medium so that a reproducing channel for the speech data matched to the reproducing pattern of the video data will be selected and the plural channels of language data matched to the reproducing pattern and the video data will be reproduced by a reproducing system.
    </p>
    <p num="22">
      With the data recording apparatus according to the present invention, speech data and/or title data, for example, is recorded as the language data on the record medium.
      <br/>
      Thus it becomes possible to record video data and plural channels of speech data on a record medium so that a reproducing channel for the speech data matched to the reproducing pattern of the video data will be selected and the plural channels of speech data matched to the reproducing pattern and the video data will be reproduced by a reproducing system.
    </p>
    <p num="23">
      With the data recording apparatus according to the present invention, video data and plural channels speech data and/or plural channels of title data are divided into packets as units by packet dividing means and recorded on a record medium in a multiplexed or separate form by recording means along with the control information generated by control information generating means and containing a flag designating a reproducing channel for the speech data and the title data matched to the reproducing pattern of the video data.
      <br/>
      Thus it becomes possible to record video data and plural channels of speech data and plural channels of title data on a record medium so that a reproducing channel for the speech and title data matched to the reproducing pattern of the video data will be selected and the speech and title data matched to the reproducing pattern and the video data will be reproduced by a reproducing system.
    </p>
    <p num="24">
      A data record medium according to the present invention has recorded thereon video data and plural channels of language data, divided into packets as units, and the control information containing a flag designating a reproducing channel of the language data matched to a reproducing pattern of the video data.
      <br/>
      Thus it becomes possible for the reproducing system to select the reproducing channel of language data matched to a reproducing pattern of the video data and to reproduce the language data matched to the reproducing pattern and the video data.
    </p>
    <p num="25">
      With the data record medium according to the present invention, video data and plural channels of language data are multiplexed and recorded thereon along with the control information containing a flag designating a reproducing channel of the language data matched to a reproducing pattern of the video data.
      <br/>
      Thus it becomes possible for the reproducing system to select the reproducing channel of language data matched to a reproducing pattern of the video data and to reproduce the language data matched to the reproducing pattern and the video data.
    </p>
    <p num="26">
      With the data record medium according to the present invention, video data and plural channels of the language data are multiplexed and recorded thereon, and the control information containing a flag designating the reproducing channel of the language data matched to the reproducing pattern of the video data is recorded in a pre-set area thereof.
      <br/>
      Thus it becomes possible for the reproducing system to select the reproducing channel of language data matched to a reproducing pattern of the video data and to reproduce the language data matched to the reproducing pattern and the video data.
    </p>
    <p num="27">
      With the data record medium according to the present invention, speech data, for example, is recorded as the language data on the record medium.
      <br/>
      Thus it becomes possible for the reproducing system to select the reproducing channel of speech data matched to a reproducing pattern of the video data and to reproduce the speech data matched to the reproducing pattern and the video data.
    </p>
    <p num="28">
      With the data record medium according to the present invention, speech data and/or title data, for example, is recorded as the language data on the record medium.
      <br/>
      Thus it becomes possible for the reproducing system to select the reproducing channel of speech data and/or the title data matched to a reproducing pattern of the video data and to reproduce the speech data and/or the title data matched to the reproducing pattern and the video data.
    </p>
    <p num="29">
      With the data record medium according to the present invention, video data and plural channels of speech data and/or plural channels of title data are divided into packets as units and recorded in a multiplexed or separate form with the control information containing a flag designating a reproducing channel for the speech data and/or the title data matched to the reproducing pattern of the video data.
      <br/>
      Thus it becomes possible for the reproducing system to select the reproducing channel of speech data and title data matched to a reproducing pattern of the video data and to reproduce the speech data and/or the title data matched to the reproducing pattern and the video data.
    </p>
    <p num="30">With the data reproducing method according to the present invention, a reproducing channel for language data matched to a reproducing pattern of video data is selected based on a flag contained in the control information for reproducing the language data matched to the reproducing pattern and the video data.</p>
    <p num="31">
      With the data reproducing method according to the present invention, the control information is reproduced from a record medium having the video data and the plural channels of language data multiplexed and recorded thereon along with the control information containing a flag designating a reproducing channel of the language data matched to a reproducing pattern of the video data, and a reproducing channel of language data matched to a reproducing pattern of the video data is selected based on the flag contained in the control information for reproducing the language data matched to the reproducing pattern and the video data.
      <br/>
      Thus it becomes possible to reproduce video data and language data matched to the reproducing pattern.
    </p>
    <p num="32">
      With the data reproducing method according to the present invention, the control information is reproduced from a record medium on which the video data and the plural channels of the language data are multiplexed and recorded and in a pre-set area of which the control information containing a flag designating the reproducing channel of the language data matched to the reproducing pattern of video data is recorded, and a reproducing channel of language data matched to a reproducing pattern of the video data is selected based on the flag contained in the control information.
      <br/>
      Thus it becomes possible to reproduce the language data matched to the reproducing pattern and the video data.
    </p>
    <p num="33">With the data reproducing method according to the present invention, speech data, for example, is reproduced as the language data from the data record medium for reproducing the speech data matched to the reproducing pattern of video data along with the video data.</p>
    <p num="34">With the data reproducing method according to the present invention, speech data and/or title data, for example, is reproduced as the language data from the data record medium for reproducing the speech data and/or the title data matched to the reproducing pattern of video data along with the video data.</p>
    <p num="35">
      With an apparatus for reproducing video data and plural channels of language data from a record medium having recorded thereon the video data divided into packets as units and plural channels of language data also divided into packets as units, and also having recorded thereon the control information containing a flag designating a reproducing channel of the language data matched to a reproducing pattern of the video data, flag detection means is provided for detecting a flag contained in the control information, and reproducing processing means is provided for selecting a reproducing channel of language data matched to a reproducing pattern of the video data based on a detection output of the flag detection means.
      <br/>
      Thus it becomes possible to reproduce the language data matched to the reproducing pattern and the video data.
    </p>
    <p num="36">
      With the data reproducing apparatus according to the present invention, flag detection means detects a flag contained in the control information reproduced from a data record medium having the video data and the plural channels of language data multiplexed and recorded thereon along with the control information containing a flag designating a reproducing channel of the language data matched to a reproducing pattern of the video data.
      <br/>
      The reproducing processing means selects a reproducing channel of language data matched to the reproducing pattern of the video data for reproducing the language data matched to the reproducing pattern and the video data.
    </p>
    <p num="37">
      With the data reproducing apparatus according to the present invention, the flag detection means detects a flag contained in the control information reproduced from a data record medium on which the video data and the plural channels of the language data are multiplexed and recorded thereon, and in a pre-set area thereon of which the control information containing a flag designating the reproducing channel of the language data matched to the reproducing pattern of video data is recorded.
      <br/>
      Based on the detection output, the reproducing processing means selects the reproducing channel of language data matched to the reproducing pattern of the video data for reproducing video data and the language data matched to the reproducing pattern of the video data.
    </p>
    <p num="38">With the data reproducing apparatus according to the present invention, the reproducing processing means reproduces speech data matched to the reproducing patter of the video data from the data record medium along with the video data.</p>
    <p num="39">With the data reproducing apparatus according to the present invention, the reproducing processing means reproduces speech data and/or title data matched to the reproducing pattern of the video data from the data record medium along with the video data.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="40">
      FIG. 1 is a block diagram showing the structure of a data encoding apparatus according to the present invention.
      <br/>
      FIG. 2 illustrates a pack format of a disc format in the data encoding apparatus shown in FIG. 1.
      <br/>
      FIG. 3 illustrates a format for an entry sector.
      <br/>
      FIG. 4 illustrates Program_Stream_Directory in the entry sector.
      <br/>
      FIG. 5 illustrates the contents of Program_Stream_Map in the entry sector.
      <br/>
      FIG. 6 illustrates the contents of description of Program Stream_Map.
      <br/>
      FIG. 7 illustrates the contents of dvd_audio_descriptor( ) described in the Program_Stream_Map.
      <br/>
      FIG. 8 illustrates the contents of dvd_lpcm_descriptor( ) described in the Program_Stream_Map.
      <br/>
      FIG. 9 illustrates the contents of dvd_subtitle descriptor( ) described in the Program_Stream_Map.
      <br/>
      FIG. 10 illustrates the contents of subtitle_type described in dvd_subtitle_descriptor( ).
      <br/>
      FIG. 11 is a block diagram showing the structure of a data decoding apparatus embodying the present invention.
      <br/>
      FIG. 12 shows an array f data in a DSM in the data encoding apparatus.
      <br/>
      FIG. 13 illustrates a typical structure of TOC data.
      <br/>
      FIG. 14 is a block diagram showing the structure of the data encoding apparatus embodying the present invention.
      <br/>
      FIG. 15 illustrates a format of an entry sector in the data encoding apparatus.
      <br/>
      FIG. 16 illustrates the contents of path_descriptor( ) described in global_descriptor 89 in Program_Stream_Map in the entry sector.
      <br/>
      FIG. 17 is a block diagram showing the structure of a data decoding apparatus embodying the present invention.
    </p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
    <p num="41">
      Referring to the drawings, preferred embodiments of the present invention will be explained in detail.
      <br/>
      The data encoding method according to the present invention is implemented by a data encoding apparatus configured as shown for example in FIG. 1.
    </p>
    <p num="42">
      The data encoding apparatus, shown in FIG. 1, includes a video encoder 1 for encoding video signals for compression, and audio encoders 2A, 2B and 2C for packetizing audio signals of, for example, three routes, that is AU1, AU2 and AU3.
      <br/>
      The data encoding apparatus also includes a multiplexer 3 connected to the video encoder 1 and to the audio encoders 2A to 2C.
    </p>
    <p num="43">
      In the above encoding apparatus, an output terminal of the video encoder 1 is connected to an input terminal of a video entry point detection circuit 31 of the multiplexer 3.
      <br/>
      An output terminal of the video entry point detection circuit 31 is connected to an input terminal of a code buffer 4.
      <br/>
      An entry sector generating circuit 32 is responsive to a control input of a controller 8 and routes its output to an input terminal E3 of a switching circuit 6.
      <br/>
      The controller 8 is also responsive to system clocks outputted by a multiplexing system clock generating circuit 9 to connect input terminals E1, E2, E3, E4 and E5 of the switching circuit 6 sequentially to an output terminal F in a pre-set period for sequentially taking out data from the code buffers 4, 5A, 5B and 5C or from the entry sector generating circuit 32, for time division multiplexing the data and for routing the data to a header appendage circuit 7.
    </p>
    <p num="44">The controller 8 also controls the header appendage circuit 7 for appending a video packet header to video data read out from the video packet header and for appending an audio packet header to audio data read out from the audio packet header.</p>
    <p num="45">
      The controller 8 is responsive to an input of an entry point generating signal generated at an I-picture generating timing from the video encoder 1 or from the video entry point detection 31 and controls the entry sector generating circuit 32 for inserting an entry sector at a pre-set position of a bitstream.
      <br/>
      If the video encoder 1 is configured for outputting an entry point generating signal, the video encoder 1 outputs an entry point generating signal at a generating timing of the I-picture.
    </p>
    <p num="46">
      If the video encoder 1 is unable to output an entry point generating signal, or a pre-encoded video bitstream is multiplexed, the video entry point detection circuit 31 generates an entry point generating signal at a generating timing of an I-picture, or detects an entry point from video data supplied from the video encoder 1 to output an entry point generating signal.
      <br/>
      An entry point storage unit 33 is a memory capable of reading and writing data from the controller 8 and stores the position of the detected entry point.
    </p>
    <p num="47">
      A MAP information storage device 35 stores the information entered from an external input device, and is controlled by the controller 8 so that the information stored therein will be read out each time the information constitutes an entry sector and subsequently stored in the entry sector.
      <br/>
      If the information is such information as uses the position of a future entry sector, the position of the entry sector is read out from the entry point storage device 33 and supplied to a DSM 10 for recording therein.
    </p>
    <p num="48">
      In the data encoding device shown in FIG. 1, a multiplexed bitstream is made up of at least one pack and ISO 11172 end code.
      <br/>
      Each pack is constituted by a format as shown for example in FIG. 2.
    </p>
    <p num="49">
      That is, at the leading end of a pack is placed a header Pack Header made up of Pack_Start_Code, SCR and MUX_Rate, followed by Video_Packet_Header and video data, not containing an I-picture in a sector configuration, in this order.
      <br/>
      Next to the video data is arrayed Entry_Packet, followed by Video_Packet Header and video data containing the I-picture in a sector configuration, in this order.
      <br/>
      Directly before video data containing the I-picture (entry point), that is directly before Video_Packet_Header, is arrayed Entry_Packet.
      <br/>
      In the present embodiment, Audio_Packet_Header is arrayed next to video data and audio data of a sector structure is arrayed next to Audio_Packet Header.
    </p>
    <p num="50">
      The entry sector Entry_Packet is of a format shown in FIG. 3.
      <br/>
      At a leading end of the entry sector shown in FIG. 3 is arrayed Pack Header made up of Pack_Start_code, SCR and MUX_Rate, followed by Program_Stream_Directory and Program_Stream_Map in this order.
      <br/>
      In the present embodiment, there is arrayed a packet other than a video packet, followed by video data inclusive of an I-picture.
      <br/>
      In the present embodiment, since the information appears from the leading end of the sector in a pre-set sequence, the information can be handled easily.
    </p>
    <p num="51">
      The directory Program_Stream_Directory is of a structure defined by the MPEG2 system standard and is used for indicating the accessible position in a stream.
      <br/>
      By traversing the loop A shown in FIG. 4 seven times, the positions of three forward intra-pictures, one directly backward intra-picture and three backward entry points are recorded.
    </p>
    <p num="52">
      The map program_Stream_Map is defined as shown for example in FIG. 5.
      <br/>
      In loops B and C in FIG. 5 are placed descriptors ( ) for accommodating a variety of information data, as shown in FIG. 6.
      <br/>
      In the present embodiment, div audio descriptor ( ) shown in FIG. 7 is defined as a descriptor ( ) contained in the loop C in Program Stream_Map.
      <br/>
      Also, dvd_lpcm_descriptor( ) shown in FIG. 8 and dvd subtitle descriptor( ) shown in FIG. 9 are defined.
    </p>
    <p num="53">
      In FIG. 7, dvd_audio_descriptor( ) is a descriptor used for audio data compressed by MPEG Audio.
      <br/>
      The flag path number flag N is a 1-bit flag which is set to 1 or 0 if an audio stream is to be reproduced by a path number N or is not to be reproduced, respectively.
      <br/>
      On the other hand, channel_configuration denotes the number of encoded channels in the audio bitstream.
    </p>
    <p num="54">
      In FIG. 8, dvd_lpcm descriptor is a 4-bit code defining an audio mix type in LPCM.
      <br/>
      The flag path_number_flag N is a 1-bit flag which is set to 1 or 0 if an audio stream is to be reproduced by a path number N or is not to be reproduced, respectively.
    </p>
    <p num="55">
      On the other hand, subtitle_type in dvd_subtitle descriptor( ) shown in FIG. 9 is a 4-bit code defining the type of the subtitle stream shown in FIG. 10, while aspect_ratio information is a 4-bit code defining the display aspect of the subtitle stream.
      <br/>
      The flag path_number_flag_N is a 1-bit flag which is set to 1 or 0 if an audio stream is to be reproduced by a pass number N or is not to be reproduced, respectively.
    </p>
    <p num="56">The data array on the DSM 10 is configured as shown in FIG. 12. That is, the information comprised of a collection of multiplexed streams termed table-of-contents (TOC) and multiplexed streams are sequentially recorded beginning from the inner rim side of the disc.</p>
    <p num="57">
      The TOC data is recorded as shown for example in FIG. 13. That is, the number of the multiplexed streams in the disc is first recorded.
      <br/>
      The loop is traversed in a number of times corresponding to the number of multiplexed streams for recording the information of each multiplexed stream.
    </p>
    <p num="58">
      In the loop are first recorded the leading and last sector addresses of the multiplexed streams, followed by Program_Stream Map defined as shown in FIG. 5.
      <br/>
      This is the same as the map recorded in the stream.
      <br/>
      That is, dvd_audio_descriptor( ), dvd_lpcm descriptor( ) and dvd_subtitle_descriptor( ) shown in FIGS. 7, 8 and 9, respectively, are defined in Program_Stream_Map.
    </p>
    <p num="59">
      The operation of the data encoding apparatus shown in FIG. 1 is now explained.
      <br/>
      The controller 8 receives an entry point generating signal from the video encoder 1 or from the video entry point detection circuit 31 and causes an entry sector to be inserted directly before the video entry point.
      <br/>
      That is, on reception of the entry point generating signal, the controller 8 causes an entry packet to be generated in the entry sector generating circuit 32.
      <br/>
      The controller 8 then sets a movable contact of the switching circuit 6 to the input terminal E3 to cause the packet to be routed to the header appendage circuit 7 for multiplexing with video data from the code buffers 4, 5A, 5B and 5C and audio data of the respective channels.
    </p>
    <p num="60">The respective elementary streams of the above video data and the audio data of the respective channels are recorded in such a manner that the types of the elementary streams are defined by stream type in Program_Stream_Map and also in such a manner that a flag specifying a reproducing channel of audio data matched to the reproducing pattern or path of the video data is supplied by dvd_audio_descriptor( ) or dvd_lpcm_descriptor( ).</p>
    <p num="61">
      It is assumed that three routes of audio signals AU1, AU2 and AU3 are all recorded with compression by DVD audio, the audio signal AU1 is the general speech, while the audio signals AU2 and AU3 are speech for adults and for children, respectively.
      <br/>
      With the reproducing pattern of video signals for general use, reproduction of the audio signals AU1 and AU3 among the three routes of the audio signal AU1 to AU3 is allowed.
      <br/>
      With the reproducing pattern or path 1 for adults, reproduction of all of the audio signals AU1 to AU3 is allowed, whereas, with the reproducing pattern or path 2 of video signals for children, only reproduction of the audio signals AU3 is allowed.
    </p>
    <p num="62">That is, in dvd_audio_descriptor( ) in PSM defining attributes of data associated with the speech for general use, the flags path_number_flag 0 and path number flag 2 are set to 1, while the flag path number flag 1 is set to 0.</p>
    <p num="63">On the other hand, in dvd_audio_descriptor( ) in the PSM defining attributes of data for adult speech, the flags path number flag are all set to 1.</p>
    <p num="64">In dvd_audio_descriptor( ) in PSM defining attributes of data associated with the speech for children, the flag path number flag 2 is set to 1, while the flags path number flag 0 and path number flag 1 is set to 0.</p>
    <p num="65">Alternatively, the reproducing channels may be fixed from one reproducing pattern to another, so that reproduction of the audio signals AU1, AU2 and AU3 will be allowed with reproducing patterns path 1, reproducing patterns path 2 and reproducing patterns path 3, respectively.</p>
    <p num="66">Stated differently, only the flag path_number_flag 0, the flag path_number_flag 1 or the flag path_number_flag 2 are set to 1 for the general speech, for speech for adults and for speech for children, respectively.</p>
    <p num="67">
      For providing the structure shown in FIG. 12, the data encoding apparatus shown in FIG. 1 operates as follows: First, the TOC area is procured.
      <br/>
      This procures an area for the DSM 10 in advance for matching with the number of the designated multiplexed streams.
      <br/>
      The encoding as described above is then performed.
    </p>
    <p num="68">
      Each time the encoding of a multiplexed stream is completed, the data encoding apparatus shown in FIG. 1 updates the TOC data.
      <br/>
      That is, dvd_audio_descriptor( ), dvd_lpcm descriptor( ) and dvd Subtitle_descriptor( ), which are the same as those described in the entry point information, are recorded as the leading and last sector addresses of the encoded multiplexed streams.
    </p>
    <p num="69">In this manner, the reproducing channel of speech data matched to the reproducing pattern of the video data are designated by the flags for encoding.</p>
    <p num="70">
      Referring to FIG. 11, a data decoding apparatus according to an embodiment of the present invention is explained.
      <br/>
      The data decoding apparatus shown in FIG. 11 decodes data reproduced from the DSM 10 having recorded thereon data encoded by the data encoding apparatus shown in FIG. 1.
    </p>
    <p num="71">
      In this data decoding apparatus, a header separation circuit 22 of the separation device 21 separates a pack header, a sector header and an entry sector from data read out from the DSM 10 and routes the separated data to a controller 24, while routing time-divisional multiplexed data to an input terminal G of a switching circuit 23.
      <br/>
      The switching circuit 23 has its output terminals H1 and H2 connected to an input terminal of an audio decoder 26.
    </p>
    <p num="72">
      The controller 24 reads out the information concerning an entry point from data supplied from the header separation circuit 22 and causes the read-out data to be routed to and stored in an entry point storage unit 33.
      <br/>
      Since the controller 24 is fed with the information concerning the current read-out position from the DSM 10, the controller 24 can store the position of the entry point in association with its contents.
    </p>
    <p num="73">In accordance with stream_id of the sector header supplied from the header separation circuit 22, the controller 24 of the separation device 21 causes an input terminal G of the switching circuit 23 to be sequentially connected to output terminals H1 and H2 thereof for routing video data and audio data to the video decoder 25 and to the audio decoder 26, respectively.</p>
    <p num="74">
      If there is sufficient capacity allowance in a storage circuit of the controller 24, the following operation s feasible.
      <br/>
      That is, prior to reproduction, the controller reads out the TOC shown in FIG. 12 for storage in its own storage circuit.
      <br/>
      This enables the processing to be performed without the necessity of fetching the information each time the multiplexed stream is reproduced.
    </p>
    <p num="75">With the present decoding apparatus for the multiplexed data, the controller 24 controls the reproducing operation so that it selects an audio stream by the path designated by the path designation signal as set by the user and the information on the path of the multiplexed bitstream for causing audio data matched to the video data to be decoded by the audio decoder 26.</p>
    <p num="76">
      If, with the above-described decoding apparatus for multiplexed data, the audio signals AU1, AU2 and AU3 is the general speech, the speech for adults and the speech for children, respectively, the audio signal AU1 or AU3 can be decoded by designation by the path designation signal for the reproducing pattern path 0 for general video signals, while any of the audio signals AU1 to AU3 can be decoded by designation by the path designation signal for the reproducing pattern path 1 for adults.
      <br/>
      Only the audio signal AU3 can be decoded by the reproducing pattern path 2 for children.
    </p>
    <p num="77">The data encoding method according to the present invention may be implemented by a data encoding apparatus shown for example in FIG. 14.</p>
    <p num="78">The data encoding apparatus shown in FIG. 14 is configured for handling eight routes of audio signals in the data encoding apparatus shown in FIG. 1, and includes title encoders 11A to 11H and code buffers 12A to 12H configured for packetizing associated eight routes of the tile data.</p>
    <p num="79">
      The controller 8 is responsive to system clocks outputted by the multiplexed system clock generating circuit 9 to interconnect input terminals E1 to E18 of the switching circuit 6 to its output terminal F in a pre-set period in order to take out data from the code buffers 4, 5A to 5H and 12A to 12H or the entry sector generating circuit 32.
      <br/>
      The controller causes the data to be time-divisionally multiplexed and outputted to the header appendage circuit, 7.
      <br/>
      The controller 8 also controls the header appendage circuit 7 to append a video packet header to video data read out from the code buffer 4.
      <br/>
      The controller also appends an audio packet header to audio data read out from the code buffers 5A to 5H, while appending a title packet header to title data read out from the code buffers 12A to 12H.
      <br/>
      In addition, the controller 8 receives an entry point generating signal, generated at an I-picture generating timing, and controls the entry sector generating circuit 32 for inserting an entry sector at a pre-set position of the bitstream.
      <br/>
      If the video encoder 1 is configured for outputting an entry point generating signal, the video encoder 1 outputs an entry point generating signal at an I-picture generating timing.
    </p>
    <p num="80">
      If the video encoder 1 is unable to output an entry point generating signal, or a pre-encoded video bitstream is multiplexed, the video entry point detection circuit 31 generates an entry point generating signal at a generating timing of an I-picture, or detects an entry point from video data supplied from the video encoder 1 to output an entry point generating signal.
      <br/>
      An entry point storage unit 33 is a memory capable of reading and writing data from the controller 8 and stores the position of the detected entry point.
    </p>
    <p num="81">
      A MAP information storage device 35 stores the information entered from an external input device, and is controlled by the controller 8 so that the information stored therein will be read out each time the information constitutes an entry sector and subsequently stored in the entry sector.
      <br/>
      If the information is such information as uses the position of a future entry sector, the position of the entry sector is read out from the entry point storage device 33 and supplied to the DSM 10 for recording therein.
    </p>
    <p num="82">
      In the data encoding apparatus, shown in FIG. 14, there is arrayed at the leading end of a pack a header Pack_Header made up of Pack_Start_Code, SCR and MUX_Rate, followed by Video_Packet Header and video data, not containing an I-picture in a sector configuration, in this order.
      <br/>
      Next to the video data is arrayed Entry_Packet, followed by Video_Packet_Header and video data containing the I-picture in a sector configuration, in this order.
      <br/>
      Directly before video data containing the I-picture (entry point), that is directly before Video_Packet_Header, is arrayed Entry Packet.
      <br/>
      In the present embodiment, Audio_Packet_Header is arrayed next to video data and audio data of a sector structure is arrayed next to Audio_Packet_Header.
    </p>
    <p num="83">
      The entry sector Entry_Packet is of a format shown in FIG. 3.
      <br/>
      At a leading end of the entry sector shown in FIG. 3 is arrayed Pack Header made up of Pack_Start_code, SCR and MUX_Rate, followed by Program_Stream_Directory and Program_Stream_Map in this order.
      <br/>
      In the present embodiment, there is arrayed a packet other than a video packet, followed by video data inclusive of an I-picture.
      <br/>
      In the present embodiment, since the information appears from the leading end of the sector in a pre-set sequence, the information can be handled easily.
      <br/>
      In this case, Audio_Packet Header is arrayed next to video data, followed by a sector structure of audio data.
      <br/>
      Next to the audio data is arrayed a title Packet_Header, followed by a sector structure of title data.
    </p>
    <p num="84">The above Program_Stream_Directory is of a structure defined by the MPEG2 system standard and is used for indicating the accessible position in a stream.</p>
    <p num="85">In Program_Stream_Map is defined global descriptor( ) in which is defined path_descriptor ( ) shown in FIG. 16.</p>
    <p num="86">The descriptor path_descriptor ( ) defines each path and has a syntax shown in FIG. 16. As shown therein, the descriptor describes path numbers path_number, track numbers track_number, sector numbers pX_sectors_to_read, pX_sectors_from_start, sector offsets pX_offset next section . . . pX_offset start track, track time codes pX_track_tc_hours-- 1 . . . pX_track_tc frames-- 2, pass time codes pX_path_tc_hours-- 1 . . . pX_path_tc frames-- 2.</p>
    <p num="87">The path number path_number is a 3-bit value according path numbers referred to by the descriptor.</p>
    <p num="88">
      The track number track_number is a 16-bit value equal to the current track number.
      <br/>
      It is an encoded value of a relative track number towards the program start position.
      <br/>
      The track numbers of the segments are used in common by a path or plural paths.
      <br/>
      The track number is incremented through paths.
      <br/>
      The absolute track number on the disc can be known by adding the track number offset provided by program_linkage in disc_toc ( ) to the relative track number.
    </p>
    <p num="89">The sector number pX_sectors_to_read is an integer without a sign for according the remaining number of sectors necessary until reading the program section of the path number X. If this value is N, N sectors inclusive of the current section are left until reading as far as the end of the section of the path.</p>
    <p num="90">
      The sector number pX_sectors_from_start is an integer without a sign which accords the number of sectors from the current sector of the path number X until the start position of the current section.
      <br/>
      If the value is 0, the current sector is the first sector of the section.
      <br/>
      If this value is N, there are N sectors, exclusive of the current sector, from the start position of the current section as far as the current sector.
    </p>
    <p num="91">
      The offset pX_offset_next_section is a sector offset from the current sector of the path of the path number as far as the entry sector of the start position of the next section.
      <br/>
      This offset is positive or negative and encoded in 2's complement form.
      <br/>
      If this value is 0, there is no section to be reproduced next to the section to which belongs the current sector, that is, the program has come to a close.
    </p>
    <p num="92">
      The offset pX_offset_previous_section is a sector offset from the current entry sector of the path of the path number X as far as the last entry sector of the previous section.
      <br/>
      This offset is positive or negative and encoded in 2's complement form.
      <br/>
      If this value is 0, there is no section to be reproduced before the section to which belongs the current sector, that is, the program has now started.
    </p>
    <p num="93">If the sector numbers (pX_sectors_to_read and pX_sectors from_start) and the above offsets (pX_offset_next_section and pX_offset_previous_section) are all zero, the path of the path number X is not used, or the entry sector is not a part of the path of the path number X.</p>
    <p num="94">
      The offset pX_offset_next_track is a sector offset from the current sector of the path of the path number X as far as the entry sector of the start position of the next current track.
      <br/>
      This offset is positive or negative and encoded in 2's complement form.
      <br/>
      If this value is 0, there is no next track on the path.
    </p>
    <p num="95">
      The offset pX_offset_start_track is a sector offset from the current sector of the path of the path number X as far as the entry sector of the start position of the current track.
      <br/>
      This offset is positive or negative and encoded in 2's complement form.
      <br/>
      If the current entry sector is the leading end of a track, this offset pX_offset_start_track is an offset to the start position of the previous track.
      <br/>
      If this value is 0, there is no previous. track on the pass.
    </p>
    <p num="96">The above is the manner of describing the path number of the section containing the current entry sector in the PSM in the entry sector.</p>
    <p num="97">
      The operation of an embodiment of a data encoding apparatus shown in FIG. 14 is now explained.
      <br/>
      The controller 8 receives an entry point generating signal from the video encoder 1 or from the video entry point detection circuit 31 and causes an entry sector to be inserted directly before the video entry point.
      <br/>
      That is, on reception of the entry point generating signal, the controller 8 causes an entry packet to be generated in the entry sector generating circuit 32.
      <br/>
      The controller 8 then sets a movable contact of the switching circuit 6 to the input terminal E18 to cause the packet to be routed to the header appendage circuit 7 for multiplexing with video data from the code buffers 4, 5A to 5H and 12A to 12H, audio data of the respective channels and title data of the respective channels.
    </p>
    <p num="98">The respective elementary streams of the above video data and the audio data of the respective channels are recorded in such a manner that the types of the elementary streams are defined by stream_type in Program_Stream_Map and also in such a manner that a flag specifying a reproducing channel of audio data matched to the reproducing pattern or path of the video data is supplied by dvd_audio_descriptor( ) or dvd_lpcm_descriptor( ).</p>
    <p num="99">
      Referring now to FIG. 17, a data decoding apparatus according to an embodiment of the present invention is explained.
      <br/>
      The data decoding apparatus shown in FIG. 17 is configured for decoding data reproduced from the DSM 10 having recorded thereon data encoded by the encoding apparatus shown in FIG. 14, and is similar to a data decoding apparatus except having further a title decoder 27.
    </p>
    <p num="100">
      In the present data decoding apparatus, the header separation circuit 28 of the separation device 21 separates the pack header, sector header and the entry sector from data read out from the DSM 10 and routes the separated data to the controller 24, while routing time-divisionally multiplexed data to the input terminal G of the switching circuit 23.
      <br/>
      The switching circuit 23 has its output terminals H1, H2 and H3 connected to input terminals of the video decoder 25, audio decoder 26 and the title decoder 27.
    </p>
    <p num="101">
      The controller 24 reads out the information concerning an entry point (entry sector information) from data supplied from the header separation circuit 22 and causes the read-out data to be routed to and stored in an entry point storage unit 41.
      <br/>
      Since the controller 24 is fed with the information concerning the current read-out position from the DSM 10, the controller 24 can store the position of the entry point in association with its contents.
    </p>
    <p num="102">In accordance with stream_id of the sector header supplied from the header separation circuit 22, the controller 24 of the separation device 21 causes the input terminal G of the switching circuit 23 to be sequentially connected to output terminals H1 to H3 thereof for routing video data and audio data to the video decoder 25 and to the audio decoder 26, respectively.</p>
    <p num="103">
      If there is sufficient capacity allowance in a storage circuit of the controller 24, the following operation is feasible.
      <br/>
      That is, prior to reproduction, the controller reads out the TOC for storage in its own storage circuit.
      <br/>
      This enables the processing to be performed without the necessity of fetching the information each time the multiplexed stream is reproduced.
    </p>
    <p num="104">In the present multiplexed data decoding apparatus, the controller 24 controls the reproducing operation so that it selects an audio stream and the title data by the path designated by the path designation signal as set by the user and the information on the path of the multiplexed bitstream for causing audio data matched to the video data and the title data to be decoded by the audio decoder 26 and by the title decoder 27, respectively.</p>
    <p num="105">
      With the above-described structure of the multiplexed data decoding apparatus, it is assumed that, among the eight routes of the audio signals AU1 to AU8, the audio signal AU1 is general English speech, the audio signal AU2 is general French speech, the audio signal AU3 is general Japanese speech, the audio signal AU4 is English speech for adults, the audio signal AU5 is French speech for adults, the audio signal AU6 is Japanese speech for adults, the audio signal AU7 is English speech for children, the audio signal AU8 is French speech for children, and the audio signal AU9 is Japanese speech for children.
      <br/>
      It is also assumed that, among the eight routes of the title signals CH1 to CH8, the title signal CH1 is general English title, the title signal CH2 is general French title, the title signal CH3 is general Japanese title, the title signal CH4 is English title for adults, the title signal CH5 is French title for adults, the title signal CH6 is Japanese title for adults, the title signal CH7 is English title for children, the title signal CH8 is French title for children, and the title signal CH9 is Japanese title for children.
    </p>
    <p num="106">
      With the reproducing pattern path 0 for general video signals, the audio signals AU1 to AU3 or AU7 and AU8 of the eight routes of the audio signal AU1 to AU8 can be decoded by designation with the path designation signal.
      <br/>
      With the reproducing pattern path 1 for adults, any of the eight routes of audio signals AU1 to AU8 can be decoded by designation by the path designation signals.
    </p>
    <p num="107">With the reproducing pattern path 1 for adults, any of the eight title signals CH1 to CH8 can be decoded, whereas, with the reproducing pattern path 2 for children, the title signals CH7 and CH8 may be decoded.</p>
    <p num="108">The on/off of audio data and title data in each reproducing pattern is designated by a 1-bit flag path_number_flag_N which is set to 1 or 0 if the audio stream is to be reproduced by the path number N or otherwise, respectively.</p>
    <p num="109">The attributes of the audio data recorded as general speech are such that, in dvd_audio_descriptor( ) in the PSM, path_number flag-- 0 and path_number_flag-- 2 are set to 1, while path_number flag-- 1 is set to 0.</p>
    <p num="110">The attributes of the title data recorded as general speech are such that, in dvd_subtitle_descriptor( ) in the PSM, path number_flag-- 0 and path_number_flag-- 2 are set to 1, while path number_flag-- 1 is set to 0.</p>
    <p num="111">The attributes of the audio data recorded as general speech for adults are such that, in dvd_subtitle descriptor( ) in the PSM, path_number_flag-- 0, path_number_flag-- 1, and path_number flag-- 2 are set to 1.</p>
    <p num="112">The attributes of the title data recorded as general speech for adults are such that, in dvd_subtitle descriptor( ) in the PSM, path_number_flag-- 0, path_number_flag-- 1, and path_number_flag 2 are set to 1.</p>
    <p num="113">The attributes of the audio data recorded as speech for children are such that, in dvd_audio_descriptor( ) in the PSM, path_number_flag-- 2 is set to 1, while path_number_flag-- 0 and path_number_flag-- 1 are set to 0.</p>
    <p num="114">The attributes of the title data recorded as speech for children are such that, in dvd_subtitle_-descriptor( ) in the PSM, path_number_flag-- 2 is set to 1, while path_number_flag-- 0 and path_number_flag-- 1 are set to 0.</p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A data recording method comprising the steps of:</claim-text>
      <claim-text>receiving video data including first and second reproducing patterns and plural (N) channels of language data; dividing said video data and said plural channels of language data into packets as units;</claim-text>
      <claim-text>and recording said video data and said plural channels of language data on a recording medium along with control information designating an available language data channel or channels for the first and second video data patterns such that all of the N plural channels of language data are available for said first video data pattern and only less than N of the channels of language data are available for said second video data pattern.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. A data recording apparatus comprising: means for receiving video data including first and second reproducing patterns and plural (N) channels of language data; means for dividing said video data and said plural channels of language data into packets as units;</claim-text>
      <claim-text>and means for recording said video data and said plural channels of language data on a recording medium along with control information designating an available language data channel or channels for the first and second video data patterns such that all of the N plural channels of language data are available for said first video data pattern and only less than N of the channels of language data are available for said second video data pattern.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. A data recording medium having recorded thereon video data including first and second reproducing patterns and plural (N) channels of language data, divided into packets as units, and control information designating an available language data channel or channels for the first and second video data patterns such that all of the N plural channels of language data are available for said first video data pattern and only less than N of the channels of language data are available for said second video data pattern.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. A method for reproducing data from a data recording medium having recorded thereon video data including first and second reproducing patterns and plural (N) channels of language data, divided into packets as units, and control information designating an available language data channel or channels for the first and second video data patterns such that all of the N plural channels of language data are available for said first video data pattern and only less than N of the channels of language data are available for said second video data pattern, comprising: selecting a reproducing channel of language data matched to a selected reproducing pattern of said video data based on said control information;</claim-text>
      <claim-text>and reproducing the language data matched to said reproducing pattern of said video data.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. An apparatus for reproducing data from a data recording medium having recorded thereon video data including first and second reproducing patterns and plural (N) channels of language data, divided into packets as units, and control information designating an available language data channel or channels for the first and second video data patterns such that all of the N plural channels of language data are available for said first video data pattern and only less than N of the channels of language data are available for said second video data pattern, comprising: means for detecting said control information; means for selecting a reproducing channel of language data matched to a selected reproducing pattern of said video data based on said control information;</claim-text>
      <claim-text>and means for reproducing the language data matched to said reproducing pattern of said video data.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. A data recording method comprising the steps of: receiving video data including first and second reproducing patterns and plural (N) channels of language data; dividing said video data and said plural channels of language data into packets as units;</claim-text>
      <claim-text>and recording said video data and said plural channels of language data on a recording medium along with control information designating an available language data channel or channels for the first and second video data patterns in which the designation by said control information is capable of enabling said first video data pattern to have associated therewith all of the N plural language data channels and is capable of enabling said second video data pattern to have associated therewith only less than N of the channels of language data.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. A data recording apparatus comprising: means for receiving video data including first and second reproducing patterns and plural (N) channels of language data; means for dividing said video data and said plural channels of language data into packets as units;</claim-text>
      <claim-text>and means for recording said video data and said plural channels of language data on a recording medium along with control information designating an available language data channel or channels for the first and second video data patterns in which the designation by said control information is capable of enabling said first video data pattern to have associated therewith all of the N plural language data channels and is capable of enabling said second video data pattern to have associated therewith only less than N of the channels of language data.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. A data recording medium having recorded thereon video data including first and second reproducing patterns and plural (N) channels of language data, divided into packets as units, and control information designating an available language data channel or channels for the first and second video data patterns in which the designation by said control information is capable of enabling said first video data pattern to have associated therewith all of the N plural language data channels and is capable of enabling said second video data pattern to have associated therewith only less than N of the channels of language data.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. A method for reproducing data from a data recording medium having recorded thereon video data including first and second reproducing patterns and plural (N) channels of language data, divided into packets as units, and control information designating an available language data channel or channels for the first and second video data patterns in which the designation by said control information is capable of enabling said first video data pattern to have associated therewith all of the N plural language data channels and is capable of enabling said second video data pattern to have associated therewith only less than N of the channels of language data, comprising: selecting a reproducing channel of language data matched to a selected reproducing pattern of said video data based on said control information;</claim-text>
      <claim-text>and reproducing the language data matched to said reproducing pattern of said video data.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. An apparatus for reproducing data from a data recording medium having recorded thereon video data including first and second reproducing patterns and plural (N) channels of language data, divided into packets as units, and control information designating an available language data channel or channels for the first and second video data patterns in which the designation by said control information is capable of enabling said first video data pattern to have associated therewith all of the N plural language data channels and is capable of enabling said second video data pattern to have associated therewith only less than N of the channels of language data, comprising: means for detecting said control information; means for selecting a reproducing channel of language data matched to a selected reproducing pattern of said video data based on said control information;</claim-text>
      <claim-text>and means for reproducing the language data matched to said reproducing pattern of said video data.</claim-text>
    </claim>
  </claims>
</questel-patent-document>