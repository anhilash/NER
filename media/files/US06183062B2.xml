<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06183062B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06183062</doc-number>
        <kind>B2</kind>
        <date>20010206</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6183062</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="23802092" extended-family-id="2345376">
      <document-id>
        <country>US</country>
        <doc-number>09453792</doc-number>
        <kind>A</kind>
        <date>19991203</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1999US-09453792</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>2444075</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>45379299</doc-number>
        <kind>A</kind>
        <date>19991203</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1999US-09453792</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010206</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>B41J   2/21        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>B</section>
        <class>41</class>
        <subclass>J</subclass>
        <main-group>2</main-group>
        <subgroup>21</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G06K  15/10        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>15</main-group>
        <subgroup>10</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>H04N   1/58        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>58</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>347041000</text>
        <class>347</class>
        <subclass>041000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>347043000</text>
        <class>347</class>
        <subclass>043000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>B41J-002/21D</text>
        <section>B</section>
        <class>41</class>
        <subclass>J</subclass>
        <main-group>002</main-group>
        <subgroup>21D</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>G06K-015/10B</text>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>015</main-group>
        <subgroup>10B</subgroup>
      </classification-ecla>
      <classification-ecla sequence="3">
        <text>H04N-001/58</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>58</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06K-015/102</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>15</main-group>
        <subgroup>102</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>B41J-002/2132</classification-symbol>
        <section>B</section>
        <class>41</class>
        <subclass>J</subclass>
        <main-group>2</main-group>
        <subgroup>2132</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06K-2215/0094</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>2215</main-group>
        <subgroup>0094</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-001/58</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>58</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>S06K-215/00D8</classification-symbol>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>21</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>16</number-of-drawing-sheets>
      <number-of-figures>24</number-of-figures>
      <image-key data-format="questel">US6183062</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Maintaining black edge quality in liquid ink printing</invention-title>
    <references-cited>
      <citation srep-phase="applicant">
        <patcit num="1">
          <text>HARRINGTON STEVEN J</text>
          <document-id>
            <country>US</country>
            <doc-number>5241396</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5241396</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="2">
          <text>REZANKA IVAN, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5371531</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5371531</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="3">
          <text>STOFFEL JAMES C, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5428377</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5428377</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="4">
          <text>REZANKA IVAN, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5570118</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5570118</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="5">
          <text>HIBI YOSHIHARU</text>
          <document-id>
            <country>US</country>
            <doc-number>5592311</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5592311</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="6">
          <text>KOIKE TAKAO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5614931</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5614931</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="7">
          <text>KLASSEN R VICTOR</text>
          <document-id>
            <country>US</country>
            <doc-number>5635967</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5635967</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="8">
          <text>KANEMATSU DAIGORO</text>
          <document-id>
            <country>US</country>
            <doc-number>5751310</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5751310</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="9">
          <text>KOIKE TAKAO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5767876</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5767876</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="10">
          <text>FUKUSHIMA HISASHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5786831</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5786831</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>BERGE THOMAS G, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5821957</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5821957</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Xerox Corporation</orgname>
            <address>
              <address-1>Stamford, CT, US</address-1>
              <city>Stamford</city>
              <state>CT</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>XEROX</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Curtis, Christopher R.</name>
            <address>
              <address-1>Pittsford, NY, US</address-1>
              <city>Pittsford</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Smith, Glenn K.</name>
            <address>
              <address-1>Webster, NY, US</address-1>
              <city>Webster</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="3">
          <addressbook lang="en">
            <name>Hull, Virgil Joseph</name>
            <address>
              <address-1>Fairport, NY, US</address-1>
              <city>Fairport</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="4">
          <addressbook lang="en">
            <name>Torpey, Peter A.</name>
            <address>
              <address-1>Webster, NY, US</address-1>
              <city>Webster</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <name>Eipert, William</name>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Nguyen, Thinh</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>GRANTED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      The present invention provides a method for processing color image data to maintain edge quality in an image recorded on a receiving medium.
      <br/>
      The method includes receiving a target pixel comprising multiple separation pixels, each separation being associated with a separate color plane and having at least three states, a first state corresponding to depositing no ink, a second state corresponding to depositing one ink drop, and a third state corresponding to depositing more than one ink drop; determining if the target pixel is within a black border region near a black/non-printed interface; and if so, setting the separation pixel associated with a black color plane to a selected black pixel state.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>CROSS REFERENCE</heading>
    <p num="1">
      Cross reference is made to the following related applications filed concurrently herewith: "Adaptive Pixel Management Using Object Type Identification," Torpey, et al., application Ser.
      <br/>
      No. 09/453,789, "Reduction Of Intercolor Bleeding In Liquid Ink Printing," Torpey et al., application Ser.
      <br/>
      No. 09/455,370, "Maintaining Black Edge Quality In Liquid Ink Printing," Torpey et al., application Ser.
      <br/>
      No. 09/453,788, "Identification Of Interfaces Between Black and Color Regions," Torpey et al., application Ser.
      <br/>
      No. 09/454,152, and "Reduction Of Intercolor Bleeding In Liquid Ink Printing," Smith et al., application Ser.
      <br/>
      No. 09/453,791.
    </p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="2">
      The present invention generally relates to liquid ink recording devices using two or more different color inks.
      <br/>
      More particularly, the present invention is directed to maintaining edge quality at the interface of printed areas and non-printed areas.
    </p>
    <p num="3">
      Liquid ink printers of the type often referred to as continuous stream or as drop-on-demand, such as piezoelectric, acoustic, phase change wax-based or thermal, employ at least one printhead from which droplets of ink are directed towards a recording sheet.
      <br/>
      Within the printhead, the ink is contained in a plurality of channels.
      <br/>
      Power pulses cause the droplets of ink to be expelled as required from orifices or nozzles at the end of the channels.
    </p>
    <p num="4">
      Liquid ink printers including ink jet printers deposit black and/or colored liquid inks which tend to spread when the ink is deposited on paper as a drop, spot, or dot.
      <br/>
      A problem of liquid ink printers is that the liquid inks used have a finite drying time, which tends to be somewhat longer than desired.
      <br/>
      Bleeding tends to occur when the drops are placed next to each other in a consecutive order or in a cluster of dots within a short time.
      <br/>
      Bleeding, spreading, and feathering causes print quality degradation including color shift, reduction in edge sharpness and solid area mottle which includes density variations in said areas due to puddling of inks.
      <br/>
      Intercolor bleeding occurs when ink from one color area blends into or bleeds with ink from another color area.
      <br/>
      Intercolor bleeding is often most pronounced where an area of black ink (relatively slow drying) adjoins an area of color ink (relatively fast drying); however, intercolor bleeding can occur at the interface between areas of any color inks having substantially different properties such as dry time or permeability.
    </p>
    <p num="5">
      Various methods have been proposed to increase edge sharpness and to reduce intercolor bleeding.
      <br/>
      Some of the proposed methods include replacing slow drying black ink with a process or composite black formed by combing fast drying color inks; under-printing a portion of the slow drying black ink with a color ink, use a fast drying black ink, and using both fast dry and slow dry black ink.
      <br/>
      While all of the proposed methods reduce intercolor bleeding to some degree, they all have one or more drawbacks that effect printer performance and/or image quality.
    </p>
    <p num="6">
      For example, using a fast dry ink in place of a slow drying black ink results in a reduced quality of black reproduction as current fast drying black inks have lower image quality than slow drying black inks.
      <br/>
      Additionally, fast drying black inks typically result in fuzzy edges in black areas next to non-printed areas.
      <br/>
      The use fast drying black ink at an interface and slow drying black ink for interior regions can eliminate lower image quality associated with fast drying black inks, but increases the cost and complexity of printer design by requiring a fifth ink in addition to the cyan, magenta, yellow and slow drying black ink.
      <br/>
      Similarly, replacing slow drying black ink with a process black (composite black) generated from fast drying color inks typically results in a reduced quality of black reproduction resulting in a lower image quality than the use of slow drying black ink.
      <br/>
      Additionally, the use of process black increases the amount of ink deposited on the print medium, increases dry time and increase the time to print a document.
      <br/>
      Furthermore, the use of additional ink may not be suitable for print medium such as transparencies and some types of paper which is not very absorbent.
      <br/>
      Under-printing a portion of the slow drying black ink with a color ink can be used to reduce intercolor bleeding; however, under-printing increases the amount of ink on the print medium.
      <br/>
      Moreover, printing color under black often results in the thickening or blurring of edges particularly along edges between printed and non-printed areas.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="7">
      One aspect of the present invention is a process for processing color image data to maintain edge quality in an image recorded on a receiving medium.
      <br/>
      The method includes receiving color image data comprising a plurality of color planes, the color planes including at least one black plane and at least one non-black plane, wherein each color plane comprises an array of separation pixels, each separation pixel having at least three states, a first state corresponding to depositing no ink, a second state corresponding to depositing one ink drop, and a third state corresponding to depositing more than one ink drop; identifying an interface between an black area and a non-printed area; defining an N-pixel wide border in the black area; and modifying the color image data corresponding to the N-pixel wide border to set substantially all the separation pixels in the black plane to a selected pixel state.
    </p>
    <p num="8">
      Another aspect of the present invention is method of processing color image data for printing on an inkjet printer to maintain edge quality in an image recorded on a receiving medium.
      <br/>
      The method comprises: receiving a target pixel comprising multiple separation pixels, each separation being associated with a separate color plane and having at least three states, a first state corresponding to depositing no ink, a second state corresponding to depositing one ink drop, and a third state corresponding to depositing more than one ink drop; determining if the target pixel is within a black border region near a black/non-printed interface; and if so, setting the separation pixel associated with a black color plane to a selected black pixel state.
    </p>
    <p num="9">
      A third aspect of the present invention is a device for processing color image data to maintain edge quality in an image recorded on a receiving medium.
      <br/>
      The device includes a black window filter, a pixel identification circuit and a pixel identification circuit.
      <br/>
      The black window filter is connected to receive a first set of pixels including a target pixel comprising multiple separation pixels, each separation being associated with a separate color plane and having at least three states, a first state corresponding to depositing no ink, a second state corresponding to depositing one ink drop, and a third state corresponding to depositing more than one ink drop, and generate a black statistics signal.
      <br/>
      The pixel identification circuit receives the black statistics signal and generates a pixel identification signal indicating whether the target pixel is within a black border region near a black/non-printed interface.
      <br/>
      The pixel identification circuit receives the pixel identification signal and filters the target pixel to set the separation pixel associated with a black color plane to a selected black pixel state.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="10">
      The following is a brief description of each drawing used to describe the present invention, and thus, are being presented for illustrative purposes only and should not be limitative to the scope of the present invention, wherein:
      <br/>
      FIG. 1 is a general representation of a suitable system-level embodiment for one or more aspects of the present invention;
      <br/>
      FIG. 2 is a diagram illustrating the steps of a process to reduce intercolor bleeding according to the concepts of the present invention;
      <br/>
      FIG. 3 illustrates an example of a pixel substitution operation;
      <br/>
      FIG. 4 and 5 illustrate examples of a pixel thinning operations;
      <br/>
      FlG. 6 shows an exemplary bitmap pattern for implementing a substitution operation;
      <br/>
      FlGS. 7-10 illustrate the bitmap patterns for each of the individual color planes for the composite bitmap pattern of FIG. 6;
      <br/>
      FIG. 11 shows an exemplary bitmap pattern for implementing a thinning operation to eliminate all color pixels from every other composite pixel;
      <br/>
      FIG. 12-15 illustrate the bitmap patterns for each of the individual color planes for the composite bitmap pattern of FIG. 11;
      <br/>
      FIG. 16 illustrates an arrangement for tiling bitmaps patterns over color image data;
      <br/>
      FIG. 17 is a flow chart illustrating various steps in an embodiment of a method for reducing intercolor bleeding according to the concepts of the present invention;
      <br/>
      FIG. 18 illustrates a composite bitmap pattern that may be used to under-print black pixels with color pixels;
      <br/>
      FIG. 19 is a flowchart illustrating the steps of a process to maintain edge quality according to the concepts of the present invention;
      <br/>
      FIG. 20 is a block diagram of a circuit for reducing intercolor bleeding in accordance with the present invention;
      <br/>
      FIG. 21 is a flowchart showing a process for differentially processing objects according to the concepts of the present invention;
      <br/>
      FIG. 22 is a flowchart showing an embodiment of process for differentially processing objects in a document image;
      <br/>
      FIG. 23 illustrates a document image comprising large and small text, graphics objects and a pictorial object; and
      <br/>
      FIG. 24 is a partial schematic perspective view of an ink jet printer suitable for use with one or more aspects of the present invention.
    </p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENT</heading>
    <p num="11">
      The following will be a detailed description of the drawings illustrated in the present invention.
      <br/>
      In this description, as well as in the drawings, like reference numbers represent like devices, circuits, or circuits performing equivalent functions.
    </p>
    <p num="12">
      Turning now to FIG. 1, there is shown an embodiment of an exemplary printing system 10 that incorporates the features of the present invention.
      <br/>
      Printing system 10 includes image source 12 that may include scanner 14, computer 16, network 18 or any similar or equivalent image input terminal providing image data 20 which may be any combination of ASCII data, bitmapped image, geometric data, graphics primitives, page description language, etc.
      <br/>
      Image data 20 is supplied to printer control system 22 which processes the received image data 20 to produce print data 24 that drives printer 26.
      <br/>
      Printer control system 22 may comprise what is commonly referred to in the art as a print driver.
      <br/>
      Those skilled in the art will recognize that control system 22 may be implemented in hardware and/or software and may reside within in image source 12, within printer 26, within a separate component or in any combination thereof.
      <br/>
      In response to print data 24, which may comprise image data and/or printer control signals (e.g., paper handling, carriage control, ink deposition), printer 26 generates an output image on a suitable print medium.
      <br/>
      Beneficially, printer 26 may comprise an ink jet printer.
    </p>
    <p num="13">
      Turning now to FIG. 23, there is shown a partial schematic perspective view of an ink jet printer 200 suitable for use in the system of FIG. 1.
      <br/>
      Printer 200 includes an ink jet printhead cartridge 202 mounted on carriage 204 supported by carriage rails 206.
      <br/>
      The printhead cartridge 202 includes housing 208 containing ink for supply to printhead 210 which selectively expels droplets of ink in response to control signals received from controller 214 through a communication cable 212.
      <br/>
      Printhead 210 contains a plurality of ink conduits or channels (not shown) which carry ink from housing 208 to respective ink ejectors, which eject ink through orifices or nozzles (also not shown).
      <br/>
      To effectuate printing, controller 214 is coupled to one or more printhead control circuits (not shown).
      <br/>
      The printhead control circuits receive information from controller 214 via control signals received through communication cable 212.
      <br/>
      In accordance with the content of the signals received, the control circuits provide for selected ejection of inks from the nozzles of printhead 210.
    </p>
    <p num="14">
      When printing, carriage 204 reciprocates or scans back and forth along carriage rails 206 in the directions of arrow 216.
      <br/>
      As the printhead cartridge 202 reciprocates back and forth across a recording medium 218, such as a sheet of paper or transparency, droplets of ink are expelled from selected ones of the printhead nozzles towards the recording medium.
      <br/>
      During each pass of carriage 204, the recording medium 218 is held in a stationary position.
      <br/>
      Upon the completion of one or more passes, the recording medium is advanced in the direction of arrow 220 by a feed mechanism under control of controller 214.
    </p>
    <p num="15">
      The present invention is directed towards aspects of printer control system 22 depicted in FIG. 1.
      <br/>
      In particular, the present invention is directed to a system and method for reducing intercolor bleeding that occurs at the interface between areas printed with inks having substantially different properties such as dry time or permeability.
      <br/>
      Bleeding of colors may occur at the interface between color areas and solid black areas and can lead to ragged edges and degraded print quality.
      <br/>
      As noted above, intercolor bleeding often occurs at the interface between black and color areas as many ink jet printers combine a slow-drying black ink with fast-drying color inks.
      <br/>
      Thus, in describing the present invention, reference will be made to intercolor bleeding occurring at black/color interfaces.
      <br/>
      However, it is noted that the invention is not limited to operating at black/color interfaces and may be adapted to reduce intercolor bleeding occurring at the interface between areas printed with color inks having substantially different properties.
      <br/>
      Furthermore, the present invention can be adapted to improve edge quality of black and/or color areas printed adjacent to a non-printed area.
    </p>
    <p num="16">
      The present invention is described as operating on color image data comprising two or more color planes or separations that are combined to form a composite image.
      <br/>
      Each color plane comprises a raster image describing the image for a color separation in terms of pixels arranged in scan lines.
      <br/>
      For purposes of describing the present invention, reference will be made to image data comprising four color planes, Cyan, Magenta, Yellow and black (CMYK).
      <br/>
      Each composite pixel comprises four associated separation pixels, one for each of the CMYK color planes.
      <br/>
      Each separation pixel beneficially comprises a pixel value which may be considered as a binary signal indicating whether the corresponding separation is on or off, i.e., whether the corresponding ink will be deposited at that location or not.
      <br/>
      It will be appreciated that in a printer which can deposit multiple ink drops of a single color at a pixel location, a separation pixel may have multiple on states wherein each corresponds to depositing a different number of ink drops.
      <br/>
      Those skilled in the art will recognize that a different number of separations as well as different combinations of colors may be used in forming a composite image.
    </p>
    <p num="17">
      To reduce intercolor bleeding, the present invention carries out a process that operates to detect black/color interfaces where intercolor bleeding is likely to occur and to modify the pixels that are to be printed near the borders of the interfaces The process comprises three general steps: identifying an interface between a black area and a color area; modifying the pixel pattern in a black border region in the black area; and modifying the pixel pattern in a color border region in the color area.
      <br/>
      Referring to FIG. 2, there is shown a flowchart illustrating this method for reducing intercolor bleeding in more detail.
    </p>
    <p num="18">
      Step 30 identifies an interface between a black area and a color area.
      <br/>
      In one embodiment, described in more detail below, step 30 collects statistics for pixels within a XxY window filter to identify an interface and determine if a given pixel is within either border region.
      <br/>
      However, step 30 can use any number of known techniques including, but not limited to, masking, look-up tables, edge detection filters, etc. to identify a black/color interface.
      <br/>
      A discussion of edge detection filters can be found in U.S. Pat. No. 5,635,967.
    </p>
    <p num="19">
      Step 32 defines a width N of the black border region near the black/color interface identified in step 30.
      <br/>
      The number of pixels N comprising the black border region should be large enough to reduce intercolor bleeding at the border and small enough to minimize the formation of additional printing artifacts that would likewise reduce image quality.
      <br/>
      Similarly, step 34 defines the width M of the color border region near the interface.
      <br/>
      As with the selection of black border region, the width M of the color border region should be selected to reduce intercolor bleeding while minimizing the addition of other printing artifacts.
    </p>
    <p num="20">
      When defining the width of the border regions consideration may be given to such factors as the position of the border regions, the type of image (e.g., text, line art, graphics, pictorial, etc.), the width of each border, how the pixel pattern within a border will be modified, the print medium used, ink composition, etc.
      <br/>
      Each of the border regions beneficially are positioned to abut the interface; however, it is understood that the border region need not abut the interface.
      <br/>
      The total width of the border regions at an interface should be selected to reduce intercolor bleeding at an interface and minimize the formation of additional printing artifacts.
      <br/>
      Optimum values for border width can be identified through calibration and image analysis studies.
      <br/>
      The width of the black border is preferably between 0 and 350  MU m, and the width of the color border is preferably between 0 and 200  MU m is used.
      <br/>
      Beneficially, for a 300 dpi ink jet the width of the N pixel black border is selected from 0 to 4 pixels, and the width M of the color border is defined to be from 0 to 2 pixels.
    </p>
    <p num="21">
      Steps 36 and 38 modify the pixel pattern within the N-pixel black border and M pixel color border regions, respectively.
      <br/>
      A number of methods exist to modify the pixels or pixel pattern within the border regions.
      <br/>
      One method of modifying the pixel pattern within a border region replaces selected pixels with a predetermined combination of separation pixels.
      <br/>
      The replacement operation effectively turns off the separation pixel this is being replaced and turns on the separation pixel(s) replacing it.
      <br/>
      The replacement of pixels is sometimes referred to as "substitution." An example of a substitution operation is illustrated in FIG. 3.
      <br/>
      In FIG. 3, window 40 shows a 5 * 5 block of composite pixels along a yellow/black interface.
      <br/>
      Window 42 shows the pixel block of window 40 after a substitution operation wherein within a 2 pixel border (columns 44 and 46) every other pixel in the black separation is turned off and replaced with alternating cyan and magenta pixels in the composite image.
    </p>
    <p num="22">
      Another method of modifying a pixel pattern removes (turns off) selected pixels in one or more separations from the composite image.
      <br/>
      This removal of pixels from separations is sometimes referred to as "thinning." FIG. 4 illustrates an example of a thinning operation wherein window 50 is a 5 * 5 pixel block of a composite pixels along a black/color interface and window 52 shows the same image block after thinning.
      <br/>
      The thinning operation removes (turns off) all color separation pixels from every other pixel in column 54 and removes yellow separation pixels from every other pixel in column 56.
    </p>
    <p num="23">
      A thinning operation can also be used to reduce the ink coverage in a multiple drop per pixel printer.
      <br/>
      Briefly, in a multi-drop per pixel printer small ink drops are often used to produce good tone transitions in graphical and pictorial images.
      <br/>
      However, the size of these drops are not large enough to produce a solid area fill or saturated colors using only one drop per pixel.
      <br/>
      Thus, the printer typically requires greater than 100% coverage, that is, multiple drops per separation pixel to obtain solid area fill.
      <br/>
      In FIG. 5 window 60 illustrates a 5 * 5 pixel area along a black/color interface wherein the black region comprises 150% coverage (i.e., an average of three drops for every two pixels).
      <br/>
      Window 62 shows the same image area as window 60 after a thinning operation to reduce the drop coverage to approximately 100%, ie., an average of one drop per separation pixel.
      <br/>
      In window 62, column 64 illustrates a thinning operation that reduces all two drop pixels to one drop pixels.
      <br/>
      Columns 66 and 68 illustrate a thinning method that removes approximately half of the two drop pixels.
    </p>
    <p num="24">
      It should be appreciated that a pixel pattern may be modified using a combination of one or more substitution and/or thinning operations.
      <br/>
      Additionally, it should be appreciated that the thinning and substitution operations need not operate on pre-defined pattern of pixels.
      <br/>
      For example, the pixel pattern modification may randomly select one pixel of every three for thinning or substitution.
      <br/>
      Furthermore, when operating to modify the pixel pattern within a selected region, the operation chosen to modify the pixel may vary based upon the position within the region.
      <br/>
      Varying the pixel modification based upon pixel position within the border allows for a transition within the border region to lessen any perceived dissimilarities between the border region and the interior region.
      <br/>
      For example, the pixels closest to the interface may be modified using a first substitution operation and the pixels farthest from the interface may be modified using a second substitution operation.
    </p>
    <p num="25">
      Substitution and thinning operations to modify a pixel pattern can be implemented by defining a pixel modification pattern for each different substitution or thinning operation and adjusting pixels according to the appropriate pixel modification pattern.
      <br/>
      Each pixel modification pattern can, for example, be represented using an array of ON/OFF (1 or 0) values corresponding to separation pixels being turned on or off, i.e., depositing ink or not, at specific locations in the cyan, magenta, yellow and/or black color planes.
      <br/>
      The substitution operation adjusts an image pixel by replacing the image pixel with the pixel value from the corresponding pixel in the pixel modification pattern.
      <br/>
      A thinning operation can adjust an image pixel by performing a logical AND of the image pixel with the corresponding pixel value for an equivalent separation in the pixel modification pattern.
    </p>
    <p num="26">
      For example, an exemplary pixel modification pattern 70 to implement a substitution operation to replace every other pixel in the black separation with alternating cyan and magenta separation pixels is shown in FIG. 6.
      <br/>
      Pixel modification pattern 70 comprises four (4) scan lines 72 with eight (8) pixels in each scanline.
      <br/>
      Modification pattern 70 comprises composite pixels wherein the CMYK data is grouped together for each pixel.
      <br/>
      For example, pixel 74 indicates that the corresponding separation pixel is turned on in the magenta separation and turned off in the cyan, yellow, and black separations.
      <br/>
      FIGS. 7-10 illustrate 8 * 4 modification patterns for each color plane, cyan, magenta, yellow and black, respectively, for modification pattern 70 of FIG. 6.
      <br/>
      Similarly, an exemplary pixel modification pattern 80 for thinning a pixel pattern to remove black from every pixel and colors in every other pixel is shown in FIG. 11. Modification pattern 80 comprises four (4) scanlines 82 with eight (8) composite pixels of CMYK grouped data in each scanline.
      <br/>
      FIGS. 12-15 illustrate 8 * 4 modification patterns for the cyan, magenta, yellow and black separations, respectively, for pixel modification pattern 80 of FIG. 11.
    </p>
    <p num="27">
      Pre-defining each of the pixel modification patterns enables the pixel modification patterns (arrays) to be tiled over the image data such that an associated pixel location within each pixel modification pattern can be identified for each pixel within the image data.
      <br/>
      FIG. 16 illustrates the tiling of modification patterns over image data 90 comprising J scanlines having I pixels in each scanline.
      <br/>
      Data 90 which may correspond to a composite image or a separation is shown with a plurality of XxY pixel modification patterns 92 tiled over the image.
      <br/>
      The corresponding location within a pixel modification pattern 92 can be identified for any pixel p(i, j) as a function of pixel position.
      <br/>
      Pixels within a black or color border region near an interface can be modified according to the pixel values in the appropriate pixel modification pattern.
    </p>
    <p num="28">
      Referring to FIG. 17, there is shown another embodiment of a process to reduce intercolor bleeding in accordance with the present invention.
      <br/>
      The process of FIG. 17 is shown including an under-color printing (under-printing) operation.
      <br/>
      The addition of under-printing reduces dry time by adding additional fast-dry color ink to interior regions of solid slow-dry black ink in order to promote absorption of the black ink into the paper.
      <br/>
      Furthermore, under-printing can reduce streakiness in solid black areas that may occur when slow-dry black ink does not readily absorb and spread into the paper.
    </p>
    <p num="29">
      Briefly, the process illustrated in FIG. 17 operates on a color corrected, halftoned image.
      <br/>
      The process passes first window filter including a target pixel therein over a portion of the image, collects statistics for the pixels within the window filter, determines if the pixel is within an N-pixel black border region near a black/color interface based on the collected statistics and modifies the target pixel according to pre-defined rules.
      <br/>
      A second window filter operating on a second portion of the image including the target pixel may be used to collect statistics for the pixels within the second window filter.
      <br/>
      The statistics collected from the second window are analyzed to determine if the target pixel is within an M-pixel color border region near a black/color interface and, if so, the target pixel is modified according to a set of pre-defined rules.
      <br/>
      The reduction of intercolor bleeding operation modifies black pixels that lie within N pixels of an interface with a color pixel and color pixels that lie within a M-pixel border of a black pixel.
    </p>
    <p num="30">
      The under-printing operation modifies selected interior black pixels to turn on one or more color separation pixels, i.e., print color under black at the selected pixel locations.
      <br/>
      The concept of "under-printing" or printing color under black is not exact, i.e., a printer may be configured and operated such that some pixels are printed with the color ink deposited under the black ink while other pixels are formed with black ink deposited first and color ink deposited on top.
    </p>
    <p num="31">
      The two operations, intercolor bleeding and under-printing, are described as integrated into a single process, although each can operate independently.
      <br/>
      More specifically, the process of FIG. 17 begins with the identification a target pixel p(i,j) for processing in step 100.
      <br/>
      In step 102, the process determines if the composite pixel for the target pixel is a black only pixel or a color only pixel.
      <br/>
      A black pixel is a composite pixel in which the separation pixel in the black plane is ON, i.e., at least one drop of black ink will be deposited.
      <br/>
      A black only pixel is a composite pixel in which the separation pixel in the black plane is ON and the separation pixels for each color plane are OFF.
      <br/>
      Similarly, in a color only pixel the separation pixel in the black plane is OFF and at least one separation pixel in a color plane is ON.
      <br/>
      If the target pixel is neither black only or color only, the process determines if there are more pixels within the color image data to process (step 128).
      <br/>
      If so, the process loops back to step 100 for identification of a new target pixel.
    </p>
    <p num="32">
      At step 104 the process branches based upon whether the target pixel is a color only pixel or a black only pixel.
      <br/>
      Each branch performs the same general operations of collecting pixel statistics for the pixels within a window filter, analyzing the collected statistics to determine if the target pixel is within a border region near a black/color interface and processing the target pixel accordingly.
      <br/>
      Following the branch for black only target pixels, in step 106 the process identifies a black window filter comprising pixels surrounding the target pixel.
      <br/>
      Beneficially the process uses a square window filter centered on the target pixel.
      <br/>
      The size of the black window filter can be determined from the width of the border region.
      <br/>
      For the N-pixel border region in the black area, the size of the black filter is beneficially set to have 2N+1 pixels on a side.
    </p>
    <p num="33">
      In step 108, the process determines if any pixels within the black window filter have color under black (i.e. print both color and black at any pixel).
      <br/>
      If any pixel within the window has color under black, no further processing is performed for the target pixel.
      <br/>
      Step 108 is an optional step in that the process need not be limited to black only, color only or non-printing pixels.
    </p>
    <p num="34">
      Step 110 collects statistics from the pixels within the black window filter to generate a black window statistics signal B(i,j) for the target pixel p(i,j).
      <br/>
      The statistics collected are used in subsequent processing (steps 112 and 114) to determine if the target pixel is within a N-pixel border region near a black/color interface and how, if at all, the target pixel should be modified to reduce intercolor bleeding.
      <br/>
      It should be appreciated that the operation of step 108 can be included in the statistics collected at step 110.
      <br/>
      In one example, statistics signal B(i,j) identifies the number of black only and color only pixels within the black window filter in step 110.
      <br/>
      Based upon the number of black only and color only pixels within the black window filter, step 112 identifies if a black/color interface exists and identifies a pixel type for the target pixel.
      <br/>
      In step 114 an output pixel is generated from the target pixel by modifying the target pixel in accordance with a pre-defined pixel modification pattern based upon the pixel type and whether an interface exists.
    </p>
    <p num="35">
      One method of identifying a pixel type determines if the number of black pixels within the window is within a predetermined pixel range and, if not, whether the number of black pixels is over or under the predetermined range.
      <br/>
      For example, the target pixel type may be identified as an interior pixel if the number of black pixels is greater than the predetermined range, a border pixel if the number is within the predetermined pixel range and an isolated pixel if the number is lower than the range.
      <br/>
      The method can be accomplished, for example, by comparing the number of black only pixels to a series of threshold values and setting the pixel type based upon the result.
      <br/>
      Additionally, if the number of color only pixels within the window is within a selected range, a black/color interface is presumed to exist.
      <br/>
      The selected range for identifying a black/color interface may be defined by a predetermined lower threshold, by predetermined upper and lower thresholds or by thresholds dynamically selected based upon the number of black only pixels.
    </p>
    <p num="36">
      In general, if the target pixel is identified as a border pixel e.g., within the N-pixel border region and a black/color interface is detected within the black window filter, the target pixel is modified to reduce intercolor bleeding according to pixel modification pattern for black border pixels.
      <br/>
      If the target is within the N-pixel border region and an interface is not detected, the pixel is left untouched.
      <br/>
      Optionally, if the target pixel is identified as an interior pixel (i.e., within a solid black area but outside the N-pixel border region), the pixel may be modified according to an under-color print pixel modification pattern designed improve image quality in large black areas.
    </p>
    <p num="37">An example of rules for identifying the pixel type of the target pixel based upon the number of black only and color only pixels within the window filter described by the following C-like programming statement:</p>
    <p num="38">
      If (-_Black_Only&gt;Border_Full) Pixel_Type=Interior
      <br/>
      If ((Border_Empty &lt;= -_Black_Only) and (-_Black_Only &lt;= Border_Full)) Pixel_Type=Border
      <br/>
      If (-_Black_Only&lt;Border_Emptyl) Pixel_Type=Isolated
      <br/>
      If (-_Color_Only &gt;= ICB_Full) Bleed=Yes else BLEED=No
    </p>
    <p num="39">Wherein N is the number of pixels in the border region; the black window filter size is given by (2N+1)*(2N+1); -_Black_Only is the number of black only pixels within the window; -_Color_Only is the number of color only pixels within the window; Border_Full is the upper threshold for identifying a border pixel and is given by (2N+1)*(2N+1)-N; Border_Empty is the lower threshold for identifying a border pixel and is given by (N+1)*(N+1); and ICB_Full is an interface threshold given by N.</p>
    <p num="40">
      General rules for modifying the target pixel based upon the pixel type and existence of an interface can be described by the following C-like programming statement:
      <br/>
      If (Pixel_Type=Interior) generate output pixel by replacing target pixel according to an interior black pixel modification pattern
      <br/>
      Else If ((Pixel_Type=Border) and (Bleed=Yes)) generate output pixel by replacing target pixel according to a black border modification pattern
      <br/>
      Else If ((Pixel_Type=Border) and (Bleed=No)) output target pixel
      <br/>
      Else If ((Pixel_Type=Isolated) and (Bleed=Yes)) output black only target pixel
      <br/>
      Else output target pixel
    </p>
    <p num="41">
      Turning to the color branch from step 104, the process identifies a color window filter surrounding the target pixel at step 116.
      <br/>
      As with the black pixel branch, the process beneficially uses a square window filter centered on the target pixel wherein the size of the color window filter is based upon width of the border region within the color area that is modified; however, filters having other sizes and shapes may also be used.
      <br/>
      For an Apixel border region the size of a square window filter is beneficially set to have 2M+1 pixels on a side.
    </p>
    <p num="42">
      Step 118 determines if any pixels within the color window filter have color under black.
      <br/>
      If any pixel within the window has color under black, no further processing is performed for the target pixel and the process is returned to step 100 for identification of a new target pixel if there are more pixels to be processed (step 128).
      <br/>
      Step 120 collects statistics for the pixels within the color window filter to generate a color statistics signal C(i,j) for the target pixel p(i,j).
    </p>
    <p num="43">
      Based upon the statistics collected, step 122 determines if the target pixel is within an M-pixel border region (e.g., a border pixel) near a black/color interface.
      <br/>
      In general, the target pixel is presumed to be within an M-pixel border region near a black/color interface if the number of color only pixels within the window filter is within a predetermined range (greater than a first threshold and less then a second threshold) and the number of black only pixels exceeds an interface threshold.
    </p>
    <p num="44">
      An output pixel is generated from the target pixel in step 124.
      <br/>
      In general, if the target pixel is a border pixel and an interface exists, the target pixel is modified according to a color border pixel pattern.
      <br/>
      In all other cases, the target pixel is untouched and provided as the output pixel.
      <br/>
      General rules for determining if the target pixel is a border pixel based upon the number of black only and color only pixels within the window filter can be described by the following C-like programming statement:
      <br/>
      If ((Border_Empty &lt;= -_Color_Only) and (-_Color_Only &lt;= Border_Full)) Pixel_Type=Border
      <br/>
      If (-_Black_Only &gt;= ICB_Full) Bleed=YES else BLEED=NO
      <br/>
      If ((Pixel_Type=Border) and (Bleed=Yes)) generate output pixel by thinning target pixel using a color border pixel modification pattern
      <br/>
      Else If ((Pixel_Type=Border) and (Bleed=NO)) output target pixel else output target pixel
    </p>
    <p num="45">Wherein M is the number of pixels in the border region; the color window filter size is given by (2M+1)*(2M+1); -_Black_Only is the number of black only pixels within the window; -_Color_Only is the number of color only pixels within the window; Border_Full=(2M+1)*(2M+1)-M, Border_Empty=(M+1)*(M+1); and ICB_Full=M.</p>
    <p num="46">
      After completing either branch, the process determines if there are more pixels within the color image data to process (step 128).
      <br/>
      If so, the process loops back to step 100 for identification of a new target pixel.
      <br/>
      The process ends when no further pixels need processing.
    </p>
    <p num="47">
      As discussed above, pre-defined pixel modification patterns comprising an array of ON/OFF (1 or 0) values corresponding to pixels values being turned on or off at specific locations in the color planes can be used to implement thinning and substitution operations.
      <br/>
      The process of FIG. 17 identifies three pre-defined pixel modification patterns: a color border pixel modification pattern, a black border pixel modification pattern and an interior black pixel modification pattern.
      <br/>
      The specific pre-defined pixel modification patterns used by the process of FIG. 17 to modify the target pixel may depend, in part, upon the type of printer, print mode (e.g., fast, slow, draft, normal, etc.), type of image (e.g., text, line art, graphic, pictorial), etc.
      <br/>
      For example, a pixel printer may employ different pixel modification patterns for controlling intercolor bleeding for a draft mode than those used for a normal mode.
    </p>
    <p num="48">
      For a single drop per pixel printer, a black border pixel pattern to modify pixels in black border regions near black/color interfaces that has been found to provide good results replaces a fraction of the black pixels with magenta pixels and a fraction of the black pixels with cyan pixels.
      <br/>
      Beneficially, the black border pixel mod modification pattern replaces approximately 50% of the black pixels with alternating cyan and magenta pixels in a regular pattern.
      <br/>
      Preferably, the black border pixel modification pattern replaces approximately 25% of the black pixels with cyan pixels and approximately 25% of the black pixels with magenta pixels.
      <br/>
      An example of such a pixel modification pattern was discussed above and shown in FIGS. 6-10. Another black border pixel modification pattern which has been found to reduce intercolor bleeding replaces a fraction of the black pixels with a regular pattern of cyan, magenta and yellow pixels.
      <br/>
      A pre-defined interior black pixel modification pattern operates to turn on (add) additional color separation pixels under selected black only pixels.
      <br/>
      Beneficially, the interior pixel modification pattern under-prints a regular pattern of cyan, magenta and yellow pixels.
      <br/>
      An example of such a pixel modification pattern for printing under approximately 25% of the black pixels is shown in FIG. 18.
    </p>
    <p num="49">
      A color border pixel modification pattern which has been found to reduce intercolor bleeding thins the color border to remove a fraction of the color pixels within the pixel border.
      <br/>
      The thinning operation performed on the color border can remove any fraction of the color pixels up to, and including, all of the color pixels.
      <br/>
      Removing all of the color pixel creates a non-printed area at the interface and is sometimes referred to as etching.
      <br/>
      Beneficially, the color border pixel modification pattern removes between 25 percent and 75 percent of the color pixels in the pixel border in a regular pattern.
      <br/>
      An example of such a pixel modification pattern as illustrated in FIGS. 11-15 operates to remove approximately half of the color pixels in a checkerboard pattern in a 2 pixel border.
      <br/>
      It is understood that other combinations of thinning may be used as well.
    </p>
    <p num="50">
      For a multiple drop per pixel printer, pixel modification patterns designed to reduce the maximum ink coverage in the border areas have been found to reduce intercolor bleeding.
      <br/>
      For border pixels in both the black border and color border regions reducing drop coverage by replacing some fraction of the multiple drop pixels with one drop pixels can be used to reduce intercolor bleeding.
      <br/>
      Optionally, a pixel modification pattern that thins a fraction of the multiple drop pixels within the border region can be used.
      <br/>
      Beneficially, the pixel patterns reduce ink drop coverage to approximately 100%, i.e., an average of one drop per separation pixel in the black border and color border regions.
      <br/>
      However, reducing the ink drop coverage to between 100% and 150% in color borders also provides good results.
      <br/>
      It should be appreciated that other values for border widths and ink coverage may be appropriate based on printer resolution, the inks used, the print medium used, dot scheduling algorithms, etc.
      <br/>
      The pixel modification patterns necessary to reduce ink drop coverage, either by replacing some multiple drop pixels with one drop pixels or removing some of the multiple drop pixels, depend upon the maximum number of drops per pixel, the maximum drop coverage that can be produced and the pattern in which the multiple drops are distributed.
    </p>
    <p num="51">
      It should be appreciated that the above described processes, as illustrated in FIG. 8 or 17, can be modified to identify pixels that are within a border region adjacent a non-printed area.
      <br/>
      The modified process operates to identify pixels within a border region near a printed/non-printed interface and modify the pixel pattern within the border region of the printed area to sharpen or maintain edge quality.
      <br/>
      FIG. 19 illustrates a flowchart of a method to maintain edge quality.
      <br/>
      The modified process identifies interfaces between a printed area and a non-printed area, e.g., between black and non-printed areas and/or between color and non-printed areas (step 130); defines an N-pixel border within black area near a black/non-printed interface (step 132) and an M-pixel border within a color black area near a black/non-printed interface (step 134), and modifies the pixel pattern within the N-pixel black border and M pixel color border regions (steps 136 and 138, respectively).
    </p>
    <p num="52">
      Identifying an interface between a printed area and a non-printed area step 130) is similar to identifying an interface between a black area and a color area and can be accomplished using many of the same techniques including statistics collection, masking, look-up tables, edge detection filters, windowing, etc.
      <br/>
      Furthermore, the process of FIG. 17 can be varied to identify printed/non-printed interfaces.
      <br/>
      The adjusted process can include two window filters.
      <br/>
      Statistics collected from a first window filter are analyzed to determine if a target pixel is within a N-pixel black border region near a black/non-printed interface.
      <br/>
      Statistics from the second window filter are analyzed to determine if a target pixel is within an Apixel color border region near a color/non-printed interface.
      <br/>
      Optionally, the process can use a single filter for identifying both black/non-printed and color/non-printed interfaces.
    </p>
    <p num="53">
      Briefly, a black window filter generates a black window statistics signal B(i,j) that is analyzed to determine if the target pixel p(i,j) is within a N-pixel border region near a black/non-printed interface.
      <br/>
      In one example, the target pixel is presumed to be within an N-pixel border region near an interface if the number of black pixels within the window filter is within a predetermined range and the number of color only pixels is less than an interface threshold.
    </p>
    <p num="54">
      An example of rules for identifying if the target pixel is within a border region near an interface based upon the number pixels within the window filter and modifying the target pixel are described by the following C-like programming statement:
      <br/>
      If (-_Black_Pixels&gt;Border_Full) Pixel_Type=Black Interior
      <br/>
      If ((Border_Empty &lt;= -_Black_Pixels) and (-_Black_Pixels &lt;= Border_Full)) Pixel_Type=Black Border
      <br/>
      If (-_Black_Pixels&lt;Border_Emptyl) Pixel_Type=Black Isolated
      <br/>
      If (-_Color_Pixels&lt;INT_Threshold) Modify=Yes else Modify=No
      <br/>
      If ((Pixel_Type=Border) and (Modify=Yes)) generate output pixel by replacing target pixel according to a black edge modification pattern
      <br/>
      Else output target pixel
    </p>
    <p num="55">Wherein N is the number of pixels in the border region; the black window filter size is given by (2N+1)*(2N+1); -_Black_Pixels is the number of black pixels within the window; -_Color_Pixels is the number of color only pixels within the window; Border_Full is the upper threshold for identifying a border pixel and is given by (2N+1 )*(2N+1)-N; Border_Empty is the lower threshold for identifying a border pixel and is given by (N+1)*(N+1); and INT_Threshold is an interface threshold given by N.</p>
    <p num="56">
      Similarly, the color window filter generates a color statistics signal C(i,j) that is analyzed to determine if the target pixel p(i,j) is within a M-pixel border region near a color/non-printed interface.
      <br/>
      In general, the target pixel is presumed to be within an M-pixel border region near an interface if the number of color only pixels within the window filter is within a predetermined range and the number of black pixels is less than an interface threshold.
      <br/>
      An example of rules for identifying if the target pixel is within a border region near an interface based upon the number pixels within the window filter and modifying the target pixel are described by the following C-like programming statement:
      <br/>
      If (-_Color_Pixels&gt;Border_Full) Pixel_Type=Color Interior
      <br/>
      If ((Border_Empty &gt;= -_Color_Pixels) and (-_Color_Pixels &lt;= Border_Full)) Pixel_Type Color Border
      <br/>
      If (-_Color_Pixels&lt;Border_Emptyl) Pixel_Type=Color Isolated
      <br/>
      If (-_Black_Pixels&lt;INT_Threshold) Modify=Yes else Modify=No
      <br/>
      If ((Pixel_Type=Border) and (Modify=Yes)) generate output pixel by replacing target pixel according to a color edge modification pattern Else output target pixel
    </p>
    <p num="57">Wherein M is the number of pixels in the border region; the color window filter size is given by (2M+1)*(2M+1); -_Color_Pixels is the number of color only pixels within the window; -_Black_Pixels is the number of black pixels within the window; Border_Full is the upper threshold for identifying a border pixel and is given by (2M+1)*(2M+1)-M, Border_Empty is the lower threshold for identifying a border pixel and is given by (M+1)*(M+1); and INT_Threshold is an interface threshold given by M.</p>
    <p num="58">
      Optionally, when collecting statistics the pixels within a window filter and identifying a pixel type based upon the collected statistics, the process may compare the number of printing and non-printing pixels.
      <br/>
      For example, if the target pixel is a black only printed pixel, the collected statistics may identify the number of black only pixels and the number of non-printed pixels within the window filter.
      <br/>
      Rules for identifying if the target pixel is a border pixel based upon the number of black only and non-printed pixels within the window filter can be described by the following C-like programming statement:
      <br/>
      If ((Border_Empty &lt;= -_Black_Pixels) and (-_Black_Pixels &lt;= Border_Full)) Pixel_Type=Border
      <br/>
      If (-_Non_Printed &gt;= INT_Threshold) Modify=YES else Modify=NO
    </p>
    <p num="59">
      The width of the border regions near the printed/non-printed interface (steps 132 and 134) should be selected to maintain/improve edge quality without introducing printing artifacts that would reduce image quality.
      <br/>
      When defining the width of the border regions consideration may be given to such factors as the type of image (e.g., text, line art, graphics, pictorial, etc.), how the pixel pattern will be modified, the print medium, ink composition, etc.
      <br/>
      Optimum values for border width can be identified through calibration and image analysis studies.
      <br/>
      The width of the black border is preferably between 0 and 520  MU m, and the width of the color border is preferably between 0 and 200  MU m. Beneficially, for a 300 dpi ink jet the width N of a border region within a black area is defined to be between 0 to 6 pixels, and the width M of the color border is selected to be from 0 to 2 pixels.
    </p>
    <p num="60">
      At steps 136 and 138 the pixel pattern within the N-pixel and M-pixel borders are modified to maintain edge quality.
      <br/>
      As with the modification of border regions near a black/color interface, the pixel modification pattern used may vary based on factors such as the printer type (single drop, multi-drop), print mode (e.g., fast, slow, draft, normal, etc.), type of image (e.g., text, line art, graphic, pictorial), etc.
      <br/>
      For a single drop per pixel printer, removing all color pixels under black within a black border region near black/non-printed interface has been found to improve/maintain edge quality of the black area.
      <br/>
      Briefly reviewing, under-printing a slow-dry black ink with a fast-dry color ink provide improved dry time and a reduction in perceived banding or streaks in large black areas.
      <br/>
      However, when fast dry ink is printed under a black area, the edges of the black area adjoining a non-printed area are poorly defined and often appear ragged.
      <br/>
      Thus, to maintain edge quality of a black area next to a non-printed area, a pixel modification pattern may operate to remove (thin) all the color under black for pixels within an M-pixel border region within a black area bordering the non-printed area.
      <br/>
      In addition to removing color under black in a border region, increasing the coverage by printing multiple drops at a pixel can be used to improve edge quality.
    </p>
    <p num="61">
      In a multi-drop per pixel printer, edge quality of both black and color areas printed adjacent to non-printed areas can be improved if all pixels within a border region have the same number of drops per pixel.
      <br/>
      For example, a multi-drop printer may limit the maximum coverage in solid black areas to 150% to prevent streakiness or pooling as well as to reduce dry-time.
      <br/>
      However, with 150% coverage some pixel locations receive two drops while other receive only one drop.
      <br/>
      The one-drop and two-drop pixels spread differently into the print a medium, producing a ragged edge.
      <br/>
      Thus, a pixel modification pattern that replaces all or substantially all one drop pixels with two drop pixels (increasing coverage to 200%) provides good results.
      <br/>
      Alternatively, replacing all two drop pixels with one drop pixels (decreasing coverage to 100%) can also be used to improve edge quality.
    </p>
    <p num="62">
      Referring now to FIG. 20, there is shown a block diagram of a circuit, according to one embodiment of the invention, for determining whether a pixel is within a border region near an interface and modifying the pixel to reduce intercolor bleeding or improve edge quality.
      <br/>
      As illustrated in FIG. 20, image data is fed to a first statistics collection filter 140 which collects statistics for a target pixel p(i,j) and the neighboring pixels within a black border window and produces a black border statistics signal B(i,j).
      <br/>
      The image data is also fed to a second statistics collection filter 142 which collects statistics for the pixels within a color border window and produces a color border statistics signal C(i,j).
      <br/>
      The statistics collected by filter 140 and filter 142 may identify the number of black only pixels, number of color only pixels, number of non-printed pixels, color under black pixels, etc.
    </p>
    <p num="63">
      The black border and color border statistics signals are fed to a pixel identification circuit 144.
      <br/>
      Pixel identification circuit 144 analyzes the statistics signals produce a pixel identification signal I(i,j) for the target pixel p(i,j).
      <br/>
      The pixel identification signal I(i,j) identifies a pixel type for the target pixel.
      <br/>
      For example, circuit 144 may analyze the target pixel to determine if the target pixel is a color or black pixel, if the target pixel is within an N-pixel or M-pixel border region and produce an identification signal that indicates the target pixel is one of a black interior pixel, a black border pixel, a color border pixel, an isolated pixel, etc.
      <br/>
      The pixel identification signal I(i,j) is fed to a pixel modification circuit 146 operating on the target pixel p(i,j).
      <br/>
      Depending upon the pixel identification signal, the modification circuit either allows the target pixel p(i,j) to pass through unprocessed or modifies the pixel data associated with the target pixel according to an appropriate pixel modification pattern.
    </p>
    <p num="64">
      One skilled in the art would understand that the filters and circuits described above can embody or be implemented using a general or special purpose computer, a programmed microprocessor or microcontroller and peripheral integrated circuit elements, an ASIC or other integrated circuit, a digital signal processor, a hardwired electronic or logic circuit such as a discrete element circuit, a programmable logic device such as a PLD, PLA, FPGA or PAL, or the like.
      <br/>
      Furthermore, specific algorithms may be accomplished using software in combination with specific hardware.
      <br/>
      In general, any device capable of implementing a finite state machine that is in turn capable of implementing a process described above can be used to realize the associated filter or circuit.
    </p>
    <p num="65">
      The N-pixel and M-pixel border widths, the border threshold values and the interface threshold values discussed above and utilized in determining the pixel type and whether to modify the pixel as well as the various pixel modification patterns can be either preset as default values or generated during a calibration process.
      <br/>
      Furthermore, several sets of parameter values for the border widths and threshold values and several different pixel modification patterns can be stored and automatically or manually selected for specified print modes or image types.
      <br/>
      For example, faster print modes with fewer number of passes might require intercolor bleed control processing to reduce dry time so that it is comparable to the print speed and reduce the higher intercolor bleeding usually associated with faster printing.
      <br/>
      On the other hand, lower speed printing using more passes may not require such processing.
    </p>
    <p num="66">
      As indicated above, parameters such as pixel modification patterns and border widths used for intercolor bleed control, under-printing or edge quality processing may be set (varied) based upon print mode (e.g., draft, normal, high speed, low speed, etc.) and/or the image type (e.g., text, line art, graphics pictorial, etc.).
      <br/>
      That is, the processes for reducing intercolor bleeding, under-printing and maintaining edge quality can be most effectively employed if they are applied selectively to different objects within a document based upon the image type and print mode.
      <br/>
      For example, a process may be designed that provides a substantial reduction of intercolor bleeding when applied to graphics objects but produces printing artifacts when applied to pictorial objects.
    </p>
    <p num="67">
      To address this situation, processes for reducing intercolor bleeding (i.e., adjusting borders at black/color interfaces), under-printing and/or maintaining edge quality (i.e., adjusting borders at printed/non-printed interfaces) can be applied on an object oriented basis.
      <br/>
      That is, objects in a document can be classified as one of several different types or classes such as text, line art, graphics, grayscale or pictorial.
      <br/>
      Each of the different classes can be assigned preferred intercolor bleed control, under-printing and edge quality processes.
      <br/>
      Moreover, analysis of the print quality obtained by application of various processes to different object types on different print mediums may be used to identify/describe various object classes.
      <br/>
      For example, consider black text on a non-printed (white) background.
      <br/>
      Small text generally has a small amount of ink and dries relatively quickly.
      <br/>
      As the text becomes larger, however, a greater amount of ink is used and the drying time increases.
      <br/>
      Thus, text below a certain point size may not benefit (and may be harmed) from processing such as under-printing to reduce dry-time.
      <br/>
      On the other hand, text above a threshold point size may benefit from under-printing processing to reduce dry-time to acceptable levels thereby improving print quality.
    </p>
    <p num="68">
      A similar analysis may be performed for black text on a color (printed) background.
      <br/>
      In general, intercolor bleeding increases when there is a greater amount of black ink available to bleed into colors.
      <br/>
      Thus, intercolor bleeding control and under-printing processes can be effective in reducing bleeding and improving print quality for larger point size text.
      <br/>
      On the other hand, the use of intercolor bleeding control and under-printing processing on small text printed on a color background can produce visual defects such as lowered optical density, colored appearance, etc.
      <br/>
      Moreover, due to lower ink content black text below a threshold point size will generate a minimal amount of bleeding.
      <br/>
      Therefore, it may be preferable to eliminate the intercolor bleeding control and under-printing processing for such text.
      <br/>
      Moreover, similar reasoning can be applied to lines, table borders, line art, etc. printed on non-printed (white) backgrounds and on printed (color) backgrounds.
      <br/>
      That is, thin lines (below a threshold width or point size) may not require intercolor bleeding control and under-printing processing and may, in fact, produce a better visual appearance without such processing.
      <br/>
      Likewise, broader lines would generally benefit from intercolor bleeding control and under-printing processing by improving dry-time and reducing intercolor bleeding.
    </p>
    <p num="69">
      The above analysis of print quality may be used to identify and support several combinations of object classes.
      <br/>
      In one embodiment, each object in a document may be classified into one of three classes: (a) black text below a selected font or point size threshold on an non-printed (white) background; (b) graphics objects including line art, black text larger than a second font or point size threshold on a printed (color) background and black text greater than a selected threshold on an non-printed background and (c) pictorial objects.
      <br/>
      The processes described above for reducing intercolor bleeding, under-printing and maintaining edge quality may be applied to objects of class (b) with objects of classes (a) and (c) receiving different pixel management processing.
      <br/>
      It should be appreciated that different font and point size threshold parameters may apply for different classes as well as within a class.
      <br/>
      For example, a first size threshold may be chosen for black text on a non-printed (white) background and a different size threshold may apply for black text on a printed (color) background.
    </p>
    <p num="70">
      Alternatively, the above analysis of print quality may lead to the following three classes: (a) text and line art smaller than a selected point size threshold; (b) graphics objects including line art and text having a point size greater than a selected threshold and (c) pictorial objects.
      <br/>
      Additionally, objects may be separated into "conventional" classes of text objects, graphics objects and pictorial objects wherein intercolor bleed control, under-printing and/or edge quality processing may be applied to each text and graphics object based on the point or font size and background type.
      <br/>
      Once again, it is understood that different size thresholds may be chosen for an object type based on whether the object is on a printed or non-printed background as well as the object type (e.g., text, line art, graphics).
      <br/>
      Furthermore, those skilled in the art will recognize that other object types may also be defined.
    </p>
    <p num="71">
      To selectively apply intercolor bleed control, under-printing and/or edge quality processing on an object oriented basis, one embodiment of the present invention carries out a process as illustrated in FIG. 21. The process of FIG. 21 operates to identify objects within a document image, classify the objects into one of several predefined image types.
      <br/>
      Each of the different object types can be processed using a preferred set of processing techniques.
      <br/>
      More specifically, document image data which may include ASCII data, bitmapped image data (including color corrected, halftoned data), geometric data, graphics primitives, page description language, etc. as well as any combination thereof is received in step 150.
    </p>
    <p num="72">
      At step 152, the document image data is analyzed to identify and classify objects within the document image that are to be rendered differentially so as to result in an output image that is more desirable than the unaltered input image.
      <br/>
      Toward this end, step 152 identifies three types of objects in the image: text, graphics and pictorial.
      <br/>
      It is understood that hybrids of these three basic classes, or entirely different or additional/more specific classes, may be used depending on the particular desired application.
      <br/>
      Objects within an image may be identified and classified from an analysis of the image data.
      <br/>
      The format of the image data received may be used to identify objects.
      <br/>
      That is, text objects may be bitmapped data or ASCII text characters, while pictorial objects may be in the form of a multibit per pixel raster image.
      <br/>
      Graphics objects may be described as graphics primitives or geometric data.
    </p>
    <p num="73">
      Similarly, for image data in a page description language, analysis of the image data can be used to identify graphics objects on the page and their attributes, such as size, border color, fill color, line thickness, and the like.
      <br/>
      The analysis can also provide information on how and where text is used on the page, as well as the text attributes, such as text size, color, spacing and whether the text is next to, or on top of colored regions.
      <br/>
      Moreover, the identification and classification of objects within an image can be accomplished using any number of well know segmentation classification functions including, but not limited to, auto-correlation, frequency analysis, pattern or template matching, peak/valley detection, histograms, etc.
      <br/>
      Furthermore, techniques for classifying image data, such as those taught by Fan et al. in U.S. Pat. No. 5,850,474 and by Revankar et al. in U.S. Pat. No. 5,767,978, can be used to identify objects within the document image.
    </p>
    <p num="74">
      In the second stage, the objects classified as text objects, graphics objects or pictorial objects are processed according to the selected or default processing techniques most appropriate for processing a text, graphics or picture image region.
      <br/>
      For example, text objects can be printed according to a first set of pixel management (e.g., intercolor bleed control, under-printing and edge quality processing) processing parameters, graphics objects according to a second set of pixel management processing parameters, and pictorial objects according to a third set of pixel management processing parameters.
    </p>
    <p num="75">
      At step 154, text objects are directed to text processing techniques as illustrated with steps 160-168.
      <br/>
      If the text is on a printed (color) background (step 160), and is greater than a predetermined font or point size threshold (step 162), then intercolor bleeding control, under-printing and edge quality processing is performed (step 166).
      <br/>
      Similarly, if the text object has a non-printed (white) background (step 160), and is greater than a predetermined point size threshold (step 164), a first pixel management process which may include intercolor bleeding control, under-printing and edge quality processing optimized for large text objects is performed (step 166).
      <br/>
      On the other hand, for text objects less than the predetermined size thresholds at steps 162 and 164, an alternative pixel management process optimized for small text is performed (step 168).
      <br/>
      The alternative pixel management process of step 168 may include any combination of intercolor bleed control, under-printing processing and edge quality processing such as edge quality processing without intercolor bleed control or under-printing processing.
      <br/>
      Likewise, the pixel management processing of step 168 may not include any intercolor bleed control, under-printing processing or edge quality processing.
    </p>
    <p num="76">
      The processing techniques applied to graphics objects (step 156) are similar to those applied to text objects.
      <br/>
      That is, in addition to image processing functions (e.g., color matching or correction, halftoning, etc.), graphics objects that are greater than a predefined graphics size threshold receive a first set of graphics pixel management processing that may include intercolor bleeding control, under-printing and edge quality processing while the graphics objects that are less than the graphics size threshold receive a second set of graphics pixel management processing.
      <br/>
      Finally, in addition to image processing functions (e.g., color matching or correction, halftoning, etc.), pictorial objects receive a set of pictorial pixel management functions that may include intercolor bleeding control, under-printing and/or edge quality processing optimized for pictorial objects.
    </p>
    <p num="77">
      As discussed above, any manner of differentiating image objects that will result in an improved quality image can be used.
      <br/>
      Thus, in certain embodiments of the system and method of the present invention, identification of images as text, graphics or pictures may be eliminated in favor of a system involving different object classes.
      <br/>
      Such a system may allow greater latitude in differentially processing images than one based on "traditional" image classes like text, graphics and pictorial objects.
      <br/>
      For example, in the process of FIG. 21 alternative classes (e.g., class one, class two and class three) may be substituted for text objects, graphics objects and pictorial objects, respectively.
      <br/>
      Wherein class one may be defined to include black text and line art on an non-printed (white) background smaller than a selected font or point size.
      <br/>
      Class two may be defined to include graphics as well as text and line art on a color background larger than a selected point size and text and line art on an non-printed background having a font or point size greater than a selected threshold.
      <br/>
      Class three would maintain pictorial objects.
      <br/>
      As previously described, classes one and three may not need intercolor bleeding control and under-printing processing applied thereto, while class two can benefit from receiving intercolor bleed control, under-printing and edge quality processing.
    </p>
    <p num="78">
      Referring to FIG. 22, there is shown a flowchart illustrating another embodiment of the present invention for differentially processing objects within a document image.
      <br/>
      The process of FIG. 22 operates to identify regions within the document image that include at least one of a graphics object, line art or text on a printed or background larger than a first threshold selected font or point size or line art or text on a non-printed background having a font or point size greater than a second threshold.
    </p>
    <p num="79">
      The process of FIG. 22 begins with the receipt of a document image which may include any combination of text, graphics and/or pictorial objects (step 170).
      <br/>
      It is understood that the objects may or may not have been previously identified and labeled as text, graphics or pictorials.
      <br/>
      The document image comprises a one or more document regions each of which can be defined in terms of number of pixels, number scanlines, bytes of image data, blocks of image data, etc.
      <br/>
      The regions comprising the document image need not be equal in size and can be of any size up to and including the entire document.
      <br/>
      Moreover, the regions can be predefined or identified dynamically as the document image data is received.
      <br/>
      For example, in a Microsoft.RTM. Windows.RTM. environment an image may printed using a technique that divides the image into printer bands and processes each band.
      <br/>
      With such a technique, each band processed which can be identified by the driver by a starting location, width and height can be considered as an image region.
    </p>
    <p num="80">
      At step 172, statistics for each image region are collected.
      <br/>
      At a minimum, the statistics collected will be used to identify image regions that include at least a portion of one of a graphics object, line art or text on a color background larger than the first font or point size and line art or text on an non-printed background greater than the second font or point size threshold.
      <br/>
      The statistics collected may include segmentation data, data describing the type of geometric objects on the page and their attributes, such as size, border color, fill color, line thickness, and the like.
      <br/>
      Other statistics may include information on how text is used on the page, as well as the text attributes, such as text size, color and spacing and whether the text is next to, or on top of printed (color) areas.
      <br/>
      Moreover, step 172 may identify within a page description language instructions for generating a graphics object such as a graphical data interface call in a Windows.RTM. environment.
      <br/>
      Additional statistics collected in step 172 may include identifying black areas that are adjacent to color areas, which objects are black only or color only objects, and which objects have a mixture of black and color.
    </p>
    <p num="81">
      At step 174, the process identifies whether each image region within the document image which may be classified as including a graphics object, line art or text on a color background larger than the first font or point size and line art or text on an non-printed background greater than the second font or point size threshold.
      <br/>
      Additionally, step 174 may identify those regions that include other types of objects as well (i.e., regions including text below a size threshold on a non-printed background or including pictorials).
      <br/>
      However, for intercolor bleeding control, under-printing and edge quality processing step 174 need not specifically identify any small text or pictorial objects or regions including them.
    </p>
    <p num="82">
      At step 176, image regions identified in step 174 as including a graphics object, line art or text on a color background larger than the first font or point size and/or line art or text on an non-printed background greater than the second font or point size threshold are processed with a first pixel management process that includes intercolor bleeding control, under-printing and/or edge quality processing optimized for such object types.
      <br/>
      Regions that do not include at least one of a graphics object, line art or text on a color background larger than the first font or point size and/or line art or text on an non-printed background greater than the second font or point size threshold are processed with a second pixel management process.
      <br/>
      The second pixel management process may comprise any combination of intercolor bleed control, under-printing processing and edge quality processing.
      <br/>
      Alternatively, the second pixel management processes may simply include operations to cause a printer to generate an output document without performing intercolor bleed control, under-printing processing or edge quality processing.
    </p>
    <p num="83">
      The following description in conjunction with FIG. 23 provides one example of the process illustrated in FIG. 22 for differentially processing objects within a document image.
      <br/>
      FIG. 23 illustrates a sample document image 180 comprising area 182 of large text, a graphics object 184 such as a bar chart, a pictorial object 186 and several areas 188 of small text.
      <br/>
      Document 180 is further divided into several image regions 190-196.
      <br/>
      In processing document image 180, the image data corresponding to image region 190 is received and statistics are collected the region are collected.
      <br/>
      Based upon the collected statistics, the process determines that region 190 includes a large text and classifies region 190 as including a graphics object, line art or text on a printed background larger than the first font or point size and line art or text on an non-printed background greater than the second font or point size threshold.
      <br/>
      Based upon this classification, the image data corresponding to region 190 is processed according to a first pixel management process that includes at least one of intercolor bleed control, under-printing processing and edge quality processing.
      <br/>
      For example, the image data within region 190 may be processed according to the method described above with reference to FIG. 17.
    </p>
    <p num="84">
      The process similarly collects statistics for the image data corresponding to regions 192, 194 and 196.
      <br/>
      From the collected statistics, the process classifies regions 192 and 194 as including a graphics object, line art or text on a printed background and/or line art or text on an non-printed background.
      <br/>
      Based upon this classification, the image data within these regions, including the small text and pictorial image data are processed according to a first pixel management process.
      <br/>
      Region 196, on the other hand, would not be so classified, and thus, would be processed according to a second pixel management process which may perform any combination, including none, of intercolor bleed control, under-printing processing or edge quality processing.
    </p>
    <p num="85">
      It should be appreciated that the above process of FIG. 22 is not limited to the binary classification described above.
      <br/>
      For example, image regions may be classified into one of the following three classes: class 1--regions including a graphics object or large text/line art; class 2--regions including both a pictorial object and one of a graphics object or large text/line art; and class 3--regions not including a graphics objects, large text/line art.
    </p>
    <p num="86">While the present invention has been described with reference to various embodiments disclosed herein, it is not to be confined to the details set forth above, but it is intended to cover such modifications or changes as made within the scope of the attached claims.</p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A method of processing color image data for printing on an inkjet printer to maintain edge quality in an image recorded on a receiving medium, comprising:</claim-text>
      <claim-text>receiving color image data comprising a plurality of color planes, the color planes including at least one black plane and at least one non-black plane, wherein each color plane comprises an array of separation pixels, each separation pixel having at least three states, a first state corresponding to depositing no ink, a second state corresponding to depositing one ink drop, and a third state corresponding to depositing more than one ink drop; identifying an interface between a black area and a non-printed area; defining an N-pixel wide border within the black area;</claim-text>
      <claim-text>and modifying the color image data corresponding to the N-pixel wide border to set substantially all the separation pixels in the black plane to the third state.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. A method of processing color image data for printing on an inkjet printer to maintain edge quality in an image recorded on a receiving medium, comprising: receiving color image data comprising a plurality of color planes, the color planes including at least one black plane and at least one non-black plane, wherein each color plane comprises an array of separation pixels, each separation pixel having at least three states, a first state corresponding to depositing no ink, a second state corresponding to depositing one ink drop, and a third state corresponding to depositing more than one ink drop; identifying an interface between a black area and a non-printed area; defining an N-Dixel wide border within the black area; modifying the color image data corresponding to the N-pixel wide border to set substantially all the separation pixels in the black plane to the second state.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The method of claim 2 wherein the N-pixel wide border abuts the interface and wherein N is selected such that the width of the N-pixel wide border is from 0 to 520  MU m.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. A method of processing color image data for printing on an inkjet printer to maintain edge quality in an image recorded on a receiving medium, comprising: receiving color image data comprising a plurality of color planes, the color planes including at least one black plane and at least one non-black plane, wherein each color plane comprises an array of separation pixels, each separation pixel having at least three states, a first state corresponding to depositing no ink, a second state corresponding to depositing one ink drop, and a third state corresponding to depositing more than one ink drop; identifying an interface between a black area and a non-printed area; defining an N-pixel wide border within the black area; modifying the color image data corresponding to the N-pixel wide border to set substantially all the separation pixels in the black plane to a selected pixel state; identifying an interface between a color area and a non-printed area; defining an M-pixel wide border region within the color area;</claim-text>
      <claim-text>and modifying the color image data corresponding to the M-pixel wide border region to set substantially all the separation pixels in a first non-black plane to a selected pixel state.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The method of claim 4, wherein substantially all the separation pixels in the first non-black plane are set to the third state.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The method of claim 4, wherein substantially all the separation pixels in the first non-black plane are set to the second state.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. A method of processing color image data for printing on an inkjet printer to maintain edge quality in an image recorded on a receiving medium, comprising: receiving a target pixel comprising multiple separation pixels, each separation pixel being associated with a separate color plane and having at least three states, a first state corresponding to depositing no ink, a second state corresponding to depositing one ink drop, and a third state corresponding to depositing more than one ink drop; determining if the target pixel is within a black border region near a black/non-printed interface, and if so, setting the separation pixel associated with a black color plane to a selected black pixel state;</claim-text>
      <claim-text>and determining if the target pixel is within a color border region near a black/non-printed interface;</claim-text>
      <claim-text>and if so, setting the separation pixels associated with the non-black color planes to a selected color pixel state.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The method of claim 7, wherein the black pixel state and the color pixel state are third state pixels.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. The method of claim 7, wherein the step of determining if the target pixel is within a black border region comprises: determining if a first condition is met, the first condition being that the number of black only pixels within a black window filter is within a black border pixel range; determining if a second condition is met, the second condition being that the number of color only pixels within the black window filter is less than an interface threshold;</claim-text>
      <claim-text>and identifying the target pixel as being within a black border region near an interface when the first and second conditions are met.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. The method of claim 9 wherein the black border region abuts the interface and is N pixels wide wherein N is selected such that the width of the black border is from 0 to 520  MU m.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. The method of claim 7, wherein the step of determining if the target pixel is within a color border region comprises: determining if a first condition is met, the first condition being that the number of color only pixels within a color window filter is within a color border pixel range; determining if a second condition is met, the second condition being that the number of black only pixels within the color window filter is less than an interface threshold;</claim-text>
      <claim-text>and identifying the target pixel as being within a color border region near an interface when the first and second conditions are met.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. The method of claim 7, wherein the step of determining if the target pixel is within a color border region comprises: determining if a first condition is met, the first condition being that the number of color only pixels within a color window filter is within a color border pixel range; determining if a second condition is met, the second condition being that the number of non-printing pixels within the color window filter is greater than an interface threshold;</claim-text>
      <claim-text>and identifying the target pixel as being within a color border region near an interface when the first and second conditions are met.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. A device for processing color image data to maintain edge quality in an image recorded on a receiving medium, comprising: a black window filter connected to receive a first set of pixels including a target pixel comprising multiple separation pixels, each separation pixel being associated with a separate color plane and having at least three states, a first state corresponding to depositing no ink, a second state corresponding to depositing one ink drop, and a third state corresponding to depositing more than one ink drop, the black window filter generating a black statistics signal; a pixel identification circuit connected to receive the black statistics signal, the identification circuit generating a pixel identification signal indicating whether the target pixel is within a black border region near a black/non-printed interface; a pixel modification circuit connected to receive the pixel identification signal, the modification circuit filtering the target pixel to set the separation pixel associated with a black color plane to a selected black pixel state;</claim-text>
      <claim-text>and a color statistics collection filter operating on a second set of pixels including the target pixel, the color statistics collection filter generating a color statistics signal; wherein the pixel identification signal further indicates whether the target pixel is within a color border region near a color/non-printed interface;</claim-text>
      <claim-text>and wherein the pixel modification circuit filters the target pixel to set the separation pixels associated with the non-black color planes to a selected color pixel state.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. The device of claim 13 wherein the wherein the pixel identification signal identifies the target pixel as being within a black border region when the number of black only pixels in the first set is within black border pixel range and the number of color only pixels within the first set is less than an interface threshold.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. The device of claim 13 where in the pixel identification signal identifies the target pixel as being within a color border region when the number of color only pixels within the second set of pixels is within a color border pixel range and the number of black only pixels within the second set of pixels is less than an interface threshold.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. A method of processing color image data for printing on an inkjet printer to maintain edge quality in an image recorded on a receiving medium, comprising: receiving a target pixel comprising multiple separation pixels, each separation pixel being associated with a separate color plane and having at least three states, a first state corresponding to depositing no ink, a second state corresponding to depositing a first volume of ink, and a third state corresponding to depositing a second volume of ink, the second volume being greater than the first volume; determining if the target pixel is within a black border region near a black/non-printed interface, and if so, setting the separation pixel associated with a black color plane to a selected black pixel state;</claim-text>
      <claim-text>and determining if the target pixel is within a color border region near a black/non-printed interface;</claim-text>
      <claim-text>and if so, setting the separation pixels associated with the non-black color planes to a selected color pixel state.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. The method of claim 16, wherein the black pixel state and the color pixel state are third state pixels.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. The method of claim 16, wherein the step of determining if the target pixel is within a black border region comprises: determining if a first condition is met, the first condition being that the number of black only pixels within a black window filter is within a black border pixel range; determining if a second condition is met, the second condition being that the number of color only pixels within the black window filter is less than an interface threshold;</claim-text>
      <claim-text>and identifying the target pixel as being within a black border region near an interface when the first and second conditions are met.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. The method of claim 16, wherein the step of determining if the target pixel is within a color border region comprises: determining if a first condition is met, the first condition being that the number of color only pixels within a color window filter is within a color border pixel range; determining if a second condition is met, the second condition being that the number of black only pixels within the color window filter is less than an interface threshold;</claim-text>
      <claim-text>and identifying the target pixel as being within a color border region near an interface when the first and second conditions are met.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. The method of claim 16, wherein the step of determining if the target pixel is within a color border region comprises: determining if a first condition is met, the first condition being that the number of color only pixels within a color window filter is within a color border pixel range; determining if a second condition is met, the second condition being that the number of non-printing pixels within the color window filter is greater than an interface threshold;</claim-text>
      <claim-text>and identifying the target pixel as being within a color border region near an interface when the first and second conditions are met.</claim-text>
    </claim>
    <claim num="21">
      <claim-text>21. A method of processing color image data for printing on an inkjet printer to maintain edge quality in an image recorded on a receiving medium, comprising: receiving color image data comprising a plurality of color planes, the color planes including at least one black plane and at least one non-black plane, wherein each color plane comprises an array of separation pixels, each separation pixel having at least three states, a first state corresponding to depositing no ink, a second state corresponding to depositing one ink drop, and a third state corresponding to depositing more than one ink drop; identifying an interface between a black area and a non-printed area; defining an N-pixel wide border within the black area; modifying the color image data corresponding to the N-pixel wide border to set substantially all the separation pixels in the black plane to a selected pixel state; identifying an interface between a color area and a non-printed area; defining an M-pixel wide border region within the color area;</claim-text>
      <claim-text>and modifying the color image data corresponding to the M-pixel wide border region to set substantially all the separation pixels in a first non-black plane to a selected pixel state.</claim-text>
    </claim>
  </claims>
</questel-patent-document>