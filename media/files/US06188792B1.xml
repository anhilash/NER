<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06188792B1.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as first publication">
      <document-id>
        <country>US</country>
        <doc-number>06188792</doc-number>
        <kind>B1</kind>
        <date>20010213</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6188792</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B1</original-publication-kind>
    <application-reference family-id="26553980" extended-family-id="13719918">
      <document-id>
        <country>US</country>
        <doc-number>09382770</doc-number>
        <kind>A</kind>
        <date>19990825</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1999US-09382770</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>14015797</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>38277099</doc-number>
        <kind>A</kind>
        <date>19990825</date>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1999US-09382770</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>JP</country>
        <doc-number>28091195</doc-number>
        <kind>A</kind>
        <date>19951027</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1995JP-0280911</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="3">
        <country>JP</country>
        <doc-number>28102795</doc-number>
        <kind>A</kind>
        <date>19951027</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="3">
        <doc-number>1995JP-0281027</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="4">
        <country>US</country>
        <doc-number>73624096</doc-number>
        <kind>A</kind>
        <date>19961024</date>
        <priority-linkage-type>3</priority-linkage-type>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="4">
        <doc-number>1996US-08736240</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010213</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G06T   9/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>9</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>H04N  19/89        20140101ALI20150212RMEP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>89</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20150212</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>382236000</text>
        <class>382</class>
        <subclass>236000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>375E07027</text>
        <class>375</class>
        <subclass>E07027</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>375E07106</text>
        <class>375</class>
        <subclass>E07106</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>375E07148</text>
        <class>375</class>
        <subclass>E07148</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>375E07155</text>
        <class>375</class>
        <subclass>E07155</subclass>
      </further-classification>
      <further-classification sequence="5">
        <text>375E07156</text>
        <class>375</class>
        <subclass>E07156</subclass>
      </further-classification>
      <further-classification sequence="6">
        <text>375E07163</text>
        <class>375</class>
        <subclass>E07163</subclass>
      </further-classification>
      <further-classification sequence="7">
        <text>375E07174</text>
        <class>375</class>
        <subclass>E07174</subclass>
      </further-classification>
      <further-classification sequence="8">
        <text>375E07176</text>
        <class>375</class>
        <subclass>E07176</subclass>
      </further-classification>
      <further-classification sequence="9">
        <text>375E07180</text>
        <class>375</class>
        <subclass>E07180</subclass>
      </further-classification>
      <further-classification sequence="10">
        <text>375E07182</text>
        <class>375</class>
        <subclass>E07182</subclass>
      </further-classification>
      <further-classification sequence="11">
        <text>375E07211</text>
        <class>375</class>
        <subclass>E07211</subclass>
      </further-classification>
      <further-classification sequence="12">
        <text>375E07218</text>
        <class>375</class>
        <subclass>E07218</subclass>
      </further-classification>
      <further-classification sequence="13">
        <text>375E07224</text>
        <class>375</class>
        <subclass>E07224</subclass>
      </further-classification>
      <further-classification sequence="14">
        <text>375E07254</text>
        <class>375</class>
        <subclass>E07254</subclass>
      </further-classification>
    </classification-national>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/587</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>587</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/107</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>107</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/132</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>132</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/137</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>137</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/146</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>146</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="6">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/149</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>149</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="7">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/15</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>15</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="8">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/152</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>152</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="9">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/166</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>166</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="10">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/17</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>17</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="11">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/174</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>174</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="12">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/176</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>176</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="13">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/44</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>44</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="14">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/527</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>527</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="15">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/61</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>61</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>19</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>17</number-of-drawing-sheets>
      <number-of-figures>18</number-of-figures>
      <image-key data-format="questel">US6188792</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Video encoding and decoding apparatus</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>NINOMIYA YUICHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4692801</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4692801</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>KITAURA MASAHIRO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5144427</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5144427</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>UENO HIDEYUKI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5150432</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5150432</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>NORMILLE JAMES O, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5267334</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5267334</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>ODAKA TOSHINORI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5317397</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5317397</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>WAI LUCAS H Y</text>
          <document-id>
            <country>US</country>
            <doc-number>5347308</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5347308</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>ASTLE BRIAN</text>
          <document-id>
            <country>US</country>
            <doc-number>5590064</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5590064</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>BOICE CHARLES EDWARD, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5644504</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5644504</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="9">
          <text>BRUDER JOHN E</text>
          <document-id>
            <country>US</country>
            <doc-number>5644660</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5644660</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="10">
          <text>BOON CHOONG SENG</text>
          <document-id>
            <country>US</country>
            <doc-number>5657416</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5657416</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="11">
          <text>YAMANE YASUHIKO</text>
          <document-id>
            <country>US</country>
            <doc-number>5661523</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5661523</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="12">
          <text>KNOWLES GREGORY P, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5661822</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5661822</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="13">
          <text>MARTUCCI STEPHEN ANTHONY, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5764805</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5764805</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="14">
          <text>GARDOS THOMAS</text>
          <document-id>
            <country>US</country>
            <doc-number>5802213</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5802213</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="15">
          <text>STRONGIN GEOFFREY S, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5872866</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5872866</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="16">
          <text>CHUJOH TAKESHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>6002802</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US6002802</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="17">
          <text>CHEN CHENG-TIE, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5241383</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5241383</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="18">
          <text>FUJIWARA HIROSHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5241401</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5241401</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="19">
          <text>TANAKA MITSUGU</text>
          <document-id>
            <country>US</country>
            <doc-number>5534929</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5534929</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="20">
          <text>TELEVERKET</text>
          <document-id>
            <country>EP</country>
            <doc-number>0545874</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-545874</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="1">
          <text>Amy R. Reibman and Barry G. Haskell, "Constraints on Variable Bit-Rate Video for ATM Networks", Dec. 2, 1992, IEEE Transactions on Circuits and Systems for Video Technology, No. 4, New York; pp. 361-372.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="2">
          <text>Patent Abstracts of Japan vol. 095, No. 004, May 31, 1995 &amp; JP 07 030589 A (Canon Inc.), Jan. 31, 1995*abstract*.</text>
        </nplcit>
      </citation>
    </references-cited>
    <related-documents>
      <division>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>73624096</doc-number>
              <kind>A</kind>
              <date>19961024</date>
            </document-id>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>6002802</doc-number>
              <kind>A</kind>
            </document-id>
          </parent-doc>
        </relation>
      </division>
    </related-documents>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Kabushiki Kaisha Toshiba</orgname>
            <address>
              <address-1>Kawasaki, JP</address-1>
              <city>Kawasaki</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>TOSHIBA</orgname>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Chujoh, Takeshi</name>
            <address>
              <address-1>Tokyo, JP</address-1>
              <city>Tokyo</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Nagai, Takeshi</name>
            <address>
              <address-1>Tokyo, JP</address-1>
              <city>Tokyo</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="3">
          <addressbook lang="en">
            <name>Kikuchi, Yoshihiro</name>
            <address>
              <address-1>Yokohama, JP</address-1>
              <city>Yokohama</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="4">
          <addressbook lang="en">
            <name>Dachiku, Kenshi</name>
            <address>
              <address-1>Kawasaki, JP</address-1>
              <city>Kawasaki</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Oblon, Spivak, McClelland, Maier &amp; Neustadt, P.C.</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Couso, Jose L.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>LAPSED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      An encoding apparatus comprising a encoder for encoding an input video signal, thereby generating encoded data, an output buffer for receiving the encoded data and outputting the data at a predetermined transmission rate, and an encoding control circuit for selecting a frame to be encoded.
      <br/>
      In the encoding control circuit, the target number of bits for each frame is calculated on the basis of the encoding bit rate, the encoding frame rate and the limits of delay, all of which are set externally.
      <br/>
      The number of encoded bits, thus calculated, is compared with the target number of encoded bits.
      <br/>
      A quantizer and a switch are controlled in accordance with the difference between the number of encoded code and the target number of encoded bits, thereby adjusting a quantization parameter and the number of frames which are to be skipped.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <p num="1">
      This application is a Divisional of Ser.
      <br/>
      No. 08/736,240 filed Oct. 24, 1996, U.S. Pat. No. 6,002,802.
    </p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="2">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="3">The present invention relates to a video encoding apparatus for compression-encoding a video picture into a small number of bits and, more particularly, to a video encoding apparatus capable of encoding data at an encoding frame rate suitable for the picture quality and decreasing the amount of delay when the encoded data is output.</p>
    <p num="4">The present invention also relates to an encoding apparatus for compression-encoding a picture into a small number of bits and a decoding apparatus for reconstructing the picture by decompressing the compression-encoded data and, more particularly, to a video encoding apparatus and a video decoding apparatus which have an intra-encoding mode and an inter-encoding mode and perform refresh by forcedly setting an intra-encoding domain.</p>
    <p num="5">2. Description of the Related Art</p>
    <p num="6">As a technique of compression-encoding pictures into a small number of bits to transmit or store the pictures in systems for transmitting or storing pictures such as a videophone, a teleconference system, a portable terminal, a digital video disk system, and a digital television broadcast system, various methods such as motion compensation, discrete cosine transform, subband encoding, pyramid encoding, and combinations of these methods have been developed.</p>
    <p num="7">
      In addition, ISO, MPEG1, MPEG2, ITU-T, H. 261, and H. 262 are defined as international standard systems of video compression encoding.
      <br/>
      All of these systems are compression encoding schemes which combine motion compensation adaptive prediction and discrete cosine transform, and the details are described in, e.g., reference 1 (Hiroshi Yasuda ed., "International Standard of Multimedia Encoding", Maruzen, June 1991).
    </p>
    <p num="8">
      When a video encoding apparatus using any of these picture compression encoding techniques encodes a video picture at a low bit rate such as 64 kbps or lower, it is difficult to encode the picture at the same frame rate as an input video signal.
      <br/>
      Therefore, a general approach is to encode an input video signal in units of a few frames to thereby perform encoding at a lowered encoding frame rate.
      <br/>
      When one frame is completely encoded, the encoded data of the frame is temporarily stored in an output buffer and output to a transmission channel or another system at a predetermined encoded data transmission speed (encoding bit rate).
    </p>
    <p num="9">
      The setting of the encoding frame rate is crucial because it has a large effect on the encoding quality.
      <br/>
      If the encoding frame rate is fixed and the frame rate of an input video signal is 30 Hz, discrete values such as 30 Hz, 15 Hz, 10 Hz, 7.5 Hz, 6 Hz, 5 Hz, 4.29 Hz, and 3 Hz are determined as the encoding frame rates in accordance with the number of frames as a unit of encoding.
      <br/>
      For example, the motion is satisfactory but the picture quality is low when encoding is performed at 10 Hz, and the picture quality is high but the motion is unsatisfactory when encoding is performed at 7.5 Hz. There is another problem that the picture quality abruptly degrades when a scene in which an object is moving at high speed appears.
    </p>
    <p num="10">
      Accordingly, encoding control which changes the encoding frame rate in accordance with a variation of the picture quality is being developed.
      <br/>
      One example is a simulation model TMN5 (ITU-T TSS LBC-95 SG15 WP15/1 VIDEO CODEC TEST MODEL, TMN5, January 1995) used in the standardizing work of H. 263 which is a video encoding standard system for PSTN (Public Switched Telephone Network).
      <br/>
      This simulation model uses an algorithm (TMN algorithm) of variable frame rate/encoding control by which the encoding frame rate changes during encoding.
      <br/>
      In the TMN algorithm, as the average of quantization parameters QP in the immediately previous frame decreases, a target encoding frame rate in the next frame is increased to decrease the target number of encoding bits (the target number of bits) in the frame.
      <br/>
      Conversely, if the average of the quantization parameters QP in the immediately previous frame increases, the encoding frame rate in the next frame is decreased to increase the target number of bits in the frame.
    </p>
    <p num="11">When a compression encoding system like this is applied to video encoding for communication or broadcast, it is desirable that the delay of transmission of encoded data be small in order to allow real-time communication.</p>
    <p num="12">
      Unfortunately, in conventional video encoding apparatuses using an algorithm such as the TMN algorithm which controls the number of encoded bits by changing the encoding frame rate in accordance with variations of the picture quality, the delay of data transmission in an output buffer is not taken into consideration.
      <br/>
      This poses the problem that a large delay occurs when encoded data is output.
    </p>
    <p num="13">A representative example of the techniques of efficiently compression-encoding video signals is a motion compensation adaptive prediction encoding scheme which encodes (inter-frame-encodes) a prediction error signal which is the difference between an input video signal and a prediction picture signal obtained by performing motion compensation prediction for the input video signal, and transmits the encoded prediction error signal.</p>
    <p num="14">
      When this motion compensation prediction encoding scheme is applied to video encoding for communication or broadcast, it is desirable that the delay of data transmission be small in order to allow real-time communication.
      <br/>
      Also, the contents of frame memories (storage media) of an encoder and a decoder are made different from each other due to a burst error in a transmission channel.
      <br/>
      A general method of solving this problem to accomplish real-time communication or broadcast is to refresh a frame by periodically inserting a pixel region for performing intra-frame encoding into the frame, so that the number of encoded bits does not vary from one frame to another.
    </p>
    <p num="15">
      For example, refresh is performed as follows in the system (ISO-IEC CD13818-2) which was examined in standardization of MPEG2.
      <br/>
      That is, an intra-frame encoding mode (intra mode) and an inter-frame encoding mode (inter mode) are switched in units of 16 pixels * 16 pixels called a macro block.
      <br/>
      In one frame including 30 vertical macro blocks * 44 horizontal macro blocks, two horizontal macro-block lines are encoded in the intra mode, and lines are slid in units of two lines for each frame time to form one cycle with 15 frames.
      <br/>
      This method is called intra slice.
      <br/>
      When a certain region is to be encoded in the inter mode in this method, a motion vector searching range is so limited that the search is not performed from another region which has not been refreshed yet.
      <br/>
      That is, in the intra slice in which the refresh direction is downward, an upward motion vector is the direction related to the limitation.
      <br/>
      With this limitation, it is ensured that refresh is completed in (two cycles--1) times even in the worst case.
    </p>
    <p num="16">
      The problem of the refresh is that the number of encoded bits in the intra mode is usually twice the number of encoded bits in the inter mode for the same quantization parameter.
      <br/>
      To perform encoding at the same rate, therefore, the quantization parameter must be increased by the amount of refresh and this degrades the picture quality.
    </p>
    <p num="17">
      Also, if a long burst occurs in a transmission channel or a storage medium when a video picture is encoded, coded data of at least several frames cannot be correctly decoded.
      <br/>
      Consequently, in a video decoder, the decoded picture is largely degraded until refresh is done in the (two cycles-1) frame in the worst case.
    </p>
    <p num="18">
      Furthermore, if a motion vector is limited when there is a global motion compensation mode in which motion compensation is performed for an entire frame, it is necessary to limit the global motion vector if the vector is in the direction of limitation.
      <br/>
      This largely degrades the picture quality.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="19">It is an object of the present invention to provide a video encoding apparatus capable of encoding data at an encoding frame rate suitable for the picture quality and decreasing the amount of delay when the encoded data is output.</p>
    <p num="20">It is another object of the present invention to provide a video encoding apparatus and a video decoding apparatus capable of improving the picture quality and suppressing disturbance of the picture quality due to mixing of an error into encoded data without decreasing the effect of refresh.</p>
    <p num="21">
      A video encoding apparatus of the present invention comprises an encoding section for encoding an input picture signal, an output section for temporarily holding the output encoded data from the encoding section and outputting the encoded data at a predetermined transmission rate, and control means for setting the target number of bits of each frame by adjusting the number of bits determined by the transmission rate and a predetermined encoding frame rate so that a delay time when the output section outputs the stored encoded data at the predetermined transmission rate is within a predetermined limit delay time, and, on the basis of this target number of bits, controlling the number of encoded bits generated by the encoding section.
      <br/>
      With this arrangement, encoding can be performed at an encoding frame rate suitable for the picture quality and the amount of delay when the encoded data is output can be decreased.
    </p>
    <p num="22">
      Another video encoding apparatus of the present invention comprises an encoding section for quantizing and encoding an input picture signal or an orthogonal transform coefficient obtained by orthogonally transforming a prediction error signal for the input picture signal, an output section for temporarily holding the encoded data output from the encoding section and outputting the encoded data at a predetermined transmission rate, a first control section for setting a target number of bits of each frame by adjusting the number of bits determined by the transmission rate and a predetermined encoding frame rate so that a delay time when the output section outputs the stored encoded data at the predetermined transmission rate is within a predetermined limit delay time, and, on the basis of this target number of bits, controlling a quantization parameter when the encoding section performs quantization, and a second control section for performing control such that the input picture signal to the encoding section is skipped in units of frames until the number of bits of the encoded data held in the output section becomes equal to a value determined by the transmission rate, the limit delay time, and the encoding frame rate.
      <br/>
      With this arrangement, encoding can be performed at an encoding frame rate suitable for the picture quality and the amount of delay when the encoded data is output can be decreased.
    </p>
    <p num="23">
      Also, the first control section controls the quantization parameter of the encoding section on the basis of the target number of bits and the picture complexity of the input picture signal.
      <br/>
      Consequently, encoding can be performed at an encoding frame rate more suitable for the picture quality, and the amount of delay when the encoded data is output can be decreased.
    </p>
    <p num="24">
      Still another video encoding apparatus of the present invention comprises an encoding section having an intra-encoding mode in which an input video signal is intra-encoded and an inter-encoding mode in which an input video signal is inter-encoded, a selector for adaptively selecting the encoding mode of the encoding section for each predetermined picture domain of the input video signal, and a decision section for deciding a motion domain and a stationary domain in the input video signal on the basis of the input video signal and a video signal in the immediately previous frame.
      <br/>
      The selector causes the encoding section to perform a refresh operation in which an intra-encoding domain to be encoded in the intra-encoding mode is periodically set in a frame of the input video signal and moved from one frame to another.
      <br/>
      On the basis of the decision result from the decision section, the period of a refresh operation for the stationary domain is set to be longer than the period of a refresh operation for the motion domain.
      <br/>
      This decreases the number of macro blocks encoded in the intra mode in the stationary domain when compared to conventional refresh.
      <br/>
      Consequently, the quantization parameter can be decreased for the same rate, and this improves the picture quality.
      <br/>
      That is, the picture quality can be improved without decreasing the effect of refresh.
    </p>
    <p num="25">
      A video decoding apparatus of the present invention comprises an input buffer for temporarily holding encoded data obtained by encoding a video signal in an intra-encoding mode or an inter-encoding mode for each predetermined picture domain, a decoding section for decoding the encoded data temporarily held in the input buffer, a storage section for storing a reference picture signal used when the encoded data is decoded in the inter-encoding mode, and a rewrite section for rewriting the reference picture signal stored in the storage section for each predetermined picture domain on the basis of the video signal obtained by the decoding section by decoding the encoded data in the intra-encoding mode.
      <br/>
      The rewrite section checks the state of the encoded data for each frame on the basis of the number of bits of the encoded data temporarily held in the input buffer and the number of bits of one frame of the encoded data.
      <br/>
      If an abnormal frame is detected, the rewrite section stops the rewrite operation of the reference picture based on a video signal of the abnormal frame until a video signal in the intra-encoding mode having a normal frame is obtained by the decoding section.
      <br/>
      With this arrangement, even if a long burst occurs due to an error occurring in encoded data received from a transmission channel or a storage medium, the influence of the long burst can be decreased.
      <br/>
      Accordingly, the disturbance of the picture quality caused by mixing of an error into the encoded data can be suppressed without decreasing the effect of refresh, resulting in an improved picture quality.
    </p>
    <p num="26">
      Still another video encoding apparatus of the present invention comprises an encoding section having an intra-encoding mode in which an input video signal is intra-encoded, a first motion compensation encoding mode in which an input video signal is inter-encoded by performing motion compensation for an entire frame, and a second motion compensation encoding mode in which an input video signal is inter-encoded by performing motion compensation in units of predetermined picture domains obtained by dividing one frame, and a selector for adaptively selecting the encoding mode of the encoding section for each predetermined picture domain of the input video signal.
      <br/>
      The selector causes the encoding section to perform a refresh operation in which an intra-encoding domain to be encoded in the intra-encoding mode is periodically set in a frame of the input video signal and moved from one frame to another.
      <br/>
      Also, when the encoding section inter-encodes the input video signal, the selector does not select the first motion compensation encoding mode for a picture domain in which a motion vector for the refresh operation must be limited.
      <br/>
      With this arrangement, the influence of the limitation on the motion vector during refresh does not spread over an entire frame but can be suppressed within a predetermined picture domain in the frame.
      <br/>
      Accordingly, the disturbance of the picture quality caused by mixing of an error into the encoded data can be suppressed without decreasing the effect of refresh, resulting in an improved picture quality.
    </p>
    <p num="27">
      Additional objects and advantages of the invention will be set forth in the description which follows, and in part will be obvious from the description, or may be learned by practice of the invention.
      <br/>
      The objects and advantages of the invention may be realized and obtained by means of the instrumentalities and combinations particularly pointed out in the appended claims.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="28">
      The accompanying drawings, which are incorporated in and constitute a part of the specification, illustrate presently preferred embodiments of the invention and, together with the general description given above and the detailed description of the preferred embodiments given below, serve to explain the principles of the invention.
      <br/>
      FIG. 1 is a block diagram of a video encoding apparatus according to one embodiment of the present invention;
      <br/>
      FIG. 2 is a graph for explaining the principle of processing of an encoding control circuit;
      <br/>
      FIG. 3 is a flow chart for explaining processing performed by the encoding control circuit for one frame;
      <br/>
      FIG. 4 is a flow chart for explaining processing of setting the target number of bits of each frame;
      <br/>
      FIG. 5 is a flow chart for explaining processing of determining an encoding frame rate;
      <br/>
      FIG. 6 is a flow chart for explaining another processing performed by the encoding control circuit for one frame;
      <br/>
      FIG. 7 is a view for explaining the format of a macro block;
      <br/>
      FIG. 8 is a block diagram of a radio communication system according to the second embodiment of the present invention, in which the video encoding apparatus of the present invention is applied;
      <br/>
      FIG. 9 is a view showing an example of the radio communication system according to the second embodiment;
      <br/>
      FIG. 10 is a block diagram of a video encoding apparatus according to the third embodiment of the present invention;
      <br/>
      FIG. 11 is a view for explaining intra slice and the operation of a refresh decision circuit;
      <br/>
      FIG. 12 is a view for explaining intra slice and the operation of the refresh decision circuit;
      <br/>
      FIG. 13 is a flow chart for explaining the operation of the refresh decision circuit, which illustrates a case where refresh is performed by intra slice;
      <br/>
      FIG. 14 is a flow chart for explaining another operation of the refresh decision circuit, which illustrates a case where refresh is performed by an intra-column;
      <br/>
      FIG. 15 is a block diagram of a video decoding apparatus according to the fourth embodiment of the present invention;
      <br/>
      FIG. 16 is a view for explaining the operation of a long burst decision circuit;
      <br/>
      FIG. 17 is a view for explaining the operation of a mode selector; and
      <br/>
      FIG. 18 is a diagram for explaining refreshing.
    </p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
    <p num="29">A video encoding apparatus according to one embodiment of the present invention will be described below with reference to FIG. 1.</p>
    <p num="30">
      Referring to FIG. 1, an input video signal to an encoder 117 is input to a switch 101.
      <br/>
      Under the control of an encoding control circuit 116, an input video signal of a frame to be encoded is selected by the switch 101 and segmented into macro blocks by a block segmenting circuit 102.
      <br/>
      The input video signal segmented into macro blocks is input to a subtracter 103.
      <br/>
      The subtracter 103 calculates the difference between the input picture signal and a prediction picture signal which is formed as will be described later and generates a prediction error signal.
      <br/>
      A mode selection switch 104 selects one of the prediction error signal and the input video signal from the block segmenting circuit 102.
      <br/>
      A DCT (Discrete Cosine Transform) circuit 105 performs discrete cosine transform for the selected signal.
      <br/>
      The DCT coefficient data obtained by the DCT circuit 105 is quantized by a quantizer 106.
      <br/>
      The signal quantized by the quantizer 106 is divided into two signals.
      <br/>
      One signal is variable-length-encoded by a variable-length encoder 113.
      <br/>
      The other signal is supplied to a dequantizer 107 and an IDCT (Inverse Discrete Cosine Transform) circuit 108 where the signal is subjected to processing which is reverse to the processing done by the quantizer 106 and the DCT circuit 105.
      <br/>
      An adder 109 adds the processed signal to an input prediction picture signal from a switch 112, thereby generating a local decoded signal.
      <br/>
      This local decoded signal is stored in a frame memory 110 and input to a motion compensation circuit 111 to generate a prediction picture signal.
    </p>
    <p num="31">
      The encoding control circuit 116 controls the encoder 117 on the basis of encoded data from the encoder 117, the number of encoded bits (the number of coded bits) from the variable-length encoder 113, and a buffer capacity from an output buffer 115, and supplies necessary data to the variable-length encoder 113.
      <br/>
      The data encoded by the variable-length encoder 113 are multiplexed by a multiplexer 114, smoothed at a fixed output rate (encoding bit rate) by the output buffer 115, and transmitted as encoded data.
    </p>
    <p num="32">
      The encoding control circuit 116 receives a signal which informs an encoding bit rate (rate (bits/sec)) of the output encoded data from the output buffer 115, a signal which informs an encoding frame rate (f_rate (Hz)), and a signal which informs a delay time permitted for the output encoded data from the output buffer 115, i.e., a limit delay time (limit_delay (msec)).
      <br/>
      On the basis of information which is preset by these signals, the encoding control circuit 116 controls the number of encoded bits generated by the encoder 117 so that the delay time of the output encoded data from the output buffer 115 is within the limit delay time (limit_delay (msec)).
    </p>
    <p num="33">
      The principle of the present invention will be described below with reference to FIG. 2.
      <br/>
      In FIG. 2, it is assumed that when encoding of one frame is completed, the encoded data of the frame is entirely input to the output buffer 115, and the encoded data is output from the output buffer in accordance with the encoding bit rate (bits/sec).
    </p>
    <p num="34">
      An average delay time ave_delay (msec) depends upon a buffer capacity B of the output buffer 115.
      <br/>
      The delay time (delay_time (msec)) in a frame of a frame number (f_no) n is obtained by dividing a peak buffer capacity B�n� when the frame of the frame number n is completely encoded by the encoding bit rate (rate) and multiplying the quotient by 1000.
      <br/>
      The average delay time ave_delay is the average of the delay times thus calculated up to the point.
    </p>
    <p num="35">In this embodiment, the basic control is to calculate the target number of bits (target) of each frame to be encoded and, on the basis of this target number of bits (target), change the quantization parameter and the encoding frame rate, i.e., the number of frames to be skipped, thereby holding the delay time constant.</p>
    <p num="36">
      Assume that an initial value of the target number of bits (target) of each frame is obtained by dividing the encoding bit rate (rate) by the set encoding frame rate f_rate.
      <br/>
      The set frame rate f_rate need not be a value obtained by dividing a frame rate FR of an input video signal by a natural number.
      <br/>
      Accordingly, the set encoding frame rate f_rate does not take a discrete value unlike in the case of a fixed encoding frame rate, and this increases the degree of freedom.
      <br/>
      As an example, a value such as 7.25 (Hz) can be set as f_rate.
      <br/>
      To ensure the setting of the delay time, however, if the average delay time ave_delay up to the point exceeds the set value limit_delay, the target number of bits (target) of each frame is decreased by the exceeded amount.
    </p>
    <p num="37">
      A method of determining a frame to be encoded next is done as follows.
      <br/>
      That is, encoded data is supplied until the buffer capacity B is equal to or smaller than an amount obtained by subtracting the default target number of bits rate/frame (bits) from a buffer capacity rate*limit_delay/1000 (bits) corresponding to the preset encoding bit rate and limit delay time.
      <br/>
      Assume that a value indicating a frame to be encoded next is represented by f_cnt.
      <br/>
      When control is performed in this way, the delay time delay_time does not exceed the set value limit_delay if the number of encoded bits in the next frame is decreased to be less than the target number of bits.
    </p>
    <p num="38">
      If the actual number of encoded bits largely exceeds the target number of bits (target), f_cnt increases and a larger number of input frames are skipped.
      <br/>
      This decreases the encoding frame rate.
      <br/>
      Conversely, if the number of encoded bits is much smaller than the target number of bits, f_cnt decreases and a smaller number of frames than usual are skipped.
      <br/>
      This increases the encoding frame rate.
    </p>
    <p num="39">
      As described above, the number of encoded bits is limited by setting the target number of bits (target) of each frame and, on the basis of the resulting number of encoded bits, a frame to be encoded next is decided.
      <br/>
      Consequently, an encoding frame rate suitable for the picture quality is realized, and the average delay time of the output encoded data from the output buffer 115 can be decreased to be less than the set limit delay time.
    </p>
    <p num="40">FIG. 3 is a flow chart for explaining the control processing performed by the encoding control circuit 116 for each frame when encoding is performed in units of frames in the video encoding apparatus shown in FIG. 1.</p>
    <p num="41">
      First, before encoding of each frame, the target number of bits (target) of each frame is set (step S101).
      <br/>
      On the basis of this "target", a reference quantization parameter b_QP of each frame used when the quantizer 106 performs quantization is set (step S102).
    </p>
    <p num="42">
      Subsequently, before encoding is performed for each macro frame, the quantization parameter QP is calculated (step S103).
      <br/>
      Encoding is performed by controlling the quantizer 106 on the basis of the calculated value (step S104).
      <br/>
      This quantization parameter QP is a quantization parameter in intra-frame encoding.
    </p>
    <p num="43">
      When the encoding of one frame is completed, the number f_cnt of frames to be skipped without being encoded is calculated by processing to be described later, and a frame to be encoded next is decided (step S105).
      <br/>
      The input video signal switch 101 is so controlled as to skip (thin) the number f_cnt of frames.
    </p>
    <p num="44">The processing of setting the target number of bits (target) of each frame performed in step S101 of FIG. 3 will be described in detail below with reference to a flow chart in FIG. 4.</p>
    <p num="45">
      For the first frame (frame number f_no=1), the target number of bits (target) of each frame is set to the preset encoding bit rate (rate) as an initial value (steps S201 and S202).
      <br/>
      For each of the second and the subsequent frames (frame number f_no=2 or more), the target number of bits (target) is first set to a value obtained by dividing the set encoding bit rate (rate) by the set encoding frame rate f_rate (step S203).
      <br/>
      However, if the average delay time ave_delay of encoded data of frames up to the previous frame exceeds the set delay time limit_delay (step S204), the number of bits corresponding to the exceeded amount is subtracted from "target" (step S205).
    </p>
    <p num="46">
      Also, if the set value of "target" is smaller than the value obtained by dividing the set value "rate" by the frame rate FR of the input video signal (step S206), the control may break down.
      <br/>
      If this is the case, therefore, rate/FR is set as "target" by giving the priority to the number of bits rather than the delay amount (step S207).
    </p>
    <p num="47">The reference quantization parameter b_QP of each frame in step S102 of FIG. 3 will be described below.</p>
    <p num="48">The reference quantization parameter b_QP is calculated by equation (1) below.  (Equation image '1' not included in text)</p>
    <p num="49">Note that b_QP is limited to 1 to 31.</p>
    <p num="50">In equation (1), pre_QP is an average quantization parameter in the immediately previous frame, pre_frame_bits is the number of bits in the immediately previous frame, and a is a reaction parameter of the first quantization parameter.</p>
    <p num="51">
      In addition to the above method, the reference quantization parameter b_QP can be calculated as follows.
      <br/>
      That is, a standard deviation sgm of a motion compensation prediction error signal (a signal 118 in FIG. 1) of one frame is previously calculated, and the reference quantization parameter b_QP is decided from this standard deviation sgm and the target number of bits (target).
      <br/>
      This standard deviation is calculated by subtracting an average value in each small region (e.g., an 8 * 8 block). b_QP can be calculated by equation (2) below.
      <br/>
      b-- QP=a*(sgm * b)/target  (2)
    </p>
    <p num="52">where a and b are constants, e.g., a=0.25 and b=1.5.</p>
    <p num="53">
      The quantization parameter QP in step S103 of FIG. 3 will be described below.
      <br/>
      The quantization parameter QP can be calculated by equation (3) below.
      <br/>
      Note that although the quantization parameter QP can be calculated for each macro block, QP is calculated for each macro-block line in this embodiment.  (Equation image '2' not included in text)
    </p>
    <p num="54">Note that QP is limited to 1 to 31.</p>
    <p num="55">In equation (3), mb is the current number (1 to MB) of macro blocks, MB is the number of macro blocks per frame,  BETA  is a reaction parameter of the second quantization parameter, and an array encoded_bits is the number of encoded bits in each macro block.</p>
    <p num="56">The processing of determining an encoding frame in step S105 of FIG. 3 will be described below with reference to a flow chart in FIG. 5.</p>
    <p num="57">In FIG. 5, f_cnt indicates a frame to be encoded next, i.e., the number of frames to be skipped without being encoded.</p>
    <p num="58">First, the variable-length encoder 113 informs the number of bits generated in a frame, and the amount is added to the buffer capacity B of the output buffer 115 at that time (step S301).</p>
    <p num="59">
      A method of deciding the value f_cnt indicating a frame to be encoded next is as follows.
      <br/>
      First, initialization is performed by setting the value of f_cnt to "0" (step S302).
      <br/>
      A value obtained by dividing the set encoding bit rate (rate) by the frame rate FR of an input video signal, i.e., the number of bits corresponding to the transmission rate at the frame rate FR of the input video signal is subtracted from the buffer capacity B (step S303). f_cnt is increased until the buffer capacity B is equal or smaller than a value obtained by subtracting the default number of bits (rate/f rate) of each frame from the number of bits (rate * limit_delay/1000) corresponding to the set limit delay time (limit_delay) (step S304).
      <br/>
      Consequently, the number f_cnt of frames to be skipped without being encoded is calculated.
    </p>
    <p num="60">Another control processing that the encoding control circuit 116 performs for each frame when performing encoding will be described below with reference to a flow chart in FIG. 6.</p>
    <p num="61">
      This encoding control method is characterized in that the target number of bits in each macro block is set by calculating the activity of the prediction error signal 118 selected by the switch 109 before encoding is performed, thereby performing encoding control more suitable for the picture quality.
      <br/>
      The activity of the prediction error signal 118 is picture status information which represents the complexity of a picture to be encoded for each macro block.
      <br/>
      For example, as the value of the activity increases, it becomes necessary to increase the number of bits.
    </p>
    <p num="62">
      First, the target number of bits (target) of each frame is set before encoding is performed in units of frames (step S401).
      <br/>
      In addition, the target number of bits target_mb of each macro block is set (step S402).
      <br/>
      Also, the reference quantization value b_QP of each frame is set (step S403).
    </p>
    <p num="63">
      Subsequently, before each macro block is encoded, the quantization parameter QP is calculated (step S404).
      <br/>
      Encoding is performed on the basis of the calculated value (step S405).
    </p>
    <p num="64">When one frame is completely encoded, the number f_cnt of frames to be skipped without being encoded is calculated to decide a frame to be encoded next (step S406).</p>
    <p num="65">The processing of setting the target number of bits (target) of each frame performed in step S401 of FIG. 6 is analogous to that shown in FIG. 4.</p>
    <p num="66">
      The target number of bits target_mb of each macro block in step S402 of FIG. 6 can be calculated by equations (4) to (9) for each macro block mode.
      <br/>
      First, the activity of an intra-frame encoded macro block (to be referred to as an intra macro block hereinafter) is calculated in accordance with equations (4) and (5).
    </p>
    <p num="67">
      Each macro block has a format generally used in, e.g., H. 261, MPEG1, and H. 263 as shown in FIG. 7.
      <br/>
      That is, a macro block contains six blocks, i.e., consists of a luminance signal (Y) containing four blocks of 8 * 8 pixels and chrominance signals (Cb and Cr) each of which is a block of 8 * 8 pixels.
    </p>
    <p num="68">Note that original_picture indicates an input video signal in each macro block, and dc is an average value of macro blocks of the input video signal calculated by equation (5).  (Equation image '3' not included in text)</p>
    <p num="69">As a consequence, the target number of bits target_mb of each intra macro block is calculated by equation (6) below.  (Equation image '4' not included in text)</p>
    <p num="70">(6) where intra is the number of intra macro block in a frame, inter is the number of inter macro blocks in the frame, and not_coded is the number of non-encoded macro blocks in the frame.</p>
    <p num="71">
      In an inter-frame encoded macro block (to be referred to as an inter macro block hereinafter), the activity is calculated in accordance with equation (7).
      <br/>
      The target number of bits target_mb in each macro block is calculated by equation (8).
    </p>
    <p num="72">Note that pred_picture is a prediction picture signal formed by the motion compensation circuit 111 for each macro block.  (Equation image '5' not included in text)</p>
    <p num="73">Note that an activity ratio comp is calculated in accordance with equation (9) from data encoded in the immediately previous frame.  (Equation image '6' not included in text)</p>
    <p num="74">(9) where encoded_bit is the number of encoded bits in each macro block and QP is the value of a quantization parameter in each macro block.</p>
    <p num="75">The reference quantization parameter b_QP of each frame in step S403 of FIG. 6 is calculated by equations (10) and (11) while the activity of a frame is taken into account.  (Equation image '7' not included in text)</p>
    <p num="76">Note that b_QP is limited to 1 to 31.</p>
    <p num="77">In equation (10) and (11), frame_act is the activity of the current frame, pre_QP is the average quantization parameter of the immediately previous frame, pre_frame_bits is the number of bits of the immediately previous frame, pre_frame_act is the activity of the immediately previous frame, and  ALPHA  is a reaction parameter of the first quantization parameter.</p>
    <p num="78">
      The quantization parameter QP in step S409 of FIG. 6 is calculated by equation (12).
      <br/>
      Although the quantization parameter QP can be calculated for each macro block, QP is calculated for each macro block line in this embodiment.  (Equation image '8' not included in text)
    </p>
    <p num="79">Note that QP is limited to 1 to 31.</p>
    <p num="80">In equation (12), mb is the current number (1 to MB) of macro blocks, MB is the number of macro blocks per frame,  BETA  is a reaction parameter of the second quantization parameter, and an array encoded_bits is the number of encoded bits in each macro block.</p>
    <p num="81">The processing of determining the encoding frame in step S406 of FIG. 6 determines f_cnt as in FIG. 5.</p>
    <p num="82">
      In this embodiment, encoding is performed in units of frames.
      <br/>
      However, it is of course possible to practice the present invention when encoding is performed in units of fields.
    </p>
    <p num="83">FIG. 8 shows the second embodiment in which the video encoding apparatus of the present invention is applied to a radio communication system.</p>
    <p num="84">Referring to FIG. 8, the radio communication system includes a picture transmission apparatus 20 and a picture reconstruction apparatus 30 and transmits and receives pictures via a base station 41 provided with a network 40.</p>
    <p num="85">
      The picture transmission apparatus 20 comprises a picture signal input section 21, a data source encoding section 22 including an error resilience processor 23, a transmission channel encoding section 24, and a radio transmitter 25.
      <br/>
      The data source encoding section 22 performs discrete cosine transform (DCT) and quantization.
      <br/>
      The transmission channel encoding section 24 performs error detection and correction for encoded data.
    </p>
    <p num="86">
      The video encoding apparatus according to the present invention is applied to the main part of the data source encoding section 22.
      <br/>
      The picture reconstruction apparatus 30 comprises a radio receiver 31, a transmission channel decoding section 32, a source decoding section 33 including an error resilience processor 34, and a picture signal output section 35.
    </p>
    <p num="87">
      FIG. 9 shows one example of the radio communication system according to the second embodiment.
      <br/>
      As shown in FIG. 9, video pictures are transmitted and received by terminals 50 such as a laptop type personal computer 51 and a desktop type personal computer 52 via base stations 41, 42, and 43 of the communication network 40.
    </p>
    <p num="88">
      For example, an input picture signal from a camera 51a attached to the personal computer 51 as a picture signal input section is encoded by the data source encoding section 22 incorporated into the personal computer 51.
      <br/>
      The encoded data output from the data source encoding section 22 is multiplexed with other information such as speech and data, and the multiplexed information is radio-transmitted via the radio transmitter 25 and an antenna 51b of the personal computer 51.
      <br/>
      The radio signal is transmitted via the base stations 41 to 43 provided in the network 40 and received via an antenna 52a of the personal computer 52 and the radio receiver 31 incorporated into the personal computer 52.
      <br/>
      The signal received by the radio receiver 31 is demultiplexed into the encoded data of the picture signal and the speech data.
      <br/>
      The encoded data of the picture signal is decoded by the source decoding section 33 of the personal computer 52 and displayed on the display of the personal computer 52.
    </p>
    <p num="89">
      Meanwhile, an input picture signal from a camera 52b attached to the personal computer 52 as the picture signal input section 21 is encoded in the same manner as above by the data source encoding section 22 incorporated into the personal computer 52.
      <br/>
      The encoded data is multiplexed with other information such as speech and data, and the multiplexed data is radio-transmitted from the radio transmitter 25 and the antenna 52a of the personal computer 52.
      <br/>
      The radio signal is transmitted via the base stations 41 to 43 provided in the network 40 and received via the antenna 51a of the personal computer 51 and the radio receiver 31 incorporated into the personal computer 51.
      <br/>
      The signal received by the radio receiver 31 is demultiplexed into the encoded data of the picture signal and the information of speech and data.
      <br/>
      The encoded data of the picture signal is decoded by the source decoding section 33 of the personal computer 51 and displayed on the display of the personal computer 51.
    </p>
    <p num="90">
      In the above embodiment as described above, the encoding control circuit 116 adjusts the number of bits (rate/f_rate) which is decided by the encoding bit rate (rate) and the encoding frame rate (f_rate), such that the delay time when the output buffer 115 outputs the stored encoded data at the predetermined encoding bit rate (rate) is within the predetermined limit delay time (limit_delay), thereby setting the target number of bits (target) of each frame.
      <br/>
      On the basis of this target number of bits (target), the encoding controller 116 controls the quantizer 106 of the encoder 117 and the switch 101 (more specifically, calculates the quantization step parameter and the number f_cnt of frames to be skipped without being encoded).
      <br/>
      Consequently, encoding can be performed at an encoding frame rate suitable for the picture quality and the amount of delay when the encoded data is output can be decreased.
    </p>
    <p num="91">
      Also, on the basis of the prediction error signal 118, the activity representing the picture complexity of an input video signal is calculated for each macro block.
      <br/>
      The quantization parameter is calculated by also taking account of the calculated activity.
      <br/>
      Consequently, encoding control more suitable for the picture quality can be performed.
    </p>
    <p num="92">A video encoding apparatus according to the third embodiment will be described below with reference to FIG. 10.</p>
    <p num="93">
      In FIG. 10, an input video signal is segmented into macro blocks by a block segmenting circuit 201.
      <br/>
      The input video signal segmented into macro blocks is input to a subtracter 202.
      <br/>
      The subtracter 202 calculates the difference between the input video signal and a prediction picture signal and generates a prediction error signal.
      <br/>
      A mode selection switch 203 selects one of the prediction error signal and the input video signal from the block segmenting circuit 201.
      <br/>
      A DCT (Discrete Cosine Transform) circuit 204 performs discrete cosine transform for the selected signal.
      <br/>
      The DCT coefficient data obtained by the DCT circuit 204 is quantized by a quantizer 205.
      <br/>
      The signal quantized by the quantizer 205 is divided into two signals.
      <br/>
      One signal is variable-length-encoded by a variable-length encoder 206.
      <br/>
      The other signal is supplied to a dequantizer 210 and an IDCT (Inverse Discrete Cosine Transform) circuit 211 where the signal is subjected to processing which is reverse to the processing performed by the quantizer 205 and the DCT circuit 204.
      <br/>
      An adder 212 adds the processed signal to an input prediction picture signal from a switch 215, thereby generating a local decoded signal.
      <br/>
      This local decoded signal is stored in a frame memory 213 and input to a motion compensation circuit 214.
    </p>
    <p num="94">As shown in FIG. 20, the motion compensation circuit 214 inhibits an unrefreshed domain 2 from performing motion compensation for an already refreshed intra domain 1, thereby forming a prediction picture signal.</p>
    <p num="95">
      An encoding control circuit 209 controls encoding on the basis of encoded information from an encoder 218 and a buffer capacity from an output buffer 208 and supplies necessary data to the variable-length encoder 206.
      <br/>
      The data encoded by the variable-length encoder 206 is multiplexed by a multiplexer 207, the transmission rate of the multiplexed data is smoothed by the output buffer 208, and the data is transmitted as encoded data.
    </p>
    <p num="96">On the basis of prediction information P from the motion compensation circuit 214, a mode selector 216 selects a macro block to be subjected to inter-frame encoding and a macro block to be subjected to intra-frame encoding in units of macro blocks.</p>
    <p num="97">To perform intra-frame encoding (intra encoding), mode selection switch information M serves as A and switch information S serves as A. To perform inter-frame encoding (inter encoding), the mode selection switch information M serves as B and the switch information S serves as B. The mode selection switch 203 performs switching on the basis of the mode selection switch information M. The switch 215 performs switching on the basis of the switch information S.</p>
    <p num="98">
      The modes are an intra mode (INTRA), an inter mode (INTER), and a non-encoding mode (NOT_CODED), and each of these modes corresponds to each macro block.
      <br/>
      That is, an INTRA macro block is a picture domain to be subjected to intra-frame encoding, an INTER macro block is a picture domain to be subjected to inter-frame encoding, and a NOT_CODED macro block is a picture domain requiring no encoding.
      <br/>
      These pieces of information are exchanged between the mode selector 216 and a refresh decision circuit 217 by mode selection information MODE.
    </p>
    <p num="99">The refresh decision circuit 217 decides whether each macro block is a motion domain or a stationary domain and decides on the basis of this decision result whether refresh is to be performed.</p>
    <p num="100">
      In a macro block of the non-encoding mode (NOT_CODED) in which a picture changes little from one frame to another, there is almost no chance of an error being mixed and so the influence of an error from another macro block is not mixed.
      <br/>
      Accordingly, it is decided that a macro block which is NOT_CODED for a fixed frame time or longer in the past is a stationary domain.
      <br/>
      For the stationary domain, the refresh period can be set to be longer than that for the motion domain.
    </p>
    <p num="101">
      Decision of the stationary domain depends upon the number of frames which cannot be successively decoded due to errors.
      <br/>
      If frames which cannot be successively decoded due to errors are present, it is necessary to consider a case in which a motion domain exists between these frames and so a frame can change.
      <br/>
      Accordingly,
    </p>
    <p num="102">
      if an error exists in one frame, one cycle
      <br/>
      if errors exist in two frames, one cycle+1
      <br/>
      if errors exist in three frames, one cycle+2
      <br/>
      if errors exist in L frames, one cycle+L-1
    </p>
    <p num="103">
      Generally, assuming the number of frames which cannot be successively decoded due to errors is L, no refresh needs to be performed for a macro block continuously found to be stationary over (one cycle+L-1) frames in the past.
      <br/>
      That is, since a picture in a frame before a frame which cannot be decoded due to an error is correct, recovery of refresh in two cycles can be ensured.
    </p>
    <p num="104">On the basis of this principle, the present invention decreases the number of intra modes for refresh.</p>
    <p num="105">The principle of the present invention will be described below with reference to FIGS. 11 and 12.</p>
    <p num="106">
      FIGS. 11 and 12 illustrate the operation of refresh in which the operation in the case of intra slice is viewed just from the side of frames in time series.
      <br/>
      Note that FIGS. 11 and 12 illustrate a case where the number of frames which cannot be decoded due to errors is L=2.
      <br/>
      Note also that the period of refresh is four frames and the frames are refreshed downward.
    </p>
    <p num="107">
      In FIG. 11, assuming the number of frames which cannot be successively decoded is 2 (L=2), it is decided that these frames form a stationary domain if NOT_CODED continues over 4+2-1=5 frames.
      <br/>
      In this case, no refresh is necessary because a correct reference picture can be used as a reference picture in the next frame.
      <br/>
      In practice, even if NOT_CODED does not continue, a macro block of the intra (INTRA) mode for refresh can be included in a stationary domain if it can be decided from an input picture signal that the macro block is NOT_CODED.
    </p>
    <p num="108">
      FIG. 12 shows the worst case when the processing as explained in FIG. 11 is performed.
      <br/>
      As in FIG. 12, if a frame memory is not rewritten for a macro block having an error, it is assured that the range over which the error propagates is recovered in (two cycles-1) times in the worst case.
    </p>
    <p num="109">
      When compared to conventional refresh, the number of macro blocks to be encoded in the intra mode in a stationary domain decreases.
      <br/>
      Accordingly, the quantization parameter can be decreased for the same rate, and this improves the picture quality.
    </p>
    <p num="110">
      FIG. 13 is a view for explaining the processing of the refresh decision circuit 217, which is a flow chart showing the processing performed for one frame.
      <br/>
      FIG. 13 illustrates an operation when refresh is performed by intra slice having one macro block line for one frame.
    </p>
    <p num="111">
      In FIG. 13, reference symbols i and j represent the vertical and horizontal addresses, respectively, of a macro block in a frame; V_NMB and H_NMB, the numbers of macro blocks in the vertical and horizontal directions, respectively, in a frame; and N, the frame number of an encoded frame counted from 0.
      <br/>
      A two-dimensional array D�i� �j� stores information concerning a motion domain and a stationary domain in each macro block.
    </p>
    <p num="112">
      The refresh decision circuit 217 operates when it receives a frame number N and mode selection information MODE from the mode selection circuit 216.
      <br/>
      If the macro blocks should be refreshed, the circuit 217 rewrites the information MODE to INTRA, which is supplied to the mode selection circuit 216.
      <br/>
      Further, the circuit 217 updates the array D which contains information relating to the motion domain and the stationary domain.
    </p>
    <p num="113">
      The operation of the refresh decision circuit 217 will be explained with reference to the flow chart of FIG. 13. The operation comprises two loops 1 and 2.
      <br/>
      The first loop 1 includes Steps 501 and 514, and the second loop 1 includes Steps 502 and 513.
    </p>
    <p num="114">
      First, in Step 503 the refresh decision circuit 217 determines whether each macro block contained in a frame needs to be refreshed or not.
      <br/>
      More precisely, the circuit 217 determines that the macro block should be refreshed, if the remainder obtained of dividing the frame number N by V_NMB equals the vertical address i of the macro block and if D�i� �i� is equal to or less than V_NMB+L-1.
      <br/>
      If Yes, the operation passes to Step 504, in which the circuit 217 rewrites MODE to INTRA.
      <br/>
      If No, the operation jumps to Step 505, in which the macro block is encoded.
      <br/>
      Thereafter, in Step 506 the circuit 217 updates the array D on the basis of the value of MODE.
      <br/>
      If MODE is INTER, the array D is initialized to "0" in Step S510.
    </p>
    <p num="115">
      If MODE is INTRA, the operation passes to Step 507.
      <br/>
      In Step 507, it is determined whether the absolute sum SAD of the input video signal and the video signal of the immediately preceding frame is less than a predetermined threshold value TH.
      <br/>
      If Yes, "NOT-CODED" is determined, and the array D is incremented by 1, so that the operation goes to Step 508.
      <br/>
      If No in Step 507, the array D is initialized to "0" (Step 509).
    </p>
    <p num="116">
      If MODE is NOT_CODED, the operation passes to Step 511.
      <br/>
      In Step 511 it is determined whether the value of the array D is equal to or less than V_NMB+L-1.
      <br/>
      If Yes, the value of the array D is increased by 1 in Step 512.
    </p>
    <p num="117">Thus, the macro block which has been regarded as NOT_CODED for a time longer than the last period (one cycle+L-1) is not refreshed even if it has become ready to be refreshed.</p>
    <p num="118">
      An intra-slice which is refreshed on the micro block line has been described with reference to the flow chart of FIG. 4.
      <br/>
      The process shown in FIG. 4 can be applied to an intra-column for refreshing the blocks in units of micro block column.
    </p>
    <p num="119">FIG. 14 is a flow chart explaining how refresh decision circuit 217 processes each frame in the case where an intra-column is refreshed.</p>
    <p num="120">
      Shown in FIG. 14 are: the vertical address i of the macro block contained in a frame; the horizontal address j thereof; the number V_NMB of macro blocks arranged in the frame in the vertical direction; the number H_NMB of macro blocks arranged in the frame in the horizontal direction; and the ordinal number N of any coded frame, counted from "0." The two-dimensional array D�i� �j� stores information relating to the motion domain and the stationary domain.
      <br/>
      The array D is initialized at the value H_NMB+L, on the assumption that the frame has no errors when N=0, that is, when the first intra macro block is encoded in its entirety.
    </p>
    <p num="121">
      As seen from the flow chart of FIG. 14, the refresh decision circuit 217 receives the frame number N and mode selection information MODE from the mode selection circuit 216.
      <br/>
      If each macro block must be refreshed, the circuit 217 rewrites the information MODE to INTRA, which is supplied to the mode selection circuit 216.
      <br/>
      Then, the circuit 217 updates the array D which contains information relating to the motion domain and the stationary domain.
    </p>
    <p num="122">
      First, in Step 601 the refresh decision circuit 217 initializes a flag B at TRUE in order to achieve a long-term refreshing.
      <br/>
      The operation comprises two loops 1 and 2.
      <br/>
      The first loop 1 includes Steps 602 and 617, and the second loop 1 includes Steps 603 and 616.
    </p>
    <p num="123">
      Next, in Step 504 the refresh decision circuit 217 determines whether each macro block contained in a frame needs to be refreshed or not.
      <br/>
      To be more specific, the circuit 217 determines that the macro block should be refreshed, if the remainder obtained by dividing the frame number N by V_NMB equals the horizontal address j of the macro block and if D�i� �i� is equal to or less than H_NMB+L-1.
      <br/>
      If Yes, the operation passes to Step 605, in which the circuit 217 rewrites MODE to INTRA.
      <br/>
      If No, the operation jumps to Step 606, in which the macro block is encoded.
      <br/>
      Thereafter, in Step 607 the circuit 217 updates the array D on the basis of the value of MODE.
      <br/>
      If MODE is INTER, the array D is initialized to "0" in Step S611.
    </p>
    <p num="124">
      If MODE is INTRA, the operation passes to Step 608.
      <br/>
      In Step 608, it is determined whether the absolute sum SAD of the input video signal and the video signal of the immediately preceding frame is less than a predetermined threshold value TH.
      <br/>
      If Yes, the operation goes to Step 609, in which the value of the array D is increased by 1.
      <br/>
      If No in Step 608, the operation passes to Step 610, in which the array D is initialized to "0."
    </p>
    <p num="125">
      If MODE is NOT_CODED, the operation passes to Step 612.
      <br/>
      In Step 612 it is determined whether the value of the array D is equal to or less than H_NMB+L-1.
      <br/>
      If Yes, the value of the array D is increased by 1 in Step 613.
      <br/>
      If the value of the array D is greater than H_NMB+L-1 and if the flag LB is set at TRUE in Step 614, the array D is initialized to "0" and the flag LB is set at FALSE.
    </p>
    <p num="126">
      In the operation illustrated in FIG. 14, the array D is initialized at the value H_NMB+L in the first frame.
      <br/>
      Therefore, the macro block which has been regarded as NOT_CODED continuing from the second frame is not refreshed even if it has become ready to be refreshed.
      <br/>
      Macro blocks that have been regarded as NOT_CODED for a time longer than a period of one cycle+L-1 are generally not refreshed, either.
      <br/>
      Nonetheless, a long-term refreshing is guaranteed so that only one of the macro blocks regarded as NOT_CODED for a time longer than a period of one cycle+L-1 may be forcedly changed to "0" to be encoded to INTRA in the next refreshing.
    </p>
    <p num="127">
      In the third embodiment, macro blocks are encoded in units of frames.
      <br/>
      Needless to say, they can be encoded in units of fields.
    </p>
    <p num="128">
      In the third embodiment, the refresh decision circuit 217 determines that a domain where an inter-frame picture changes little for a time longer than a predetermined frame period is a stationary domain, on the basis of the input video signal and the video signal of the immediately preceding frame.
      <br/>
      When the domain is found to be stationary, the refreshing cycle is set longer.
      <br/>
      Hence, less macro blocks need to be encoded at the stationary domain in the intra-encoding mode, than in the conventional refresh operation.
      <br/>
      This decreases the quantization parameter, ultimately improving the picture quality.
    </p>
    <p num="129">A video decoding apparatus according to the fourth embodiment of the invention will be described.</p>
    <p num="130">
      FIG. 15 is a block diagram of the fourth embodiment.
      <br/>
      As seen from FIG. 15, the encoded data supplied through a transfer path or a storage medium is temporarily stored in an input buffer 301 and then supplied to a demultiplexer 302.
      <br/>
      The demultiplexer 302 demultiplexer the encoded data, frame by frame, on the basis of prescribed syntax.
      <br/>
      The data thus demultiplexer is input to a variable-length decoder 303.
      <br/>
      The decoder 303 decodes the data items of various syntaxes, thereby generating mode information MODE.
    </p>
    <p num="131">
      The mode information MODE is input to a mode decision circuit 306.
      <br/>
      The circuit 306 turns on switches 309 and 311 if the mode information MODE is NOT_CODED, whereby the reconstruction picture signal stored as reference picture in a frame memory 310 is output in the form of a motion-picture signal from the video decoding apparatus.
    </p>
    <p num="132">
      If the mode information MODE is INTRA, the switch 311 is turned off.
      <br/>
      In this case, the quantized DCT coefficient data obtained by the variable-length decoder 303 is input to an inverse quantization circuit 305.
      <br/>
      The circuit 305 inversely quantizes the DCT coefficient data, generating inversely quantized DCT coefficient data.
      <br/>
      This data is supplied to an IDCT circuit 307, which performs inverse discrete cosine transform (IDCT) on the data, generating a reconstruction picture signal.
      <br/>
      The reconstruction picture signal is stored in the frame memory 310 in the form of reference picture.
      <br/>
      The signal, i.e., a motion picture signal, is output through the switch 309 from the video decoding apparatus.
    </p>
    <p num="133">
      If the mode information MODE is INTER, the switch 311 is turned on.
      <br/>
      In this case, too, the quantized DCT coefficient data obtained by the variable-length decoder 303 is input to an inverse quantization circuit 305, which inversely quantizes the DCT coefficient data, generating inversely quantized DCT coefficient data, and the data thus generated is supplied to an IDCT circuit 307, which performs inverse discrete cosine transform (IDCT) on the data, generating a reconstruction picture signal.
      <br/>
      The reconstruction picture signal is supplied to an adder 308.
      <br/>
      Meanwhile, one of the storage areas of the frame memory 310 is designated by the motion-vector data MV generated by the variable-length decoder 303.
      <br/>
      The reference picture signal stored in the storage area thus designated is supplied to the adder 308, too.
      <br/>
      The adder adds the reconstruction picture signal to the reference picture signal, generating a reconstruction picture signal.
      <br/>
      This signal is stored as a reference picture signal in the frame memory 310 and is output as a motion picture signal via the switch 309 from the video decoding apparatus.
    </p>
    <p num="134">
      The video decoding apparatus comprises a long-burst decision circuit 312.
      <br/>
      The circuit 312 monitors the amount of data stored in the input buffer 301 and the amount of one-frame code being processed in the demultiplexer 302.
      <br/>
      The circuit 312 determines that the frame is a long burst if the amount of data in the input buffer 301 is less than the storage capacity of the buffer 301 and if the amount of one-frame code is less than a predetermined value.
      <br/>
      If the frame is regarded as a long burst, the switch 304 is operated, inhibiting the components connected to the output of the switch 304 from operating.
    </p>
    <p num="135">
      As for any frame succeeding the frame regarded as a long burst, each macro block which is found to be INTRA by the mode decision circuit 306 is decoded again by turning the switch 304.
      <br/>
      Those macro blocks of the frames succeeding the long burst frame which take the same position are subjected to ordinary decoding.
    </p>
    <p num="136">
      The switch 304 is turned of if no macro blocks are found to be INTRA by the mode decision circuit 306 after the components connected to the output of the switch 304 are inhibited from operating.
      <br/>
      In this case, the ordinary decoding is not performed on the macro blocks.
    </p>
    <p num="137">
      A display-prohibiting period L_STOP is externally set in accordance with the refresh cycle adapted in the video decoding apparatus.
      <br/>
      During this period L_STOP the switch 309 remains off so that no motion picture is displayed for a prescribed time which begins at the frame containing a motion picture signal having a long burst.
    </p>
    <p num="138">
      As long as the video decoding apparatus operates correctly, the input buffer 301 neither overflows nor underflows.
      <br/>
      Should the input buffer 301 underflows, it would indicate that the amount of one-frame code is much greater than the predetermined value.
      <br/>
      Thus, some frames may not be correctly decoded because errors in the transfer path or the storage medium destruct the sync codes of the frames, even if the video decoding apparatus operates correctly.
      <br/>
      Namely, the sync codes of the frames can be considered to be spaced apart greatly.
    </p>
    <p num="139">
      If the amount of one-frame code is equal to or greater than the predetermined value, e.g., 1 second, it can be inferred that at least several frames cannot be decoded.
      <br/>
      In this case, it is determined that a long burst has mixed into the motion picture signal.
      <br/>
      Assume that a frame containing a long burst is decoded without processing the frame at all, a picture containing errors will be displayed.
      <br/>
      To avoid it, this frame is not decoded so that the picture corresponding to the immediately preceding frame may be continuously displayed.
    </p>
    <p num="140">
      The picture corresponding to the frame succeeding the frame containing a long burst may be far from clear since the reference picture is not correct in the case of a macro block of INTER mode.
      <br/>
      In the case of a macro block of INTRA mode, the picture can be decoded correctly, and a clear image can be constructed from the succeeding macro block of either INTER mode or non-encoding mode unless motion compensation is effected at that storage area of the frame memory 310 in which an incorrect reference picture signal is stored.
    </p>
    <p num="141">
      Thus, as shown in FIG. 16, decoding of any frame succeeding a frame containing a long burst is inhibited until a macro block of INTRA mode is decoded.
      <br/>
      In other words, frames are decoded once a macro block of INTRA mode has been decoded.
      <br/>
      The frames appear as if partly decoded once the macro block of INTRA mode has been decoded, even if the display is not stopped.
      <br/>
      Hence, the displayed picture is rather clear.
      <br/>
      When the display is stopped while the picture is recovering, the picture will be recovered almost completely merely only if the video decoding apparatus stops the display for one refresh cycle.
    </p>
    <p num="142">
      In the fourth embodiment, macro blocks are encoded in units of frames.
      <br/>
      They can of course be encoded in units of fields.
    </p>
    <p num="143">
      A video coding apparatus according to the fifth embodiment of the present invention will be described.
      <br/>
      The fifth embodiment is identical in structure to the third embodiment illustrated in FIG. 10.
    </p>
    <p num="144">
      In a conventional intra-slice or intra-column, any micro block refreshed must have its motion vector limited before the next frame is encoded.
      <br/>
      The global motion vector of the micro block may be limited in the global motion compensation mode to apply motion compensation on the entire frame.
      <br/>
      If the vector is so limited, however, not only the macro block but also the entire picture will be affected to impair the picture quality.
    </p>
    <p num="145">
      In the fifth embodiment, the mode selection circuit 316 does not select the global motion compensation mode for any macro block that must have its motion vector limited.
      <br/>
      Otherwise such a macro block would not be refreshed at all.
    </p>
    <p num="146">How the mode selection circuit 316 serves to refresh micro blocks of an intra-slice will be explained with reference to FIG. 17.</p>
    <p num="147">
      The global motion vector must be limited if it is downward.
      <br/>
      Therefore, the mode selection circuit 316 does not select the global motion compensation mode for any polka-dotted marco block shown FIG. 17, under the control of the a motion compensation circuit 314.
      <br/>
      The circuit 314 selects non-encoding mode (NOT_CODED) for the polka-dotted macro blocks.
      <br/>
      As a result, the motion vector limited does not the entire picture, it adversely influences the polka-dotted macro blocks only.
    </p>
    <p num="148">
      The video coding apparatus which is the third embodiment can be incorporated in the data source encoding section 22 of the radio communication system illustrated in FIG. 8.
      <br/>
      The video decoding apparatus which is the fourth embodiment can be incorporated in the source decoding section 33 of the radio communication system (FIG. 8).
      <br/>
      Also can the video coding apparatus and the video decoding apparatus be incorporated in the radio communication system which is shown in FIG. 9.
    </p>
    <p num="149">
      As has been described, the present invention can provide a video encoding apparatus which encodes input picture data at an encoding frame rate corresponding to the desired quality of a motion picture and which minimizes the delay in outputting the encoded data.
      <br/>
      Furthermore, the invention can provide a video encoding apparatus and a video decoding apparatus which serve to improve the quality of a motion picture without impairing the advantage achieved by refreshing macro blocks and which minimize the deterioration of picture quality resulting from errors contained in encoded data.
    </p>
    <p num="150">
      Additional advantages and modifications will readily occur to those skilled in the art.
      <br/>
      Therefore, the invention in its broader aspects is not limited to the specific details, representative devices, and illustrated examples shown and described herein.
      <br/>
      Accordingly, various modifications may be made without departing from the spirit or scope of the general inventive concept as defined by the appended claims and their equivalents.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A video encoding apparatus comprising:</claim-text>
      <claim-text>encoding means for encoding an input picture signal and outputting encoded data; output buffer means for temporarily holding the encoded data and for outputting the encoded data at a transmission rate; first control means for determining the target number of encoding bits using the transmission rate and a frame rate in order to set, within a limit delay time, a delay in outputting the encoded data held in the buffer means at the transmission rate, and for controlling the number of encoded bits generated by the encoding means, in accordance with the target number of encoding bits;</claim-text>
      <claim-text>and second control means for skipping the input picture signal input to the encoding means in units of frame until the number of coded bits held in the output buffer means reaches a value determined by the transmission rate, the limit delay time and the encoding frame rate, thereby to control a frame rate in accordance with the number of coded bits.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. A video encoding apparatus according to claim 1, wherein the encoding means comprises segmenting means for segmenting the input picture signal into a plurality of blocks to output a plurality of picture signal blocks;</claim-text>
      <claim-text>an orthogonal transform circuit for orthogonal-transforming each of the picture signal blocks to produce a plurality of orthogonal-transformed signals;</claim-text>
      <claim-text>a quantizer for quantizing the orthogonal-transformed signals to produce a quantized signal;</claim-text>
      <claim-text>an encoder for encoding the quantized signal to produce encoded data;</claim-text>
      <claim-text>a local decoder for local-decoding the quantized signal to produce a local-decoded signal;</claim-text>
      <claim-text>a motion compensation circuit for subjecting the local-decoded signal to motion compensation processing to produce a prediction picture signal;</claim-text>
      <claim-text>and means for obtaining a prediction error signal from the picture signal blocks and the prediction picture signal and inputting the prediction error signal to the orthogonal transform circuit.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. A video encoding apparatus according to claim 2, wherein said encoding control means sets a reference quantization parameter for each frame at the quantizer in quantizing the orthogonal-transformed signals on the basis of the target number of bits.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. A video encoding apparatus according to claim 1, wherein said first control means includes means for determining the target number of encoded bits for each frame before encoding the input picture signal for each frame, and sets a reference quantization parameter for each frame at the encoding means on the basis of the target number of encoded bits.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. A video encoding apparatus comprising: encoding means for quantizing an orthogonal transform coefficient obtained by performing orthogonal transform on an input picture signal or a prediction error signal regarding the input picture signal, to produce encoded data; output buffer means for temporarily holding the encoded data and for outputting the encoded data at a transmission rate;</claim-text>
      <claim-text>and first control means for determining the target number of encoded bits for each frame on the basis of the transmission rate and a preset encoding frame rate so that a delay time in outputting the encoded data held in the output buffer means at the transmission rate is within a limit delay time, and for controlling a quantization parameter used for quantizing the orthogonal transform coefficient on the basis of the target number of encoded bits;</claim-text>
      <claim-text>and second control means for skipping the input picture signal input to the encoding means in units of frame until the number of coded bits held in the output buffer means reaches a value determined by the transmission rate, the limit delay time and the preset encoding frame rate, to control a frame rate in accordance with the number of coded bits.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. A video encoding apparatus according to claim 5, wherein the encoding means comprises segmenting means for segmenting the input picture signal into a plurality of blocks to output a plurality of picture signal blocks;</claim-text>
      <claim-text>an orthogonal transform circuit for orthogonal-transforming each of the picture signal blocks to produce a plurality of orthogonal-transformed signals;</claim-text>
      <claim-text>a quantizer for quantizing the orthogonal-transformed signals to produce a quantized signal;</claim-text>
      <claim-text>an encoder for encoding the quantized signal to produce encoded data;</claim-text>
      <claim-text>a local decoder for local-decoding the quantized signal to produce a local-decoded signal;</claim-text>
      <claim-text>a motion compensation circuit for subjecting the local-decoded signal to motion compensation processing to produce a prediction picture signal;</claim-text>
      <claim-text>and means for obtaining a prediction error signal from the picture signal blocks and the prediction picture signal and inputting the prediction error signal to the orthogonal transform circuit.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. A video encoding apparatus according to claim 6, wherein said first control means determines the quantization parameter for quantizing the orthogonal-transformed signals on the basis of the target number of encoded bits and picture complexity of the input picture signal, and for controlling the quantizer on the basis of the quantization parameter.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. A video encoding method comprising the steps of: encoding an input picture signal to obtain encoded data; temporarily holding the encoded data in a buffer memory and reading the encoded data at a transmission rate therefrom; determining the target number of encoding bits using the transmission rate and an encoding frame rate in order to set, within a limit delay time, a delay time in outputting the encoded data held in the buffer memory at the transmission rate;</claim-text>
      <claim-text>and skipping the input picture signal input to the encoding means in units of frame until the number of coded bits held in the output buffer means reaches a value determined by the transmission rate, the limit delay time and the encoding frame rate, to control a frame rate in accordance with the number of coded bits.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. A video encoding method according to claim 8, wherein the encoding step comprises segmenting the input picture signal into a plurality of blocks to obtain a plurality of picture signal blocks, orthogonal-transforming each of the picture signal blocks to produce a plurality of orthogonal-transformed signals, quantizing the orthogonal-transformed signals to produce a quantized signal, encoding the quantized signal to produce encoded data, local-decoding the quantized signal to produce a local-decoded signal, subjecting the local-decoded signal to motion compensation processing to produce a prediction picture signal, and obtaining a prediction error signal from the picture signal blocks and the prediction picture signal and subjecting the prediction error signal to the orthogonal-transforming.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. A video encoding method according to claim 9, wherein said encoding step includes setting a reference quantization parameter for each frame in quantizing the orthogonal-transformed signals on the basis of the target number of bits.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. A video encoding method according to claim 8, wherein said determining step includes determining the target number of encoded bits for each frame before encoding the input picture signal for each frame, and setting a reference quantization parameter for each frame on the basis of the target number of encoded bits.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. A video encoding method comprising the steps of: quantizing an orthogonal transform coefficient obtained by performing orthogonal transform on an input picture signal or an error signal predicted for the input picture signal, to produce encoded data; temporarily holding the encoded data in a buffer memory and reading the encoded data at a predetermined transmission rate;</claim-text>
      <claim-text>and determining the target number of encoded bits for each frame on the basis of the transmission rate and a preset encoding frame rate so that a delay time in reading the encoded data held in the buffer memory at the transmission is within a limit delay time, and controlling a quantization parameter used for quantizing the orthogonal transform coefficient on the basis of the target number of encoded bits;</claim-text>
      <claim-text>and skipping the input picture signal in units of frame until the number of coded bits held in the buffer memory reaches a value determined by the transmission rate, the limit delay time and the encoding frame rate, to control a frame rate in accordance with the number of encoded bits.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. A video encoding method according to claim 12, wherein the encoding step comprises segmenting the input picture signal into a plurality of blocks to output a plurality of picture signal blocks, orthogonal-transforming each of the picture signal blocks to produce a plurality of orthogonal-transformed signals, quantizing the orthogonal-transformed signals to produce a quantized signal, encoding the quantized signal to produce encoded data, local-decoding the quantized signal to produce a local-decoded signal, subjecting the local-decoded signal to motion compensation processing to produce a prediction picture signal, and obtaining a prediction error signal from the picture signal blocks and the prediction picture signal and subjecting the prediction error signal to the orthogonal-transforming.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. A video encoding method according to claim 13, wherein said step of determining the target includes determining the quantization parameter for quantizing the orthogonal-transformed signals on the basis of the target number of encoded bits and picture complexity of the input picture signal, and controlling the quantizer on the basis of the quantization parameter.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. A video encoding apparatus comprising: an encoder section configured to encode an input picture signal and output encoded data; an output buffer section configured to temporarily hold the encoded data and for outputting the encoded data at a transmission rate; a first control section configured to determine the target number of encoding bits using the transmission rate and a frame rate in order to set, within a limit delay time, a delay in outputting the encoded data held in the buffer section at the transmission rate, and to control the number of encoded bits generated by the encoder section, in accordance with the target number of encoding bits;</claim-text>
      <claim-text>and a second control section configured to skip the input picture signal input to the encoder section in units of frame until the number of coded bits held in the output buffer section reaches a value determined by the transmission rate, the limit delay time and the encoding frame rate, thereby to control a frame rate in accordance with the number of coded bits.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. A video encoding apparatus comprising: an encoder section configured to quantize an orthogonal transform coefficient obtained by performing orthogonal transform on an input picture signal or an error signal predicted for the input picture signal, to produce encoded data; an output buffer section configured to temporarily hold the encoded data and output the encoded data at a predetermined transmission rate;</claim-text>
      <claim-text>and a first control section configured to determine the target number of encoded bits for each frame on the basis of the transmission rate and a predetermined encoding frame rate so that a delay time in outputting the encoded data held in the output buffer section at the transmission rate is within predetermined limits, and control a quantization parameter used for quantizing on the basis of the target number of encoded bits;</claim-text>
      <claim-text>and a second control section configured to skip the input picture signal input to the encoder section in units of frame until the number of coded bits held in the output buffer section reaches a value determined by the transmission rate, the predetermined limits and the encoding frame rate, to control a frame rate in accordance with the number of coded bits.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. A video encoding apparatus according to claim 16, wherein the encoder section comprises: a segmenting circuit configured to segment the input picture signal into a plurality of blocks and output a plurality of picture signal blocks; an orthogonal transform circuit configured to orthogonal-transform each of the picture signal blocks and produce a plurality of orthogonal-transformed signals; a quantizer configured to quantize the orthogonal transformed signals for producing a quantized signal; an encoder configured to encode the quantized signal for producing encoded data; a local decoder configured to local-decode the quantized signal for producing a local-decoded signal; a motion compensation circuit configured to subject the local-decoded signal to motion compensation processing for producing a prediction picture signal;</claim-text>
      <claim-text>and a prediction circuit configured to obtain a prediction error signal from the picture signal blocks and the prediction picture signal, and input the prediction error signal to the orthogonal transform circuit.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. A video encoding apparatus according to claim 17, wherein said first control section determines the quantization parameter for quantizing the orthogonal-transformed signals on the basis of the target number of encoded bits and picture complexity of the input picture signal, and controls the quantizer on the basis of the quantization parameter.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. A video encoding apparatus according to claim 18, wherein said first control section determines a quantization parameter QP in accordance with the following equation:  (Equation image '9' not included in text)  where mb is the current number (1 to MB) of macro blocks, MB is the number of macro blocks per frame,  BETA  is a reaction parameter of the second quantization parameter, and an array encoded bits is the number of encoded bits in each macro block.</claim-text>
    </claim>
  </claims>
</questel-patent-document>