<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06182192B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06182192</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6182192</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference family-id="10845833" extended-family-id="13754167">
      <document-id>
        <country>US</country>
        <doc-number>09481096</doc-number>
        <kind>A</kind>
        <date>20000111</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>2000US-09481096</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>14051104</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>GB</country>
        <doc-number>9900521</doc-number>
        <kind>A</kind>
        <date>19990111</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1999GB-0000521</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G06F  13/16        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>13</main-group>
        <subgroup>16</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>711111000</text>
        <class>711</class>
        <subclass>111000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>365191000</text>
        <class>365</class>
        <subclass>191000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>711005000</text>
        <class>711</class>
        <subclass>005000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G06F-013/16A2R2</text>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>013</main-group>
        <subgroup>16A2R2</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06F-013/1631</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>13</main-group>
        <subgroup>1631</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>22</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>7</number-of-drawing-sheets>
      <number-of-figures>11</number-of-figures>
      <image-key data-format="questel">US6182192</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Memory interface device and method for accessing memories</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>HANG CHIA-LUN</text>
          <document-id>
            <country>US</country>
            <doc-number>5487049</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5487049</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>CHUNG CHAN H</text>
          <document-id>
            <country>US</country>
            <doc-number>5587953</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5587953</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="3">
          <text>FUNG MICHAEL G, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4924375</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4924375</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="4">
          <text>KURTZE JEFFREY D, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5022004</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5022004</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="5">
          <text>LE CHINH H, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5502835</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5502835</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="6">
          <text>ADKISSON RICHARD W</text>
          <document-id>
            <country>US</country>
            <doc-number>5590304</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5590304</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="7">
          <text>WAGNER STEVEN D</text>
          <document-id>
            <country>US</country>
            <doc-number>5615355</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5615355</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="8">
          <text>KIM SEONG-WOON, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5659687</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5659687</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="9">
          <text>LAU WINNIE K W, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5765182</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5765182</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="10">
          <text>JEDDELOH JOSEPH</text>
          <document-id>
            <country>US</country>
            <doc-number>5950229</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5950229</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>CANON KK</text>
          <document-id>
            <country>EP</country>
            <doc-number>0733980</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-733980</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="12">
          <text>AST RESEARCH INC</text>
          <document-id>
            <country>WO</country>
            <doc-number>9630838</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>WO9630838</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>STMicroelectronics Limited</orgname>
            <address>
              <address-1>Bristol, GB</address-1>
              <city>Bristol</city>
              <country>GB</country>
            </address>
          </addressbook>
          <nationality>
            <country>GB</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>STMICROELECTRONICS</orgname>
          </addressbook>
          <nationality>
            <country>GB</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Rovati, Fabrizio</name>
            <address>
              <address-1>Cinisello Balsamo, IT</address-1>
              <city>Cinisello Balsamo</city>
              <country>IT</country>
            </address>
          </addressbook>
          <nationality>
            <country>IT</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <name>Galanthay, Theodore E.</name>
          </addressbook>
        </agent>
        <agent sequence="2" rep-type="agent">
          <addressbook lang="en">
            <name>Iannucci, Robert</name>
          </addressbook>
        </agent>
        <agent sequence="3" rep-type="agent">
          <addressbook lang="en">
            <orgname>Seed IP Law Group PLLC</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Nelms, David</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>LAPSED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A memory interface is disclosed for accessing a plurality in memory regions.
      <br/>
      The interface includes a register which stores a number of memory request signals received from a processor or the like.
      <br/>
      The memory interface includes circuitry for detecting which memory region each memory request refers to and also which page within that memory region is required to be accessed.
      <br/>
      Using the information contained in the register, the memory interface is able to determine which page within a memory region will be required to be accessed after the currently open page is closed.
      <br/>
      The memory interface can detect this information a number of memory requests in advance.
      <br/>
      Thus the memory interface is able to provide the necessary control instructions to initiate the opening of the subsequently required page within a memory region so that when the memory request requiring access to this page is serviced, there is no delay in opening the page.
      <br/>
      The memory interface is arranged so that a page within a first memory region can be opened while a page within a second memory is being actually accessed.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>FIELD OF THE INVENTION</heading>
    <p num="1">The present invention relates to a memory interface device and a method for accessing memories and, in particular, for memories comprising a plurality of memory regions.</p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="2">
      One type of known memory device is the synchronous dynamic random access memory (SDRAM).
      <br/>
      A typical example of an SDRAM is shown in FIG. 1.
      <br/>
      The SDRAM 2 comprises two memory banks 4a and 4b.
      <br/>
      In some known SDRAMs, four memory banks are in fact provided.
      <br/>
      Each memory bank 4a and 4b contains a plurality of rows R which are sometimes referred to as pages.
      <br/>
      Each memory bank 4a and 4b also contains a plurality of columns C which intersect the rows R. A memory location is therefore identified by the bank number, the row number and the column number.
      <br/>
      To access a given memory location (or word) a memory interface unit 6 is provided.
      <br/>
      The memory interface unit 6 receives an input 7 which provides the address of the word to be accessed.
      <br/>
      The address identifies the memory bank, row and column of the word to be accessed.
    </p>
    <p num="3">
      Based on the address input to the memory interface unit 6, control signals 12 are generated which are output to a respective column control unit 8 and to a respective row control unit 10.
      <br/>
      Each bank 4a and 4b has its own row and column control units 8 and 10.
      <br/>
      The row and column control units 8 and 10 are sometimes referred to as row and column decoders respectively.
      <br/>
      The row control unit 10 will, in accordance with the address input to the memory interface unit, select a row R in the selected memory bank 4a or 4b.
      <br/>
      Once the row R or page has been selected (or opened), then the appropriate column C is selected by the column control unit 8, again in accordance with the input address.
    </p>
    <p num="4">
      The operation to open a page or row R will generally take several cycles.
      <br/>
      Once a page or row R has been opened, any word in that page or row R can be selected in one cycle.
      <br/>
      Thus a first word at a first column C location can be accessed in one cycle and a different word in that same row R but in a different column C location can be accessed in the next cycle.
      <br/>
      Once all the required accesses in a given row R or page have been completed, the open page or row R needs to be closed.
      <br/>
      This is achieved by the row control unit 10 precharging all the rows R including the selected row in the selected memory bank 4a or 4b to a given voltage.
      <br/>
      This closing operation must be completed before another page or row in the same bank can be selected or opened.
      <br/>
      This closing operation also takes several cycles.
    </p>
    <p num="5">
      Reference will now be made to FIG. 2 which shows a sequence of steps which occurs when eight words from a first selected row R in a first memory bank 4a are read and then eight words from a second selected row in the second memory bank 4b are read.
      <br/>
      As can be seen, the first six cycles A are used to open the first selected row R and read the first required word in that row of the first memory bank 4a.
      <br/>
      The next seven cycles B are used to read the remaining required seven words in the opened row R. The next three cycles D are required to close the first selected row R in the first bank 4a.
      <br/>
      The next six cycles E are used to open the second selected row R in the second memory bank 4b and read the first required word from that row.
      <br/>
      The next seven cycles F are required to read the other seven required words in the second selected row.
      <br/>
      The last three cycles G are required to close the second selected row R in the second memory bank 4b.
      <br/>
      Thus, in order to read eight words from a given row in a memory bank requires 16 cycles even though the reading operation itself only requires 8 cycles.
      <br/>
      This therefore reduces the efficiency of the memory device and increases the time required in order to complete read and write operations.
    </p>
    <p num="6">It is therefore an aim of embodiments of the present invention to reduce the number of cycles required to carry out an operation in respect of a memory having a plurality of memory regions.</p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="7">According to one aspect of the present invention, there is provided a memory interface device for generating a plurality of commands for controlling a memory having first and second memory regions, only one of said memory regions being accessible at a time, each memory region comprising a plurality of rows, said device comprising: a buffer for storing a plurality of received memory requests for said memory, said memory request each including information as to the row to be accessed of said respective memory region, and said buffer arranged to provide a respective output for each memory request, each of said outputs indicating said row to be accessed for the respective memory request; a detector arranged to receive said plurality of outputs from said buffer and to detect a next different row in each of said memory regions to be subsequently selected, said detector providing an output signal indicative of said detected next different row of said memory regions; and a command provider for providing a sequence of commands in response to said received memory requests and said output signals provided by said detector for controlling said memory, said command sequence being arranged so that a row of one of the first and second memory regions is accessed while said detected next different row of the other of the first and second memory regions is being selected.</p>
    <p num="8">Thus, as it is possible for one memory region to be accessed whilst the other memory region is being selected or deselected, the number of cycles required to access a burst may be reduced as compared to the prior art described in relation to FIG. 1.</p>
    <p num="9">
      Preferably, the portion of the memory regions which is selected or deselected comprises a row.
      <br/>
      A row is sometimes referred to as a page in relation to certain memory devices.
      <br/>
      When a portion of the first or second memory regions is accessed, information may be read from the respective portion.
      <br/>
      Alternatively, when a portion of the first or second memory regions is accessed, the information is written into the respective portion.
    </p>
    <p num="10">
      A register for storing a plurality of access requests may be provided, said access requests each including information as to the portion to be accessed and the memory region.
      <br/>
      This information may comprise address information.
      <br/>
      The register means may comprise a first-in-first-out register or may be any other suitable buffer.
      <br/>
      A detector for detecting the portion which is next to be accessed in each of the memory means may be provided.
      <br/>
      The detector may be arranged to receive from the register information as to the next portion which is to be accessed in each memory region.
      <br/>
      The detecting means may receive from the register, address information in respect of each request stored in the memory means.
    </p>
    <p num="11">A comparer may be provided for comparing the portion of a memory region which is currently selected with a portion of the memory region which is next to be accessed and outputting a signal based on the comparison.</p>
    <p num="12">
      The command provider may be arranged to process received requests in a nonsequential manner if a later request specifies the same memory location of a given memory region as an earlier request with intervening requests for said given memory region being processed after said later request.
      <br/>
      In this way, if, for example, a given page is open, a later request for that same page can be processed before a request for a different page is located.
      <br/>
      This reduces the number of times that a memory page needs to be opened and closed, thus increasing the cycle time of adjacent channels as small as possible.
    </p>
    <p num="13">According to a second aspect of the present invention, there is provided a method for accessing a memory comprising a plurality of memory regions, said method comprising the steps of: selecting a row of a first one of said memory regions; subsequently selecting or deselecting a row of a second one of said memory regions; and while the row of the second one of the memory regions is being selected or deselected, the row of the first one of the memory regions is accessed.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="14">
      For a better understanding of the present invention and as to how the same may be carried into effect, reference will now be made by way of example to the accompanying drawings in which:
      <br/>
      FIG. 1 is a schematic diagram of a known SDRAM;
      <br/>
      FIG. 2 illustrates the timing of the SDRAM of FIG. 1;
      <br/>
      FIG. 3 is a SDRAM with circuitry embodying the present invention;
      <br/>
      FIG. 4 illustrates the timing of the embodiment shown in FIG. 3;
      <br/>
      FIG. 5 illustrates a modified version of the circuitry shown in FIG. 2;
      <br/>
      FIG. 6 schematically shows a conventional integrated circuit device and three data storage devices to which the integrated circuit device may be connected;
      <br/>
      FIG. 7 shows an arrangement for connecting a Direct Rambus memory to a conventional integrated circuit;
      <br/>
      FIG. 8 shows instantaneous and average data transfer rates for a Direct Rambus memory;
      <br/>
      FIG. 9 shows a Direct Rambus connected to an integrated circuit via an interface;
      <br/>
      FIG. 10 schematically illustrates how the contents of the interface of FIG. 5 vary with time; and
      <br/>
      FIG. 11 shows a Direct Rambus connected to a number of integrated circuits via a number of interfaces of the type shown in FIG. 9.
    </p>
    <heading>DETAILED DESCRIPTION OF THE INVENTION</heading>
    <p num="15">
      Reference will now be made to FIG. 3 which illustrates a memory interface 22 embodying the present invention with a SDRAM 20.
      <br/>
      The memory interface 22 controls the accessing of the SDRAM 20.
      <br/>
      As with the SDRAM shown in FIG. 1, the SDRAM 20 comprises a first and a second memory bank 21a and 22b.
      <br/>
      Each memory bank 21a and 21b has a plurality of rows and columns which define memory locations.
      <br/>
      Each memory bank 21a and 21b is also provided with a row control unit 60 and a column control unit 58, similar to those described in relation to FIG. 1.
    </p>
    <p num="16">
      The memory interface 22 comprises a requester 24 which generates or receives requests to access particular locations in the SDRAM 20.
      <br/>
      In practice the requester 24 is a computer processing unit (CPU).
      <br/>
      Each request will identify the memory bank of the SDRAM 20, the row (page) and the column which are to be accessed.
      <br/>
      The requests output from the requester 24 are input to a FIFO (first in first out) buffer 26 where they are stored in the order in which they are received.
      <br/>
      The requests are output by the FIFO 26 in the same order in which they are received.
    </p>
    <p num="17">
      Each location of the FIFO 26 which stores an address provides an output 28 to a detection circuit 30.
      <br/>
      In the example shown in FIG. 3, the FIFO 26 is able to store nine different requests and accordingly the FIFO has nine outputs 28 which are connected to the detection circuit 30.
      <br/>
      The detection circuit 30 is arranged to detect which row (page) in the first bank 21a of the SDRAM 20 is next to be accessed as well as the next page which is to be accessed in the second bank 21b of the SDRAM 20.
      <br/>
      In the embodiment illustrated in FIG. 3, page N is the next page to be accessed in the second bank 21b whilst page J is the next page to be accessed in the first bank 21a.
      <br/>
      The detect circuit 30 will generally be a combinatorial logic circuit but can take any other suitable form.
    </p>
    <p num="18">
      The detect circuit 30 provides two outputs 32 and 34.
      <br/>
      The first output 32 contains information as to the next page to be accessed in the first bank 21a.
      <br/>
      The second output 34 contains information as to the next page to be accessed in second bank 21b.
      <br/>
      The first and second outputs 32 and 34 of the detect circuit 30 are connected to respective bank managers 36 and 38.
      <br/>
      The first bank manager 36, which receives the first output 32 from the detect circuit 30 also receives a second input 41 from a memory or buffer 40 which stores the current page which is currently open or selected in the first bank 21a.
      <br/>
      The first bank manager 36 thus compares the page of the first bank 21a which is currently open with the next page of the first bank 2la which is to be accessed.
      <br/>
      The first bank manager 36 thus determines the next action for the first bank 21a.
      <br/>
      If the current page which is open and next page which is to be accessed are the same, first bank manager 36 will indicate that the next action for the first bank 21a will be the accessing of the required location on the open page or alternatively provide no output.
      <br/>
      If the current page which is open and the page which is next to be accessed are not the same, the first bank manager 36 will provide an output 44 which indicates that the next action for the first bank 21a will be to close the page which is currently open and then to open the page which is next to be accessed.
    </p>
    <p num="19">
      In some circumstances, there will be no page which is currently open.
      <br/>
      The first bank manager 36 will still output the next action which is required at the first bank 21a.
      <br/>
      In a preferred embodiment of the present invention the first bank manager 36 is arranged to output one action at a time.
      <br/>
      For example, the first bank manager 36 is arranged to provide an output which indicates that a page is to be closed.
      <br/>
      The first bank manager 36 is arranged to provide a subsequent output indicating which page in the first bank 21a is to be opened.
      <br/>
      This subsequent instruction may, but not necessarily, be provided when the previous instruction has been completed or is likely to be completed shortly.
      <br/>
      In one embodiment of the present invention each instruction from the first bank manager 36 is output once.
      <br/>
      In other embodiments of the present invention, each instruction is output until that instruction is acknowledged.
    </p>
    <p num="20">
      The second bank manager 38 operates in a similar manner to the first bank manager 36.
      <br/>
      In particular, the second bank manager 38 receives the second output 34 from the detect circuit and an output 41 from a second memory 42 which stores information as to the page which is currently open in the second bank 21b.
      <br/>
      As with the first bank manager 36, the second bank manager 38 provides an output 46 which determines the next action for the second bank 21b.
    </p>
    <p num="21">
      The two outputs 44 and 46 from the first and second bank managers 36 and 38 are input to a multiplexer 48 along with the next request which has the next address which is to be accessed.
      <br/>
      The next request which is to be accessed is output from the FIFO 26 to the multiplexer 48.
      <br/>
      This next request is the oldest request stored in the FIFO 26.
      <br/>
      The operation of the multiplexer 48 is controlled by a multiplexer controller 50 which arbitrates between the outputs 44 and 46 of the first and second bank managers 36 and 38 and the request output from the FIFO 26.
      <br/>
      The multiplexer controller 50 receives an input from the FIFO 26 which provides the next request, an input from the first memory 40 as to which, if any, page is open in the first bank 21a and an input from the second memory 42 as to which, if any, page is currently open in the second bank 21b.
      <br/>
      Based on this information, the multiplexer controller 50 decides what action should be carried out in the next clock cycle and controls the multiplexer 48.
      <br/>
      Effectively the multiplexer controller 50 acts as an arbiter and provides a series of commands.
      <br/>
      Usually, but not necessarily, one command may be provided per clock cycle.
      <br/>
      An open or close page command may take priority over a read command so that one bank may have a page being opened/closed whilst the other bank is being read.
      <br/>
      However some commands may include the open and/or close page instruction within a single command with the read/write instructions.
      <br/>
      In other words, the multiplexer 48 provides a suitable multiplexed output of commands so that, for example, reading of one bank may take place whilst the other bank has a row which is being opened or closed.
    </p>
    <p num="22">
      The output of the multiplexer 48 is input to a memory logic device 56.
      <br/>
      The output of the multiplexer 48 constitutes the outputs of the memory interface 22.
      <br/>
      Based on the input, the memory logic device 56 will cause a row to be opened or closed or a location to be accessed (read or written to).
      <br/>
      The memory logic device 56 controls the row and column control units 58 and 60 in accordance with the output from the memory interface 22.
      <br/>
      The location can either be read or written to.
      <br/>
      The memory logic 56 acts as a command decoder and also generates the control logic.
    </p>
    <p num="23">
      Because of the detect circuit 30, it is possible to ensure that a row in one bank can be opened or closed at the same time that a row in the other bank is being read.
      <br/>
      This significantly reduces the number of cycles taken to complete operations.
      <br/>
      The column control units 58 control the accessing of columns of the respective banks.
      <br/>
      The row control units 60 control the selection and deselection of the rows of the first and second banks 21a and 21b.
    </p>
    <p num="24">
      The multiplexed output from the multiplexer 48 is received by the memory logic device 56.
      <br/>
      As discussed hereinbefore, the output of the multiplexer 48 consists of a series of commands which arc achieved by the memory logic device 56.
    </p>
    <p num="25">
      Reference is made to FIG. 4 which shows an example of the timing where two eight word bursts are accessed.
      <br/>
      Each burst comprises eight words which are located in the same row of the same memory bank.
      <br/>
      Each burst may be accessed by a single command.
      <br/>
      The single command may also include the close page instructions.
      <br/>
      The first and second bursts are located in different banks.
      <br/>
      For the purposes of illustration, it will be assumed that the first burst requires access to the first bank 21a and the second burst requires access to the second bank 21b.
      <br/>
      The first six cycles H are required in order to open the required page in the first memory bank 21a for the first word in the first burst.
      <br/>
      The first word and the first burst are also accessed at the same time.
      <br/>
      In the next seven cycles I, the remaining seven words of the first burst are accessed.
      <br/>
      At the same time that the row in the first bank 21a is being opened and subsequently read, the required row in the second bank 21b is also being opened, for example during the five cycles marked J.
    </p>
    <p num="26">Accordingly, when the first burst has been completely been accessed, the required row of the second bank 21b can be immediately accessed in order to access the eight words of the second burst, this occurring in the eight cycles marked L. At the same that the second burst is being accessed, the row of the first bank 21a from which the first word was accessed can be closed in the three cycles marked M. In the six cycles marked N, which occur at the same time as five of the cycles marked L in which the words of the second burst are read, the next required row in the first memory bank 21a is opened and the first word of a third burst is read.</p>
    <p num="27">
      Thus, the first two eight word bursts can be read in 21 cycles.
      <br/>
      This compares favourably with the 29 cycles required with the known SDRAM described in relation to FIG. 1.
      <br/>
      Additionally, any subsequent burst in this mode will only require eight cycles.
      <br/>
      With the conventional SDRAM described in relation to FIG. 1, any subsequent burst requires 16 cycles.
    </p>
    <p num="28">
      In preferred embodiments of the present invention, the two banks cannot be read from or written to at the same time.
      <br/>
      However reading or writing in one bank can take place at the same time that the other bank is having a page opened or closed.
    </p>
    <p num="29">
      Reference is made to FIG. 5 which shows a modified version of the present invention.
      <br/>
      Two requesters 100 and 102 in the form of CPU1 and CPU2 are provided.
      <br/>
      The requests from the requesters 100 and 102 are input into respective first and second FIFO buffers 104 and 106.
      <br/>
      These FIFO buffers are the same as FIFO 26 of FIG. 3.
      <br/>
      The output of the first and second FIFO buffers 104 and 106 are input to a common unit 108 which includes the remaining circuitry of the memory interface unit 22 of FIG. 3.
      <br/>
      The bank defect circuit (not shown), will thus look at the contents of both the first and second FIFOs 104 and 106 but will otherwise operate in a similar manner to that of FIG. 3.
      <br/>
      The first and second FIFOs 104 and 106 and the common unit 108 define a memory interface unit 110.
      <br/>
      The output of the common unit is input to the memory logic for a SDRAM 20.
    </p>
    <p num="30">
      In preferred embodiments of the present invention, a different format is used for addressing the SDRAM.
      <br/>
      In typical SDRAMs the address is defined by bank, row and column, with the bank part being the most important part of the address and the column being the least important part of the address.
      <br/>
      In other words, one bank will have locations 0 to n-1 whilst the second bank will have locations n to 2n-1.
      <br/>
      However, in preferred embodiments of the present invention, an address format of row, bank and column is used with the row being the most important part of the address.
      <br/>
      In other words, the first row of the first bank will contain addresses 0 to M-1 (where M is the number of columns) and the first row of the second bank will have address locations M to 2M-1.
      <br/>
      The next rows in the first and second banks will have the locations 2M to 4M-1 and so on.
      <br/>
      This means that when data is being written into the memory, the two banks are more likely to be equally used so that the advantages of embodiments of the present invention can be achieved.
    </p>
    <p num="31">
      The input may be arranged to receive an input from a requester which may be in the form of a computer processing unit.
      <br/>
      In a preferred embodiment of the present invention, the input is arranged to receive an input from a plurality of requesters.
      <br/>
      It is preferred that a respective register be provided for storing the requests from each requester.
    </p>
    <p num="32">
      It should be appreciated that whilst embodiments of the present invention have been described in relation to an SDRAM, an embodiment of the present invention is applicable to any other type of memory which has two separate banks or regions which cannot be accessed at the same time.
      <br/>
      Embodiments of the present invention can be used with, for example, other types of DRAM.
    </p>
    <p num="33">
      In the embodiment described hereinbefore, two banks are shown.
      <br/>
      However, it should be appreciated that any other suitable number of banks may be provided, for example four.
    </p>
    <p num="34">In the illustrated embodiment, the FIFO 26 can have any suitable number of locations.</p>
    <p num="35">
      In one modification to the embodiment of the present invention, the detect circuit 30 may be arranged to check that the FIFO 26 does not contain any more requests for an open page before closing that page.
      <br/>
      This may involve reordering of the requests and accordingly additional storage capacity may be required in order to ensure that the information read out of the memory banks is ultimately output in the same order in which the requests are made.
      <br/>
      The additional memory may be required to receive the output of the memory banks.
    </p>
    <p num="36">
      The SDRAM 20 itself may be of any suitable conventional design or may be specially modified to be used with the accessing device 22.
      <br/>
      Any other suitable memory device may be used with embodiments of the present invention.
    </p>
    <p num="37">
      In such systems as described hereinbefore which use integrated circuits, one of the areas which restricts the overall system performance is the rate of data transfer between the memory device and the internal bus of an operational circuit which accesses that memory.
      <br/>
      A number of memory devices have been recently introduced which have improved data transfer rates in comparison to conventional memory devices.
      <br/>
      For example, conventional SDRAM (synchronous dynamic random access memory) typically has a data transfer rate of 32 bits at 100 MHz.
      <br/>
      An improvement to this is double data rate (DDR) SDRAM which is capable of transferring double the data rate than a conventional SDRAM and hence has a data transfer rate of 32 bits at 200 MHz.
      <br/>
      There are also available memory devices known as Direct Rambus memories (RDRAM Rambus Dynamic Random Access Memory) which have a transfer rate of 16 bits at 800 MHz. `Rambus` and `Direct Rambus` are trade marks of Rambus Inc.
    </p>
    <p num="38">
      Presently conventional integrated circuits typically have an internal system bus with a data transfer rate of 32 bits at 100 MHz.
      <br/>
      FIG. 6 schematically illustrates a conventional integrated circuit 61 with an internal system bus 65 and three known memory devices, a conventional SDRAM 62, a double data rate SDRAM 63 and a Direct Rambus memory 64. (In practice only one of the three memory devices is provided).
      <br/>
      Each of the memory devices 62, 63 and 64 has an output bus which in use is coupled to the internal system bus 65 of the integrated circuit.
      <br/>
      The output bus 66 of the conventional SDRAM 62 has a data transfer rate of 32 bits at 100 MHz and is therefore entirely compatible with the internal bus 65 of the integrated circuit 61, which as shown, also has a data transfer rate of 32 bits at 100 MHz.
      <br/>
      However, the output bus 67 of the DDR SDRAM 63 has a data transfer rate of 32 bits at 200 MHz and the output bus 68 of the Direct Rambus memory 64 has a data transfer rate of 16 bits at 800 MHz.
      <br/>
      Accordingly the output buses 67 and 68 of the DDR SDRAM 63 and the Direct Rambus memory 64 are not compatible with the internal system bus 65 of the integrated circuit 61 in terms of data rate.
      <br/>
      Accordingly, with the existing conventional internal bus system of the integrated circuit, the higher data transfer rate of the DDR SDRAM and the Direct Rambus cannot be readily used.
    </p>
    <p num="39">
      To exploit the increased transfer rate of the faster memory devices, the width of the internal bus of the operational integrated circuit could be increased.
      <br/>
      For example, for a Direct Rambus memory with a transfer rate of 16 bits at 800 MHz, the internal bus of the operational integrated circuit would have to be increased to a 128 bit bus operating at 100 MHz.
      <br/>
      As this is four times the present conventional bus width the resulting integrated circuit would be much more complex and require increased effort in designing the layout of the interconnects within the integrated circuit and would also consume a much larger area of silicon.
      <br/>
      This is disadvantageous.
      <br/>
      FIG. 7 illustrates an example of a Direct Rambus 64 connected to an integrated circuit 61, the integrated circuit having an internal system bus 65 with a transfer rate of 128 bits at 100 MHz.
      <br/>
      At the interface between the Direct Rambus memory 64 and the integrated circuit 61, a demultiplexer 70 would be required to spread the short 16 bit words from the Direct Rambus onto the 128 bit wide internal bus of the integrated circuit.
      <br/>
      The addition of a demultiplexer 70 further increases the complexity and required silicon area of the integrated circuit.
    </p>
    <p num="40">
      The speed of the internal bus of the integrated circuit could be increased to match that of the memory device connected to it.
      <br/>
      However, this would require redesigning the integrated circuit and in practice, the internal buses of integrated circuits which represent the current state of the art already typically operate at a speed close to the current maximum possible speed.
    </p>
    <p num="41">It would therefore be desirable to provide an improved interface between data storage devices with a relatively high data transfer rate and the internal bus system of an integrated circuit operating with a relatively low data transfer which overcomes or at least mitigates against the problems described hereinbefore.</p>
    <p num="42">
      As described hereinbefore with reference to FIG. 2, in a conventional SDRAM, to retrieve 8 words of data, it takes 3 clock cycles to close a previous page, 6 cycles to open the next page and retrieve the first-word of data and a further 7 clock cycles to transfer the requested data from the memory.
      <br/>
      In a Direct Rambus memory device, the delay necessary to close a page and open a subsequent page is 9 cycles and the time taken to transfer the remaining data from the memory is a further 1 cycle.
    </p>
    <p num="43">
      Because of the delay required to close and open pages, the instantaneous data transfer from the memory device is not constant.
      <br/>
      FIG. 8 shows the variation of instantaneous data transfer from a Direct Rambus device with respect to time.
      <br/>
      The instantaneous data transfer rate is shown by the line I and it can be seen that the memory only in fact outputs data at a high transfer rate for short periods of time or bursts.
      <br/>
      One such period is referenced db in FIG. 8.
      <br/>
      The average data transfer rate over a longer period of time is shown by line II and is much lower than the peak data transfer rate of the memory device.
    </p>
    <p num="44">
      As stated hereinbefore, a Direct Rambus memory device requires a total of 10 cycles to output data from the memory which has been requested by the integrated circuit (3 cycles to close a page and 6 cycles to open a new page and retrieve the first data word and 1 cycle to retrieve the remaining data words).
      <br/>
      As the transfer rate of a Direct Rambus memory device is 16 bits at 800 MHz, the average rate of data transfer is 320 M bytes per second.
      <br/>
      An internal bus of an integrated circuit operating at 32 bits at 100 MHz is capable of sustaining a data transfer rate of 400 M bytes per second.
    </p>
    <p num="45">
      Reference is now made to FIG. 9 which shows a Direct Rambus 102 connected to an integrated circuit 103 via an interface 101, 106.
      <br/>
      To take advantage of the higher average data transfer rate of a conventional internal bus of a integrated circuit in comparison to the average data transfer rate of a Direct Rambus memory device, the interface 101, 106 is provided between the Direct Rambus 102 and the integrated circuit 103.
      <br/>
      This interface 101, 106 is capable of smoothing out the peaks in the instantaneous data transfer rate of the Direct Rambus and providing an output to the internal bus of the integrated circuit 103 which operates at least at the average data transfer rate of the Direct Rambus 102.
      <br/>
      It is preferred that the average data transfer rate of the Direct Rambus 102 be the same as the internal bus of the integrated circuit 103.
    </p>
    <p num="46">
      In FIG. 9, the Direct Rambus memory device 102 is connected to the internal bus of integrated circuit 103 via the interface 101, 106 which consists of a buffer 101 and a controller 106.
      <br/>
      Connected between the Direct Rambus 102 and the integrated circuit 103 is the buffer 101 and the interface controller 106.
      <br/>
      The controller 106 may comprise, but not necessarily, the memory interface 22 as described in FIG. 3, with buffer 101 replacing FIFO 26 and integrated 103 replacing the requestor 26.
      <br/>
      The buffer 101 has an input 110 and an output 112.
      <br/>
      Connected between the input 110 of the buffer 101 and the integrated circuit 103 is a first data bus 105a which has a transfer rate equal to that of the internal bus of the integrated circuit 103, i.e., 32 bits at 100 MHz.
      <br/>
      Also connected between the input 110 of the buffer 101 and the integrated circuit 103 is a first control line 118.
      <br/>
      Connected from the output 112 of the buffer 101 to the integrated circuit 103 is a second data bus 105b which has a transfer rate equal to the first data bus 105a.
      <br/>
      It will be appreciated that first and second data buses 105a and 105b in fact comprise the same data bus and are shown separately in FIG. 9 merely for the sake of convenience.
      <br/>
      Also connected between the output 112 of the buffer 101 and the integrated circuit 103 is a second control line 120.
    </p>
    <p num="47">
      Connected between the Direct Rambus 102 and the interface controller 106 is a third data bus 104.
      <br/>
      The third data bus 104 has a data transfer rate of 128 bits at 100 MHz which is equal to the peak instantaneous data transfer rate of the Direct Rambus.
      <br/>
      Also connected between the Direct Rambus 102 and the interface controller 106 is a third Direct Rambus control line 122.
      <br/>
      The interface controller 106 is connected to the buffer 101 by an interface bus 108.
      <br/>
      The interface bus 108 comprises a plurality of individual data transfer lines 1081, 108i, 108n.
      <br/>
      There are n data transfer lines provided where n is the number of storage locations within buffer 101.
    </p>
    <p num="48">
      The operation of the circuit shown in FIG. 9 will now be described.
      <br/>
      Beginning from the initial conditions of the buffer 101 being empty and the Direct Rambus 102 having all its pages closed, the integrated circuit 103 loads a memory request, MEM-REQ, into the buffer 110 via the first data bus 105a.
      <br/>
      The memory request M-REQ may be a request to access (read) data stored in the Direct Rambus memory 102 or it may be a request to write data to the Direct Rambus memory 102.
      <br/>
      If the memory request is a request to write data to the Direct Rambus memory 102, the data to be written is also loaded into the buffer 101 via the data bus 105a.
      <br/>
      Control signals for controlling the operation of the buffer 101 are also output from the integrated circuit 103 via the first control line 118.
    </p>
    <p num="49">
      The interface controller 106 scans the storage locations of the buffer 101 in turn, starting from the nth data storage location and when a data storage location is scanned which contains a memory request the memory request is output from the buffer 101 via the corresponding data transfer line to the interface controller 106.
      <br/>
      The interface controller 106 scans a number of data storage locations within buffer 101 and multiplexes the memory request signals and any corresponding data onto the third data bus 104 such that the memory requests are input to the Direct Rambus 102.
      <br/>
      The Direct Rambus 102 now begins the action of opening a page in the memory array in order to supply the requested data or to write the supplied data in the relevant memory location.
      <br/>
      As previously discussed, there is a delay of 6 cycles while the page is opened before any data can be output from the Direct Rambus 102.
      <br/>
      During this delay, the integrated circuit 103 may be outputting further memory requests to the buffer 101.
      <br/>
      These further memory requests are stored in the buffer 101 during the delay period which occurs while the Direct Rambus 102 is opening the page associated with the first memory request.
    </p>
    <p num="50">
      When the Direct Rambus 102 has opened the page associated with the first memory request, if that memory request is a request to access data from the Direct Rambus, the requested data is then transferred from the Direct Rambus 102 via the third data bus 104 to the interface controller 106.
      <br/>
      Control signals associated with controlling the input and output from the Direct Rambus 102 are passed between the Direct Rambus 102 and the interface controller 106 by the third control line 122.
      <br/>
      The interface controller 106 demultiplexes the data received from the Direct Rambus 102 and inputs it via data transfer lines 108i to empty data storage locations within buffer 101.
      <br/>
      The interface controller 106 then scans the data storage locations within the buffer 101 for the next memory requests which are to be served.
      <br/>
      The data accessed from the Direct Rambus 102 in response to a memory request received from the integrated circuit 103 via the interface controller 106 and buffer 101, is passed through the buffer 101 and output at output 112 to the integrated circuit 103 via the second data bus 105b, together with associated control signals via the second control line 120.
    </p>
    <p num="51">
      The buffer 101 serves two functions.
      <br/>
      Firstly, it is able to buffer the memory requests from the integrated circuit 103 to the Direct Rambus 102, allowing the integrated circuit to output a number of memory requests without having to wait for each of those requests to be served by the Direct Rambus 102 before outputting subsequent requests.
      <br/>
      Secondly, the buffer 101 is able to buffer the data supplied from the Direct Rambus 102 before it is transmitted to the integrated circuit 103.
      <br/>
      Preferably, the buffer 101 should always have space available to store the accessed data from the Direct Rambus 102 thus enabling the Direct Rambus 102 to always output data at its maximum speed of 16 bits at 800 MHz.
    </p>
    <p num="52">
      To calculate the required size of the buffer it is assumed that the integrated circuit 103 will output ICY consecutive memory requests.
      <br/>
      The Direct Rambus 102 will see these as MemY accesses, as MemY=ICY (integrated circuit internal bus width / Direct Rambus internal bus width).
      <br/>
      It is assumed that all of the memory requests are in the same page in the Direct Rambus 102.
      <br/>
      The Direct Rambus 102 can process MemY-1 memory requests in MemY-1 cycles.
      <br/>
      During the same time, the integrated circuit 103 can issue X memory requests, where
    </p>
    <p num="53">X=MemY-1 (Direct Rambus bus width / ic bus width)</p>
    <p num="54">Approximating MemY-1 to MemY we have buffer size (in memory word units)</p>
    <p num="55">=MemY-X</p>
    <p num="56">=MemY (1- (icclk * 1cwd))/(memclk memwd))</p>
    <p num="57">where iclk=integrated circuit clock speed, mem clk=Direct Rambus clock speed, icwd=integrated circuit internal bus width, and memwd =Direct Rambus internal bus width.</p>
    <p num="58">
      FIG. 10 demonstrates the behaviour of the buffer when the size of the buffer has been correctly chosen.
      <br/>
      Line A represents the number of memory requests stored in the buffer which are yet to be processed by the memory and line B represents the number of memory requests which have been processed by the memory with the associated data being stored in the buffer.
      <br/>
      The distance between lines A and B represents the total amount of data stored in the buffer.
      <br/>
      Initially line A rises sharply over the time period top as the buffer stores an increasing number of memory requests from the integrated circuit.
      <br/>
      This initial sharp rise occurs during the delay caused by the memory opening the required page of the first memory request.
      <br/>
      Once the required page has been opened, the memory is able to output the requested data to the buffer and begin to process the next memory request stored in the buffer.
      <br/>
      If subsequent memory requests require the same page which is currently open, a number of bursts of requested data may be output to the buffer.
      <br/>
      This line A begins to fall as the number of memory requests in the buffer falls, and line B begins to fall, representing an increase in the amount of data stored in the buffer.
      <br/>
      This is indicated on FIG. 6 by the period tserv.
    </p>
    <p num="59">
      At a subsequent point in time, point c, it will be necessary to close the currently open page and open a new page in the memory, causing the delay in outputting data from the memory as previously discussed.
      <br/>
      The memory is said, at this point, to be `stalled`. Whilst the memory is stalled lines A and B rise again as the number of memory requests stored in the buffer once again rises and the amount of data stored in the buffer from the memory decreases.
      <br/>
      This is shown by the period tstall.
      <br/>
      This action continues over time with lines A and B rising and falling together.
      <br/>
      It can be seen that the distance between lines A and B which represents the total amount of data contained within the buffer remains approximately constant.
    </p>
    <p num="60">
      The circuitry described hereinbefore operates particularly advantageously when memory requests are issued by the integrated circuit 103 in short bursts.
      <br/>
      When this occurs data stored in the buffer in response to memory requests can always be output to the integrated circuit 103 at the same time that the Direct Rambus 102 is stalled during the opening of a further page in the memory.
      <br/>
      If the number of memory requests issued by the integrated circuit 103 at any one time is too large then when those requests are served by the Direct Rambus 102 the average rate of data transfer will increase to a value which is in excess of the transfer rate of the internal bus within the integrated circuit 103 and the Direct Rambus 102 will be forced to wait for previously served memory requests to be delivered to the integrated circuit before the Direct Rambus can output any further data.
      <br/>
      However, this occasional loss in performance may not be fatal to the operation of the integrated circuit, it will be more cost effective in terms of design effort and silicon area consumed to use the buffering arrangement of embodiments of the present invention.
    </p>
    <p num="61">
      A further example of improved interface described hereinbefore is shown in FIG. 11. In this example a number of buffers 201a, 201b, 201c are connected via a demultiplexer 130 to the output of a Direct Rambus 202.
      <br/>
      Each of the buffers 201a, 201b and 201c are of the same type as the buffer 101 shown in FIG. 9 and described hereinbefore.
      <br/>
      Each of the integrated circuits is of the same type as integrated circuit 103 shown in FIG. 9.
      <br/>
      Each buffer is connected to the internal bus of an integrated circuit 203a, 203b, 203c, each of the internal buses having a lower peak data transfer rate than that of the Direct Rambus 202.
      <br/>
      Each of the integrated circuits may have a different function from each other and may thus make different memory requests to the Direct Rambus 202 at different times.
      <br/>
      The Direct Rambus 202 provides the data in response to these requests and outputs the data to the multiplexer 130 which is arranged to route the data to whichever of the buffers 201a, 201b or 201c issued the memory requests.
      <br/>
      In this example, by providing a number of buffers connected to the Direct Rambus 202 a higher maximum average data transfer rate from the Direct Rambus can be achieved as the data output from the memory is stored in a number of different buffers.
      <br/>
      If, as shown, the number of buffers provided is 3, then this allows 3 times the maximum average data transfer rate from the Direct Rambus before the Direct Rambus is forced to wait for the slower internal buses of the integrated circuit to retrieve the stored memory data from the relevant buffers.
    </p>
    <p num="62">
      It should be appreciated that in embodiments of the present invention, it is not necessary that when one memory region is being accessed that the other memory region have a portion thereof being selected or deselected.
      <br/>
      Rather, embodiments of the present invention are particularly applicable to situations where the instructions occur in an order such that it is possible that one memory region can be accessed whilst a portion of the other memory region is being selected or deselected.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A memory interface device for generating a plurality of commands for controlling a memory having first and second memory regions, only one of said memory regions being accessible at a time, each memory region comprising a plurality of rows, said device comprising:</claim-text>
      <claim-text>a buffer for storing a plurality of received memory requests for said memory, said memory requests each including information as to the row to be accessed of said respective memory region, and said buffer arranged to provide a respective output for each memory request, each of said outputs indicating said row to be accessed for the respective memory request; a detector arranged to receive said plurality of outputs from said buffer and to detect a next different row in each of said memory regions to be subsequently selected, said detector providing an output signal indicative of said detected next different row for each of said memory regions;</claim-text>
      <claim-text>and a command provider for providing a sequence of commands in response to said received memory requests and said output signals provided by said detector for controlling said memory, said command sequence being arranged so that a row of one of the first and second memory regions is accessed while said detected next different row of the other of the first and second memory regions is being selected.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. A device as claimed in claim 1, wherein said detector receives at least two said outputs from said buffer, said at least two outputs corresponding to at least one of said memory regions.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. A device as claimed in claim 1, wherein said outputs provided from said buffer are equal in number to said plurality of memory requests stored in said buffer.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. A device as claimed in claim 1, wherein when said row of the first or the second memory regions is accessed, infonnation is read from said row.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. A device as claimed in claim 1, wherein when said row of the first or second memory regions is accessed, information is written into said row.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. A device as claimed in claim 1, wherein said buffer comprises a first in first out register.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. A device as claimed in claim 6, wherein said register also stores data from said memory, said register comprising output means for outputting request signals and said stored data from the memory to a requesting device.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. A device as claimed in claim 7, wherein said requesting device is an operational circuit.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. A device as claimed in claim 8, wherein a first data bus is provided between the operational circuit and the register and a second data bus is provided between the memory interface device and the memory, the maximum data transfer rate of the first bus being different to that of the second bus.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. A device as claimed in claim 1, wherein a comparer is provided for comparing the row of a memory region which is currently selected with the row of that memory region which is next to be accessed and outputting a signal based on said comparison.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. A device as claimed in claim 10, wherein a respective comparer is provided for each memory region.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. A device as claimed in claim 1, wherein an output is provided for outputting said commands to said memory.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. A device as claimed in claim 1, wherein said buffer is arranged to receive said memory requests from a requester.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. A device as claimed in claim 13, wherein said requester is a computer processing unit.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. A device as claimed in claim 13, wherein said buffer is arranged to receive said memory requests from a plurality of requesters.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. A device as claimed in claim 15, wherein a respective register is provided for storing requests for each requester.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. A device as claimed in claim 1, wherein said command provider is arranged to process received requests in a nonsequential manner if a later request specifies the same memory location of a given memory region as an earlier request, with intervening requests for said given memory region being processed after said later request.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. In combination, a device as claimed in claim 1 and a memory comprising a plurality of memory regions.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. A combination as claimed in claim 18, wherein said memory is a dynamic random access memory.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. A combination as claimed in claim 18, wherein said memory comprises a synchronous dynamic random access memory.</claim-text>
    </claim>
    <claim num="21">
      <claim-text>21. A device as claimed in claim 13, wherein said memory regions are arranged so that row n of the first memory region contains address x to x+y where y+1 is the number of locations in said row and row n of the second memory region contains address x+y+1 to x+2y+1.</claim-text>
    </claim>
    <claim num="22">
      <claim-text>22. A method for accessing a memory comprising a plurality of memory regions, said method comprising the steps of: selecting a row of a first one of said memory regions; subsequently selecting or deselecting a row of a second one of said memory regions;</claim-text>
      <claim-text>and while the row of the second one of the memory regions is being selected or deselected, the row of the first one of the memory regions is accessed.</claim-text>
    </claim>
  </claims>
</questel-patent-document>