<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06182200B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06182200</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6182200</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="46256864" extended-family-id="42072781">
      <document-id>
        <country>US</country>
        <doc-number>09470702</doc-number>
        <kind>A</kind>
        <date>19991223</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1999US-09470702</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>43115954</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>47070299</doc-number>
        <kind>A</kind>
        <date>19991223</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1999US-09470702</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>US</country>
        <doc-number>93547897</doc-number>
        <kind>A</kind>
        <date>19970924</date>
        <priority-linkage-type>2</priority-linkage-type>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1997US-08935478</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G06F   3/06        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>3</main-group>
        <subgroup>06</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G11B  27/034       20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>27</main-group>
        <subgroup>034</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>G11B  27/10        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>27</main-group>
        <subgroup>10</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>711165000</text>
        <class>711</class>
        <subclass>165000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>704278000</text>
        <class>704</class>
        <subclass>278000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>707999202</text>
        <class>707</class>
        <subclass>999202</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>707999206</text>
        <class>707</class>
        <subclass>999206</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>710006000</text>
        <class>710</class>
        <subclass>006000</subclass>
      </further-classification>
      <further-classification sequence="5">
        <text>710024000</text>
        <class>710</class>
        <subclass>024000</subclass>
      </further-classification>
      <further-classification sequence="6">
        <text>710030000</text>
        <class>710</class>
        <subclass>030000</subclass>
      </further-classification>
      <further-classification sequence="7">
        <text>710052000</text>
        <class>710</class>
        <subclass>052000</subclass>
      </further-classification>
      <further-classification sequence="8">
        <text>711004000</text>
        <class>711</class>
        <subclass>004000</subclass>
      </further-classification>
      <further-classification sequence="9">
        <text>711171000</text>
        <class>711</class>
        <subclass>171000</subclass>
      </further-classification>
      <further-classification sequence="10">
        <text>718102000</text>
        <class>718</class>
        <subclass>102000</subclass>
      </further-classification>
      <further-classification sequence="11">
        <text>G9B027012</text>
        <class>G9B</class>
        <subclass>027012</subclass>
      </further-classification>
      <further-classification sequence="12">
        <text>G9B027019</text>
        <class>G9B</class>
        <subclass>027019</subclass>
      </further-classification>
    </classification-national>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G11B-027/034</classification-symbol>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>27</main-group>
        <subgroup>034</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06F-003/0613</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>3</main-group>
        <subgroup>0613</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06F-003/0656</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>3</main-group>
        <subgroup>0656</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06F-003/0674</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>3</main-group>
        <subgroup>0674</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G11B-027/105</classification-symbol>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>27</main-group>
        <subgroup>105</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="6">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G11B-2220/20</classification-symbol>
        <section>G</section>
        <class>11</class>
        <subclass>B</subclass>
        <main-group>2220</main-group>
        <subgroup>20</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130823</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="7">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>Y10S-707/99953</classification-symbol>
        <section>Y</section>
        <class>10</class>
        <subclass>S</subclass>
        <main-group>707</main-group>
        <subgroup>99953</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130518</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="8">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>Y10S-707/99957</classification-symbol>
        <section>Y</section>
        <class>10</class>
        <subclass>S</subclass>
        <main-group>707</main-group>
        <subgroup>99957</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130518</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>18</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>5</number-of-drawing-sheets>
      <number-of-figures>5</number-of-figures>
      <image-key data-format="questel">US6182200</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Dense edit re-recording to reduce file fragmentation</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>PENN STEVEN C, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4868687</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4868687</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>NILSEN KELVIN D, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5560003</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5560003</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>JERNIGAN IV RICHARD P, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5574907</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5574907</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>WELLS STEVEN, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5740395</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5740395</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>YANKOWSKI CARL J</text>
          <document-id>
            <country>US</country>
            <doc-number>5751672</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5751672</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>DAVY WILLIAM</text>
          <document-id>
            <country>US</country>
            <doc-number>5808821</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5808821</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>MAEDA YASUAKI</text>
          <document-id>
            <country>US</country>
            <doc-number>5829050</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5829050</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>LOWE DAVID A</text>
          <document-id>
            <country>US</country>
            <doc-number>6070172</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US6070172</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <related-documents>
      <continuation-in-part>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>93547897</doc-number>
              <kind>A</kind>
              <date>19970924</date>
            </document-id>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>6047360</doc-number>
              <kind>A</kind>
            </document-id>
          </parent-doc>
        </relation>
      </continuation-in-part>
    </related-documents>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Sony Corporation</orgname>
            <address>
              <address-1>Tokyo, JP</address-1>
              <city>Tokyo</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
        <applicant data-format="original" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>Sony Electronics, Inc.</orgname>
            <address>
              <address-1>Park Ridge, NJ, US</address-1>
              <city>Park Ridge</city>
              <state>NJ</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="3">
          <addressbook lang="en">
            <orgname>SONY</orgname>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="4">
          <addressbook lang="en">
            <orgname>SONY ELECTRONICS</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Duvall, Roger Mather</name>
            <address>
              <address-1>Garden Grove, CA, US</address-1>
              <city>Garden Grove</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Claar, Jeffrey Mark</name>
            <address>
              <address-1>Aliso Viejo, CA, US</address-1>
              <city>Aliso Viejo</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Blakely, Sokoloff, Taylor &amp; Zafman LLP</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Nguyen, Hiep T.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>LAPSED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      The present invention is a method and apparatus for re-recording audio events.
      <br/>
      Scattered audio events on a first track are determined based on a linked list.
      <br/>
      The scattered audio events are merged into a combined audio event on a second track.
      <br/>
      The combined audio event is copied on the second track to the first track.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>CROSS-REFERENCES TO RELATED APPLICATIONS</heading>
    <p num="1">
      This is a Continuation-in-Part of U.S. patent application Ser.
      <br/>
      No. 08/935,478 which was filed Sep. 24, 1997 now U.S. Pat. No. 6,047,360 and is owned by Assignee of the present Application.
    </p>
    <heading>BACKGROUND</heading>
    <p num="2">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="3">
      The present invention is related to recording.
      <br/>
      In particular, the present invention is related to dense edit re-recording.
    </p>
    <p num="4">2. Description of Related Art</p>
    <p num="5">
      During editing, a track of audio may consist of a few large or many small sequential audio segments (events).
      <br/>
      These sequential sections are stored onto recording media, e.g., hard disk, in a random order depending on the particular file allocation at the time.
      <br/>
      When there are many small sequential edited segments, these segments are scattered over the entire disk.
      <br/>
      During playback, the seek time for these scattered sections increases because of their random location on the disk.
      <br/>
      The system therefore cannot provide real-time audio during playback.
    </p>
    <p num="6">
      There are several conventional approaches to the above problem.
      <br/>
      One approach is merely not to play audio if disk access cannot be completed.
      <br/>
      This approach leads to random drop-outs in the audio, resulting in unacceptable quality.
      <br/>
      Another approach is to limit the size of the sections during edit so that small edits will never occur.
      <br/>
      This approach severely limits the usability of the system.
      <br/>
      A third approach is to re-record the affected area to combine the small events into one recording.
      <br/>
      This approach requires a real-time copy of the audio, leading to unacceptable delays in the recording process.
    </p>
    <p num="7">Accordingly, there is a need in the technology to provide an efficient dense edit to reduce playback file access time.</p>
    <heading>SUMMARY</heading>
    <p num="8">
      The present invention is a method and apparatus for re-recording audio events.
      <br/>
      Scattered audio events on a first track are determined based on a linked list.
      <br/>
      The scattered audio events are merged into a combined audio event on a second track.
      <br/>
      The combined audio event is copied on the second track to the first track.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="9">
      The features and advantages of the present invention will become apparent from the following detailed description of the present invention in which:
      <br/>
      FIG. 1 is a block diagram illustrating an audio system that operates in accordance with the teachings of the present invention.
      <br/>
      FIG. 2 is a diagram illustrating an embedded box in the audio system according to one embodiment of the present invention.
      <br/>
      FIG. 3 is a diagram illustrating a process of dense edit via re-recording according to one embodiment of the present invention.
      <br/>
      FIG. 4 is a diagram illustrating a linked list used in the re-recording according to one embodiment of the present invention.
      <br/>
      FIG. 5 is a flowchart illustrating a process for re-recording according to one embodiment of the present invention.
    </p>
    <heading>DESCRIPTION</heading>
    <p num="10">
      The present invention is a method and apparatus to re-record audio events.
      <br/>
      Scattered audio events on a first track are determined based on a linked list.
      <br/>
      The scattered audio events are merged into a combined audio event on a second track.
      <br/>
      The combined audio event is copied on the second track to the first track.
    </p>
    <p num="11">
      In the following description, numerous specific details are set forth in order to provide a thorough understanding of the present invention.
      <br/>
      It will be apparent, however, to one of ordinary skill in the art that the present invention may be practiced without these specific details.
      <br/>
      In other instances, well-known architectures, steps, and techniques have not been shown where unnecessary for an understanding of the present invention.
      <br/>
      For example, specific details are not provided as to whether the method is implemented in a station as a software routine, hardware circuit, firmware, or a combination thereof.
    </p>
    <p num="12">
      Embodiments of the invention may be represented as a software product having program code segments to perform the necessary tasks corresponding to the elements of the present invention.
      <br/>
      The program or code segments can be stored in a processor readable medium or transmitted by a computer data signal embodied in a carrier wave, or a signal modulated by a carrier, over a transmission medium.
      <br/>
      The processor or machine readable medium may include any medium that can store or transfer information.
      <br/>
      Examples of the processor readable medium include an electronic circuit, a semiconductor memory device, a ROM, a flash memory, an erasable ROM (EROM), a floppy diskette, a compact disk CD-ROM, an optical disk, a hard disk, a fiber optic medium, a radio frequency (RF) link, etc.
      <br/>
      The processor or machine readable medium may contain various sets of instructions, code sequences, configuration information, or other data.
      <br/>
      Those of ordinary skill in the art will appreciate that other instructions and operations necessary to implement the described invention may also be stored on the machine-readable medium.
      <br/>
      The computer data signal may include any signal that can propagate over a transmission medium such as electronic network channels, optical fibers, air, electromagnetic, RF links, etc.
      <br/>
      The code segments may be downloaded via computer networks such as the Internet, Intranet, etc.
    </p>
    <p num="13">
      FIG. 1 is a block diagram illustrating an audio system 100 that operates in accordance with the teachings of the present invention.
      <br/>
      The system 100 comprises embedded boxes (EBX) EBX1 through EBXN 1101 through 110N ("N" being a whole positive number), K remote client computers (RCCs) 1201 through 120K ("K" being a positive whole number), network channel 115, audio engineering society (AES) standard input/output channels 125, and synchronizing clock 130.
    </p>
    <p num="14">
      Each of the EBX 1101 through 110N is an audio signal processing system with mass storage.
      <br/>
      In one embodiment, each EBX consists of a personal computer (PC) system and one or more digital signal processors (DSPs).
      <br/>
      Other configurations that provide similar functionalities are also contemplated.
      <br/>
      Audio sampled data are stored in multiple dynamic random access memory (DRAM) banks.
      <br/>
      These DRAM banks are accessible to both the host processor of the PC and the DSPs.
      <br/>
      The details of the EBX architecture will be discussed later.
    </p>
    <p num="15">
      Each of the RCC's 1201 through 120K provides graphical user interface (GUI) to users for sending command and control information to the EBXes 1101 through 110N over the network channel 115.
      <br/>
      Each RCC has two modes of communication to the EBXes: individual addressing and broadcasting.
      <br/>
      In individual addressing, the RCC issues the command/control information to the specified EBX.
      <br/>
      The individual address of the destination is encoded as part of the command/control information.
    </p>
    <p num="16">
      The AES I/O channels 125 consist of 16 audio I/O channels per EBX conforming to the AES standard.
      <br/>
      The standard is AES 3-1992 and is available from the Audio Engineering Society, Inc., located in New York, New York.
      <br/>
      The synchronizing clock 130 provides a master timing signal for synchronizing all real-time activities of the EBXes 1101 through 110N.
    </p>
    <p num="17">
      FIG. 2 is a diagram illustrating an embedded box (EBX) 110 in the audio system according to one embodiment of the present invention.
      <br/>
      The EBX 110 comprises one or more processors 2051 -205M ("M" being a positive whole number), a host bus 210, a host bridge chipset 220, a main memory element 230, a peripheral bus 235, a signal processing subsystem 240, a serial interface 250, an audio interface 260, an audio player 262, an audio recorder 264, a disk controller 270, and K (where "K" is a positive whole number) peripheral devices 2801 to 280K.
    </p>
    <p num="18">
      Processors 2051 -205M are any microprocessors.
      <br/>
      In this embodiment, processors 2051 -205N are the Pentium.RTM. or Pentium Pro.RTM. microprocessors manufactured by Intel Corporation at Santa Clara, California.
      <br/>
      The host bus 210 is a bus that can support transactions to a number of connected processors.
      <br/>
      Host bus 210 may be referred to as a parallel bus or multiprocessor bus because it supports parallel operations and multiple processors.
      <br/>
      It is contemplated that host bus 210 operates in a pipelined manner to increase efficiency.
      <br/>
      However, these features should not be construed to limit the teachings of the present invention.
      <br/>
      The present invention can be utilized even if there is only one processor connected to the host bus 210, or the host bus 210 is a uni-processor bus.
    </p>
    <p num="19">
      The host bridge chipset 220 is coupled to the host bus 210 to provide interface between the host processors 2051 -205M and the memory 230 and the peripheral bus 235.
      <br/>
      In general, the chipset 220 operates as an interface between a host bus 210 and a peripheral bus 235.
      <br/>
      Chipset 220 typically includes cache DRAM controller (CDC), peripheral bus controller, and data path unit (DPU).
      <br/>
      The Peripheral Component Interconnect (PCI) Bridge (PB) provides a set of host-to-PCI and PCI-to-host bus transaction translations.
      <br/>
      The memory 230 is the memory accessed by the host processors 2051 -205M and other processors coupled to the peripheral bus 235.
      <br/>
      The memory 230 may include dynamic random access memory (DRAM), static random access memory (SRAM), flash memory, read-only memory (ROM), or any other storage media.
      <br/>
      The memory 230 includes program code and data for the dense edit, including a re-recording module 238.
      <br/>
      The re-recording module 238 includes functions, programs, subroutines to perform tasks such as control, communication, play back, recording, and re-recording.
      <br/>
      The re-recording module 238 may be downloaded from a storage medium or transferred via a communication channel.
      <br/>
      The re-recording module 238 may contain computer readable program code for determining scattered audio events on a first track based on a linked list, computer readable program code for merging the scattered audio events into a combined audio event on a second track, and computer readable program code for copying the combined audio event on the second track to the first track.
      <br/>
      In addition, the re-recording module 238 may include computer readable program code for identifying the elements of the linked list having the corresponding sizes less than a predetermined threshold.
      <br/>
      The computer readable program code for merging the scattered audio events may include computer readable program code for allocating the second track based on the identified elements.
    </p>
    <p num="20">
      The peripheral bus 235 provides a communication path between the processors 2051 -205M or main memory element 230 and a plurality of peripheral devices 2801 -280K ("K" being a positive whole number).
      <br/>
      These peripheral devices 2801 -280K may include I/O devices such as disk controller, local area network (LAN) card.
      <br/>
      The disk controller 270 is a small computer system interface (SCSI)-2 controller which is interfaced to a number of mass storage devices such as optical read/write drive 272 and hard drive 274, through the SCSI-2 bus.
    </p>
    <p num="21">
      The signal processing subsystem (SPS) 240 includes digital signal processors (DSPs) 245, a memory 247, and other devices such as PCI bus interface circuits.
      <br/>
      The memory 247 stores program code and data for the dense edit including buffers containing the audio data that has been read from disk or are waiting to be recorded into.
      <br/>
      The memory 247 may include playback and recording module 248.
      <br/>
      The playback and recording module 248 may contain computer readable program code for playing back the audio events in the identified elements from the first track, and computer readable program code for recording the played back audio events to the second track to form the combined audio event.
    </p>
    <p num="22">
      The SPS 240 has interface to the serial input/output communication device 250 which is connected to the AES I/O channel interface 260.
      <br/>
      The peripheral bus 235 may include a Peripheral Component Interconnect (PCI) bus or any other type of bus architecture.
    </p>
    <p num="23">
      Other buses may be coupled to the peripheral bus 235 via appropriate chipsets or interface circuits.
      <br/>
      Examples of these buses include an Industry Standard Architecture (ISA) bus or an Extended Industry Standard Architecture (EISA) bus.
    </p>
    <p num="24">
      During recording, the EBX 110 write the audio data from the AES audio channels on a mass storage medium The stored data are then organized for efficient access.
      <br/>
      The organization can be performed by any one of the processors 2051 through 205M.
    </p>
    <p num="25">
      FIG. 3 is a diagram illustrating a process of dense edit via re-recording according to one embodiment of the present invention.
      <br/>
      The organization involves a sequence of events 310, a first track 320, a second track 330, and a re-recorded first track 340.
    </p>
    <p num="26">
      The sequence of recording events 310 includes a number of recording events.
      <br/>
      Each recording event corresponds to an audio segment.
      <br/>
      The length of the audio segments helps to determine if data re-organization or dense editing is necessary.
      <br/>
      If the lengths of the segments are too short, disk fragmentation is likely to result and data re-organization is necessary.
      <br/>
      In one embodiment, if two or more segments are less than one second in length, and have less than one second of silence between them, then they will be combined or re-organized because scattered events are likely to occur.
      <br/>
      If the lengths are sufficiently long, no data re-organization or combining is necessary.
      <br/>
      In one embodiment, a segment length of one second or above is considered sufficiently long and therefore is not marked for re-organization or combining.
      <br/>
      To keep track of this information, a linked list is created and information about the audio segments is stored in this linked list for later determination.
      <br/>
      The linked list will be described later.
    </p>
    <p num="27">
      In this illustrative example, the sequence 310 includes four small events A, B, C, and D of different sizes.
      <br/>
      During recording, these events are written onto the first track 320.
      <br/>
      Due to disk allocation, the audio events A, B, C, and D are scattered on the first track 320.
      <br/>
      A linked list keeps information about the audio events A, B, C, and D including the sizes of the events.
      <br/>
      From the linked list, it is determined that the audio events A, B, C, and D are small and scattered and need to be merged or combined into a large event.
      <br/>
      Using the information from the linked list, a second track 330 is allocated.
    </p>
    <p num="28">
      The audio events A, B, C, and D are then played back and re-recorded onto the second track 330.
      <br/>
      During the re-recording, the audio events are re-organized and merged into a contiguous sequence of events to restore the same sequence as in the original sequence 310.
      <br/>
      After re-recording, the contiguous event on the second track 330 is copied onto the first track 340.
      <br/>
      The first track 340 now contains the contiguous sequence of audio events A, B, C, and D.
    </p>
    <p num="29">
      FIG. 4 is a diagram illustrating a linked list used in the re-recording according to one embodiment of the present invention.
      <br/>
      The linked list 400 includes K elements 4101 through 410K.
      <br/>
      The K elements 4101 through 410K represent the data structure that store information on the audio segments 1 through K.
    </p>
    <p num="30">
      Element 4101 has at least three fields: field 4201 is the label A which is the label of the audio data segment A, field 4301 is the size of the audio data segment A, and field 4401 is the link field that points to the next element, element 4102.
      <br/>
      Additional fields may be included as attributes to the corresponding audio segments such as type (e.g., sound, silence).
    </p>
    <p num="31">
      Similarly, elements 4102 through 410K have at least three fields: fields 4202 through 420K represent the labels for the corresponding audio data segments, fields 4302 through 430K represent the sizes of the corresponding audio data segments, and fields 4302 through 430K represent the link fields.
      <br/>
      Additional fields may be included as attributes to the corresponding audio segments such as type (e.g., sound, silence).
    </p>
    <p num="32">For element 410K, the link field 440K is the terminating field.</p>
    <p num="33">
      The size of the audio data segment can be represented by the number of samples, the number of bytes of memory that stores the segment, or the time interval of the audio segment.
      <br/>
      The size field is one attribute that is used by the system to determine if there is disk fragmentation.
      <br/>
      Other attributes include the nature or type of the sequence of the audio segments (e.g., sound or silence).
    </p>
    <p num="34">FIG. 5 is a flowchart illustrating a process 500 for re-recording according to one embodiment of the present invention.</p>
    <p num="35">
      At START, the process 500 records the audio events in real-time, as these events are processed by the signal processing subsystem, onto the first track in a mass storage (Block 510).
      <br/>
      The process 500 then updates the linked list (Block 520).
      <br/>
      The linked list is a data structure that contains information about the recording events.
      <br/>
      This information includes the length of the audio segments, or alternatively, the number of samples of each segment.
      <br/>
      Next the process 500 scans the linked list to examine the fields of the linked list (Block 530).
    </p>
    <p num="36">
      Next, the process 500 determines if there are any scattered events on the first track (Block 535).
      <br/>
      The determination is based on the contents of the linked list.
      <br/>
      For example, the size fields of the linked list may be compared with a threshold value.
      <br/>
      If the size of the recorded event is less than a predetermined value, it is inferred that the event is sufficiently small that should be merged with other events to form a combined large event.
      <br/>
      Then, the process 500 allocates a second track having sufficient available space to store the identified scattered events (Block 540).
    </p>
    <p num="37">
      Next, the process 500 plays back the scattered events from the first track (Block 550).
      <br/>
      Then, the process 500 re-records the played back scattered events onto the allocated second track to form a combined contiguous audio event (Block 560).
      <br/>
      Then, the process 500 is terminated.
    </p>
    <p num="38">
      The present invention thus provides efficient dense edit for scattered small audio events.
      <br/>
      The technique uses a linked list to identify the scattered events and re-records these identified scattered events into a combined contiguous large event.
      <br/>
      The technique reduces seek time during real-time playback and provides efficient utilization of disk space.
    </p>
    <p num="39">
      While this invention has been described with reference to illustrative embodiments, this description is not intended to be construed in a limiting sense.
      <br/>
      Various modifications of the illustrative embodiments, as well as other embodiments of the invention, which are apparent to persons skilled in the art to which the invention pertains are deemed to lie within the spirit and scope of the invention.
    </p>
    <p num="40">
      While this invention has been described with reference to illustrative embodiments, this description is not intended to be construed in a limiting sense.
      <br/>
      Various modifications of the illustrative embodiments, as well as other embodiments of the invention, which are apparent to persons skilled in the art to which the invention pertains are deemed to lie within the spirit and scope of the invention.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A method to re-recording audio events, the method comprising:</claim-text>
      <claim-text>determining scattered audio events on a first track based on a linked list; merging the scattered audio events into a combined audio event on a second track;</claim-text>
      <claim-text>and copying the combined audio event on the second track to the first track.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The method of claim 1 wherein the linked list comprises a plurality of elements, each element having at least a label identifying an audio segment, a size field specifying a size of the audio segment, and a pointer pointing to a next audio segment.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The method of claim 2 wherein determining scattered audio events comprises: identifying the elements of the linked list having the corresponding sizes less than a predetermined threshold.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The method of claim 3 wherein merging the scattered audio events comprises: allocating the second track based on the identified elements; playing back the audio events in the identified elements from the first track;</claim-text>
      <claim-text>and recording the played back audio events to the second track to form the combined audio event.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The method of claim 4 wherein the first and second tracks are stored on a storage medium.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The method of claim 5 wherein the storage medium is a hard disk.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. A computer program product comprising: a computer usable medium having computer program code embodied therein to re-recording audio events, the computer program product having: computer readable program code for determining scattered audio events on a first track based on a linked list; computer readable program code for merging the scattered audio events into a combined audio event on a second track;</claim-text>
      <claim-text>and computer readable program code for copying the combined audio event on the second track to the first track.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The computer program product of claim 1 wherein the linked list comprises a plurality of elements, each element having at least a label identifying an audio segment, a size field specifying a size of the audio segment, and a pointer pointing to a next audio segment.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. The computer program product of claim 2 wherein the computer readable program code for determining scattered audio events comprises: computer readable program code for identifying the elements of the linked list having the corresponding sizes less than a predetermined threshold.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. The computer program product of claim 3 wherein the computer readable program code for merging the scattered audio events comprises: computer readable program code for allocating the second track based on the identified elements; computer readable program code for playing back the audio events in the identified elements from the first track;</claim-text>
      <claim-text>and computer readable program code for recording the played back audio events to the second track to form the combined audio event.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. The computer program product of claim 4 wherein the first and second tracks are stored on a storage medium.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. The computer program product of claim 5 wherein the storage medium is a hard disk.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. A system comprising: a processor; a memory coupled to the processor to store program code to re-record audio events, the program code, when executed, causing the processor to: determine scattered audio events on a first track based on a linked list, merge the scattered audio events into a combined audio event on a second track, and copy the combined audio event on the second track to the first track.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. The system of claim 13 wherein the linked list comprises a plurality of elements, each element having at least a label identifying an audio segment, a size field specifying a size of the audio segment, and a pointer pointing to a next audio segment.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. The system of claim 14 wherein the program code causing the processor to determine scattered audio events causes the processor to identify the elements of the linked list having the corresponding sizes less than a predetermined threshold.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. The system of claim 15 wherein the program code causing the processor to merge the scattered audio events causes the processor to allocate the second track based on the identified elements, play back the audio events in the identified elements from the first track by a player, and record the played back audio events to the second track to form the combined audio event by a recorder.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. The system of claim 16 wherein the first and second tracks are stored on a storage medium.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. The system of claim 17 wherein the storage medium is a hard disk.</claim-text>
    </claim>
  </claims>
</questel-patent-document>