<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06181376B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06181376</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6181376</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="25490049" extended-family-id="42107826">
      <document-id>
        <country>US</country>
        <doc-number>08950166</doc-number>
        <kind>A</kind>
        <date>19971014</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1997US-08950166</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>43164135</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>95016697</doc-number>
        <kind>A</kind>
        <date>19971014</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1997US-08950166</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G06T   3/40        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>3</main-group>
        <subgroup>40</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>H04N   9/04        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>9</main-group>
        <subgroup>04</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>348273000</text>
        <class>348</class>
        <subclass>273000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>348280000</text>
        <class>348</class>
        <subclass>280000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>348E09010</text>
        <class>348</class>
        <subclass>E09010</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G06T-003/40C</text>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>003</main-group>
        <subgroup>40C</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>H04N-009/04B</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>009</main-group>
        <subgroup>04B</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-003/4015</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>3</main-group>
        <subgroup>4015</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-009/045</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>9</main-group>
        <subgroup>045</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>17</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>7</number-of-drawing-sheets>
      <number-of-figures>11</number-of-figures>
      <image-key data-format="questel">US6181376</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Method of determining missing color values for pixels in a color filter array</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>TSAI YUSHENG T, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5065229</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5065229</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>LU NING, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5805217</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5805217</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>ADAMS JR JAMES E, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5808674</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5808674</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>ADDISON STEPHEN B</text>
          <document-id>
            <country>US</country>
            <doc-number>5990950</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5990950</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="5">
          <text>BAYER BRYCE E</text>
          <document-id>
            <country>US</country>
            <doc-number>3971065</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US3971065</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="1">
          <text>Dillon, Lewis, Kaspar; "Color Imaging System Using A Single CCD Area Array"; IEEE Transactions on Electron Devices, vol. ED-25, No. 2, Feb. 1998, pp. 102-107.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="2">
          <text>Gonzales, Woods, "Digital Image Processing", Addison-Wesley Publishing Company, Jun. 1992, pp. 195-197.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="3">
          <text>Weldy, "Optimized Design for a single-sensor color electronic camera system", SPIE vol. 1071, Optical Sensors and Electronic Photography (1989), pp. 300-308.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="4">
          <text>John E. Greivenkamp, "Color dependent optical prefilter for the suppression of aliasing artifacts", Applied Optics, vol. 29, No. 5, Feb. 10, 1990, pp. 676-684.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="5">
          <text>Unser, Aldroubi, Eden, "Fast B-Spline Transforms for Continuous Image Representation and Interpolation", IEEE Transactions on Pattern Analysis and Machine Intelligence, vol. 13, No. 3, Mar. 1991, pp. 277-285.</text>
        </nplcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Intel Corporation</orgname>
            <address>
              <address-1>Santa Clara, CA, US</address-1>
              <city>Santa Clara</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>INTEL</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Rashkovskiy, Oleg</name>
            <address>
              <address-1>Cupertino, CA, US</address-1>
              <city>Cupertino</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Macy, William</name>
            <address>
              <address-1>Palo Alto, CA, US</address-1>
              <city>Palo Alto</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <name>Skabrat, Steven P.</name>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Ho, Tuan</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      Missing color values for pixels in a color filter array created by a digital camera and having a Bayer pattern are generated by determining values for all missing green color values for pixels in the color filter array by interpolation of known green color values adjacent along diagonal lines and determining values for all missing red and blue color values for the pixels from the sum of an interpolation term and a luminance correction term based on differences between green color values of adjacent pixels.
      <br/>
      The missing green color values are determined by computing temporary values for green which lie at the corners of pixels having known green color values using cubic B-spline filters oriented along diagonally adjacent green color pixels, determining final values for green at the centers of pixels having known red and blue values by using cubic B-spline filters oriented along diagonally adjacent red and blue color pixels, and by sampling the temporary green values.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <p num="1">
      A portion of the disclosure of this patent document contains material which is subject to copyright protection.
      <br/>
      The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure, as it appears in the Patent and Trademark Office patent file or records, but otherwise reserves all copyright rights whatsoever.
    </p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="2">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="3">The present invention relates generally to computer graphics and more specifically to the manipulation of color filter arrays used to represent color images captured by a digital camera.</p>
    <p num="4">2. Description of Related Art</p>
    <p num="5">
      Digital cameras that capture color images are rapidly becoming popular.
      <br/>
      These digital cameras are used for still photography and full motion video recording.
      <br/>
      The images captured by the camera may be transferred to a computer system and displayed on a computer monitor for viewing by the user.
      <br/>
      The increasing power of microprocessors permits many sophisticated and computationally intensive image processing operations to be performed by software executing on the computer system rather than by special purpose circuitry in the camera.
      <br/>
      Image processing methods implemented in software allow presentation of higher quality images to the user while lowering the cost of the digital camera, because the specialized circuitry for performing various image processing operations is no longer needed.
    </p>
    <p num="6">
      Most commercial digital cameras use a single-chip color filter array to capture images.
      <br/>
      The color filter array is located in the focal plane of the camera in the same place that film is located in a traditional film camera.
      <br/>
      A single-chip color filter array is a two-dimensional grid of picture elements, called pixels, covered by color filters.
      <br/>
      Each pixel is typically implemented through the use of a charge-coupled device (CCD) or CMOS circuit.
      <br/>
      To minimize the cost of the color filter array (and therefore the cost of the camera), only one of the red, green or blue colors is sensed at each pixel.
      <br/>
      Hence, information for two colors of a red, green, and blue (RGB) color combination is missing at each pixel of the sensed image.
      <br/>
      The colors that are sensed are arranged in a predetermined pattern in the color filter array so that the entire image may be represented to the user in an aesthetically pleasing manner, despite the missing color information.
      <br/>
      One pattern that is useful for representing such images is disclosed in U.S. Pat. No. 3,971,065, issued to B. E. Bayer. There are also many other patterns that can be used to represent color images.
    </p>
    <p num="7">
      An example of a color filter array with a Bayer pattern is shown in FIG. 1.
      <br/>
      Pixels are represented by squares in the grid of FIG. 1.
      <br/>
      Each pixel includes an electronic sensor which measures the light falling on it.
      <br/>
      Those pixels which have a red filter measure red light and are represented by an R in the pattern, those pixels which have a green filter measure green light and are represented by a G in the pattern, and those pixels which have a blue filter measure blue light and are represented by a B in the pattern.
      <br/>
      The Bayer pattern is replicated throughout the entire color filter array in both the horizontal and vertical directions.
    </p>
    <p num="8">
      A problem with this method of capturing color images is that only a single color is sensed and stored at each pixel in the color filter array, although three colors (red, green and blue) are needed to reconstruct the true color at each pixel.
      <br/>
      Typically, each pixel is represented by eight bits for a color.
      <br/>
      Hence, the amount of color information being collected at each pixel in the captured image is only eight bits, but 24 bits are needed for the complete set of red, green and blue color values for the pixel.
      <br/>
      Cameras which use a single color filter array must determine the missing color values at each pixel.
      <br/>
      For example, values of missing red and blue colors must be found for a pixel with a green filter.
    </p>
    <p num="9">
      Existing systems use color values of adjacent pixels to interpolate the missing color values.
      <br/>
      The simplest approach is to treat each color plane separately.
      <br/>
      A color plane is the representation of a single color for the whole color filter array.
      <br/>
      With the separate color plane method, missing red, green, and blue values are determined by reference to neighboring red, green, and blue pixels, respectively.
    </p>
    <p num="10">
      Some methods for computing missing color values use color values from other color planes.
      <br/>
      In most cases, values from the green plane are combined with values of adjacent red pixels to determine missing red values, and values from the green plane are combined with values of adjacent blue pixels to determine missing blue values.
      <br/>
      Generally, color array patterns (such as the Bayer pattern) use more green pixels than red or blue pixels.
      <br/>
      Using more green pixels than red and blue pixels improves luminance resolution or sharpness of the image without significantly degrading color quality.
      <br/>
      A method disclosed by P. D. Dillon, D. M. Lew, and F. G. Kaspar in "Color Imaging System Using A Single CCD Array", IEEE Trans.
      <br/>
      Electron Devices, vol.
      <br/>
      ED-32, pp. 102-107, 1978, combines green with other colors, subtracts a purposely blurred green value from an original green value, and adds the difference to all three color planes.
      <br/>
      This method is an image sharpening technique also known as unsharp masking as discussed by R. C. Gonzalez and R. E. Woods in "Digital Image Processing", published by Addison-Wesley of Reading, Mass., 1992. Another method, taught by J. A. Weldy in "Optimized Design For A Single-Sensor Color Electron Camera System", Proceedings of SPIE, vol. 107, vol. 1071, pp. 300-308, 1989, linearly interpolates missing green values so that there are green values at all pixel locations, and then uses the difference between red and green at red pixel locations to interpolate missing red values, and the difference between blue and green at blue pixel locations to interpolate missing blue values.
    </p>
    <p num="11">
      These methods for interpolating missing color values suffer from two problems.
      <br/>
      Interpolation results in blurred images, and inaccurate interpolation of red and blue values tends to produce aliasing artifacts at object boundaries within the image.
      <br/>
      Object boundaries may appear as red or blue instead of their true colors.
      <br/>
      Most cameras reduce these aliasing artifacts by optically blurring the image before it reaches the sensor.
      <br/>
      This technique is discussed by J. E. Grievenkamp in "Color Dependent Optical Prefilter For The Suppression Of Aliasing", Applied Optics, vol. 29, pp. 676-684, February 1990.
      <br/>
      A new method is needed which overcomes these problems by forming a compromise between blurring and aliasing reduction methods to provide excellent quality, true color images in a cost-efficient manner.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="12">
      An embodiment of the present invention is a method for generating missing color values for pixels in an array, each pixel having one of three color values.
      <br/>
      The method includes the steps of determining values for all missing second color values for pixels in the array by interpolation of known second color values adjacent along diagonal lines from the missing second color values, and determining values for all missing first and third color values for the pixels from a sum of an interpolation term and a luminance correction term based on differences between second color values of adjacent pixels.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="13">
      The features and advantages of the present invention will become apparent from the following detailed description of the present invention in which:
      <br/>
      FIG. 1 is a diagram of a Bayer pattern (Prior Art).
      <br/>
      FIG. 2 is a block diagram of a digital camera having a color filter image stored in a memory.
      <br/>
      FIG. 3 is a high level flow diagram of the processing steps of the present invention.
      <br/>
      FIGS. 4a-b are diagrams of sample Bayer patterns of pixels showing diagonal lines of processing according to the present invention.
      <br/>
      FIG. 5 is a flow diagram showing the steps of determining missing green pixels.
      <br/>
      FIGS. 6a-d are diagrams of possible color patterns to be processed by the present invention.
      <br/>
      FIG. 7 is a diagram of a detailed example of a Bayer pattern as processed by the present invention.
    </p>
    <heading>DETAILED DESCRIPTION OF THE PRESENT INVENTION</heading>
    <p num="14">
      In a single-sensor system, the three colors of information (typically red, green, and blue) cannot be sampled by each pixel of the sensor.
      <br/>
      However, for an aesthetically pleasing display of the current scene, three colors of information should be displayed at every pixel.
      <br/>
      Therefore, image reconstruction processing is used to create three color information at every pixel of the display.
      <br/>
      The present invention is a method of image reconstruction processing for determining missing color values for a color filter array which results in an excellent quality image without requiring purposely blurring of the image by the camera.
      <br/>
      It effectively allows for improving or increasing the pixel depth of a displayed image to provide a more accurate representation of a sensed image.
    </p>
    <p num="15">
      Embodiments of the present invention include methods for "upsampling" 8-bit color filter array values into 24-bit color values for a color image captured by a digital camera.
      <br/>
      However, the present invention can be used in any computer application where individual red, green, and blue color values are represented in an array and the depth of the pixels needs to be improved.
      <br/>
      Typically, the depth improvement will be from 8 bits to 24 bits.
      <br/>
      However, other depth improvement operations (for example, from 16 bits to 48 bits) are also within the scope and spirit of the present invention.
      <br/>
      The present invention also is applicable to color schemes using colors other than red, green, and blue.
      <br/>
      Furthermore, the present invention is discussed below in terms of an implementation in software, however, an implementation in hardware is also feasible.
    </p>
    <p num="16">
      FIG. 2 is a block diagram of a digital camera having a color filter image stored in a memory.
      <br/>
      Digital Camera 10 uses Lens 12 to accept light from the environment around the camera.
      <br/>
      The light passes through and is filtered by Color Filter Array 13 and is sensed by electronics Sensors 14.
      <br/>
      The resulting Color Filter Image 16 is stored in Memory 18.
      <br/>
      The Sensors may be CCDs, CMOS arrays, or other light sensing devices.
      <br/>
      The Color Filter Image is a representation of the image sensed by the camera.
      <br/>
      Memory 18 is coupled to Interfaces (I/F) 20, 22 to connect Digital Camera 10 to a Computer System 24 for displaying the captured images.
      <br/>
      Computer System 24 is a general purpose computer such as a personal computer (PC) or workstation having a Processor 26, Memory 28, and a Display 30.
      <br/>
      The Color Filter Image 16 generated by Digital Camera 10 is stored as Color Filter Image 16' in Memory 28 in Computer System 24 and manipulated as a result of instructions being executed by Processor 26 according to the present invention.
    </p>
    <p num="17">
      FIG. 3 is a high level flow diagram of the processing steps of the present invention.
      <br/>
      The Color Filter Image 16' has a plurality of individual pixels, each pixel being one of the red, green, and blue colors, with the other two colors being missing at each pixel.
      <br/>
      At Step 100, color values for all missing green pixels are determined by interpolation based on known green pixels adjacent along diagonal lines.
      <br/>
      At Step 102, the color values for all missing red and blue pixels are determined from the sum of an interpolation term and a luminance correction term based on the differences between the values of neighboring green pixels.
    </p>
    <p num="18">
      Missing green pixel values are computed at Step 100 using a cubic B-spline digital filter as disclosed by M. Unser, A. Aldroubi, and M. Eden in "Fast B-spline Transforms For Continuous Image Representation And Interpolation", IEEE Trans.
      <br/>
      Pattern Anal.
      <br/>
      Machine Intell., vol. 13, pp. 277-285, 1991.
      <br/>
      In an illustrative embodiment of the present invention, green pixels are sampled along diagonals instead of the conventional approach along rows and columns in the Color Filter Array.
      <br/>
      FIGS. 4a and 4B are diagrams of sample Bayer patterns of pixels showing diagonal lines of processing according to the present invention.
      <br/>
      The diagonal lines of FIG. 4a are lines angled diagonally connecting green pixels.
      <br/>
      The diagonal lines of FIG. 4b are lines angled diagonally (perpendicular to the first type) connecting alternating red and blue pixels.
      <br/>
      FIG. 5 is a flow diagram showing the steps of determining missing green pixels corresponding to Step 100 of FIG. 3.
      <br/>
      First, values for green at the corners of green pixels which lie on the diagonal lines of FIG. 4a are determined at Step 110 using the cubic B-spline filter oriented along the diagonal lines.
      <br/>
      Next, at Step 112, values for green at the centers of pixels labeled red and blue are determined by orienting the cubic B-spline filter along the diagonal lines of FIG. 4b and the interpolated green values at the corners of pixels determined in Step 110 are sampled.
    </p>
    <p num="19">
      The determination of the missing red and blue values of Step 102 of FIG. 3 can be illustrated by several examples using FIGS. 4a and 4b to indicate pixel positions in the Bayer pattern.
      <br/>
      The missing red value for the pixel at the first row of the second column, denoted R12 is computed according to the present invention as (R11 +R13)/2+(G12 -(G11 +G13)/2).
      <br/>
      The first term of the equation (referencing the adjacent red values) is called the interpolation term.
      <br/>
      This term is the linear interpolation of the neighboring red values.
      <br/>
      The second term (referencing the green values) is called the luminance correction term.
      <br/>
      This term represents the difference between green at the location of the interpolated value of red and green at the locations of measured red values used in the interpolation calculation.
      <br/>
      The luminance correction terms use results obtained from the green interpolation calculations of Step 100 of FIG. 3.
      <br/>
      The missing red value for the pixel at the second row of the first column, denoted R21, is computed as (R11 +R31)/2+(G21 -(G11 +G31)/2).
      <br/>
      The missing red value for the pixel at the second row of the second column, denoted R22, is computed as (R11 +R13 +R31 +R33)/4+(G22 -(G11 +G13 +G31 +G33)/4).
      <br/>
      Note that red values bordering edges of the image are determined by reference to only two adjacent red pixels; otherwise four diagonally adjacent red pixels are used for the interpolation term.
      <br/>
      In a similar manner, missing blue values are computed.
      <br/>
      The missing blue value for the pixel at the second row of the third column, denoted B23, is computed according to the present invention as (B22 +B24)/2+(G23 -(G22 +G24)/2).
      <br/>
      The missing blue value for the pixel at the third row of the second column, denoted B32, is computed as (B22 +B42)/2+(G32 -(G22 +G42)/2).
      <br/>
      The missing blue value for the pixel at the third row of the third column, denoted B33 is computed as (B22 +B24 +B42 +B44)/4+(G22 -(G11 +G13 +G31 +G33)/4).
      <br/>
      Note that blue values bordering edges of the image are determined by reference to only two adjacent blue pixels; otherwise four diagonally adjacent blue pixels are used for the interpolation term.
    </p>
    <p num="20">
      FIGS. 6a-d are diagrams of possible color patterns to be processed by the present invention.
      <br/>
      All are variations of Bayer patterns.
      <br/>
      FIG. 6a shows a pattern called "Bayer Pattern 1 Red Top." FIG. 6b shows a pattern called "Bayer Pattern 2 Red Top." FIG. 6c shows a pattern called "Bayer Pattern 1 Blue Top." FIG. 6d shows a pattern called "Bayer Pattern 2 Blue Top." Note the variations between the patterns.
      <br/>
      The present invention handles each of these patterns equally well.
    </p>
    <p num="21">
      FIG. 7 is a diagram of a detailed example of a Bayer pattern as processed by the present invention.
      <br/>
      One of the four possible Bayer patterns (the Bayer Pattern 1 Red Top pattern) is shown in FIG. 7.
      <br/>
      First, the green values for pixels marked as red (R) and blue (B) are computed by using diagonal splines whenever possible.
      <br/>
      Pixels along the boundaries of the sensed image must be handled differently than the pixels in the interior of the sensed image.
      <br/>
      It is not possible to use splines along the sensed image boundaries.
      <br/>
      Instead, linear interpolation is used along the boundaries.
      <br/>
      Linear interpolation is used to set an interpolated green value at a red or blue pixel equal to the average of the neighboring green pixels.
      <br/>
      For example, green values for two of the corners of the pattern of FIG. 7 are computed as G0,0 =(G0,1 +G1,0)/2 and G17,17 =(G16,17 +G17,16)/2.
      <br/>
      Those pixels with two green neighbors use the general form Gi,j =(Gi-1,j +Gi,j-1)/2.
      <br/>
      Other pixels on the top and bottom rows, and the first and last columns, have three green neighbors.
      <br/>
      Therefore, for the top row, green values are computed as Gi,j =(Gi,j-1 +Gi,j+1 +Gi+1,j)/3.
      <br/>
      For the bottom row, green values are computed as Gi,j =(Gi,j-1 +Gi,j+1 +Gi-1,j)/3.
      <br/>
      For the left column, green values are computed as Gi,j =(Gi-1,j +Gi+1,j +Gi,j+1)/3.
      <br/>
      For the right column, green values are computed as Gi,j =(Gi-1,j +Gi+1,j +Gi,j-1)/3.
      <br/>
      All other linearly interpolate green values are computed using the equation Gi,j =(Gi-1,j-1 +Gi-1,j+1 +Gi+1,j-1 +Gi+1,j+1)/4.
    </p>
    <p num="22">
      The diagonal splines are computed by finding temporary values with the spline filter along one diagonal line, and then using those temporary values to find the final result with the spline filter along the other diagonal line.
      <br/>
      FIG. 7 shows an example of an eight tap filter with its top at G0,7 and bottom at G7,14.
      <br/>
      The filter result is L0,3, halfway between the fourth and fifth pixel along the diagonal.
      <br/>
      L0,3 represents an interpolated value in the green plane.
      <br/>
      It is computed as follows: L0,3 =C0 G0,7 +C1 G1,8 +C2 G2,9 +C3 G3,10 +C4 G4,11 +C5 G5,12 +C6 G6,13 +C7 G7,14.
      <br/>
      The general form for a filter result is as follows:
    </p>
    <p num="23">Li,k =the sum from m=0 to n-1 (Cm Gi,j+m) where n is the filter length, Cm is the filter coefficient and k=floor (j/2).</p>
    <p num="24">
      For example, in FIG. 7, i=0, j=7, n=8, and k=floor (7/2)=floor (3.5)=3. Once the L values are found, green values at red and blue pixel locations can be computed.
      <br/>
      In FIG. 7, the filter whose top is at L0,3 and whose bottom is at L7,0 computes G7,7 at the location of the circled B as G7,7 =C0 L0,3 +C1 L1,3 +C2 L2,2 +C3 L3,2 +C4 L4,1 +C5 L5,1 +C6 L6,0 +C7 L7,0.
      <br/>
      The general form is as follows:
    </p>
    <p num="25">Gi,j =the sum from m=0 to n-1 (Cm Li-n+1,k) where k=floor ((j-m)/2)</p>
    <p num="26">Note that in the example, all of the Li,j values to the upper left of the diagonal line whose top is L0,3 are never used to compute green values because there are too few values (less than n) of Li,j along the diagonal.</p>
    <p num="27">
      The method for computing red and blue values according to the present invention can be generalized as follows.
      <br/>
      Interpolation of a red value at a location where the pixel in the original Bayer pattern (i.e., the sensed image) is green in a row of alternating reds is computed as Ri,j =(Ri,j +Ri,j+1)/2+(Gi,j -(Ri,j-1 +Ri,j+1)/2).
      <br/>
      Interpolation of a red value at a location where the pixel in the original Bayer pattern is green in a row of alternating blues is computed as Ri,j =(Ri-1,j +Ri+1,j)/2+(Gi,j -(Ri-1,j +Ri+1,j)/2).
      <br/>
      Interpolation of a red value at a location where the pixel in the original Bayer pattern is blue is computed as Ri,j =(Ri-1,j-1 +Ri-1,j+1 +Ri+1,j-1 +Ri+1,j+1)/4+(Gi,j -(Gi-1,j-1 +Gi-1,j+1 +Gi+1,j-1 +Gi+1,j+1)/4).
      <br/>
      Interpolation of a blue value at a location where the pixel in the original Bayer pattern is green in a row of alternating blues is computed as Bi,j =(Bi,j-1 +Bi,j+1)/2+(Gi,j -(Bi,j-1 +Bi,j+1)/2).
      <br/>
      Interpolation of a blue value at a location where the pixel in the original Bayer pattern is green in a row of alternating reds is computed as Bi,j =(Bi-1,j +Bi+1,j)/2+(Gi,j -(Gi-1,j +Gi+1,j)/2).
      <br/>
      Interpolation of a blue value at a location where the pixel in the original Bayer pattern is red is computed as Bi,j =(Bi-1,j-1 +Bi-1,j+1 +Bi+1,j-1 +Bi+1,j+1)/4+(Gi,j -(Gi-1,j-1 +Gi-1,j+1 +Gi+1,j-1 +Gi+1,j+1)/4).
    </p>
    <p num="28">An embodiment of the present invention is represented below in the form of detailed pseudo-code in Appendix A.</p>
    <p num="29">
      Cubic spline interpolation produces better images than conventional methods by finding values with continuous and equal first derivatives and equal second derivatives at image points.
      <br/>
      Green pixels do not form a square grid along rows and columns of the image, but they do form a square grid along diagonals.
      <br/>
      Green pixels are evenly spaced and they are most closely spaced along diagonals.
      <br/>
      Cubic splines which interpolate halfway between two grid points, as in the present invention, can be computed with a digital filter which has a low computational complexity.
    </p>
    <p num="30">
      The luminance correction term corrects red and blue interpolation errors.
      <br/>
      Changes in green represent changes in luminance, which affects overall image sharpness.
      <br/>
      Interpolation of red and blue tends to produce a smooth transition between points in the image.
      <br/>
      The luminance correction term correlates red and blue color values with green so that if higher resolution green has a sharp transition, red and blue values are modified to take into account this transition.
      <br/>
      The luminance correction term increases image sharpness and reduces aliasing artifacts.
    </p>
    <p num="31">
      The combination of the effect of diagonal cubic spline interpolation and luminance correction according to the present invention provides sharp images with limited aliasing artifacts.
      <br/>
      The present invention also has low computational complexity.
      <br/>
      Results indicate that the optical blurring required to further suppress aliasing may be provided by focus errors and aberrations in low cost digital cameras alone without the need for additional blurring of the image by software.
    </p>
    <p num="32">
      Testing was accomplished by decimating good quality 24-bit color images so that the remaining pixel values are those of an 8-bit Bayer pattern, and then reconstructing the images according to the present invention.
      <br/>
      Differences between original and reconstructed images were difficult to detect when the original image was pre-filtered with a smoothing filter which removes only 15 percent of the high frequency content, rather than 50 percent as in prior art methods.
      <br/>
      Use of interpolated green values in the luminance correction term is supported by tests which show that interpolated green planes of images with high frequency content appear identical to the original green planes.
      <br/>
      The luminance correction increases image sharpness and reduces aliasing in images in which only the cubic spline filter is used.
      <br/>
      Results using the spline filter on red and blue planes do not differ noticeably from those results produced by using linear interpolation, so linear interpolation is used in the present method because it requires fewer operations.
      <br/>
      Testing results indicated that the present invention reconstructs images better than other conventional methods known in the art.
    </p>
    <p num="33">
      While this invention has been described with reference to illustrative embodiments, this description is not intended to be construed in a limiting sense.
      <br/>
      Various modifications of the illustrative embodiments, as well as other embodiments of the invention, which are apparent to persons skilled in the art to which the inventions pertains are deemed to lie within the spirit and scope of the invention.       (Vertical spacing image '1' not included in text)  (Vertical spacing image '2' not included in text)  (Vertical spacing image '3' not included in text)  (Vertical spacing image '4' not included in text)  (Vertical spacing image '5' not included in text)  (Vertical spacing image '6' not included in text)  (Vertical spacing image '7' not included in text)  (Vertical spacing image '8' not included in text)  (Vertical spacing image '9' not included in text)  (Vertical spacing image '10' not included in text)  (Vertical spacing image '11' not included in text)  (Vertical spacing image '12' not included in text)  (Vertical spacing image '13' not included in text)  (Vertical spacing image '14' not included in text)  (Vertical spacing image '15' not included in text)
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A method of generating missing color values for pixels in an array, each pixel having one of at least first, second, and third color values, comprising:</claim-text>
      <claim-text>determining values for all missing second color values for pixels in the array through interpolation of known second color values adjacent along diagonal lines from the missing second color values by determining temporary values for the second color which lie at the corners of pixels having known second color values using filters oriented along diagonally adjacent second color pixels and by determining final values for the second color at centers of pixels having known first and third color values by using filters oriented along diagonally adjacent first and third color pixels and sampling the temporary second color values;</claim-text>
      <claim-text>and determining values for all missing first and third color values for the pixels from a sum of an interpolation term and a luminance correction term based on differences between second color values of adjacent pixels.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The method of claim 1, wherein the filters comprise cubic B-spline filters.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The method of claim 1, wherein the pixels of the array have color values arranged according to a Bayer pattern.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The method of claim 1, wherein the interpolation term comprises first color values of at least two horizontally or vertically adjacent pixels.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The method of claim 1, wherein the interpolation term comprises third color values of at least two horizontally or vertically adjacent pixels.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The method of claim 1, wherein the luminance correction term includes the difference between the second color value at the location of an interpolated value of a first color value and second color values at locations of measured first color values used in the calculation of the interpolation term.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. The method of claim 1, wherein the luminance correction term includes the difference between the first color value at the location of an interpolated value of a third color value and second color values at locations of measured third color values used in the calculation of the interpolation term.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The method of claim 1, wherein the first color value is red, the second color value is green, and the third color value is blue.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. A system for generating missing color values for pixels in an array, each pixel having one of first, second, or third color values, comprising: means for determining values for all missing second color values for pixels in the array through interpolation of known second color values adjacent along diagonal lines from the missing second color values by determining temporary values for the second color which lie at the corners of pixels having known second color values using filters oriented along diagonally adjacent second color pixels and by determining final values for the second color at centers of pixels having known first and third color values by using filters oriented along diagonally adjacent first and third color pixels and sampling the temporary second color values;</claim-text>
      <claim-text>and means for determining values for all missing first and third color values for the pixels from a sum of an interpolation term and a luminance correction term based on differences between second color values of adjacent pixels.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. The system of claim 9, wherein the first color value is red, the second color value is green, and the third color value is blue.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. The system of claim 9, wherein the filters comprise cubic B-spline filters.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. A system for processing a color filter image having a plurality of pixels, each pixel having one of first, second, or third color values, comprising: a storage medium to store the color filter array and a plurality of programming instructions;</claim-text>
      <claim-text>and a processor coupled to the storage medium, the processor executing the programming instructions for determining values for all missing second color values for pixels in the color filter image through interpolation of known second color values adjacent along diagonal lines from the missing second color values by determining temporary values for the second color which lie at the corners of pixels having known second color values using filters oriented along diagonally adjacent second color pixels and by determining final values for the second color at centers of pixels having known first and third color values by using filters oriented along diagonally adjacent first and third color pixels and sampling the temporary second color values;</claim-text>
      <claim-text>and determining values for all missing first and third color values for the pixels from a sum of an interpolation term and a luminance correction term based on differences between second color values of adjacent pixels.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. The system of claim 12, wherein the first color value is red, the second color value is green, and the third color value is blue.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. The system of claim 12, wherein the filters comprise cubic B-spline filters.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. A machine readable medium having stored therein a plurality of machine readable instructions designed to be executed by a processor, the machine readable instructions for generating missing color values for pixels in a color filter image, each pixel having one of first, second, or third color values, the machine readable instructions comprising instructions for determining values for all missing second color values for pixels in the color filter image through interpolation of known second color values adjacent along diagonal lines from the missing second color values by determining temporary values for the second color which lie at the corners of pixels having known second color values using filters oriented along diagonally adjacent second color pixels and by determining final values for the second color at centers of pixels having known first and third color values by using filters oriented along diagonally adjacent first and third color pixels and sampling the temporary second color values, and for determining values for all missing first and third color values for the pixels from a sum of an interpolation term and a luminance correction term based on differences between second color values of adjacent pixels.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. The machine readable medium of claim 15, wherein the first color value is red, the second color value is green, and the third color value is blue.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. The machine readable medium of claim 15, wherein the filters comprise cubic B-spline filters.</claim-text>
    </claim>
  </claims>
</questel-patent-document>