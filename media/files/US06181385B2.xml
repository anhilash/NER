<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06181385B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06181385</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6181385</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference family-id="7830761" extended-family-id="4633776">
      <document-id>
        <country>US</country>
        <doc-number>09080675</doc-number>
        <kind>A</kind>
        <date>19980518</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1998US-09080675</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>4823545</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>DE</country>
        <doc-number>19722358</doc-number>
        <kind>A</kind>
        <date>19970528</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1997DE-1022358</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>H04N   5/272       20060101AFI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>272</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G06T   5/00        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>00</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>H04N   5/208       20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>208</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>H04N   9/64        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>9</main-group>
        <subgroup>64</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>348625000</text>
        <class>348</class>
        <subclass>625000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>348266000</text>
        <class>348</class>
        <subclass>266000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>348382000</text>
        <class>348</class>
        <subclass>382000</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>348606000</text>
        <class>348</class>
        <subclass>606000</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>348624000</text>
        <class>348</class>
        <subclass>624000</subclass>
      </further-classification>
      <further-classification sequence="5">
        <text>348630000</text>
        <class>348</class>
        <subclass>630000</subclass>
      </further-classification>
      <further-classification sequence="6">
        <text>348631000</text>
        <class>348</class>
        <subclass>631000</subclass>
      </further-classification>
      <further-classification sequence="7">
        <text>348E05076</text>
        <class>348</class>
        <subclass>E05076</subclass>
      </further-classification>
      <further-classification sequence="8">
        <text>348E09042</text>
        <class>348</class>
        <subclass>E09042</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>H04N-005/208</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>208</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>H04N-009/64E</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>009</main-group>
        <subgroup>64E</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-005/208</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>208</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-009/646</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>9</main-group>
        <subgroup>646</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>12</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>6</number-of-drawing-sheets>
      <number-of-figures>11</number-of-figures>
      <image-key data-format="questel">US6181385</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Method for processing transitional regions in a picture signal</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>RABII KHOSRO M</text>
          <document-id>
            <country>US</country>
            <doc-number>4935806</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4935806</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>SHIBAYAMA KENJI</text>
          <document-id>
            <country>US</country>
            <doc-number>5029004</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5029004</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>PARK YOUNG-JUN</text>
          <document-id>
            <country>US</country>
            <doc-number>5151787</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5151787</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>MIZUTA MASASHI</text>
          <document-id>
            <country>US</country>
            <doc-number>5159442</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5159442</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>FAROUDJA YVES C</text>
          <document-id>
            <country>US</country>
            <doc-number>5237414</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5237414</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>AOKI KAZUYO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5304854</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5304854</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>RZESZEWSKI THEODORE S</text>
          <document-id>
            <country>US</country>
            <doc-number>5374964</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5374964</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>HONG SUNG H</text>
          <document-id>
            <country>US</country>
            <doc-number>5412432</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5412432</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="9">
          <text>HONG SUNG H</text>
          <document-id>
            <country>US</country>
            <doc-number>5469225</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5469225</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="10">
          <text>PENNEY BRUCE J</text>
          <document-id>
            <country>US</country>
            <doc-number>5515112</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5515112</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="11">
          <text>HONG SUNG-HOON</text>
          <document-id>
            <country>US</country>
            <doc-number>5699126</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5699126</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="12">
          <text>OGATA MASAMI</text>
          <document-id>
            <country>US</country>
            <doc-number>5848181</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5848181</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="13">
          <text>OHARA KAZUHIRO</text>
          <document-id>
            <country>US</country>
            <doc-number>5920357</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5920357</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="14">
          <text>KASAHARA MISA, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5926577</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5926577</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="15">
          <text>THOMAS JOSEPH, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5936682</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5936682</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="16">
          <text>SHIMAZAKI SHINGO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>6043853</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US6043853</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="17">
          <text>MURATA KAZUYUKI</text>
          <document-id>
            <country>US</country>
            <doc-number>5311328</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5311328</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="18">
          <text>LIMBERG ALLEN L</text>
          <document-id>
            <country>US</country>
            <doc-number>5467145</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5467145</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="19">
          <text>ZENITH ELECTRONICS CORP</text>
          <document-id>
            <country>DE</country>
            <doc-number>3943307</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>DE3943307</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="20">
          <text>BROADCAST TELEVISION SYST</text>
          <document-id>
            <country>DE</country>
            <doc-number>3919817</doc-number>
            <kind>C2</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>DE3919817</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="21">
          <text>SAMSUNG ELECTRONICS CO LTD</text>
          <document-id>
            <country>DE</country>
            <doc-number>4039122</doc-number>
            <kind>C2</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>DE4039122</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="22">
          <text>GOLD STAR CO</text>
          <document-id>
            <country>DE</country>
            <doc-number>4340687</doc-number>
            <kind>C2</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>DE4340687</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="23">
          <text>FUJI PHOTO FILM CO LTD</text>
          <document-id>
            <country>EP</country>
            <doc-number>0094597</doc-number>
            <kind>A2</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP--94597</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="24">
          <text>DUBNER COMPUTER SYSTEMS, et al</text>
          <document-id>
            <country>EP</country>
            <doc-number>0384718</doc-number>
            <kind>B1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-384718</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="25">
          <text>TEXAS INSTRUMENTS INC</text>
          <document-id>
            <country>EP</country>
            <doc-number>0805603</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-805603</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="1">
          <text>German Search Report dated: Feb. 5, 1998.</text>
        </nplcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Deutsche Thomson-Brandt GmbH</orgname>
            <address>
              <address-1>Villingen-Schwenninghen, DE</address-1>
              <city>Villingen-Schwenninghen</city>
              <country>DE</country>
            </address>
          </addressbook>
          <nationality>
            <country>DE</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>THOMSON BRANDT</orgname>
          </addressbook>
          <nationality>
            <country>DE</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Correa, Carlos</name>
            <address>
              <address-1>Villingen-Schwenningen, DE</address-1>
              <city>Villingen-Schwenningen</city>
              <country>DE</country>
            </address>
          </addressbook>
          <nationality>
            <country>DE</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <name>Tripoli, Joseph S.</name>
          </addressbook>
        </agent>
        <agent sequence="2" rep-type="agent">
          <addressbook lang="en">
            <name>Herrmann, Eric P.</name>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Peng, John K.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A method is proposed for processing transitional regions in a picture signal.
      <br/>
      The picture signal comprises a sequence of digital pixel values.
      <br/>
      A number of adjacent pixel values, which contain a processing pixel value, are combined to form a processing block.
      <br/>
      A corrected pixel value is calculated for the processing pixel value.
      <br/>
      The maximum and minimum pixel values are first determined in the processing block to define the transitional region.
      <br/>
      The transitional region is then split into a number of sections on the basis of the magnitude of pixel value.
      <br/>
      Finally, a determination is made as to the section in which the processing pixel value is located.
      <br/>
      The processing pixel value is allocated a corresponding correction value in order to increase, to reduce or to leave unchanged the processing pixel value, in accordance with a predetermined transfer function.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <p num="1">The invention relates to a method for processing transitional regions in a digital picture signal.</p>
    <heading>PRIOR ART</heading>
    <p num="2">
      The invention is based on a method for processing transitional regions in a picture signal, of the generic type of the independent Claim 1.
      <br/>
      A method for picture signal edge correction has been disclosed, for example, in German Patent Specification DE 40 39 122 C2.
      <br/>
      In the case of the method which is known from this patent, a digitized luminance signal of a video signal is delayed in four series-connected delay circuits.
      <br/>
      The delayed luminance signals are processed in downstream stages, namely subtraction circuits, absolute-value circuits, comparators and multiplying circuits.
      <br/>
      These processing stages are used to define the start of an edge and the end of an edge.
      <br/>
      When the start of an edge is identified, control signals are produced such that one of the delayed luminance signals is output instead of the undelayed luminance signal.
      <br/>
      This results in an increase in the gradient of a transition in the picture signal since the upper luminance value of the transition from one sample value to the next is virtually output without having to output intermediate values.
    </p>
    <heading>INVENTION</heading>
    <p num="3">On the basis of the prior art cited above, the object of the invention is to specify a method for processing transitional regions in a digital picture signal, which operates as far as possible at the sampling clock rate of the respective picture signal, is easy to implement in terms of circuitry and, in particular, manages without complex circuits to identify transitions (edges) in the picture signal.</p>
    <p num="4">
      In contrast to the method known from the prior art, the method according to the invention and having the features of Claim 1 has the advantage that it processes each pixel individually at the normal sampling clock rate and, to this extent, is easy to implement in terms of circuitry.
      <br/>
      With regard to the processing of a pixel, the position of this pixel within a transition is irrelevant.
      <br/>
      There is no need for circuit elements for definition of what is a transition in the picture signal and to detect such a transition in the picture.
      <br/>
      This characteristic of the method also provides insensitivity to noise occurring in the picture signal.
    </p>
    <p num="5">
      The measures described in the dependent claims allow further improvements in the method.
      <br/>
      On the basis of the method according to the invention, a transitional region is defined simply by the maximum and minimum pixel values in the processing block under consideration.
      <br/>
      Splitting the transitional region defined in this way into upper and lower sections according to Claim 2 makes it easy to allocate correction values to increase the gradient of the transition.
      <br/>
      In this case, the processing pixel value is allocated a positive correction value if said processing pixel is located in one of the upper sections of the transition and, accordingly, is allocated a negative correction value if said processing pixel value is in one of the lower sections of the transition.
      <br/>
      This results in the gradient of the transition being increased in a simple manner.
    </p>
    <p num="6">The splitting of the defined transitional region into upper and lower sections is accomplished in a simple manner by determining the mean value between the minimum and maximum pixel values in the processing block and using this mean value as a boundary between the upper and lower sections.</p>
    <p num="7">
      The method can advantageously be used to increase the edge gradient in a picture signal.
      <br/>
      In this case, the picture signal is predominantly a luminance signal of a video signal.
    </p>
    <p num="8">
      For the situation where the edge gradient of a luminance signal is increased, it is advantageous if the respective correction value for the processing pixel value is chosen as a function of the difference between the maximum and minimum pixel values.
      <br/>
      In this case, the edge gradient increasing function can gradually tend to zero if the difference between the maximum and minimum pixel values likewise tends to zero.
      <br/>
      This also makes it possible to use the edge gradient increasing measure to avoid the undesirable effect of unnaturally acting human faces in a video picture.
    </p>
    <p num="9">
      The measures according to Claim 6 are advantageous for a specific implementation of the method for luminance signals.
      <br/>
      As a result of the fact that the specified transfer function, with whose aid the pixel values of the transition are corrected, has sections with different gradients, in particular two gradients which differ substantially from zero, undesirable aliasing effects at the higher frequencies are avoided in the picture.
    </p>
    <p num="10">
      The method can also advantageously be used to improve the colour transitions in a picture signal, as is claimed in Claim 9.
      <br/>
      Aliasing effects at the higher horizontal frequencies of the chrominance signal are less easily visible by the human eye, so that in this case it is possible to simplify the method.
      <br/>
      A simplified method, which is easy to implement, is claimed in Claim 10.
    </p>
    <p num="11">
      The measure according to Claim 11 leads to a further simplification of the downstream switching units.
      <br/>
      The increase in the number of sample values by a factor of 2 specifically results in the capability to use the same processing clock rate in the downstream circuit parts for processing the luminance and chrominance signals (for example conversion of these signals into corresponding RGB signals).
    </p>
    <heading>DRAWINGS</heading>
    <p num="12">
      Exemplary embodiments of the invention are explained in more detail in the following description, and are illustrated in the drawings, in which:
      <br/>
      FIG. 1 shows the representation of a transfer function for a method for edge gradient increasing in a video signal;
      <br/>
      FIG. 2 shows a processing block for the method for edge gradient increasing in a video signal;
      <br/>
      FIG. 3 shows a rough block diagram for an apparatus for carrying out the method for edge gradient increasing in a video signal;
      <br/>
      FIG. 4 shows a detailed block diagram for a first section of the edge gradient increasing method;
      <br/>
      FIG. 5 shows a detailed block diagram for a second part of the edge gradient increasing method;
      <br/>
      FIG. 6 shows the representation of a transfer function for a method for improving the colour transitions in a video picture;
      <br/>
      FIG. 7 shows a processing block for the method for improving the colour transitions in a video picture;
      <br/>
      FIG. 8 shows a rough block diagram for an apparatus for carrying out the method for improving the colour transitions in a video picture;
      <br/>
      FIG. 9 shows a detailed block diagram for a first section of the method for improving the colour transitions in a video picture;
      <br/>
      FIG. 10 shows a detailed block diagram for a second section of the method for improving the colour transitions in a video picture, and
      <br/>
      FIG. 11 shows a detailed block diagram for a third section of the method for improving the colour transitions in a video picture.
    </p>
    <heading>DESCRIPTION OF THE INVENTION</heading>
    <p num="13">
      The invention will be described first of all on the basis of an example of a picture signal edge correction circuit.
      <br/>
      In the case of video pictures, in particular television pictures, it is generally known for the video signal (composite video signal) to be converted into a luminance signal Y and a chrominance signal C. In the case of the edge correction method used here, the luminance signal Y, which first of all is still in analogue form, is digitized by being sampled and quantized.
      <br/>
      The edge correction is then carried out using digital circuits.
      <br/>
      A precondition in the following text is thus that the luminance signal Y is fed to the edge correction circuit in digital form.
      <br/>
      The reference number 10 in FIG. 1 denotes the general form of a transition in the luminance signal Y. When the luminance signal is output to a colour picture tube, such transitions in the end lead to a representation of an edge in the picture, that is to say it is possible to identify a sudden change from a relatively dark region in the picture to a bright region in the picture.
      <br/>
      The luminance values of the various pixels are shown in the ordinate in FIG. 1.
      <br/>
      Y0 denotes the lowest luminance value.
      <br/>
      Y6 denotes the highest luminance value that occurs.
      <br/>
      The abscissa in FIG. 1 virtually represents a position coordinate, that is to say the numbers of the pixels of a video line are plotted on the X-axis, in which case, for simplicity, the splitting of the luminance signal into different pixels is not illustrated in detail.
      <br/>
      The illustrated transition 10 is formed by relatively few pixel elements (in the order of magnitude of nine pixel elements) .
      <br/>
      The band limiting of the luminance signal (for example to 5 MHz in the case of transmitted television pictures) leads to the loss of the capability to transmit a number of fine details in the luminance signal in more detail, and the transition therefore has the linear profile illustrated in FIG. 1.
      <br/>
      Postprocessing of such transitions is thus desirable in order to increase the contrast at such picture edges.
      <br/>
      The method used here for picture edge correction is carried out by postprocessing the luminance signal in such a manner that the transition has the form denoted by the reference number 11 in FIG. 1.
      <br/>
      The procedure for doing this is as follows: first of all, in a block of adjacent pixel values, those pixels having the minimum and maximum luminance values are determined.
      <br/>
      FIG. 2 shows the processing block relating to this.
      <br/>
      In FIG. 2, Y10 denotes, for example, a pixel value which occurs at the zero position in line 1.
      <br/>
      Accordingly, for example, Y14 denotes the pixel value which occurs in the fifth position in the processing block in line 1.
      <br/>
      Overall, the processing block comprises the nine successive pixel values in a central line and the pixels Y04 and Y24 adjacent to the pixel numbered Y14 in the vertical direction.
      <br/>
      Such a processing block is used to calculate a corrected pixel value for the pixel Y14 located in the centre.
      <br/>
      When calculating the next corrected pixel value, the processing block is in practice shifted such that the pixel which now has the number Y15 is then located in the centre of the new processing block.
    </p>
    <p num="14">
      First of all, the minimum and maximum pixel values in the processing block are determined.
      <br/>
      However, in this case, only the pixel values numbered Y10 to Y18 and Y04 as well as Y24 are considered.
      <br/>
      According to FIG. 1, Y6 is the maximum luminance value that occurs for the pixels, and Y0 is the minimum luminance value that occurs.
      <br/>
      The mean value between the minimum and maximum pixel values is determined in the next step.
      <br/>
      This value corresponds to the value Y3 in FIG. 1.
      <br/>
      The defined mean value Y3 splits the transition into an upper section and a lower section.
      <br/>
      Next, the upper and lower sections are split in a sensible manner into finer sections.
      <br/>
      This is done by determining the greatest difference, in terms of magnitude, between two adjacent pixel values in the processing block.
      <br/>
      The value obtained in this way is also subtracted from the difference between the maximum pixel value Y6 and the minimum pixel value Y0, and the result is divided by four.
      <br/>
      This produces a parameter P by means of which the further splitting of the upper section and lower section of the transition is carried out.
      <br/>
      This results in the split shown in FIG. 1, with the limit values Y1, Y2, Y3, Y4 and Y5.
      <br/>
      A determination is then made as to the lower section in which the processing pixel value Y14 is located.
      <br/>
      Based on this, this processing pixel value is allocated a correction value which is either positive or negative.
      <br/>
      As is shown in FIG. 1, the correction value in the upper sections of the transition is positive while, in contrast, in the lower sections it is negative.
      <br/>
      Finally, the correction value obtained in this way is added to the original processing pixel value Y14.
    </p>
    <p num="15">
      It can clearly be seen from FIG. 1 that, for a luminance value which is located in the section between the values Y5 and Y6, a correction value is determined which allocates a value virtually equal to the luminance value Y6 to the processing pixel value.
      <br/>
      A corresponding situation applies to the section between the luminance values Y0 and Y1.
      <br/>
      In this case, the processing pixel value is allocated a value which corresponds virtually to the luminance value (Y0).
      <br/>
      In the section Y1 to Y2, the processing pixel value is allocated a correction value such that the resultant pixel value virtually lies on a linear function which is shifted downwards and has the same gradient as the original transition.
      <br/>
      A corresponding situation applies once again to the section between the values Y4 and Y5.
      <br/>
      However, in this case, a correction value is determined which shifts the processing pixel value upwards.
      <br/>
      If the luminance value of the processing pixel value is located in the sections between the values Y2 and Y3, a negative correction value is thus determined which maps the processing pixel value onto a linear function which has a gradient which is greater by a factor of 2 than the gradient of the linear function of the original transition.
      <br/>
      This linear function runs through the mean value Y3 of the transition.
      <br/>
      A corresponding situation applies to a processing pixel value which is located in the section between the values Y3 and Y4.
      <br/>
      However, in this case, the processing pixel value is shifted upwards.
      <br/>
      A specific example for a mathematical implementation of the method is quoted below, on the basis of formulae.
      <br/>
      In this case, the allocation of correction values in the various sections is described with the aid of the "if-then-else" instruction.
      <br/>
      This instruction is well known to the person skilled in the art, from many computer programming languages.
      <br/>
      It should be mentioned that the value UC_ER_CTRL used represents a parameter which can be chosen and may assume the integer values from -128 to +127.
      <br/>
      The value to be used here is determined once for the algorithm.
      <br/>
      This optimization of this parameter then takes place during product development, for example for a specific television chassis with a specific colour picture tube.
      <br/>
      For optimum operation, this parameter value will frequently lie in the vicinity of the value 0.
      <br/>
      If the value -128 is chosen for UC_ER_CTRL, this means that the edge gradient increasing function is switched off.
      <br/>
      This can easily be seen from the formula for the intermediate value ER_GAIN and YER.
      <br/>
      The luminance values for Y0 and Y6 in the case of the example under consideration here relate to integer values in the range from 0-128.
    </p>
    <p num="16">Computation algorithm:</p>
    <p num="17">YI=Y14</p>
    <p num="18">
      YO=MIN(Y04, Y10, Y11, Y12, Y13, Y14, Y15, Y16, Y17, Y18, Y24)
      <br/>
      Y6=MAX(Y04, Y10, Y11, Y12, Y13, Y14, Y15, Y16, Y17, Y18, Y24)
      <br/>
      A=.vertline.Y11-Y10.vertline., B=.vertline.Y12-Y11.vertline., C=.vertline.Y13-Y12.vertline.,
      <br/>
      D=.vertline.Y14-Y13.vertline.,
      <br/>
      E=.vertline.Y15-Y14.vertline., F=.vertline.Y16-Y15.vertline., G=.vertline.Y17-Y16.vertline.,
      <br/>
      H=.vertline.Y14-Y10.vertline.,
      <br/>
      I=.vertline.Y24-Y14.vertline., J=.vertline.Y04-Y14.vertline.
    </p>
    <p num="19">
      M=MAX(A, B, C, D, E, F, G, H, I, J)
      <br/>
      Y3=(Y0+Y6)/2
      <br/>
      N=(Y6-Y0)
      <br/>
      P=(N-M)/4
      <br/>
      Y1=Y0+P, Y2=Y3-P, Y4=Y3+P, Y5=Y6-P
    </p>
    <p num="20">
      --
      <br/>
      --              If (Y0&lt;=YI&lt;Y1) DY=Y0-Y1  Gradient 0
      <br/>
      --      else    if (Y1&lt;=YI&lt;Y2) DY=Y0-Y1 = -P Gradient 1
      <br/>
      --      else    if (Y2&lt;=YI&lt;Y3) DY=YI-Y3  Gradient 2
      <br/>
      --      else    if (Y3&lt;=YI&lt;Y4) DY=YI-Y3  Gradient 2
      <br/>
      --      else    if (Y4&lt;=YI&lt;Y5) DY=Y6-Y5 = P Gradient 1
      <br/>
      --      else                     DY=Y6-Y   Gradient 0
      <br/>
      ER_GAIN=MAX(MIN(.vertline.N/2.vertline.+UC_ER_CTRL, 128), 0)
    </p>
    <p num="21">
      Finally:
      <br/>
      YER=YI+((ER_GAIN)*DY)/128
    </p>
    <p num="22">
      The described method is carried out by a circuit in the video signal receiver.
      <br/>
      FIG. 3 shows a rough block diagram of this circuit.
      <br/>
      The reference number 20 denotes the actual correction circuit which carries out the previously described computation algorithm for each processing pixel value.
      <br/>
      The reference number 21 denotes a control register in which the optimized parameter UC_ER_CTRL is entered.
      <br/>
      The reference number 22 denotes a control unit.
      <br/>
      This control unit 22 is used, for example, to programme the parameter UC_ER_CTRL into the control register 21.
      <br/>
      For this purpose, the control unit 22 is connected to the correction circuit 20 via an address, data and control bus 23.
      <br/>
      The correction circuit 20 operates at the same sampling clock rate as that for sampling the analogue signal.
      <br/>
      The corrected pixel values are thus present at the output YOUT of the correction circuit 20 at the same clock rate as is used to read them to the correction circuit 20 via the input YIN.
    </p>
    <p num="23">
      The search for the maximum and minimum luminance values in the processing block and the search for the maximum difference values between two adjacent pixel values are carried out in the correction circuit 20, using a circuit which is illustrated in FIG. 4.
      <br/>
      The reference number 30 virtually denotes a shift register memory in which all the pixel values numbered Y05-Y10 are stored.
      <br/>
      Thus, the pixel value numbered Y10 is present at the output of this circuit.
      <br/>
      The reference number 31 in each case denotes a memory location for a pixel value.
      <br/>
      The luminance values present at the output of the respective stages 31 are in each case indicated at the left-hand edge of the illustration.
      <br/>
      All the stages 30, 31 and 30 are organized as shift register memories.
      <br/>
      The luminance value for the pixel Y24 is then present at the output of the last shift register memory 30.
      <br/>
      The reference number 32 denotes the maximum value selection circuits.
      <br/>
      The first column of maximum value evaluation circuits 32 denotes the selection of the maximum luminance value Y6 in the processing block under consideration.
      <br/>
      The reference number 33 denotes minimum value selection circuits.
      <br/>
      As is indicated in FIG. 4, the column with the minimum value selection circuits 33 determines the minimum luminance value Y0.
      <br/>
      The reference number 34 denotes subtraction and magnitude forming stages.
      <br/>
      One of the values A, B, C-J is calculated in each of the stages.
      <br/>
      The greatest of these values is determined with the aid of the maximum value evaluation circuits 32 in the last column.
      <br/>
      The determined values Y6, Y0, YI and M are thus present at the outputs of the circuit according to FIG. 4.
      <br/>
      These values are passed onto the next processing stage.
    </p>
    <p num="24">
      This next processing stage is illustrated in FIG. 5.
      <br/>
      The reference number 35 in FIG. 5 denotes invertors.
      <br/>
      Adder circuits in FIG. 5 are denoted by the reference number 36.
      <br/>
      Furthermore, a circuit is also indicated which results in addition of the input data, with subsequent division by the value 4.
      <br/>
      These processing stages have the reference number 38.
      <br/>
      The reference number 37 denotes a processing stage which performs addition of the input values and subsequent division by the value 2.
      <br/>
      The reference number 39 denotes a processing stage in which the magnitude of the input value is formed, and this value is divided by 2.
      <br/>
      Finally, the reference number 40 denotes a processing stage in which the input value is divided by the value 128.
      <br/>
      Finally, the reference number 41 also denotes a multiplication stage which multiplies the input values by one another.
      <br/>
      Maximum value selection circuits 32 and minimum value selection circuits 33 are present, once again, as further stages.
      <br/>
      The illustrated circuit carries out the previously described second part of the computation algorithm, so that the corrected luminance value for the processing pixel value Y14 is output at its output YOUT.
      <br/>
      If the circuit in FIG. 5 is considered in more detail, it can be shown that the illustrated structure of maximum value selection circuits and minimum value selection circuits corresponds to the allocation process of the previously described computation algorithm with the "if-then-else" instructions.
    </p>
    <p num="25">
      Next, the method according to the invention will be described using an example of a method for improving colour transitions in a video signal.
      <br/>
      FIG. 6 shows a colour transition.
      <br/>
      The reference number 10 denotes the colour transition in its original form.
      <br/>
      A position coordinate is once again plotted on the abscissa.
      <br/>
      The respective chrominance value of a pixel is in this case illustrated on the ordinate.
      <br/>
      The splitting of the abscissa into pixel values has once again been omitted for the sake of simplicity.
      <br/>
      As is known, the band limiting in the case of the chrominance signals is even more drastic than in the case of the luminance signals.
      <br/>
      The transmission band width for the chrominance element of a television signal is, for example, about 1.3 MHz. However, since the human eye reacts in as highly insensitive manner to colour transitions, the colour transitions do not need to be improved in as complex a manner, in contrast to the luminance transmissions.
      <br/>
      The method proposed here therefore uses a somewhat simplified transfer function.
      <br/>
      The transfer function which is used to correct the colour transitions has the reference number 11 in FIG. 6.
      <br/>
      The reference symbol C0 denotes the minimum chrominance value of the transition.
      <br/>
      The reference number C4 denotes the maximum chrominance value of the transition.
      <br/>
      The reference value C2 denotes the mean value between the maximum chrominance value C4 and the minimum chrominance value C0.
      <br/>
      The mean value C2 is once again used to distinguish between the upper and lower sections of the transition.
      <br/>
      The upper section and the lower section are in this case each split into only two sections.
      <br/>
      Only a sequence of nine successive pixel values in a video line is considered here as the processing block.
      <br/>
      The corresponding processing block is illustrated in FIG. 7.
    </p>
    <p num="26">
      The method used to improve the colour transition is virtually the same as for the previously described edge correction.
      <br/>
      For a current processing pixel value which corresponds to the value C04 in the processing block illustrated in FIG. 7, a determination is once again carried out to find the section in which the transition of the associated chrominance value is located.
      <br/>
      If the chrominance value C04 is located in the section between the values C0 and C1, then it is allocated a negative correction value, which maps the original processing pixel value onto the linear function which is illustrated in FIG. 6 and has a small gradient.
      <br/>
      A corresponding situation applies to a processing pixel value which is located in the section between the chrominance values C3 and C4.
      <br/>
      However, a positive correction value is allocated here.
      <br/>
      For processing pixel values which are located in the section between the chrominance values C1 and C2, values are allocated which map the current processing pixel value onto the linear function which is illustrated in FIG. 6 and has a gradient which is increased by a factor of approximately 4 in comparison with the original transition.
      <br/>
      The negative correction values are allocated in this section.
      <br/>
      In contrast, a corresponding positive correction value is allocated in the first upper section between the chrominance values C2 and C3.
    </p>
    <p num="27">The following text discloses the specific mathematical implementation of the described method for improving colour transitions, on the basis of formulae.</p>
    <p num="28">
      Computation algorithm:
      <br/>
      CI0=C04
      <br/>
      CI1=(C04+C05)/2
      <br/>
      C0=MIN(C00, C01, C02, C03, C04, C05, C06, C07, C08)
      <br/>
      C4=MAX(C00, C01, C02, C03, C04, C05, C06, C07, C08)
      <br/>
      C2=(C0+C4)/2
      <br/>
      N=(C4-C0)
      <br/>
      P=N/8
      <br/>
      C1=C0+P, C3=C4-P
    </p>
    <p num="29">
      --
      <br/>
      --                    If (CO&lt;=CIO&lt;C1) DC0= (C0-CI0)
      <br/>
      --        else        if (C1&lt;=CIO&lt;C2) DC0= 3*(CI0-C2)
      <br/>
      --        else        if (C2&lt;=CIO&lt;C3) DC0= 3*(CI0-C2)
      <br/>
      --        else                             DC0= (C4-CI0)
      <br/>
      --                    If (CO&lt;=CI1&lt;C1) DC1= (CO-CI1)
      <br/>
      --        else        if (C1&lt;=CI1&lt;C2) DC1= 3*(CI1-C2)
      <br/>
      --        else        if (C2&lt;=CI1&lt;C3) DC1= 3*(CI1-C2)
      <br/>
      --        else                             DC1= (C4-CI1)
    </p>
    <p num="30">
      Finally:
      <br/>
      CTI0=CI0+((UC_CTI_GAIN)*DC0)/64
      <br/>
      CTI1=CI1+((UC_CTI_GAIN)*DC1)/64
    </p>
    <p num="31">
      The algorithm is designed such that two chrominance values CTI0 and CTI1 are in each case calculated as output values.
      <br/>
      Two corrective chrominance values are thus present at the output per processing pixel value.
      <br/>
      This doubling of the sampling frequency is carried out in order that the downstream stages can operate at the same clock frequency.
      <br/>
      The increase in the sampling rate ratio in the manner 4:4:4 then specifically corresponds to an increase in the sampling rate of the luminance signal Y in comparison with the colour difference signals U, V, since, as is known, the colour difference signals in the present-day 4:2:2 television systems are obtained at half the sampling rate in comparison with the luminance sampling rate.
      <br/>
      If the output corrected luminance values and chrominance values are now converted into corresponding RGB signals and, finally, are output via D/A converters to the colour picture tube, then this circuit is considerably simplified since the calculation conversions and D/A conversions can all be carried out at the same clock frequency.
    </p>
    <p num="32">The parameter UC_CTI_GAIN used in the computation algorithm is once again used for the purpose of optimizing the method for improving colour transitions in product development for a specific television chassis and a specific colour picture tube.</p>
    <p num="33">
      The circuitry implementation of the method is very similar to the circuitry implementation of the previously described edge correction method.
      <br/>
      FIG. 8 shows the rough block diagram of this circuit.
      <br/>
      The same reference numbers in this case denote the same items as in FIG. 3.
    </p>
    <p num="34">
      FIG. 9 once again shows a first circuit part which is used to determine the maximum and minimum values as well as the intermediate values CI0 and CI1 and the mean value C2.
      <br/>
      Once again, the same reference numbers denote the same components as in FIG. 4.
    </p>
    <p num="35">
      The circuit parts for calculating the output values CTI0 and CTI1 are illustrated in FIGS. 10 and 11. Once again, the reference numbers in these figures are taken from the preceding figures.
      <br/>
      The reference number 42 denotes a multiplier stage which multiplies the input value via the factor -3.
      <br/>
      The reference number 43 denotes a processing stage which divides the input value by the factor 64.
      <br/>
      The method of operation of the two circuit stages can be seen in each case directly from the respective figures.
      <br/>
      The described circuit implementations each represent optimized versions of the method according to the invention.
    </p>
    <p num="36">
      The method may be modified in many ways.
      <br/>
      For example, the processing blocks may be chosen differently for other implementations.
      <br/>
      Thus, the pixel values under consideration may be extended, for example, such that 5, 7 or 9 vertically adjacent pixel values are considered in the processing block.
      <br/>
      The computation algorithms and the corresponding circuit parts must then, of course, also be changed.
      <br/>
      As a transition region, it is also, of course, possible to consider a transition which, contrary to the illustrations in FIGS. 1 and 6, changes from a region with high pixel values to a region with low pixel values.
    </p>
    <p num="37">
      The method can be used in a multiplicity of television signal receivers.
      <br/>
      Alternatively, it can be used for picture improvement measures for computer monitors, etc.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>Method for processing transitional regions in a picture signal, the picture signal comprising a sequence of digital pixel values, comprising the steps of:</claim-text>
      <claim-text>forming a processing block with a processing pixel value for which a corrected pixel value is to be calculated and a number of adjacent pixel values, which surround said processing pixel value; determining the maximum and minimum pixel values in the processing block; defining the transitional region in said processing block by building a group of pixel values inclusive and in between the maximum and minimum pixel values; determining the mean value between the maximum and minimum pixel values; splitting the transitional region into at least one upper and lower section, wherein the mean value represents the border between upper and lower section; assigning the processing pixel value to one of the upper and lower sections or to the mean value; allocating a corresponding correction value to the processing pixel value, in accordance with a predetermined transfer function having at least one corresponding lower and upper section, in order to increase, to reduce or to leave unchanged the processing pixel value.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. Method according to claim 1, further comprising: allocating a positive correction value to the processing pixel value when said processing pixel value is in one of the upper sections of the transition, and allocating a negative correction value to the processing pixel value when said processing pixel value is in one of the lower sections of 35 the transition.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. Method according to claim 1, wherein the edge gradient in the picture signal is increased, and the picture signal corresponds to a luminance signal of a video signal.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. Method according to claim 1, wherein allocating a corresponding correction value comprises: determining the difference between the maximum and minimum pixel values;</claim-text>
      <claim-text>and choosing a correction value as a function of the difference between the maximum and minimum pixel values.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. Method according to claim 1, wherein the step of splitting the transitional region comprises: splitting the transition region into six sections, and the transfer function has an approximately constant profile in the first lower section and the third upper section, having a linear profile at a first gradient in the second lower section and the second upper section, and having a linear profile at a second gradient in the third lower section at the first upper section;</claim-text>
      <claim-text>and choosing the magnitude of first gradient to be less than the magnitude of the second gradient.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. Method according to claim 5, wherein the first gradient corresponds to the gradient of the unprocessed transition and the second gradient corresponds to the gradient of the unprocessed transition increased by a factor of about 2.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. Method according to claim 1, wherein forming a processing block comprises: selecting a matrix of pixel values from three successive video lines each having nine successive pixel values, the processing pixel value being located in the center of the matrix of pixels values.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. Method according to claim 1, wherein color transitions in the picture signal are improved, and the picture signal corresponds to a chrominance signal of a video signal.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. Method according to claim 8, further including: splitting the transitional region into four sections, and the transfer function having a linear profile at a third gradient in the first lower section and the second upper section, and having a linear profile at a fourth gradient in the second lower section and the first upper section;</claim-text>
      <claim-text>and choosing the magnitude of the third gradient to be less than the magnitude of the fourth gradient.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. Method according to claim 9, wherein the fourth gradient corresponds to the gradient of the unprocessed transition increased by a factor of 4.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. Method according to claim 8, wherein the processing block includes nine successive pixel values in a video line and the method further comprises: locating the processing pixel value in the center of the nine pixel values.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. Method according to claim 1, further comprising: calculating a further pixel value (CT11) in addition to the processing pixel value (C04), which further pixel value (CTI1) is located between the processing pixel value (C04) and the subsequent pixel value (COS), in order to improve the resolution of the chrominance signal.</claim-text>
    </claim>
  </claims>
</questel-patent-document>