<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06188791B1.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as first publication">
      <document-id>
        <country>US</country>
        <doc-number>06188791</doc-number>
        <kind>B1</kind>
        <date>20010213</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6188791</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B1</original-publication-kind>
    <application-reference is-representative="YES" family-id="17641994" extended-family-id="27911862">
      <document-id>
        <country>US</country>
        <doc-number>08753687</doc-number>
        <kind>A</kind>
        <date>19961127</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1996US-08753687</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>43177720</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>75368796</doc-number>
        <kind>A</kind>
        <date>19961127</date>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1996US-08753687</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>JP</country>
        <doc-number>28164593</doc-number>
        <kind>A</kind>
        <date>19931015</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1993JP-0281645</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="3">
        <country>US</country>
        <doc-number>32311394</doc-number>
        <kind>A</kind>
        <date>19941014</date>
        <priority-linkage-type>B</priority-linkage-type>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="3">
        <doc-number>1994US-08323113</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010213</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>H04N   5/04        20060101AFI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>04</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G06T   9/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>9</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>H04B   1/66        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>B</subclass>
        <main-group>1</main-group>
        <subgroup>66</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>H04B  14/04        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>B</subclass>
        <main-group>14</main-group>
        <subgroup>04</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="5">
        <text>H04N   1/41        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>41</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="6">
        <text>H04N   7/24        20060101A I20051110RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>7</main-group>
        <subgroup>24</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051110</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="7">
        <text>H04N  19/00        20140101ALI20140317RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>00</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140317</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="8">
        <text>H04N  19/126       20140101ALI20150401RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>126</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150401</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="9">
        <text>H04N  19/134       20140101ALI20150401RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>134</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150401</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="10">
        <text>H04N  19/149       20140101ALI20150401RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>149</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150401</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="11">
        <text>H04N  19/176       20140101ALI20150401RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>176</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150401</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="12">
        <text>H04N  19/196       20140101ALI20150401RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>196</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150401</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="13">
        <text>H04N  19/423       20140101ALI20150401RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>423</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150401</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="14">
        <text>H04N  19/65        20140101ALI20150401RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>65</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150401</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="15">
        <text>H04N  19/70        20140101ALI20150401RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>70</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150401</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="16">
        <text>H04N  19/91        20140101ALI20150401RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>91</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150401</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>382232000</text>
        <class>382</class>
        <subclass>232000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>382246000</text>
        <class>382</class>
        <subclass>246000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>386328000</text>
        <class>386</class>
        <subclass>328000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G06T-009/00T</text>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>009</main-group>
        <subgroup>00T</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-009/007</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>9</main-group>
        <subgroup>007</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>11</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>5</number-of-drawing-sheets>
      <number-of-figures>5</number-of-figures>
      <image-key data-format="questel">US6188791</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Image processing apparatus</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>IINUMA KAZUMOTO</text>
          <document-id>
            <country>US</country>
            <doc-number>4534055</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4534055</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>KURODA HIDEO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4603347</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4603347</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>SCHAPHORST RICHARD A, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4729020</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4729020</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>AONO TOMOKO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5109451</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5109451</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>JURI TATSURO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5272528</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5272528</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>JURI TATSURO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5329375</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5329375</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>OGURO MASAKI</text>
          <document-id>
            <country>US</country>
            <doc-number>5349384</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5349384</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>NISHINO MASAKAZU, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5351131</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5351131</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="9">
          <text>SAKAMOTO TAKAYUKI</text>
          <document-id>
            <country>US</country>
            <doc-number>5398067</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5398067</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <related-documents>
      <continuation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>32311394</doc-number>
              <kind>A</kind>
              <date>19941014</date>
            </document-id>
            <parent-status>ABANDONED</parent-status>
          </parent-doc>
        </relation>
      </continuation>
    </related-documents>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Canon Kabushiki Kaisha</orgname>
            <address>
              <address-1>Tokyo, JP</address-1>
              <city>Tokyo</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>CANON</orgname>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Takizawa, Hiroshi</name>
            <address>
              <address-1>Yokohama, JP</address-1>
              <city>Yokohama</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Fitzpatrick, Cella, Harper &amp; Scinto</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Couso, Jose L.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      An image processing apparatus includes an input device for inputting image data, a coder for variable-length-coding the image data input by the input device, and an adder for adding sync information as to the location of an image sync signal in the image data to the variable-length-coded image data.
      <br/>
      The invention also relates to an image processing apparatus for reproducing variable-length-coded image data with which sync information indicating the location of the image sync signal of the image data is transmitted.
      <br/>
      The apparatus includes a decoder for decoding the variable-length-coded image data, a detector for detecting the sync information indicating the location of an image sync signal, and an output device for outputting the image data decoded by the decoder in accordance with an output from the detector.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <p num="1">
      This application is a continuation application of application Ser.
      <br/>
      No. 08/323,113 filed Oct. 14, 1994, now abandoned.
    </p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="2">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="3">The present invention relates to an image processing apparatus and, more particularly, to instantaneous reproduction of variable-length-coded image data.</p>
    <p num="4">2. Description of the Related Art</p>
    <p num="5">An image coding apparatus for quantizing input image data and variable-length-coding the quantized image data so as to correspond to a transmission speed is conventionally known.</p>
    <p num="6">FIG. 1 is a block diagram showing an image coding apparatus for performing variable length coding by controlling the data amount to be generated during a next unit time T (s) in accordance with a generated data amount N �bits� per unit time T �s�.</p>
    <p num="7">
      The image coding apparatus shown in FIG. 1 comprises a quantization circuit 12, a variable length coding circuit 13, a buffer memory 14, a redundancy code addition circuit 15, and a data amount detection/control circuit 16.
      <br/>
      Image data S1 input from an input terminal 11 is converted into quantized data S2 by the quantization circuit 12.
      <br/>
      This quantized data S2 is supplied to the variable length coding circuit 13 and is coded into data having a target data amount in accordance with a coding parameter S3 supplied from the data amount detection/control circuit 16.
    </p>
    <p num="8">
      Coded data S4 is temporarily stored in the buffer memory 14, and then added with an error correction code, a transmission sync signal, a control code, and the like in the redundancy code addition circuit 15.
      <br/>
      The resultant data is output as redundancy-code-added data S5 from an output terminal 17.
    </p>
    <p num="9">The data amount detection/control circuit 16 outputs the coding parameter S3 on the basis of a detection signal S6 for detecting the amount of data stored in the buffer memory 14 and determines the target data amount of the coded data S4 output from the variable length coding circuit 13.</p>
    <p num="10">FIG. 2 is a view showing the data amount generated when the image coding apparatus in FIG. 1 controls the generated data amount using one frame time as the unit time T �s�.</p>
    <p num="11">
      For example, if data amounts generated during the frame times �s� of the first to nth frames are defined as N1 to Nn, �bits�, respectively, the generated data amount is controlled such that m frames have a data amount which is m times a reference data amount �(total transmission amount - redundancy data amount)/frame count per second�. FIG. 2 exemplifies a case for m=3.
      <br/>
      The data amount of the first frame is N1 �bits�; the data amount of the second frame, N2 ; and the data amount of the third frame, N3.
      <br/>
      As can be apparent from FIG. 2, when data amount control of the image data is performed as described above, the data amounts of the respective frame images are not equal to each other.
    </p>
    <p num="12">When variable-length-coded image data as described above is to be received and decoded, an implementation for reproducing the sync frequency of an image signal is required at the receiving end because the transmission clock frequency which determines the transmission speed is asynchronous with the sync frequency of the image signal.</p>
    <p num="13">More specifically, as shown in FIG. 2, a data end code (EOB) is added to the end of the image data of each frame, the EOB is detected at the receiving end, and the reproduction sync frequency at the transmitting end is reproduced in accordance with a phase-locked loop using the frame frequency as a reference.</p>
    <p num="14">According to this method, however, the variable range of data amount control at the transmitting end cannot be widened because limitations are imposed by the lock range of the phase-locked loop.</p>
    <p num="15">
      In above method the convergence time of the phase-locked loop is long because the frame frequency serves as a reference.
      <br/>
      Therefore, the method cannot instantaneously cope with trouble caused by the hit of a sync signal or the like.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="16">The present invention has been made in consideration of the above situation and has as its object to provide an image processing apparatus capable of instantaneously reproducing an image sync frequency of the transmitting end at the receiving end even if the image data amount generated in each frame greatly varies.</p>
    <p num="17">In order to achieve the above object, according to an aspect of the present invention, there is provided an image processing apparatus comprising input means for inputting image data, coding means for performing variable length coding of the image data input from the input means, and addition means for adding frequency information of an image sync signal of the image data to the variable-length-coded image data.</p>
    <p num="18">In order to achieve the above object, according to another aspect of the present invention, there is provided an image processing apparatus for reproducing variable-length-coded image data with which frequency information of an image sync signal of the image data is transmitted, comprising decoding means for decoding the variable-length-coded image data, detection means for detecting the frequency information of the transmitted image sync signal, and reproduction means for reproducing the image sync signal in accordance with an output from the detection means.</p>
    <p num="19">
      Other objects, features and advantages of the invention will become apparent from the following detailed description taken in conjunction with the accompanying drawings.
      <br/>
      BRIEF DESCRIPTION OF THE DRAWINGS
      <br/>
      FIG. 1 is a block diagram of a conventional image coding apparatus;
      <br/>
      FIG. 2 is a view for explaining the data amount of one frame which is generated by variable length coding;
      <br/>
      FIG. 3 is a block diagram of an image coding apparatus according to an embodiment of the present invention;
      <br/>
      FIG. 4 is a block diagram showing the arrangement of a transmission frame according to the embodiment; and
      <br/>
      FIG. 5 is a block diagram of an image decoding apparatus according to the embodiment of the present invention.
    </p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT</heading>
    <p num="20">The preferred embodiment of the present invention will be described below with reference to the accompanying drawings.</p>
    <p num="21">FIG. 3 is a block diagram of an image coding apparatus for controlling the data amount to be generated during a next unit time T �s� to variable-length-code an image in accordance with a generated data amount N �bits� per unit time T �s�.</p>
    <p num="22">FIG. 4 is a view showing the arrangement of a transmission frame according to this embodiment.</p>
    <p num="23">
      A data transmission format according to this embodiment is constituted by unit transmission frames 301 obtained by dividing a total transmission code amount N �bits� per second by n. The data amount of the unit transmission frame 301 is N/n �bits�. Each unit transmission frame 301 is constituted by small transmission blocks 302 obtained by dividing each unit transmission frame by 16.
      <br/>
      Each small transmission block 302 comprises a transmission sync signal 311, image frequency information 312, coded image data 314, and an error correction code 315.
    </p>
    <p num="24">
      Referring to FIG. 3, a digital image signal input from an input terminal 100 is formed into blocks by a block forming circuit 110.
      <br/>
      Each block consists of 8 * 8 pixels.
    </p>
    <p num="25">
      The block forming circuit 110 also forms the input digital image signal into block data S100 (to be referred to as macroblocks S100 hereinafter) each serving as a coding process unit consisting of 16 * 16 pixels.
      <br/>
      The macroblock S100 is supplied to a mode discrimination circuit 120, an operation circuit 130, and a prediction value calculation circuit 140.
    </p>
    <p num="26">
      The mode discrimination circuit 120 calculates the data powers of the macroblock data S100 and difference value data S102 obtained by subtracting prediction data S101 generated by the prediction value calculation circuit 140 from the macroblock data S100 output from the operation circuit 130.
      <br/>
      A switch 150 selects macroblock data S103 having a lower power (i.e., data having a smaller generated information amount).
      <br/>
      The data S103 is then supplied to a DCT (Discrete Cosine Transform) circuit 160.
    </p>
    <p num="27">
      When the following coding is performed using the macroblock data S100, intraframe coding is performed.
      <br/>
      When the following coding is performed using the difference value data S102, interframe coding is performed.
    </p>
    <p num="28">In units of blocks (8 * 8), the DCT circuit 160 performs DCT of the data S103 selected by the mode discrimination circuit 120.</p>
    <p num="29">DCT data S104 is quantized by a quantization circuit 170, and quantized data S105 is output.</p>
    <p num="30">The quantized data S105 is input to a variable length coding circuit 180.</p>
    <p num="31">In the variable length coding circuit 180, the amounts of data generated in units of macroblocks are different from each other because the input data is variable-length-coded.</p>
    <p num="32">Therefore, a coded data amount obtained by coding one-frame image data in one frame is different from that in another frame.</p>
    <p num="33">Coded data S106 from the variable length coding circuit 180 is supplied to a buffer memory 190.</p>
    <p num="34">
      A code amount control circuit 200 detects the data occupancy rate of the buffer memory 190 and feeds back the data occupancy rate to the quantization circuit 170 and an inverse quantization circuit (not shown) in the prediction value calculation circuit 140, thereby controlling the quantization step.
      <br/>
      That is, the quantization step is controlled such that the data occupancy rate is set at an occupancy rate within a predetermined range.
    </p>
    <p num="35">Output data S107 from the buffer memory 190 is supplied to a formatter circuit 210.</p>
    <p num="36">The formatter circuit 210 forms a transmission frame (FIG. 4) for the output data S107 output from the buffer memory 190 and outputs the transmission frame from an output terminal 240.</p>
    <p num="37">The transmission sync signal 311 (a sync signal for block synchronization) shown in FIG. 4 is generated inside the formatter circuit 210.</p>
    <p num="38">The formatter circuit 210 receives an error correction code generated by an error correction coding circuit 220 for the coded image data.</p>
    <p num="39">The formatter 210 also receives the frequency information of the image sync signal which is generated by a frequency information generation circuit 230.</p>
    <p num="40">The frequency information of the image sync signal represents a leading edge position (position along the time base) of an image frame frequency signal or a signal (to be referred to as a 30 * k (where k is an integer) signal hereinafter) having a frequency of 30 * k and phase-locked at a frequency k times a frequency of 30 Hz.</p>
    <p num="41">
      In this case, the condition n/N&lt;1/(30 * k) is satisfied.
      <br/>
      The 30 * k frequency signal is used since the image data has a frame frequency of 30 Hz.
      <br/>
      For example, if the frame frequency is 25 Hz, a 25 * k frequency signal is used.
    </p>
    <p num="42">The contents of the frequency information of this image sync signal are determined upon a comparison between the unit transmission frame and the image frame frequency or 30 * k signal as a function of time as follows.</p>
    <p num="43">(1) One bit is assigned to indicate whether a leading edge of a clock of the image frame frequency signal or the 30 * k frequency signal is present within the unit transmission frame 301.</p>
    <p num="44">(2) One bit is assigned to indicate whether the signal present within the unit transmission frame 301 is the image frame frequency signal or the 30 * k frequency signal.</p>
    <p num="45">(3) Four bits are assigned to indicate a specific leading edge position, as to one of 16 small transmission blocks No. 1 to No. 16 in the unit transmission frame 301, of the clock of the image frame frequency signal or the 30 * k frequency signal present within the unit transmission frame 301.</p>
    <p num="46">A total of six bits as described above are inserted into the frequency information 312 area of the image sync signal in the small transmission block 302, and the resultant frame is transmitted.</p>
    <p num="47">A decoding apparatus for decoding data coded by the coding apparatus shown in FIG. 3 and transmitted to a receiving end will be described with reference to FIG. 5.</p>
    <p num="48">Referring to FIG. 5, transmitted data is stored in an input buffer memory 401 in accordance with the transmission sync signal 311 (FIG. 4) added to the transmitted data.</p>
    <p num="49">After the transmitted data is stored in the input buffer memory 401, a data transmission error of the stored data is corrected by an error correction circuit 402.</p>
    <p num="50">The error correction circuit 402 performs error correction on the basis of an error correction code 315 (FIG. 4) transmitted together with the image data.</p>
    <p num="51">The error-corrected image data is supplied to a variable length decoding circuit 403, which then performs variable length decoding.</p>
    <p num="52">The image data decoded by the variable length decoding circuit 403 is supplied to an inverse quantization circuit 404.</p>
    <p num="53">The inverse quantization circuit 404 performs inverse quantization on the basis of quantization step information output from a quantization step detection circuit 405.</p>
    <p num="54">The quantization step detection circuit 405 detects quantization step information transmitted together with the image data and outputs the quantization step information.</p>
    <p num="55">The inversely quantized data is supplied to an inverse DCT circuit 406 and is subjected to inverse DCT.</p>
    <p num="56">
      The inverse DCT image data is input to an addition circuit 407.
      <br/>
      The addition circuit 407 adds the image data output from a prediction data detection circuit 408 and the image data output from the inverse DCT circuit 406.
    </p>
    <p num="57">A switch 409 switches between the image data output from the addition circuit 407 and the image data output from the inverse DCT circuit 406 in accordance with an output from a mode detection circuit 410 and outputs the selected data to an output buffer memory 411.</p>
    <p num="58">The mode detection circuit 410 detects information associated with a coding mode transmitted together with the image data and controls the switch 409 on the basis of this detection result.</p>
    <p num="59">The prediction data detection circuit 408 detects motion information transmitted together with the image data and generates prediction data.</p>
    <p num="60">The output buffer memory 411 outputs the image data in synchronism with the image sync signal.</p>
    <p num="61">The output buffer memory 411 receives information associated with the image sync signal output from a frequency information detection circuit 412 and outputs the image data on the basis of this information.</p>
    <p num="62">The frequency information detection circuit 412 detects the frequency information 312 (FIG. 4) transmitted together with the image data to instantaneously obtain an image sync signal matching the transmitted image data.</p>
    <p num="63">As described above, at the receiving end for receiving transmitted data, the frequency information 312 is detected, and the image frame frequency signal is instantaneously reproduced by a phase-locked loop having 30 * k �Hz� as a reference frequency.</p>
    <p num="64">In addition, an image signal phase-locked with respect to the transmitting end can be reproduced because the leading edge position of the image frame frequency signal is clear.</p>
    <p num="65">Various changes and modifications may be made without departing from the spirit and scope of the present invention.</p>
    <p num="66">
      For example, the unit transmission frame 301 is divided into 16 small blocks in the above embodiment in FIG. 4.
      <br/>
      However, the number of blocks and the insertion position of the frequency information of the image sync signal are not limited to the ones described in the above embodiment.
    </p>
    <p num="67">In other words, the foregoing description of embodiments has been given for illustrative purposes only and not to be construed as imposing any limitation in every respect.</p>
    <p num="68">The scope of the invention is, therefore, to be determined solely by the following claims and not limited by the text of the specifications and alterations made within a scope equivalent to the scope of the claims fall within the true spirit and scope of the invention.</p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>An image processing apparatus comprising:</claim-text>
      <claim-text>a) an inputter, arranged to input image data; b) an encoder, adapted to encode, using variable length coding, the image data input via the inputter; c) a divider, adapted to divide the variable-length-coded image data into blocks based upon a unit basis of predetermined data amount;</claim-text>
      <claim-text>and d) a data adder, arranged to discriminate whether or not a position in a time base of an image sync signal of the image data lies within the block data, and to add to the block data divided by said divider, addition data representing the discrimination result.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. An apparatus according to claim 1, further comprising a transmitter, adapted to transmit the image data to which the data is added by said data adder.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. An apparatus according to claim 1, wherein said encoder comprises: a) a block former, adapted to form the image data into blocks; b) an orthogonal transformer, adapted to orthogonally transform the block-formed image data;</claim-text>
      <claim-text>and c) a quantizer, adapted to quantize the orthogonally transformed image data.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. An apparatus according to claim 1, wherein said encoder performs the variable length coding in accordance with a transmission speed.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. An apparatus according to claim 1, wherein the image sync signal is a horizontal sync signal or a vertical sync signal.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. An image processing apparatus comprising: a) an inputter, adapted to input variable-length-coded image data divided into block data based upon a unit basis of predetermined data amount, said inputter inputting addition data representing whether or not a position in a time base of an image sync signal of the image data lies within the block data; b) a decoder. adapted to decode the variable-length-coded image data; c) a detector, adapted to detect the addition data;</claim-text>
      <claim-text>and d) an outputter, arranged to output the image data decoded by said decoder in accordance with an output from said detector.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. An apparatus according to claim 6, wherein the image sync signal is a horizontal sync signal or a vertical sync signal.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. An image processing apparatus comprising: a) an inputter, adapted to input image data; b) an encoder, adapted to encode, using variable length coding, the image data input by said inputter; c) a divider, adapted to divide the variable-length-coded image data into a plurality of blocks;</claim-text>
      <claim-text>and d) a data adder, adapted to discriminate whether or not a position in a time base of an image sync signal of the image data lies within the block data, and to add to the block data divided by said divider, addition data representing the discrimination result.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. A method of processing image data comprising the steps of: a) inputting image data; b) variable length coding the image data input in said inputting step; c) dividing the variable-length-coded image data into blocks based upon a unit basis of predetermined data amount;</claim-text>
      <claim-text>and d) discriminating whether or not a position in a time base of an image sync signal of the image data lies within the block data, and adding to the block data divided in said dividing step, addition data representing the discrimination result.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. A method of processing image data comprising the steps of: a) inputting variable-length-coded image data divided into block data based upon a unit basis of predetermined data amount, said inputting step inputting addition data representing whether or not a position in a time base of an image sync signal of the image data lies within the block data; b) decoding the variable-length-coded image data; c) detecting the addition data;</claim-text>
      <claim-text>and d) outputting the image data decoded in said decoding step in accordance with an output obtained in said detecting step.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. A method of processing image data comprising the steps of: a) inputting image data; b) variable length coding the image data input in said inputting step; c) dividing the variable-length-coded image data into a plurality of blocks;</claim-text>
      <claim-text>and d) discriminating whether or not a position in a time base of an image sync signal of the image data lies within the block data, and adding to the block data divided in said dividing step, addition data representing the discrimination result.</claim-text>
    </claim>
  </claims>
</questel-patent-document>