<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06184933B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06184933</doc-number>
        <kind>B2</kind>
        <date>20010206</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6184933</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="16581357" extended-family-id="23736016">
      <document-id>
        <country>US</country>
        <doc-number>08978009</doc-number>
        <kind>A</kind>
        <date>19971125</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1997US-08978009</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>43170823</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>97800997</doc-number>
        <kind>A</kind>
        <date>19971125</date>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1997US-08978009</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>JP</country>
        <doc-number>20995094</doc-number>
        <kind>A</kind>
        <date>19940902</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1994JP-0209950</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="3">
        <country>US</country>
        <doc-number>52074295</doc-number>
        <kind>A</kind>
        <date>19950829</date>
        <priority-linkage-type>B</priority-linkage-type>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="3">
        <doc-number>1995US-08520742</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010206</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>H04N   5/232       20060101AFI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>232</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>H04N   5/235       20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>235</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>H04N   9/04        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>9</main-group>
        <subgroup>04</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>348364000</text>
        <class>348</class>
        <subclass>364000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>348280000</text>
        <class>348</class>
        <subclass>280000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>348296000</text>
        <class>348</class>
        <subclass>296000</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>348312000</text>
        <class>348</class>
        <subclass>312000</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>348347000</text>
        <class>348</class>
        <subclass>347000</subclass>
      </further-classification>
      <further-classification sequence="5">
        <text>348E05035</text>
        <class>348</class>
        <subclass>E05035</subclass>
      </further-classification>
      <further-classification sequence="6">
        <text>348E05036</text>
        <class>348</class>
        <subclass>E05036</subclass>
      </further-classification>
      <further-classification sequence="7">
        <text>348E09010</text>
        <class>348</class>
        <subclass>E09010</subclass>
      </further-classification>
      <further-classification sequence="8">
        <text>396096000</text>
        <class>396</class>
        <subclass>096000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>H04N-005/235B</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>005</main-group>
        <subgroup>235B</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>H04N-005/235C</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>005</main-group>
        <subgroup>235C</subgroup>
      </classification-ecla>
      <classification-ecla sequence="3">
        <text>H04N-009/04B</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>009</main-group>
        <subgroup>04B</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-005/2351</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>2351</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-005/2352</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>2352</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-009/045</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>9</main-group>
        <subgroup>045</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>10</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>4</number-of-drawing-sheets>
      <number-of-figures>4</number-of-figures>
      <image-key data-format="questel">US6184933</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Image pickup apparatus wherein plural elements simultaneously pick up the image and the state of the incident</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>DISCHERT ROBERT A</text>
          <document-id>
            <country>US</country>
            <doc-number>4599640</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4599640</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>KIMURA KENJI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4599653</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4599653</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>SUZUKI NOBUO</text>
          <document-id>
            <country>US</country>
            <doc-number>4843474</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4843474</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>KONDO SHIGERU, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5081535</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5081535</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>TSURUTA MASAAKI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5307158</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5307158</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>TANI NOBUHIRO</text>
          <document-id>
            <country>US</country>
            <doc-number>5379069</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5379069</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>AOKI HARUMI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5418564</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5418564</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>SAKAMOTO YUKIO</text>
          <document-id>
            <country>US</country>
            <doc-number>5436660</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5436660</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="9">
          <text>IWASAKI HIROYUKI</text>
          <document-id>
            <country>US</country>
            <doc-number>5515132</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5515132</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="10">
          <text>YAMAMOTO YASUHIRO</text>
          <document-id>
            <country>US</country>
            <doc-number>5526048</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5526048</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="11">
          <text>TSUKUI AKIMI</text>
          <document-id>
            <country>US</country>
            <doc-number>5589880</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5589880</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="12">
          <text>MIYADERA SHUNICHI</text>
          <document-id>
            <country>US</country>
            <doc-number>5619260</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5619260</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="13">
          <text>ITO KAZUHIKO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5914755</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5914755</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="14">
          <text>SUGA AKIRA, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5363137</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5363137</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="15">
          <text>MATSUSHITA ELECTRIC IND CO LTD</text>
          <document-id>
            <country>JP</country>
            <doc-number>H043670</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP04003670</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="16">
          <text>CANON KK</text>
          <document-id>
            <country>JP</country>
            <doc-number>H04212577</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP04212577</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="1">
          <text>Yoshihiro Fujita, et al., "An HDTV 2/3-inch CCD Hand-held Camera Employing Dual-green Spacially Offset Image Pickup Method," J. Telev. Soc., vol. 47, No. 2, 1993 (with English Abstract).</text>
        </nplcit>
      </citation>
    </references-cited>
    <related-documents>
      <continuation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>52074295</doc-number>
              <kind>A</kind>
              <date>19950829</date>
            </document-id>
            <parent-status>ABANDONED</parent-status>
          </parent-doc>
        </relation>
      </continuation>
    </related-documents>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Canon Kabushiki Kaisha</orgname>
            <address>
              <address-1>Tokyo, JP</address-1>
              <city>Tokyo</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>CANON</orgname>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Ogura, Shigeo</name>
            <address>
              <address-1>Tokyo, JP</address-1>
              <city>Tokyo</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Fitzpatrick, Cella, Harper &amp; Scinto</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Garber, Wendy</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      An image pickup apparatus wherein plural elements simultaneously pick up the image and the state of the incident light includes a plurality of image pickup elements for generating an object image signal on the basis of a signal output from at least one of the plurality of image pickup elements, and for generating an incident light state signal on the basis of a signal from another image pickup element having substantially the same photographing region as a photographing region of said at least one image pickup element which generates the object image signal.
      <br/>
      A read-out period for one frame of said at least one image pickup element which generates the object image signal being different from the read-out period for one frame of said another image pickup signal which generates the incident light state signal.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <p num="1">
      This application is a continuation of application Ser.
      <br/>
      No. 08/520,742, filed Aug. 29, 1995, now abandoned.
    </p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="2">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="3">The present invention relates to image pickup apparatus and, more particularly, to an apparatus which is suitably used in a so-called multi-element image pickup device which picks up an object image using a plurality of image pickup elements.</p>
    <p num="4">2. Related Background Art</p>
    <p num="5">
      A conventional video camera reproduces a picked-up image on a television screen.
      <br/>
      For this reason, the recording rate of the video camera is determined to be a predetermined value.
      <br/>
      For example, in the case of the NTSC system, 60 fields (frames) of images are recorded per second.
      <br/>
      More specifically, an exposure is performed in 1/60 sec, and an image signal is read out and recorded in the next 1/60 sec.
    </p>
    <p num="6">On the other hand, upon detection of the state of incident light for auto-focus (to be abbreviated as AF hereinafter) control, auto-exposure (to be abbreviated as AE hereinafter) control, and the like, a signal for a photographing operation is read out, and thereafter, required data is fed back from this signal to control the iris and the lens driving operation.</p>
    <p num="7">
      For example, photometry for the AE control is performed based on a signal obtained by averaging, by an integrator, a plurality of frames of (three to four frames) of signals, which are output from an image pickup element and are amplified by an amplifier.
      <br/>
      On the other hand, in the AF control, a high-frequency component of a signal of each field is extracted, and the lens is controlled to maximize the extracted component.
    </p>
    <p num="8">Japanese Laid-Open Patent Application No. 4-212577 discloses a technique for performing two or more AF scans per field period by setting the read-out range in the vertical direction to be a portion of a photographing screen including a distance measurement frame.</p>
    <p num="9">
      As described above, the video camera can control the iris and lens only after a signal exposed in one field period (1/60 sec) is read out for one field period.
      <br/>
      For this reason, since the video camera cannot quickly respond to an abrupt movement of an object or an abrupt change in brightness, the photographed image often becomes too dark or bright.
    </p>
    <p num="10">
      For the same reason as above, the focal point cannot often be adjusted to an object which moves abruptly.
      <br/>
      When a photographing light beam is split by, e.g., a prism, and is received by AE and AF sensors different from the image pickup element, the amount of light guided to the image pickup element for a photographing operation decreases, resulting in deterioration of image quality and an increase in cost.
    </p>
    <p num="11">
      In the technique proposed by Japanese Laid-Open Patent Application No. 4-212577, since a signal read out from the image pickup element corresponds to a portion of the screen, the signal cannot be used in a photographing operation.
      <br/>
      Therefore, in this case, since a photographing operation is started after the end of the AF operation, an image to be photographed cannot be confirmed during the AF operation, and the time required until the photographing operation is started is long, resulting in a large time lag.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="12">The present invention has been made in consideration of the above-mentioned problems, and has as its object to provide an image pickup device which can simultaneously perform an image pickup operation of an object image and detection of the state of incident light.</p>
    <p num="13">It is another object of the present invention to provide an image pickup device which can prevent an image in a finder from being interrupted during a photographing operation.</p>
    <p num="14">
      An image pickup device according to an embodiment of the present invention has a plurality of image pickup elements.
      <br/>
      An object image signal is generated on the basis of a signal output from at least one of these image pickup elements, and the state of incident light is detected on the basis of a signal from another image pickup element having substantially the same photographing region as that of the image pickup element used for generating the object image.
    </p>
    <p num="15">As another feature of the present invention, the image pickup element for generating the object image has an exposure amount different from the image pickup element used for detecting the state of incident light.</p>
    <p num="16">As still another feature of the present invention, the read-out time or read-out interval (or cycle) per frame of the image pickup element for generating the object image is different from that of the image pickup element used for detecting the state of incident light.</p>
    <p num="17">As still another feature of the present invention, the effective read-out range of the image pickup element for generating the object image is different from that of the image pickup element used for detecting the state of incident light.</p>
    <p num="18">As still another feature of the present invention, the image pickup device has a plurality of image pickup elements, and has a first mode for detecting the state of incident light on the basis of a signal from at least one of these image pickup elements, and a second mode for photographing an object image using at least two of the plurality of image pickup elements.</p>
    <p num="19">As still another feature of the present invention, the first and second modes are selected by single operation means.</p>
    <p num="20">
      Since the embodiment of the present invention has the above-mentioned technical means, generation of an object image and detection of the state of incident light can be simultaneously performed.
      <br/>
      Therefore, the state of incident light can be detected at the position and time of an image to be photographed which are independent from the read-out state of the image to be photographed such as the read-out range, read-out time or read out interval (or cycle) recording rate, and the like of the image to be photographed while photographing an image or while confirming an object as a finder image.
    </p>
    <p num="21">
      According to other features of the present invention, since the device has the first mode for detecting the state of incident light on the basis of a signal from at least one image pickup element and the second mode for photographing an object image using at least two image pickup elements, a case wherein the AE control, AF control, and the like are performed at high speed, a case wherein the recording capacity is to be reduced, and a case wherein an image is to be photographed with higher image quality can be desirably selected.
      <br/>
      In addition, the time lag upon switching from the first mode to the second mode can be reduced.
    </p>
    <p num="22">The above and other features and objects of the present invention will become apparent from the following description taken in conjunction with the accompanying drawings.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="23">
      FIG. 1 is a block diagram of an image pickup device according to the first embodiment of the present invention;
      <br/>
      FIG. 2 is a timing chart for explaining the operation of the image pickup device according to the first embodiment of the present invention;
      <br/>
      FIG. 3 is an explanatory view of the method of reading out signals from a partial region of an image pickup element; and
      <br/>
      FIG. 4 is a timing chart for explaining the operation of an image pickup device according to the second embodiment of the present invention.
    </p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
    <p num="24">An image pickup device according to an embodiment of the present invention will be described below with reference to the accompanying drawings.</p>
    <p num="25">FIG. 1 is a block diagram which best illustrates the features of the first embodiment of an image pickup device according to the present invention.</p>
    <p num="26">
      Referring to FIG. 1, an image pickup unit 1 of a camera comprises a photographing optical system 2 which includes an iris, a zooming lens, a focusing lens, and the like.
      <br/>
      The photographing optical system 2 is driven by a drive control circuit 3.
      <br/>
      First, second, and third image pickup elements 4a, 4b, and 4c are arranged around the photographing optical system 2.
    </p>
    <p num="27">The image pickup unit 1 also comprises a prism 5 for splitting an object image toward the first to third image pickup elements 4a to 4c, a first driving circuit 6 for driving the first image pickup element 4a, a second driving circuit 7 for driving the second and third image pickup elements 4b and 4c, amplifiers 8, A/D converters 9, process circuits 10, and a memory 11.</p>
    <p num="28">
      The image pickup unit 1 further comprises a digital signal processor (DSP) 12, an image display unit 13, a recording unit 14, a switch 15, a light amount detection circuit 16, and a high-frequency component detection circuit 17.
      <br/>
      The image pickup unit 1 is connected to a system controller 18 to which a release switch 19 is connected.
    </p>
    <p num="29">
      In the image pickup device of this embodiment with the above arrangement, an optical image from an object is incident into the prism 5 via the photographing optical system 2.
      <br/>
      The optical image is split by the prism 5, and the split images are imaged on the image pickup elements 4a, 4b, and 4c.
    </p>
    <p num="30">
      Red (R), blue (B), and green (G) filters are respectively adhered to these image pickup elements 4a, 4b, and 4c.
      <br/>
      In this embodiment, the image pickup elements 4b and 4c are driven by the single driving circuit 7.
    </p>
    <p num="31">
      One of a state wherein a signal output from the first image pickup element 4a, which is driven by the first driving circuit 6, is output to the light amount detection circuit 16 and the high-frequency component detection circuit 17 (to be referred to as state 1 hereinafter) and a state wherein the signal from element 4a is output to the memory 11 via the amplifier 8, the A/D converter 9, and the process circuit 10 (to be referred to as state 2 hereinafter) is selected depending on the state of the switch 15.
      <br/>
      The state of the switch 15 is controlled by a signal output from the system controller 18.
    </p>
    <p num="32">
      When state 1 is selected, an R signal from the first image pickup element 4a is input to the system controller 18 via the light amount detection circuit 16 and the high-frequency component detection circuit 17.
      <br/>
      The light amount detection circuit 16 outputs a signal obtained by integrating the light amount of an object image with respect to a signal read out from the first image pickup element 4a for a predetermined period of time.
      <br/>
      The high-frequency component detection circuit 17 detects a high-frequency component from the signal read out from the first image pickup element 4a.
      <br/>
      Based on these signals, the system controller 18 drives the photographing optical system 2 via the drive control circuit 3, thus attaining AE control and AF control.
    </p>
    <p num="33">On the other hand, G and B signals from the second and third image pickup elements 4b and 4c are output to the memory 11 via the amplifiers 8, the A/D converters 9, and the process circuits 10.</p>
    <p num="34">Since data stored in the memory 11 do not include a red (R) signal, only the G signal, for example, is converted into, e.g., an NTSC monochrome video signal by the digital signal processor 12, and is recorded or displayed on a monitor.</p>
    <p num="35">When state 2 is selected, the R, G, and B signals from the three image pickup elements 4a, 4b, and 4c are output to the memory 11 via the amplifiers 8, the A/D converters 9, and the process circuits 10.</p>
    <p num="36">Data stored in the memory 11 are converted into a signal format such as NTSC video signals, which corresponds to the format of the image display unit 13 or the recording unit 14, and the converted signals are recorded or displayed on the monitor.</p>
    <p num="37">The data stored in the memory 11 are input to the above-mentioned light amount detection circuit 16 and high-frequency component detection circuit 17 via the system controller 18 to perform AE control and AF control.</p>
    <p num="38">
      FIG. 2 is a timing chart of the photographing operation of this embodiment.
      <br/>
      The photographing operation will be explained below.
      <br/>
      The release switch 19 changes between states 1 and 2 described above depending on the stroke position of a release button (not shown).
    </p>
    <p num="39">
      When the release switch 19 is depressed and state 1 is detected, exposure of the image pickup elements 4a, 4b, and 4c is started in synchronism with the timing of a vertical sync signal.
      <br/>
      During state 1, the second and third image pickup elements 4b and 4c repeat exposure and read-out operations in synchronism with the vertical sync signal.
    </p>
    <p num="40">
      More specifically, in the case of an NTSC video signal, exposure is performed for a one-field period (1/60 sec), and a signal is read out for the next one-field period.
      <br/>
      The readout signal, e.g., the G signal from the image pickup element 4b, which is suitable for a luminance signal in the NTSC video signal, is displayed on the image display unit 13 as a monochrome reproduced image, which is utilized as, e.g., a finder image.
      <br/>
      Upon recording, since image data for one image pickup element is recorded, the recording capacity can be reduced as compared to image data for the three image pickup elements (to be described later).
    </p>
    <p num="41">
      Referring to FIG. 2, signals A1 and A2 exposed by the third image pickup element 4c are respectively read out as signals X1 and X2.
      <br/>
      Similarly, signals B1 and B2 exposed by the second image pickup element 4b are respectively read out as signals Y1 and Y2.
    </p>
    <p num="42">
      In the NTSC video signal, odd and even fields are alternately read out in units of fields.
      <br/>
      In state 1, a signal exposed on the first image pickup element 4a is exposed for a predetermined exposure time by a read-out method (to be described later), and the predetermined range of a frame is read out at high speed.
    </p>
    <p num="43">In FIG. 2, signals C1, C2, and C3 are respectively read out as signals Z1, Z2, and Z3.</p>
    <p num="44">The readout signals Z1, Z2, and Z3 are supplied to the system controller 18 via the light amount detection circuit 16 and the high-frequency component detection circuit 17, and the system controller 18 performs AE control and AF control, thus driving the iris and the focusing lens.</p>
    <p num="45">More specifically, in order to obtain high AE and AF control speeds, the feedback time is shortened by shortening the exposure times of the signals C1, C2, and C3.</p>
    <p num="46">On the other hand, in order to attain AE control and AF control with high precision, the exposure times of the signals C1, C2, and C3 may be prolonged to increase their exposure amounts, thus improving the S/N ratio of the signals.</p>
    <p num="47">When the release switch 19 is further depressed and state 2 is detected, a photographing operation is performed using all the signals exposed by the three image pickup elements 4a, 4b, and 4c as an NTSC color video signal.</p>
    <p num="48">At this time, since state 1 can be switched to state 2 depending on the stroke position of the single release switch 19, an operator can perform this operation without removing his or her eye from the finder, and can quickly select state 2.</p>
    <p num="49">
      In FIG. 2, after state 1 is switched to state 2, signals A4, B4, and C4 exposed by the third, second, and first image pickup elements 4c, 4b, and 4a are respectively read out as signals X4, Y4, and Z4, and signals A5, B5, and C5 are respectively read out as X5, Y5, and Z5.
      <br/>
      In the mode of state 2, the time lag from when the release switch 19 is depressed to the stroke position for selecting state 2 until the beginning of exposure corresponds to the time required until the next vertical sync signal, i.e., TR in FIG. 2.
    </p>
    <p num="50">
      Therefore, the photographing operation in state 2 is started after a time lag of a one-field period (1/60 sec) or less.
      <br/>
      During the switching period from state 1 to state 2, since signals from the image pickup elements 4b and 4c are exposed and read out, a photographed image can be utilized as a finder image without being interrupted.
    </p>
    <p num="51">Since the signals X4, Y4, and Z4 or X5, Y5, and Z5 read out at the same time are respectively R, G, and B signals, an image for a one-field period is formed on the memory 11, and thereafter, is reproduced or recorded.</p>
    <p num="52">As described above, in state 2, the signals on the memory 11 are supplied to the light amount detection circuit 16 and the high-frequency component detection circuit 17 via the system controller 18 to attain AE control and AF control.</p>
    <p num="53">
      FIG. 3 shows the signal read-out method of the first image pickup element 4a.
      <br/>
      Since this method is disclosed in, e.g., Japanese Laid-Open Patent Application No. 4-3670, a brief explanation thereof will be given below.
      <br/>
      Referring to FIG. 3, a full pixel region 31 represents the maximum photographing field angle of the image pickup element.
      <br/>
      The region 31 includes an effective read-out range 32 for detecting the state of incident light.
      <br/>
      FIG. 3 also illustrates a horizontal CCD transfer signal 33, a high-speed transfer portion 34 of the horizontal CCD transfer signal, a vertical CCD transfer signal 35, and a high-speed transfer portion 36 of the vertical CCD transfer signal.
    </p>
    <p num="54">
      In this case, since a signal from a region other than the effective read-out range 32 of the first image pickup element 4a is not used, high-speed transfer can be realized and the read-out time for one frame can be shortened.
      <br/>
      More specifically, by changing the range of the high-speed transfer portion, an arbitrary region can be selected as the effective read-out range 32 in the full pixel region 31.
      <br/>
      As the effective read-out range 32 becomes smaller, the transfer speed becomes higher.
    </p>
    <p num="55">
      FIG. 4 is a timing chart for explaining the second embodiment of the present invention.
      <br/>
      In FIG. 4, since state 1 is the same as that in FIG. 2 described above, state 2 will be explained below.
    </p>
    <p num="56">When the release switch 19 is depressed to the deep position, and state 2 is detected, the iris is temporarily closed in synchronism with a horizontal sync signal.</p>
    <p num="57">
      Thereafter, the iris is opened to attain a shutter speed TV1 shown in the upper portion in FIG. 4, and the image pickup elements 4a, 4b, and 4c are exposed.
      <br/>
      Signals D1, B4, and A4 exposed by the image pickup elements are respectively read out as signals Z4, Y4, and X4.
    </p>
    <p num="58">
      During the read-out period, the iris is closed to prevent smearing due to noise added during signal transfer, which deteriorates image quality.
      <br/>
      Since no photographing signal is supplied during this period, the latest readout signal, i.e., signal X4 or Y4 is repetitively read out from the memory 11 to prevent interruption of an image display until a new photographing signal is read out.
    </p>
    <p num="59">
      The first image pickup element 4a starts exposure in synchronism with the end of the read-out operation of the signal Z4.
      <br/>
      Since this exposure is performed for AE control and AF control, and signals other than a given region on the image pickup element 4a are transferred at high speed, all pixels can be read out at high speed.
      <br/>
      More specifically, signals C4 and C5 are read out as signals Z4 and Z5, and after the end of AE and AF operations, the iris begins to open to attain a determined shutter speed TV2.
      <br/>
      As a result, the image pickup elements 4a, 4b, and 4c are simultaneously exposed again.
    </p>
    <p num="60">
      In FIG. 4, the time TV2 is longer than the one-field period, so that signals from the image pickup elements are not read out in synchronism with the first vertical sync signal after the beginning of exposure but are read out in synchronism with the next vertical sync signal.
      <br/>
      More specifically, signals D2, B5, and A5 exposed by the three image pickup elements are read out as signals Z7, Y5, and X5.
      <br/>
      In this case, the exposure is started after the iris is closed completely.
      <br/>
      However, the exposure operation may be attained by an electronic shutter using the image pickup elements.
    </p>
    <p num="61">
      In the above description, since a photographed image signal is recorded or reproduced as an NTSC video signal, odd and even fields are alternately read out in the signal read-out operation from the image pickup elements.
      <br/>
      Alternatively, all the pixels may be read out and recorded during a one-field period, and an image may be reproduced on an image display such as a multi-scan monitor for a computer, which can sequentially display all the lines.
    </p>
    <p num="62">Table 1 below summarizes the number of image pickup elements and their color filter arrangements.</p>
    <p num="63">
      --                TABLE 1
      <br/>
      --                Color Filter   State 1            State 2
      <br/>
      -- (1)    3-element G              For Photographing or For Photo-
      <br/>
      --        Type                     Finder             graphing
      <br/>
      --                  R              For State Detection For Photo-
      <br/>
      --                                                    graphing
      <br/>
      --                  B              (For State         For Photo-
      <br/>
      --                                 Detection)         graphing
      <br/>
      -- (2)    3-element R/B            For Photographing or For Photo-
      <br/>
      --        Type                     Finder             graphing
      <br/>
      --                  G1             For Photographing or For Photo-
      <br/>
      --                                 Finder             graphing
      <br/>
      --                  G2             For State Detection For Photo-
      <br/>
      --                                                    graphing
      <br/>
      -- (3)    2-element Complementary  For Photographing or For Photo-
      <br/>
      --        Type      Mosaic (M, G,  Finder             graphing
      <br/>
      --                  C, Y)
      <br/>
      --                  Complementary  For State Detection For Photo-
      <br/>
      --                  Mosaic (M, G,                     graphing
      <br/>
      --                  C, Y)
    </p>
    <p num="64">
      Note that (1) corresponds to a 3-element type image pickup system which uses three image pickup elements respectively adhered with R (red), G (green), and B (blue) filters, as has been described in the above embodiment.
      <br/>
      A signal from one of these image pickup elements is used for detecting the state of incident light, and a photographed image is displayed using signals from the remaining image pickup elements.
    </p>
    <p num="65">In this case, since a color image is formed when all the signals from the three image pickup elements are input, in an image display operation in state 1, i.e., upon detection of the state of incident light using one image pickup element, a photographed image is displayed as a monochrome image using signals from other image pickup elements.</p>
    <p num="66">
      Therefore, a signal used for displaying an image at that time is preferably a signal from the image pickup element with the G filter, which is closest to the luminance component.
      <br/>
      Alternatively, if an importance is to be placed on incident light state detection performance, a signal output from the image pickup element with the G filter may be used for detecting the state of incident light, and an image may be displayed based on a signal from the image pickup element with the R or B filter.
    </p>
    <p num="67">
      Also, (2) similarly corresponds to a 3-element image pickup system.
      <br/>
      In this system, G filters are adhered to two image pickup elements, and a filter having R and B stripes is adhered to the last image pickup element.
      <br/>
      In the image pickup system with this filter arrangement, two out of three image pickup elements (CCDs) adhered to a prism are pixel-displaced from each other to pick up an object image, as described in "High definition television 2/3 Compact CCD Camera Using Dual-green system", Image Information Technology &amp; Broadcast Technique as Journal of Television Society, Vol. 47, No. 2, 1993.
    </p>
    <p num="68">
      In this case, the state of incident light is detected using a signal of one image pickup element with the G filter, and an image is formed based on signals from the remaining two image pickup elements with G and R/B filers.
      <br/>
      Thus, a color image can be displayed or reproduced even in state 1.
    </p>
    <p num="69">
      (3) corresponds to an example of a 2-element image pickup system.
      <br/>
      In this system, complementary mosaic filters of Y (yellow), M (magenta), C (cyan), and G (green), which are used for a video camera, are adhered to the two image pickup elements.
      <br/>
      In state 1, a signal from one of the two image pickup elements is used for detecting the state of incident light, and a signal from the other image pickup element is used for a photographing operation.
    </p>
    <p num="70">
      In this system as well, since a color image can be formed based on a signal from one image pickup element, a color image can be displayed or reproduced in state 1.
      <br/>
      When the two image pickup elements are pixel-displaced, a high-definition image can be photographed in state 2.
    </p>
    <p num="71">
      As described above, according to the first embodiment of the present invention, since an object image is generated on the basis of a signal output from at least one of a plurality of image pickup elements, and the state of incident light is detected on the basis of a signal from another image pickup element having substantially the same photographing region as that of the image pickup element used for generating the object image, the photographing operation of the object image and detection of the state of incident light can be simultaneously attained.
      <br/>
      Thus, while photographing an image or while confirming an object image as a finder image, the state of incident light can be detected at the position and time of an image to be photographed independently of the read-out state of an image to be photographed such as the read-out range, the read-out time or read-out interval (or cycle), and the like with respect to the image to be photographed, and AE control, AF control, and the like of the image to be photographed can be performed on the basis of the detected information.
    </p>
    <p num="72">
      According to another embodiment, the exposure amount of an image pickup element for generating an object image is set to be different from that of an image pickup element for detecting the state of incident light.
      <br/>
      For this reason, when high AE and AF control speeds are to be obtained, the exposure time is shortened to shorten the feedback time, and when AE control and AF control are to be performed with higher precision, the exposure time is prolonged to increase the exposure amount, thereby improving the S/N ratio of a signal.
    </p>
    <p num="73">
      According to still another embodiment, the read-out time or read-out interval (or cycle) for one frame of an image pickup element for generating an object image is set to be different from that of an image pickup element for detecting the state of incident light.
      <br/>
      For this reason, by shortening the read-out time or the read-out interval, information for AE control, AF control, and the like can be fed back at high speed.
    </p>
    <p num="74">
      According to still another embodiment, the effective read-out range of an image pickup element for generating an object image is set to be different from that of an image pickup element for detecting the state of incident light.
      <br/>
      For this reason, by widening the effective read-out range of the image pickup element for detecting the state of incident light, the exposure amount can be increased, thereby improving the S/N ratio of a signal used in detection of the state of incident light.
    </p>
    <p num="75">
      According to still another embodiment, an image pickup device has a plurality of image pickup elements, and has a first mode for detecting the state of incident light on the basis of a signal from at least one of these image pickup elements, and a second mode for photographing an object image using at least two of the plurality of image pickup elements.
      <br/>
      For this reason, a case wherein AE control, AF control, and the like are to be performed at higher speed, a case wherein the recording capacity is to be reduced, and a case wherein an image is to be photographed with higher image quality can be freely selected, and the time lag required upon switching from the first mode to the second mode can be reduced.
      <br/>
      Thus, a finder image can be prevented from being interrupted.
    </p>
    <p num="76">According to still another embodiment, since the selection operation between the first and second modes is attained by single operation means, the operability of the camera can be improved.</p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>An image pickup device comprising:</claim-text>
      <claim-text>a plurality of image pickup elements for generating an object image signal on the basis of a signal output from at least one of said plurality of image pickup elements, and for generating an incident light state signal on the basis of a signal from another image pickup element;</claim-text>
      <claim-text>and a readout cycle of said at least one image pickup element being different from a readout cycle of said another image pickup element while said object image is supplied to a viewfinder, wherein said device has a first mode for generating the object image signal using a part of said plurality of image pickup elements and for generating the incident light state signal on the basis of a signal from the rest of said plurality of image pickup elements, and a second mode for generating the object image signal using all of said plurality of image pickup elements.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. A device according to claim 1, wherein an exposure amount of said at least one image pickup element which generates the object image signal is set to be different from an exposure amount of said another image pickup element which generates the incident light state signal.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. A device according to claim 1, wherein an effective read-out range of said at least one image pickup element which generates the object image signal is different from an effective read-out range of said another image pickup element which generates the incident light state signal.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. A device according to claim 1, further comprising operation means for selecting the first and second modes.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. A device according to claim 1, wherein the object image supplied to the viewfinder comprises a monochrome image.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. A device according to claim 1, wherein the plurality of image pickup elements comprise a Red element, a Blue element, and a Green element, and wherein the readout cycle of the Red image element is different from the readout cycle of the Blue and Green image elements when the object image is supplied to the viewfinder.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. A device according to claim 1, further comprising a switch for selectively supplying an output of said at least one image pickup element to either automatic exposure processing circuitry or to imaging processing circuitry.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. A device according to claim 1, wherein, when the readout cycle of the at least one image pickup element is different from the readout cycle of the another image pickup element, the output of said at least one image pickup element is supplied to automatic exposure processing circuitry at the same time that the output of said another image pickup element is supplied to image processing circuitry.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. A device according to claim 1, wherein the readout cycle of said at least one image pickup element is changed between (i) a first readout cycle when an output from said at least one image pickup element is provided to image processing circuitry, and (ii) a second, different, readout cycle when the output of said at least one image pickup element is provided to circuitry other than the image processing circuitry.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. A device according to claim 1, wherein the readout cycle of said at least one image pickup element is made to be different from the readout cycle of said another image pickup element by changing an effective readout range of said at least one image pickup element.</claim-text>
    </claim>
  </claims>
</questel-patent-document>