<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06192135B1.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as first publication">
      <document-id>
        <country>US</country>
        <doc-number>06192135</doc-number>
        <kind>B1</kind>
        <date>20010220</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6192135</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B1</original-publication-kind>
    <application-reference is-representative="YES" family-id="25519456" extended-family-id="42111425">
      <document-id>
        <country>US</country>
        <doc-number>08972278</doc-number>
        <kind>A</kind>
        <date>19971118</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1997US-08972278</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>43168895</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>97227897</doc-number>
        <kind>A</kind>
        <date>19971118</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1997US-08972278</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010220</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>H04R  27/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>R</subclass>
        <main-group>27</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>381095000</text>
        <class>381</class>
        <subclass>095000</subclass>
      </main-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>H04R-027/00</text>
        <section>H</section>
        <class>04</class>
        <subclass>R</subclass>
        <main-group>27</main-group>
        <subgroup>00</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04R-027/00</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>R</subclass>
        <main-group>27</main-group>
        <subgroup>00</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>20</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>6</number-of-drawing-sheets>
      <number-of-figures>7</number-of-figures>
      <image-key data-format="questel">US6192135</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Dearticulator</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>CUMMISKEY PETER, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5418778</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5418778</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>FREEMAN MICHAEL J</text>
          <document-id>
            <country>US</country>
            <doc-number>5894523</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5894523</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant app-type="applicant" sequence="1">
          <addressbook lang="en">
            <name>MONOPOLI DONALD S.</name>
          </addressbook>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Monopoli, Donald S.</name>
            <address>
              <address-1>Melbourne, FL, 32904, US</address-1>
              <city>Melbourne</city>
              <state>FL</state>
              <postcode>32904</postcode>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <name>Steinberger, Brian S.</name>
          </addressbook>
        </agent>
        <agent sequence="2" rep-type="agent">
          <addressbook lang="en">
            <orgname>Law Offices of Brian S. Steinberger</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Chang, Vivian</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      An amusement and entertainment system where participants try to continuously speak and/or sing while simultaneously listening to their own voices on a Â½ second sound delay.
      <br/>
      The confusing feedback does not act as a sound enhancement echo but instead causes confusion, disorientation and amusement to the participants and others watching the participants.
      <br/>
      The system can be used by one or more participants and a third person can switch signals so that one or more participants or others watching can hear the resultant effects of another participant.
      <br/>
      The system can be table mounted so that participants can be seated about a table.
      <br/>
      Alternatively, the system can be mounted in a mobile vehicle.
      <br/>
      Video cameras and monitors can be used to further add to the amusement of participants and others watching the participants.
      <br/>
      Each headphone can include microphones built into the headbands.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <p num="1">This invention relates to an entertainment and amusement system, and in particular to a two dimensional audio synchronization interactive system where participants try to continuously speak and sing while listening to their own voice after an approximate 1/2 second delay time, the effects of which confuse, distort and prevent the participant(s) from continuing to speak and/or sing articulately.</p>
    <heading>BACKGROUND AND PRIOR ART</heading>
    <p num="2">
      Karaoke machines have become very popular for sing-alongs where the purpose is to have the participants follow the lyrics of songs.
      <br/>
      Technology has been developed to create echo effects for Karaoke machines as well as in public auditoriums.
      <br/>
      See for example: U.S. Pat. No. 3,681,531 to Burkhard et al.; U.S. Pat. No. 5,442,711 to Toyama; and U.S. Pat. No. 5,444,785 to Izawa et al.
      <br/>
      However, these devices are used to enhance and magnify the voices of performers such as singers and the like.
      <br/>
      No confusing feedback of the voices is anticipated nor desired by these devices.
    </p>
    <p num="3">
      U.S. Pat. No. 4,630,301 to Hohl et al. describes a voice activated echo generator that can be used as a toy and as a speech learning aid for the deaf.
      <br/>
      However, the application is strictly described for creating echo effects.
      <br/>
      Similarly, U.S. Pat. No. 5,127,870 to Lin describes a microphone used for generating echoes.
      <br/>
      None of these patents are intended to have any confusing feedback distortion for entertainment.
    </p>
    <p num="4">
      Helmets and masks have been proposed for modifying a wearer's voice.
      <br/>
      See for example, U.S. Pat. No. 4,683,588 to Goldberg and U.S. Pat. No. 4,949,378 to Mammone.
      <br/>
      However, each of these patents alters the voices by scrambling, camouflaging and disguising the actual voices. U.S. Pat. No. 5,149,104 describes a video game and audio player interaction with real time video synchronization, where player can have their voices modified to reflect video images of objects and animals and the like.
      <br/>
      For example, the patent mentions an instance where a speaking player has their voice modified to sound like a sheep so that the image of the sheep is emitting animal sounds.
      <br/>
      None of these patents are intended to have any confusing feedback distortion for entertainment.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="5">The primary objective of the present invention is to provide an amusement and entertainment system where participants try to speak and/or sing while hearing a constant delayed back feedback of themselves which confuses and prevents the participant from continuing to speak and/or sing.</p>
    <p num="6">
      A preferred embodiment of the entertaining and amusement invention includes at least one microphone receiver for receiving voice signals from at least one participant, a delay means for delaying the voice signals up to approximately 1/2 second to a transmitter adjacent to the participant for playing the delayed voice signals while the participant in real-time continues to generate the voice signals, wherein the delayed signal does not echo the voice signals, but instead causes confusion and disorientation and eventually stops the participant from continuing to generate the voice signals, all while amusing and entertaining the participant.
      <br/>
      The transmitter can include an amplified public address speaker, an amplified headphone, or a combination thereof.
      <br/>
      Multiple microphones for plural participants can include a single mixer connected between the microphones and the delay means.
      <br/>
      A master of ceremonies can use a three-way switch for switching each of the microphones to the headphones and the loudspeakers.
      <br/>
      The invention can be built into a table base so that participants can be seated around the table.
      <br/>
      Another embodiment has the invention built into a mobile vehicle.
      <br/>
      A camera can be incorporated for taking video images of the participants, and a video monitor can be used for showing the video images to the participant and/or to others.
      <br/>
      Both the microphone and headphone can be built into one headset with the microphone mounted in the headband of the headset.
    </p>
    <p num="7">Further objects and advantages of this invention will be apparent from the following detailed description of a presently preferred embodiment which is illustrated schematically in the accompanying drawings.</p>
    <heading>BRIEF DESCRIPTION OF THE FIGURES</heading>
    <p num="8">
      FIG. 1 is a schematic view of a dearticulator invention embodiment with a single input.
      <br/>
      FIG. 2 is a schematic view of the dearticulator embodiment with multiple inputs.
      <br/>
      FIG. 3 is a schematic view of the multiple input dearticulator of FIG. 2 using a Master of Ceremonies(MC) embodiment.
      <br/>
      FIG. 4 is a perspective view of using the multiple input dearticulator of FIG. 2 with a single microphone embodiment.
      <br/>
      FIG. 5A is a perspective view of the multiple input dearticulator of FIG. 2 in a mobile vehicle embodiment.
      <br/>
      FIG. 5B is a side view of the mobile dearticulator embodiment of FIG. 5A along arrow X.
      <br/>
      FIG. 6 is a perspective view of a dearticulator headphone embodiment for use with the preceding figures.
    </p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENT</heading>
    <p num="9">
      Before explaining the disclosed embodiment of the present invention in detail it is to be understood that the invention is not limited in its application to the details of the particular arrangement shown since the invention is capable of other embodiments.
      <br/>
      Also, the terminology used herein is for the purpose of description and not of limitation.
    </p>
    <p num="10">
      FIG. 1 is a schematic view of a dearticulator invention 1 with a single input.
      <br/>
      Single input 1 includes uni- or omni-directional microphone 10, such as model no. SM-58 by Shure, Radio Shack Omni 33-1070, wire connected 12 to a delay box 20, having an approximate 1/2 second delay, such as model no. SPX-900 manufactured by Yamaha.
      <br/>
      From delay 20, the signal 21 splits to output along line 23 to a Public Address PA AMP 30, such as model no. CS 800, manufactured by Peavey, which outputs at 31, 33 to two house speakers 32, 34 such as model no. SP-2manufactured by Peavey.
      <br/>
      The other split from line 21 goes to line 25 and to the stereo headphone AMP 30, such as model no. MH-40 manufactured by Tascam, and to a headphone 40 such as model no. MDR-V600, manufactured by SONY.
      <br/>
      In operation, a participant 45 wearing headphones 40 tries to continuously speak and/or sing into microphone 10.
      <br/>
      The constant approximate 1/2 second delay in the sound transmission causes confusion when being heard by the
    </p>
    <p num="11">user 45, so that user 45 starts to stumble, slur, hesitate and cannot keep concentrating on speaking and/or singing while hearing their own voice on a delay.</p>
    <p num="12">
      FIG. 2 is a schematic view of another dearticulator 100 with a multiple input.
      <br/>
      Multiple input device 100 includes omni-directional microphones 110, 112, 114 such as model no. SM-58 by Shure, Radio Shack Omni 33-1070, wire connected 111, 113, 115 to a microphone mixer 120, such as model no. 32-1214 manufactured by Radio Shack.
      <br/>
      Stereo line 121 connects to delay box 130, having an approximate 1/2 second delay, such as model no. SPX-900 manufactured by Yamaha.
      <br/>
      From delay 130, the signal 131 splits to output along line 133 to a Public Address PA AMP 140, such as model no. CS 800, manufactured by Peavey, which outputs at 141, 143 to two house speakers 142, 144 such as model no. SP-2 manufactured by Peavey.
      <br/>
      The other split from line 131 goes to line 135 and to the stereo headphone AMP 140, such as model no. MH-40manufactured by Tascam, and to headphones 152, 154, 156 such as model no. MDR-V600, manufactured by SONY.
      <br/>
      In operation, participants 162, 164, 166 wearing respective headphones 152, 154, 156 each try to continuously speak and/or sing into microphones 110, 112, and 114, respectively.
      <br/>
      The constant approximate 1/2 second delay while speaking/singing causes confusion when being heard so that each of the participants eventually stumble, slur, hesitate and cannot keep concentrating on speaking/singing while hearing their own voice on a delay.
    </p>
    <p num="13">
      FIG. 3 is a schematic view 200 of the multiple input dearticulator of FIG. 2 using a Master of Ceremonies(MC).
      <br/>
      An MC 201 using a separate microphone 270 connected to an external box 272 that can plug into the dearticulator unit, has a three-way control switch 273.
      <br/>
      First switch 281 connects by line 282 to node 291 allowing participant A to speak/sing and/or listen 252 by stereo or mono line 212 which connects by line 292 to dearticulator 105.
      <br/>
      The latter housing mixer 120, delay 130 and headphone AMP 130 shown and described in reference to FIG. 2.
      <br/>
      Moving switch 273 to second switch 283 connects to line 284 to node 293 allowing participant B to speak/sing and/or listen 254 by line 214 which connects by line 294 to dearticulator 105.
      <br/>
      Third switch position 285 connects line 286 to both nodes 287 and 289 allowing both participants A and B to speak/sing and/or listen.
      <br/>
      Three-way switch 272 connects by line 274 and 276 to unit outputs 277, 275, which in turn output to amplifiers 240 and loudspeakers 242, 244, similar to those described in reference to FIG. 2.
      <br/>
      The MC application 200 can allow an MC 201 to direct and ask questions between two or more people A, B, such as in a politicians debate, board meeting, radio/television interviews, parties, bars, social gatherings such as weddings, and the like.
    </p>
    <p num="14">
      FIG. 4 is a perspective view 300 of using the multiple input dearticulator 100 of FIG. 2 using a table 330 with a single omni-directional microphone 320, where individual participants siting about the table 330 can each plug their respective headphones 303, 305, 307, 309, 311, 313 into respective plug input consoles 304, 306, 308, 310, 312, 314.
      <br/>
      Table 330 can include components 120, 130, and 140 shown in FIG. 2.
      <br/>
      While table 330 is shown as being rectangular, the tables used can be of other shapes such as but not limited to square, circular, semi-circular and the like, and be made from different materials such as but not limited to plastic, wood, and the like.
      <br/>
      The table dearticulator embodiment 300 can be used in both commercial and residential settings.
      <br/>
      An MC 201 shown in FIG. 3 can also be incorporated to direct the participants with questions, songs and the like.
    </p>
    <p num="15">
      FIG. 5A is a perspective view of the multiple input dearticulator of FIG. 2 in a mobile vehicle embodiment 400.
      <br/>
      FIG. 5B is a side (rear) view of the mobile dearticulator embodiment 400 of FIG. 5A along arrow X. Referring to FIGS. 5A-5B, mobile vehicle embodiment 400 includes a mobile vehicle 410 such as a van, truck with entry way doors 412, 414, so that participants 403 can enter inside of the vehicle 410.
      <br/>
      Inside vehicle 410, seats P1, P2, headphones H1, H2, and microphones m1, m2 can be used for the participants 403, using the schematic circuitry described in reference to the previous figures.
      <br/>
      Furthermore, camcorder type cameras C1, C2, connected to video monitors V1, V2 so that participant P1, can view through monitor V1, the video image of participant P2.
      <br/>
      And participant P2, can likewise view through monitor V2, the video image of participant P1.
      <br/>
      Mobile vehicle embodiment 400 can be used at various sites such as but not limited to fairs, carnivals, festivals.
      <br/>
      The outside of the van can have one way mirrors so that vehicle occupants cannot look out but a passerby can look in to see the participants laughing but not knowing why they are laughing.
    </p>
    <p num="16">
      FIG. 6 is a perspective view 500 of a dearticulator headphone embodiment for use with the preceding figures.
      <br/>
      Headphone 500 includes ear cup portions 510, 520, with respective speakers 512, 522 with curved headband 530 there between.
      <br/>
      Two built-in microphones 545, 565, such as those previously described, can be mounted within the curved band 530 on opposite sides of the band 530 adjacent to ear cups 510, 520.
      <br/>
      A plug-in line 570 can be connected to the speakers 512, 522 and microphones 545, 565, to the components depicted in the preceding figures.
    </p>
    <p num="17">Although not depicted, the embodiments can be used in a coin operated system.</p>
    <p num="18">While the invention has been described, disclosed, illustrated and shown in various terms of certain embodiments or modifications which it has presumed in practice, the scope of the invention is not intended to be, nor should it be deemed to be, limited thereby and such other modifications or embodiments as may be suggested by the teachings herein are particularly reserved especially as they fall within the breadth and scope of the claims here appended.</p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>I claim:</claim-text>
      <claim-text>1. An apparatus for entertaining and amusing participants by delaying feedback of their voices in order to confuse the participants, without echo enhancement, comprising in combination:</claim-text>
      <claim-text>a receiver for receiving voice signals from a participant; a delay means for delaying the voice signals greater than a 1/10 of a second;</claim-text>
      <claim-text>and a transmitter adjacent to the participant for playing the delayed voice signals while the participant in real-time continues to generate the voice signals, wherein the delayed signal does not echo the voice signals, but instead causes confusion and disorientation, and eventually stops the participant from continuing to generate the voice signals, while amusing and entertaining the participant.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The apparatus of claim 1, wherein the receiver includes: a microphone.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The apparatus of claim 1, wherein the delay means includes: a delay of approximately 1/2 second.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The apparatus of claim 1, wherein the transmitter includes: a speaker.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The apparatus of claim 4, wherein the transmitter further includes: an amplifier connected between the delay means and the speaker.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The apparatus of claim 1, wherein the transmitter includes: a headphone.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. The apparatus of claim 6, wherein the transmitter includes: an amplifier connected between the delay means and the headphone.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The apparatus of claim 2, wherein the receiver includes: a mixer connected between the microphone and the delay means.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. The apparatus of claim 1, wherein the transmitter includes: a headphone;</claim-text>
      <claim-text>and a speaker.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. The apparatus of claim 9, further including: a first amplifier connected between the delay means and the headphone;</claim-text>
      <claim-text>and a second amplifier connected between the delay means and the speaker.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. The apparatus of claim 10, wherein the receiver includes: a microphone;</claim-text>
      <claim-text>and a mixer connected between the microphone and the delay means.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. The apparatus of claim 2, wherein the receiver includes: a second microphone.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. The apparatus of claim 12, further comprising: a switch means for switching the transmitter connecting between the first microphone and the second microphone.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. The apparatus of claim 1, further comprising: a table base connected to the receiver and the transmitter.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. The apparatus of claim 1, further comprising: a mobile vehicle for housing the transmitter and the receiver.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. The apparatus of claim 15, wherein the vehicle further includes: a camera for taking video images of the participant;</claim-text>
      <claim-text>and a video monitor for showing the video images.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. The apparatus of claim 1, wherein the receiver and the transmitter includes: a headset having at least one speaker for covering an ear of the participant;</claim-text>
      <claim-text>and a microphone attached to the headset.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. The apparatus of claim 17, wherein the microphone further includes: a support mount in a headband of the headset.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. An entertainment and amusement device, comprising: a microphone for receiving audible voice emissions from a participant, and for generating a signal corresponding to the audible voice emissions; a delay means for receiving the signal and causing a pre-selected delay in the signal; a speaker connected to the delay means for passing the delayed signal back to the participant while the participant in real-time continues to generate the audible voice emissions, wherein the delayed signal does echo the audible voice emissions, and the participant hears their voice in a delayed version that causes confusion and disorientation to the participant.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. The entertainment and amusement device of claim 19, wherein the microphone and the speaker are mounted in a headset.</claim-text>
    </claim>
  </claims>
</questel-patent-document>