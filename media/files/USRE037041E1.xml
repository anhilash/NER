<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="USRE037041E1.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Reissue">
      <document-id>
        <country>US</country>
        <doc-number>RE037041</doc-number>
        <kind>E1</kind>
        <date>20010206</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>USRE37041</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>E1</original-publication-kind>
    <application-reference family-id="27473007" extended-family-id="20631776">
      <document-id>
        <country>US</country>
        <doc-number>08918869</doc-number>
        <kind>A</kind>
        <date>19970826</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1997US-08918869</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>62290091</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>91886997</doc-number>
        <kind>A</kind>
        <date>19970826</date>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1997US-08918869</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>JP</country>
        <doc-number>15025690</doc-number>
        <kind>A</kind>
        <date>19900608</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1990JP-0150256</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="3">
        <country>JP</country>
        <doc-number>15025790</doc-number>
        <kind>A</kind>
        <date>19900608</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="3">
        <doc-number>1990JP-0150257</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="4">
        <country>US</country>
        <doc-number>26615194</doc-number>
        <kind>A</kind>
        <date>19940627</date>
        <priority-linkage-type>5</priority-linkage-type>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="4">
        <doc-number>1994US-08266151</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="5">
        <country>US</country>
        <doc-number>4056193</doc-number>
        <kind>A</kind>
        <date>19930331</date>
        <priority-linkage-type>B</priority-linkage-type>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="5">
        <doc-number>1993US-08040561</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="6">
        <country>US</country>
        <doc-number>71058691</doc-number>
        <kind>A</kind>
        <date>19910605</date>
        <priority-linkage-type>B</priority-linkage-type>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="6">
        <doc-number>1991US-07710586</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010206</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G10H   1/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>10</class>
        <subclass>H</subclass>
        <main-group>1</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G10H   1/20        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>10</class>
        <subclass>H</subclass>
        <main-group>1</main-group>
        <subgroup>20</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>G10H   1/36        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>10</class>
        <subclass>H</subclass>
        <main-group>1</main-group>
        <subgroup>36</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>G10H   1/38        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>10</class>
        <subclass>H</subclass>
        <main-group>1</main-group>
        <subgroup>38</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>084669000</text>
        <class>084</class>
        <subclass>669000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>084DIG022</text>
        <class>084</class>
        <subclass>DIG022</subclass>
      </further-classification>
    </classification-national>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G10H-001/38</classification-symbol>
        <section>G</section>
        <class>10</class>
        <subclass>H</subclass>
        <main-group>1</main-group>
        <subgroup>38</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20161014</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G10H-001/0066</classification-symbol>
        <section>G</section>
        <class>10</class>
        <subclass>H</subclass>
        <main-group>1</main-group>
        <subgroup>0066</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20161014</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G10H-001/20</classification-symbol>
        <section>G</section>
        <class>10</class>
        <subclass>H</subclass>
        <main-group>1</main-group>
        <subgroup>20</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20161014</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G10H-001/366</classification-symbol>
        <section>G</section>
        <class>10</class>
        <subclass>H</subclass>
        <main-group>1</main-group>
        <subgroup>366</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20161014</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G10H-2210/066</classification-symbol>
        <section>G</section>
        <class>10</class>
        <subclass>H</subclass>
        <main-group>2210</main-group>
        <subgroup>066</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20161014</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="6">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G10H-2240/311</classification-symbol>
        <section>G</section>
        <class>10</class>
        <subclass>H</subclass>
        <main-group>2240</main-group>
        <subgroup>311</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20161014</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="7">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>Y10S-084/22</classification-symbol>
        <section>Y</section>
        <class>10</class>
        <subclass>S</subclass>
        <main-group>84</main-group>
        <subgroup>22</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130518</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>46</number-of-claims>
    <exemplary-claim>40</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>2</number-of-drawing-sheets>
      <number-of-figures>3</number-of-figures>
      <image-key data-format="questel">USRE37041</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Voice processor</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>KAWASHIMA SUSUMU</text>
          <document-id>
            <country>US</country>
            <doc-number>4991484</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4991484</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="2">
          <text>RUPERT ROBERT E</text>
          <document-id>
            <country>US</country>
            <doc-number>4463650</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4463650</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="3">
          <text>HOFF JR MARCIAN E</text>
          <document-id>
            <country>US</country>
            <doc-number>4771671</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4771671</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="4">
          <text>DILLARD HOMER</text>
          <document-id>
            <country>US</country>
            <doc-number>4915001</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4915001</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="5">
          <text>MINAMITAKA JUNICHI</text>
          <document-id>
            <country>US</country>
            <doc-number>4926737</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4926737</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="6">
          <text>SAKASHITA SHIGEO</text>
          <document-id>
            <country>US</country>
            <doc-number>5014586</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5014586</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="7">
          <text>TSURUTA SCHICHIROU, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5038658</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5038658</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="8">
          <text>SUWA SEIKOSHA KK</text>
          <document-id>
            <country>JP</country>
            <doc-number>S56168698</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP56168698</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="9">
          <text>NIPPON MUSICAL INSTRUMENTS MFG</text>
          <document-id>
            <country>JP</country>
            <doc-number>S582893</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP58002893</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="10">
          <text>SHARP KK</text>
          <document-id>
            <country>JP</country>
            <doc-number>S59200299</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP59200299</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>NIPPON MUSICAL INSTRUMENTS MFG</text>
          <document-id>
            <country>JP</country>
            <doc-number>S59116696</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP59116696</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="12">
          <text>NIPPON ATOMIC IND GROUP CO, et al</text>
          <document-id>
            <country>JP</country>
            <doc-number>S59126294</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP59126294</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="13">
          <text>KORG KK</text>
          <document-id>
            <country>JP</country>
            <doc-number>S6265098</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP62065098</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="14">
          <text>ROLAND KK</text>
          <document-id>
            <country>JP</country>
            <doc-number>S63174096</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP63174096</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="15">
          <text>NEC CORP</text>
          <document-id>
            <country>JP</country>
            <doc-number>S6336400</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP63036400</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <related-documents>
      <reissue>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>26615194</doc-number>
              <kind>A</kind>
              <date>19940627</date>
            </document-id>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>05446238</doc-number>
              <date>19950829</date>
            </document-id>
          </parent-doc>
        </relation>
      </reissue>
      <continuation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>4056193</doc-number>
              <kind>A</kind>
              <date>19930331</date>
            </document-id>
            <parent-status>ABANDONED</parent-status>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>71058691</doc-number>
              <kind>A</kind>
              <date>19910605</date>
            </document-id>
            <parent-status>ABANDONED</parent-status>
          </parent-doc>
        </relation>
      </continuation>
    </related-documents>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Yamaha Corporation</orgname>
            <address>
              <address-1>Hamamatsu, JP</address-1>
              <city>Hamamatsu</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>YAMAHA</orgname>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Koyama, Hirohisa</name>
            <address>
              <address-1>Machida, JP</address-1>
              <city>Machida</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Bushida, Takeshi</name>
            <address>
              <address-1>Oume, JP</address-1>
              <city>Oume</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Pillsbury Madison &amp; Sutro LLP</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Witkowski, Stanley J.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      The voice processor includes a microphone for a device for inputting a voice signal, a device for inputting chord information from an electronic musical instrument or the like, a converter for converting the pitch of the voice signal into a specified pitch according to the chord information, a mixer for mixing the input voice signal and a pitch-converted voice signal, and a loudspeaker for outputting the mixed signal.
      <br/>
      The pitch of the input voice signal is converted into such one as will be consonant with the chord information or as will coincide therewith and thereafter the pitch converted signal will be output along with the input voice signal.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <p num="1">
      This is a continuation of application Ser.
      <br/>
      No. 08/040,561, filed Mar. 31, 1993, now abandoned which is a file wrapper continuation of application Ser.
      <br/>
      No. 07/710,586 filed on Jun. 5, 1991, now abandoned.
    </p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="2">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="3">The present invention relates to a voice processor which is capable of producing sound effects by pitch conversion of voices.</p>
    <p num="4">2. Description of the Prior Art</p>
    <p num="5">
      By now, there have come into practical use electronic musical instruments so arranged that when a monotone melody is played, additional harmonic tones are automatically generated for simplifying the playing thereof.
      <br/>
      Also, there have been devices practically available which are adapted to convert the pitch of a voice to be generated for its output to thereby increase special impression of tones as well as entertaining features thereof.
    </p>
    <p num="6">However, in such electronic musical instruments adapted to generate additional tones in connection with a monotone melody as above, only a separate tone generator for additional tones is provided in addition to a tone generator (tone waveform shaping circuit) for melodies.</p>
    <p num="7">
      Moreover, a conventional device adapted to automatically make pitch conversion for its output has been arranged only such that an input voice is simply transposed up or down by a specified interval (5th above, 3rd below, etc.).
      <br/>
      Thus, to its disadvantages, the device would result in noticeable monotonous performance when used for a long melody or in a dissonance due to exclusion of harmony with chords when a chord is generated in addition to a melody tone.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="8">Accordingly, it is an object of the present invention to provide a voice processor which has overcome the foregoing problems by being adapted to convert the pitch of an input voice according to a chord input.</p>
    <p num="9">A voice processor of the present invention comprises: voice input means for inputting a voice signal having a pitch; chord information input means for inputting chord information; pitch conversion means for converting an input voice signal inputted from the voice input means into a pitch-converted voice signal having a pitch different from the pitch of the input voice signal according to chord information inputted from the chord information input means and for outputting the pitch-converted voice signal.</p>
    <p num="10">
      According to the voice processor of the invention, a voice is input through the voice input means, which may be given by a microphone, a line input device, or the like.
      <br/>
      Chord information is input through the chord information input means.
      <br/>
      The chord information is such information that includes the types of chords (e.g. major, minor, seventh) and roots.
      <br/>
      This chord information input means may be given by a real-time playing instrument (e.g. keyboard), a chord sequencer that can previously store chordal progression, or the like.
    </p>
    <p num="11">The pitch of a voice input through the voice input means is converted into a pitch according to the chord information input through the chord information input means.</p>
    <p num="12">The above and other objects, features and advantages of the present invention will become more apparent from the following detailed description with reference to the accompanying drawings.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="13">
      FIG. 1 is a block diagram of a voice processor embodying the present invention; and
      <br/>
      FIGS. 2 and 3 are flow charts showing operations of the same voice processor.
    </p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENT OF THE INVENTION</heading>
    <p num="14">
      FIG. 1 is a block diagram of a voice processor embodying the present invention.
      <br/>
      This system is designed to pitch convert a voice input through a microphone 1 with a pitch conversion LSI 5 and thereafter put it out as mixed with the original voice by a mixer 6.
    </p>
    <p num="15">
      The main part of the system is made up of digital circuits.
      <br/>
      A voice input through the microphone 1 is amplified by an amplifier 2 and then converted into a digital signal by an A/D converter circuit 3.
      <br/>
      The digital signal converted by the A/D converter circuit 3 is fed to a pitch detector circuit 4, the pitch conversion LSI 5, and the mixer 6.
      <br/>
      The pitch detector circuit 4 and pitch conversion LSI 5 are connected to a CPU 10.
      <br/>
      Others, which include a ROM 11, a RAM 12, an external memory 13, a panel switch 14, and a MIDI input/output connectors 15,16, are also connected to the CPU 10.
      <br/>
      The ROM 11 has stored programs for processing input digital data.
      <br/>
      The external memory 13 is given by a floppy disk unit or a `karaoke` system (the system of recorded instrumental music used to accompany live singing), where a floppy disk to be set to the unit has previously stored chord sequence data (data of chord progression).
      <br/>
      To the MIDI connector 15 is connected a playing instrument (electronic musical instrument) such as a keyboard, wherein from key data input therethrough, the type of chord and a root are detected by a chord detector circuit 17 and then chord information is fed to the CPU 10.
      <br/>
      The MIDI connector 15 is connected to an external device which is capable of generating a tone, e.g., tone generator.
      <br/>
      The pitch of a voice is detected by the pitch detector circuit 4, the resulting pitch information being fed to the CPU 10.
      <br/>
      The CPU 10 decides to what cents the pitch of the voice input through the microphone 1 should be converted, according to the chord information stored in the external memory 13 or input via the MIDI connector 15, then feeding the resulting parameter to the pitch conversion LSI 5.
      <br/>
      The pitch conversion LSI 5 converts the pitch of the voice according to the parameter fed from the CPU 10, where the pitch conversion is performed by such a known method that data is interpolated in accordance with a conversion ratio, the pitch conversion LSI 5 having contained therein buffer, clock, arithmetic circuit (not shown) for doing that.
    </p>
    <p num="16">
      The pitch-converted voice (harmony voice) is brought into the mixer 6.
      <br/>
      The mixer has also input voice (direct voice) that has been fed through the microphone 1 and digital converted.
      <br/>
      The mixer 6 adds these harmony and direct voices and feeds the result to a D/A converter circuit 7.
      <br/>
      The D/A converter circuit 7 digital-to-analog converts the added signal.
      <br/>
      The analog converted signal is amplified by an amplifier 8, thus output from a loud speaker 9.
    </p>
    <p num="17">
      FIGS. 2 and 3 are flow charts showing operations of the CPU 10.
      <br/>
      The operation in FIG. 2 is that for feeding chord information from a chord sequencer (external memory 13), while the operation in FIG. 3 is that for feeding chord information (key data) from the playing instrument connected to the MIDI connector 15.
      <br/>
      These operations are to be performed every several milliseconds by the CPU 10.
    </p>
    <p num="18">
      In FIG. 2, first the buffer in the pitch detector circuit 4 is read (n1).
      <br/>
      When the pitch detector circuit 4 can detect the pitch of an input voice, the buffer stores the pitch.
      <br/>
      When not, or when there is no voice input, the buffer stores data for no pitch detection (FFH).
      <br/>
      For any pitch detection, the operation goes from step n2 to n3, while for no pitch detection, it returns to the initial step as it is.
      <br/>
      At step n3, a piece of chord information specified to the present (the timing the processor is carrying out) is read out from the external memory 13.
      <br/>
      This chord information is fed to the MIDI connector 16 (n4) to make an externally connected tone generator generate the resulting chord.
      <br/>
      Then the parameter for pitch conversion is calculated (n5) to tone generate such additional tones within the melody range as will be consonant with this chord.
      <br/>
      The pitch conversion is done in such a way that a pitch Of the input voice is converted into the one closest to an input voice out of pitches corresponding to chord component pitch names of the input chord within a melody range (intervals higher than an accompaniment range), but not the same pitch.
      <br/>
      For example, if the pitch of an input voice is C4 and the chord composing tones are G1, C2, and E2, then the pitches corresponding to chord composing pitch names within the melody range are G3, C4, and E4, resulting in selection of E4 as the pitch for the pitch conversion parameter.
      <br/>
      Such a parameter is fed to the pitch conversion LSI 5 (n6).
      <br/>
      The pitch conversion LSI 5, having received this parameter, converts the direct voice into a harmony voice.
      <br/>
      In the steps n5 and n6, which decides the parameter for converting the pitch of the input voice, another process may be carried out as follows.
      <br/>
      The parameter for pitch conversion is calculated so as to convert the .�.chord.�.  pitch of the input voice into a chord composing tone for generating.
      <br/>
      The pitch conversion is done in such a way that a pitch is converted into one corresponding to a chord component pitch name of the input chord within an accompaniment range (intervals lower than a melody range).
      <br/>
      For example, if the chord composing tones are G1, C2, and E2, then the direct voice is converted into any of these tone pitches; in this case, .�.E4.�. E2, which is a three-degree tone, would reasonably be selected as the pitch conversion parameter.
      <br/>
      At step n6, this parameter is fed to the pitch conversion LSI 5.
      <br/>
      The pitch conversion LSI 5, having received this parameter, converts the direct voice into a harmony voice.
    </p>
    <p num="19">
      In FIG. 3, first the buffer in the pitch detector circuit 4 is read (n11).
      <br/>
      When a tone pitch is detected, the operation goes from step n12 to n13, while when not, the operation returns to the initial step as it is.
      <br/>
      At step n13, the chord currently played is read from the playing instrument (electronic musical instrument) connected with the MIDI connector 15.
      <br/>
      In this step, if the playing instrument is one that outputs chord information, the resulting chord information can be used as it is, while if the instrument is one that does not output chord information, the chord detector circuit 17 decides a chord according to the pattern of an input key depression and the like (n14).
      <br/>
      The method of deciding a chord can use such a conventionally known one that the pattern of an input key depression are applied to a table in which chord composing tones are stored or other methods of various types.
      <br/>
      When a chord has been detected, the parameter for pitch conversion is calculated so as to generate such additional tones as will be consonant with the chord within the melody range or to convert the direct voice into any of the tones composing the chord that has been detected (n15 to n16).
      <br/>
      This conversion method is the same as that described in regard to FIG. 2, explanation thereof omitted.
      <br/>
      The resulting parameter is fed to the pitch conversion LSI 5 (n17).
      <br/>
      The pitch conversion LSI 5, having received this parameter, converts the direct voice into a converted voice.
      <br/>
      Incidentally, the decided chord is already generated by the playing instrument (electronic musical instrument), and may not be output to MIDI connector 16 further.
      <br/>
      In addition, if a chord has not been detected at step n14, the pitch conversion cannot be performed, causing the operation to return directly from step n15.
    </p>
    <p num="20">Although the conversion method in this embodiment for determining the pitch of a harmony tone is such that the pitch is selected in connection with the range of direct input voices, it can otherwise be such that a pitch is converted into that of a tone which is a integral multiple of a root of a chord generated as an accompaniment tone (pitched approximately 2 octaves lower than a melody tone) irrespectively of the direct voice range, or other method of various types.</p>
    <p num="21">According to the voice processor of the present invention, since an input voice is converted into a harmony voice in accordance with an accompaniment chord, the result is not a simple pitch conversion but the one that enables such harmony voices to be generated as will be consonant with the accompaniment chord.</p>
    <p num="22">
      In addition, in the case where a direct voice is tone generated as it is converted into one of tones composing a chord within the accompaniment range, it can also be arranged that a plurality of pitch conversion LSIs 5 are provided in parallel so as to allow the direct voice to be converted at a time into all the tones composing the chord (root, 3-degree tone, 5-degree tone and, for a 7th chord, 7-degree tone).
      <br/>
      This arrangement will permit the chord to be tone generated only with the above device.
      <br/>
      Further, even in the case where only one of the chord composing tones is output, it can be arranged that the root, 3-degree tone, and 5-degree tone are switched over in short time intervals thereby to produce such an effect as arpeggio.
      <br/>
      Moreover, this effect can be realized also by such a device that can simultaneously output a plurality of chord composing tones (in a more complicated manner).
    </p>
    <p num="23">According to the voice processor of the present invention, since an input voice is converted into a harmony voice that is one of tones composing an accompaniment chord, such a harmony voice can be generated not as a simple tone conversion but as another in which the harmony voice can be utilized as an accompaniment chord.</p>
    <p num="24">
      Although the present invention has been fully described by way of example with reference to the accompanying drawings, it is to be understood that various changes and modifications will be apparent to those skilled in the art.
      <br/>
      Therefore, unless otherwise such changes and modifications depart from the scope of the invention, they should be construed as being included therein.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
    </claim>
    <claim num="40">
      <claim-text>40.</claim-text>
      <claim-text>A voice processor comprising: a circuit for receiving a voice signal having a first pitch; a chord information terminal for receiving chord information data representative of information for at least one of a chord-type and a chord-root in accordance with a progression of a musical piece; a pitch converter for converting the first pitch of the input voice signal to a second pitch different from the first pitch of the input voice signal based on the detected first pitch and the chord information data to provide a pitch-converted voice, signal having the second pitch;</claim-text>
      <claim-text>and a circuit for combining the pitch converted voice signal with the input voice signal to provide a sound effect to the input voice signal.</claim-text>
      <claim-text>1. A voice processor comprising:</claim-text>
      <claim-text>voice input means for inputting a voice signal having a pitch; chord information input means for inputting a chord; pitch conversion means for converting the input voice signal into a pitch-converted voice signal having a pitch different from the pitch of the input voice signal, the pitch conversion means converting the pitch of the input voice signal in accordance with the input chord from the chord information input means and for outputting the pitch-converted voice signal;</claim-text>
      <claim-text>and means for combining the pitch-converted voice signal with the input voice signal to add sound effects thereto; the chord information input means comprising play information input means for inputting playing information and chord detection means for detecting the input chord from playing information inputted by the play information input means.</claim-text>
      <claim-text>2. A voice processor according to claim 1 further comprising, voice mixing means for mixing the input voice signal from the voice input means and the pitch-converted voice signal from the pitch conversion means and outputting a mixed voice signal.</claim-text>
      <claim-text>3. A voice processor according to claim 1, wherein chord sequence data is input by the chord information input means as the input chord.</claim-text>
      <claim-text>4. A voice processor comprising: voice input means for inputting a voice signal having a pitch; chord information input means for inputting chord information; pitch conversion means for converting the input voice signal into a pitch-converted voice signal having a pitch different from the pitch of the input voice signal, the pitch conversion means converting the pitch of the input voice signal in accordance with the chord information from the chord information input means and outputting the pitch-converted voice signal, the pitch conversion means converting the input voice signal inputted from the voice input means consonant with the chord information;</claim-text>
      <claim-text>and means for combining the pitch-converted voice signal with the input voice signal; the chord information input means comprising play information input means for inputting playing information and chord detection means for detecting the input chord information from playing information inputted by the play information input means.</claim-text>
      <claim-text>5. A voice processor according to claim 4, wherein the pitch resulting from conversion by said pitch conversion means is a pitch closest to the pitch of the voice signal input to said voice input means out of pitches corresponding to chord composing pitch names of said chord information within a melody range.</claim-text>
      <claim-text>6. A voice processor comprising: voice input means for inputting a voice signal having a pitch; chord information input means for inputting a chord having a plurality of pitches; pitch conversion means for converting the input voice signal into a pitch-converted voice signal having a pitch different from the pitch of the input voice signal, the pitch conversion means converting the pitch of the input voice signal in accordance with the chord information from the chord information input means and outputting the pitch-converted voice signal, the pitch conversion means converting the input voice signal so that the pitch different from the pitch of the input voice signal is at least one pitch of the plurality of pitches of the inputted chord;</claim-text>
      <claim-text>and means for combining the pitch-converted voice signal with the input voice signal; the chord information input means comprising play information input means for inputting playing information and chord detection means for detecting the input chord from playing information inputted by the play information input means.</claim-text>
      <claim-text>7. A method of voice processing comprising the steps of: picking up a voice as a voice signal; inputting chord information; converting the voice signal into a pitch-converted voice signal having a pitch different from a pitch of the voice signal in accordance with the input chord information;</claim-text>
      <claim-text>and combining the pitch-converted voice signal with the picked up voice signal to add sound effects thereto; the step of inputting chord information comprising the steps of inputting playing information and detecting the input chord information from the inputted playing information.</claim-text>
      <claim-text>8. A voice processor comprising: a circuit for receiving a voice signal having a first pitch; a playing information generator for providing playing information data for playing music, the playing information data including data representative of harmony information; a tone generator for generating musical tone signals based upon the playing information data; a pitch converter for converting the input voice signal to a pitch-converted voice signal having a second pitch different from the first pitch of the input voice signal in accordance with the harmony information the pitch converter utilizing a pitch conversion parameter related to a ratio of the first pitch to the second pitch;</claim-text>
      <claim-text>and a circuit for combining the pitch converted voice signal with the input voice signal to provide a sound effect imparted to the input voice signal.</claim-text>
      <claim-text>9. A voice processor according to claim 8, wherein the playing information generator further provides data representative of chord information as the data representative of harmony information.</claim-text>
      <claim-text>10. A voice processor according to claim 8, wherein the playing information generator further includes: a circuit for receiving playing information data;</claim-text>
      <claim-text>and a chord detector for detecting chord information based on the input playing information data.</claim-text>
      <claim-text>11. A voice processor according to claim 8, wherein the playing information generator further includes a chord information generator for providing sequential chord data based upon a progression of a piece of music, wherein the harmony information includes the chord data.</claim-text>
      <claim-text>12. A voice processor according to claim 9, wherein the chord information includes a sequential progression of chords, the sequential progression of chords being based upon a piece of music, and wherein the pitch converter converts the input voice signal to a pitch-converted voice signal such that the second pitch includes a tone pitch corresponding to a pitch of a chord composing tone of each of the chords in the progression.</claim-text>
      <claim-text>13. A voice processor according to claim 12, wherein the pitch converter includes a tone pitch shifter for shifting the tone pitch of the pitch-converted voice signal within a melody range such that a tone of the pitch-converted voice signal is in harmony with a tone of the input voice signal.</claim-text>
      <claim-text>14. A voice processor according to claim 8, wherein a tone of the pitch converted voice signal is consonant with tones of the musical tone signals generated by the tone generator.</claim-text>
      <claim-text>15. A voice processor comprising: a circuit for receiving a voice signal having a first pitch; a playing information generator for providing playing information data for playing music, the playing information data including data representative of harmony information, the harmony information having at least one pitch in a time period; a pitch shifter for shifting a pitch of the harmony information to provide a shifted pitch information signal that is set within a melody range; a pitch converter for converting the input voice signal to a pitch-converted voice signal having a second pitch different from the first pitch, wherein the second pitch of the pitch-converted voice signal corresponds to the shifted pitch information signal;</claim-text>
      <claim-text>and a circuit for combining the pitch converted voice signal with the input voice signal to provide a sound effect imparted to the input voice signal.</claim-text>
      <claim-text>16. A voice processor according to claim 15, wherein the harmony information includes chord information.</claim-text>
      <claim-text>17. A voice processor according to claim 16, wherein the chord information includes at least one pitch in a time interval and the pitch shifter shifts a pitch of the chord information to a pitch corresponding to a chord component pitch name of said chord information within a melody range which is closest to the first pitch of the input voice signal.</claim-text>
      <claim-text>18. A voice processor according to claim 15, the voice processor further comprising a tone generator for generating tone signals based on the playing information data.</claim-text>
      <claim-text>19. A voice processor comprising: a circuit for receiving a voice signal having a first pitch; a playing information generator for providing playing information data for playing music, the playing information data including data representative of harmony information, the harmony information including at least one harmony pitch in a time period within an accompaniment range; a tone generator for generating tone signals based upon the playing information data;</claim-text>
      <claim-text>and, a pitch converter for converting the input voice signal to a pitch-converted voice signal having a second pitch different from the first pitch of the input voice signal, the pitch converter utilizing a pitch conversion parameter related to a ratio of the first pitch to the second pitch, and the second pitch of the pitch-converted voice signal corresponding to the at least one harmony pitch, wherein a tone of the pitch converted voice signal is consonant with tones of the signals generated by the tone generator.</claim-text>
      <claim-text>20. A voice processor according to claim 19, wherein the harmony information includes chord information.</claim-text>
      <claim-text>21. A voice processor according to claim 20, wherein the chord information includes a plurality of chord composing pitches in a time period and the at least one harmony pitch is one or more of chord composing pitches of the chord information within an accompaniment range.</claim-text>
      <claim-text>22. A voice processor according to claim 19, the voice processor further comprising a circuit for combining the pitch-converted voice signal with the input voice signal to provide a sound effect to the input voice signal.</claim-text>
      <claim-text>23. A voice processor comprising: a circuit for receiving a voice signal having a first pitch; a pitch information generator for providing data representative of sequential pitches being sequentially changed in accordance with a progression of a musical piece; a tone generator for generating tone signals based upon the data representative of the sequential pitches; a pitch converter for converting the first pitch of the input voice signal to a second pitch different from the first pitch of the input voice signal in accordance with at least one of the sequential pitches to provide a pitch-converted voice signal, the pitch converter utilizing a pitch conversion parameter related to a ratio of the first pitch to the second pitch;</claim-text>
      <claim-text>and a circuit for combining the pitch-converted voice signal with the input voice signal to provide a sound effect imparted to the input voice signal.</claim-text>
      <claim-text>24. A voice processor according to claim 23, wherein the pitch information generator provides chord sequence data as the data representative of sequential pitches.</claim-text>
      <claim-text>25. A voice processor according to claim 23, wherein the pitch information generator further includes: a circuit for receiving playing information data;</claim-text>
      <claim-text>and a chord detector for detecting chord information based on the input playing information data, wherein the sequential pitches in accordance with the progression of the music piece are based upon the detected chord information.</claim-text>
      <claim-text>26. A voice processor according to claim 23, wherein a tone of the pitch-converted voice signal is consonant with tones of the tone signals generated by the tone generator.</claim-text>
      <claim-text>27. A voice processor comprising: a circuit for receiving a voice signal having a first pitch; a pitch detector for detecting the first pitch of the input voice signal; a chord information generator for providing chord information data that varies with progression of a musical piece; a tone generator for generating tone signals based upon the chord information data; a pitch conversion parameter generator for providing a pitch conversion parameter based on the detected first pitch and the chord information data;</claim-text>
      <claim-text>and a pitch converter for converting the first pitch of the input voice signal to a second pitch different from the first pitch of the input voice signal in accordance with the pitch conversion parameter to provide a pitch-converted voice signal having the second pitch.</claim-text>
      <claim-text>28. A voice processor according to claim 27, the voice processor further comprising a circuit for combining the pitch converted voice signal with the input voice signal to provide a sound effect to the input voice signal.</claim-text>
      <claim-text>29. A voice processor according to claim 27, wherein the chord information generator further includes: a circuit for receiving playing information data;</claim-text>
      <claim-text>and a chord detector for detecting chord information based on the playing information data.</claim-text>
      <claim-text>30. A voice processor according to claim 27, wherein the chord information generator further includes a chord sequencer for providing a series of chord data as the chord information based upon the progression of the musical piece.</claim-text>
      <claim-text>31. A voice processor according to claim 27, wherein a tone of the pitch-converted voice signal is consonant with tones of the tone signals generated by the tone generator.</claim-text>
      <claim-text>32. A voice processor according to claim 27, wherein the chord information data includes data representative of at least one chord pitch and the pitch converter further includes a tone pitch shifter for shifting at least one pitch represented by the chord information to within a melody range such that a tone of the pitch-converted voice signal is consonant with the chord information and a melody of the music piece.</claim-text>
      <claim-text>33. A voice processor according to claim 30, wherein the series of chord data is representative of information of a chord-type and a chord-root.</claim-text>
      <claim-text>34. A voice processor according to claim 27, wherein the chord information generator retrieves the chord information data from a memory.</claim-text>
      <claim-text>35. A voice processor according to claim 27, wherein the chord information generator provides the chord information data in response to an instrumental performance.</claim-text>
      <claim-text>36. A voice processor according to claim 27, wherein the pitch conversion parameter represents the second pitch.</claim-text>
      <claim-text>37. A voice processor according to claim 36, wherein the second pitch is within a melody range.</claim-text>
      <claim-text>38. A voice processor according to claim 36, wherein the second pitch is within an accompaniment range.</claim-text>
      <claim-text>39. A voice processor according to claim 27, wherein the pitch conversion parameter generator provides a plurality of pitch conversion parameters, and wherein the pitch converter further includes a plurality of pitch conversion devices, each pitch conversion device converting the first pitch of the input voice signal to a second pitch different from the first pitch in accordance with one of the pitch conversion parameters to provide one of a plurality of pitch-converted voice signals.</claim-text>
    </claim>
    <claim num="41">
      <claim-text>41. A voice processor according to claim 40, the voice processor further comprising a tone generator for generating tone signals based on the chord information data, wherein a tone of the pitch-converted voice signal is consonant with tones of the tone signals generated by the tone generator.</claim-text>
    </claim>
    <claim num="42">
      <claim-text>42. A voice processor comprising: a circuit for receiving a voice signal having a first pitch; a playing information generator for providing playing information data for playing music including harmony information, the harmony information varying in accordance with a progression of the music; a tone generator for generating musical tone signals based upon the playing information data; a pitch converter for converting the input voice signal to a pitch-converted voice signal having a second pitch different from the first pitch of the input voice signal in accordance with the harmony information;</claim-text>
      <claim-text>and a circuit for combining the pitch-converted voice signal with the input voice signal to provide a sound effect imparted to the input voice signal, wherein a waveform of the pitch-converted voice signal is made from a waveform of the input voice signal.</claim-text>
    </claim>
    <claim num="43">
      <claim-text>43. A voice processor comprising: a circuit for receiving a voice signal having a first pitch; a playing information generator for providing playing information data for playing music including harmony information, the harmony information varying in accordance with a progression of the music, wherein the harmony information is set within an accompaniment range; a tone generator for generating tone signals based upon the playing information data;</claim-text>
      <claim-text>and a pitch converter for converting the input voice signal to a pitch-converted voice signal having a second pitch different from the first pitch in accordance with the harmony information, wherein a tone of the pitch-converted voice signal is consonant with tones of the tone signals generated by the tone generator.</claim-text>
    </claim>
    <claim num="44">
      <claim-text>44. A voice processor comprising: a circuit for receiving a voice signal having a first pitch; a pitch information generator for providing data representative of sequential pitches being sequentially changed in accordance with a progression of a musical piece; a tone generator for generating tone signals based upon the data representative of the sequential pitches; a pitch converter for converting the first pitch of the input voice signal to a second pitch different from the first pitch in accordance with at least one of the sequential pitches to provide a pitch-converted voice signal;</claim-text>
      <claim-text>and a circuit for combining the pitch-converted voice signal with the input voice signal to provide a sound effect imparted to the input voice signal wherein a waveshape of the pitch-converted voice signal is made of a waveshape of the input voice signal.</claim-text>
    </claim>
    <claim num="45">
      <claim-text>45. A voice processor comprising: a circuit for receiving a voice signal having a first pitch; a playing information generator for providing playing information data for playing automatic performance music including harmony information, the harmony information varying in accordance with a progression of the automatic performance music; a tone generator for generating musical tone signals based upon the playing information data; a pitch converter for converting the input voice signal to a pitch-converted voice signal having a second pitch different from the first pitch of the input voice signal in accordance with the harmony information;</claim-text>
      <claim-text>and a circuit for combining the pitch-converted voice signal with the input voice signal to provide a sound effect imparted to the input voice signal wherein a waveshape of the pitch-converted voice signal is made of a waveshape of the input voice signal.</claim-text>
    </claim>
    <claim num="46">
      <claim-text>46. A voice processor comprising: a circuit for receiving a voice signal having a first pitch; a pitch detector for detecting the first pitch of the input voice signal; a chord information terminal for receiving chord information data representative of information for at least one of a chord-type and a chord-root in accordance with a progression of a musical piece; a pitch converter for converting the first pitch of the input voice signal to a second pitch different from the first pitch in accordance with the chord information data to provide a pitch-converted voice signal having the second pitch;</claim-text>
      <claim-text>and a circuit for combining the pitch-converted voice signal with the input voice signal to provide a sound effect imparted to the input voice signal, wherein a waveform of the pitch-converted voice signal is made from a waveform of the input voice signal.</claim-text>
    </claim>
  </claims>
</questel-patent-document>