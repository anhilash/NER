<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06188794B1.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as first publication">
      <document-id>
        <country>US</country>
        <doc-number>06188794</doc-number>
        <kind>B1</kind>
        <date>20010213</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6188794</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B1</original-publication-kind>
    <application-reference family-id="26421636" extended-family-id="622536">
      <document-id>
        <country>US</country>
        <doc-number>09315038</doc-number>
        <kind>A</kind>
        <date>19990520</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1999US-09315038</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>637653</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>31503899</doc-number>
        <kind>A</kind>
        <date>19990520</date>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1999US-09315038</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>JP</country>
        <doc-number>27384391</doc-number>
        <kind>A</kind>
        <date>19911022</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1991JP-0273843</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="3">
        <country>JP</country>
        <doc-number>8065492</doc-number>
        <kind>A</kind>
        <date>19920402</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="3">
        <doc-number>1992JP-0080654</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="4">
        <country>US</country>
        <doc-number>80323597</doc-number>
        <kind>A</kind>
        <date>19970220</date>
        <priority-linkage-type>3</priority-linkage-type>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="4">
        <doc-number>1997US-08803235</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="5">
        <country>US</country>
        <doc-number>12129393</doc-number>
        <kind>A</kind>
        <date>19930913</date>
        <priority-linkage-type>1</priority-linkage-type>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="5">
        <doc-number>1993US-08121293</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="6">
        <country>US</country>
        <doc-number>96229992</doc-number>
        <kind>A</kind>
        <date>19921016</date>
        <priority-linkage-type>3</priority-linkage-type>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="6">
        <doc-number>1992US-07962299</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="7">
        <country>US</country>
        <doc-number>17861998</doc-number>
        <kind>A</kind>
        <date>19981026</date>
        <priority-linkage-type>3</priority-linkage-type>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="7">
        <doc-number>1998US-09178619</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010213</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>H04N  19/60        20140101AFI20150402RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>60</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150402</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G06T   9/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>9</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>H04N  11/04        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>11</main-group>
        <subgroup>04</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>H04N  19/00        20140101ALI20150402RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>00</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150402</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="5">
        <text>H04N  19/119       20140101ALI20150402RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>119</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150402</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="6">
        <text>H04N  19/124       20140101ALI20150402RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>124</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150402</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="7">
        <text>H04N  19/129       20140101ALI20150402RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>129</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150402</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="8">
        <text>H04N  19/132       20140101ALI20150402RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>132</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150402</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="9">
        <text>H04N  19/136       20140101ALI20150402RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>136</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150402</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="10">
        <text>H04N  19/176       20140101ALI20150402RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>176</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150402</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="11">
        <text>H04N  19/196       20140101ALI20150402RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>196</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150402</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="12">
        <text>H04N  19/85        20140101ALI20150402RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>85</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150402</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="13">
        <text>H04N  19/91        20140101ALI20150402RHJP</text>
        <ipc-version-indicator>
          <date>20140101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>91</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150402</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>382238000</text>
        <class>382</class>
        <subclass>238000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>375E07133</text>
        <class>375</class>
        <subclass>E07133</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>375E07163</text>
        <class>375</class>
        <subclass>E07163</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>375E07211</text>
        <class>375</class>
        <subclass>E07211</subclass>
      </further-classification>
    </classification-national>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/577</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>577</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/105</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>105</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/112</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>112</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/119</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>119</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/124</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>124</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="6">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/132</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>132</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="7">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/137</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>137</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="8">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/14</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>14</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="9">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/152</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>152</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="10">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/16</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>16</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="11">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/172</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>172</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="12">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/176</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>176</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="13">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/61</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>61</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>5</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>21</number-of-drawing-sheets>
      <number-of-figures>35</number-of-figures>
      <image-key data-format="questel">US6188794</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Image signal coding system</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>MATSUMOTO SHUICHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4546386</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4546386</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>BORGERS STEPHANUS M C, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4849812</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4849812</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>KRAUSE EDWARD A, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5091782</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5091782</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>KRAUSE EDWARD A, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5093720</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5093720</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>NG SHEAU-BAO</text>
          <document-id>
            <country>US</country>
            <doc-number>5146325</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5146325</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>UEDA MOTOHARU, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5175618</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5175618</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>WANG FENG MING, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5193004</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5193004</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>ODAKA TOSHINORI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5317397</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5317397</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="9">
          <text>MURAKAMI TOKUMICHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5428693</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5428693</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="10">
          <text>SAITO OSAMU</text>
          <document-id>
            <country>US</country>
            <doc-number>5732155</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5732155</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>MATSUMOTO SHUICHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4437119</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4437119</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="12">
          <text>HATORI YOSHINORI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4571618</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4571618</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="13">
          <text>TANIMOTO MASAYUKI</text>
          <document-id>
            <country>US</country>
            <doc-number>4675733</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4675733</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="14">
          <text>JURI TATSURO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4691329</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4691329</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="15">
          <text>KONDO TETSUJIRO</text>
          <document-id>
            <country>US</country>
            <doc-number>4703351</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4703351</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="16">
          <text>KONDO TETSUJIRO</text>
          <document-id>
            <country>US</country>
            <doc-number>4772947</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4772947</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="17">
          <text>HARNEY KEVIN</text>
          <document-id>
            <country>US</country>
            <doc-number>4783698</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4783698</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="18">
          <text>AMOR HAMED, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4931869</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4931869</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="19">
          <text>BIRCH CHRISTOPHER H</text>
          <document-id>
            <country>US</country>
            <doc-number>4941045</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4941045</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="20">
          <text>SUGIYAMA KENJI</text>
          <document-id>
            <country>US</country>
            <doc-number>5045938</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5045938</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="21">
          <text>HOFFERT ERIC M, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5046119</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5046119</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="22">
          <text>KRAUSE EDWARD A, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5068724</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5068724</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="23">
          <text>NIIHARA TAKAMI</text>
          <document-id>
            <country>US</country>
            <doc-number>5157742</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5157742</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="24">
          <text>MURAKAMI TOKUMICHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5274442</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5274442</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="25">
          <text>TAKAHASHI TOSHIYA</text>
          <document-id>
            <country>US</country>
            <doc-number>5347309</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5347309</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="26">
          <text>MURAKAMI TOKUMICHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5416523</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5416523</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="27">
          <text>MURAKAMI TOKUMICHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5638127</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5638127</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="28">
          <text>SONY CORP</text>
          <document-id>
            <country>EP</country>
            <doc-number>0385654</doc-number>
            <kind>A2</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-385654</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="29">
          <text>VICTOR COMPANY OF JAPAN</text>
          <document-id>
            <country>EP</country>
            <doc-number>0484140</doc-number>
            <kind>A2</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-484140</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="30">
          <text>FRANCE TELECOM, et al</text>
          <document-id>
            <country>EP</country>
            <doc-number>0490799</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-490799</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="31">
          <text>PHILIPS NV</text>
          <document-id>
            <country>EP</country>
            <doc-number>0499307</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-499307</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="32">
          <text>MATSUSHITA ELECTRIC IND CO LTD</text>
          <document-id>
            <country>EP</country>
            <doc-number>0510972</doc-number>
            <kind>A2</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP-510972</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="33">
          <text>NIPPON ELECTRIC CO</text>
          <document-id>
            <country>JP</country>
            <doc-number>S58137379</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP58137379</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="34">
          <text>SONY CORP</text>
          <document-id>
            <country>JP</country>
            <doc-number>S62102685</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP62102685</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="35">
          <text>GTE LABORATORIES INC</text>
          <document-id>
            <country>JP</country>
            <doc-number>S632244</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP63002244</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="36">
          <text>NIPPON DENKI HOME ELECTRONICS</text>
          <document-id>
            <country>JP</country>
            <doc-number>H01278184</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP01278184</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="37">
          <text>SONY CORP</text>
          <document-id>
            <country>JP</country>
            <doc-number>H031668</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP03001668</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="38">
          <text>MATSUSHITA ELECTRIC IND CO LTD</text>
          <document-id>
            <country>JP</country>
            <doc-number>H0397320</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP03097320</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="39">
          <text>MATSUSHITA ELECTRIC IND CO LTD</text>
          <document-id>
            <country>JP</country>
            <doc-number>H04178088</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP04178088</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="40">
          <text>VICTOR COMPANY OF JAPAN</text>
          <document-id>
            <country>JP</country>
            <doc-number>H04167882</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP04167882</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="41">
          <document-id>
            <country>JP</country>
            <doc-number>2522690</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP02522690</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="42">
          <text>VICTOR COMPANY OF JAPAN</text>
          <document-id>
            <country>JP</country>
            <doc-number>H04288790</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP04288790</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="43">
          <text>NIPPON TELEGRAPH &amp; TELEPHONE</text>
          <document-id>
            <country>JP</country>
            <doc-number>H0522718</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP05022718</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="1">
          <text>Chiang, et al. "Compatible Coding of Digital Interlaced HDTV Using Prediction of the Even Fields from the Odd Fields", Apr. 9, 1991, pp. 523-530.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="2">
          <text>European Search Report dated Apr. 13, 1999.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="3">
          <text>Satoshi Nogaki et al. "A study on HDTV Signal Coding with Motion Adaptive Noise Reduction", Aug./Sep., 1989.</text>
        </nplcit>
      </citation>
    </references-cited>
    <related-documents>
      <division>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>80323597</doc-number>
              <kind>A</kind>
              <date>19970220</date>
            </document-id>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>96229992</doc-number>
              <kind>A</kind>
              <date>19921016</date>
            </document-id>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>17861998</doc-number>
              <kind>A</kind>
              <date>19981026</date>
            </document-id>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>5427678</doc-number>
              <kind>A</kind>
            </document-id>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>09/128619</doc-number>
              <date>19981026</date>
            </document-id>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>5867220</doc-number>
              <kind>A</kind>
            </document-id>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>5274442</doc-number>
              <kind>A</kind>
            </document-id>
          </parent-doc>
        </relation>
      </division>
      <continuation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>12129393</doc-number>
              <kind>A</kind>
              <date>19930913</date>
            </document-id>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>5638127</doc-number>
              <kind>A</kind>
            </document-id>
          </parent-doc>
        </relation>
      </continuation>
    </related-documents>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Mitsubishi Denki Kabushiki Kaisha</orgname>
            <address>
              <address-1>Tokyo, JP</address-1>
              <city>Tokyo</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>MITSUBISHI ELECTRIC</orgname>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Nishikawa, Hirofumi</name>
            <address>
              <address-1>Kanagawa-ken, JP</address-1>
              <city>Kanagawa-ken</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Yamada, Yoshihisa</name>
            <address>
              <address-1>Kanagawa-ken, JP</address-1>
              <city>Kanagawa-ken</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="3">
          <addressbook lang="en">
            <name>Murakami, Tokumichi</name>
            <address>
              <address-1>Kanagawa-ken, JP</address-1>
              <city>Kanagawa-ken</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="4">
          <addressbook lang="en">
            <name>Asai, Kohtaro</name>
            <address>
              <address-1>Kanagawa-ken, JP</address-1>
              <city>Kanagawa-ken</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
      </inventors>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Couso, Jose I.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      An adaptive blocking coding system selects an effective blocking of an input image signal to be encoded in accordance with the correlation between fields, even if motion is detected between the fields.
      <br/>
      The blocking patterns include an individual field blocking, a non-interlace blocking, a split blocking and an inverted split blocking.
      <br/>
      Further, the coding system searches for motion from both odd and even fields of a frame for producing a motion compensated prediction signal in order to provide high-efficient coding.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <p num="1">
      This application is a divisional of application Ser.
      <br/>
      No. 09/178,619 filed Oct. 26, 1998 now U.S. Pat. No. 5,427,678, now allowed, which is a Div. of Ser. No. 08/803,235 filed Feb. 20, 1997, U.S. Pat. No. 5,867,220, which is a Cont. of Ser. No. 08/121,293 filed Sep. 13, 1993, U.S. Pat. No. 5,638,127, which is a Div. of Ser. No. 07/962,299 filed Oct. 16, 1992, U.S. Pat. No. 5,274,442.
    </p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="2">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="3">The present invention relates to an image coding system for coding an image signal with high efficiency.</p>
    <p num="4">2. Description of the Prior Art</p>
    <p num="5">
      As is known in the art, means for eliminating redundant components-included in an image signal is used for coding an image signal.
      <br/>
      A typical approach to image coding is the transform coding method wherein an image is divided into blocks, an orthogonal transform is carried out for each of the blocks, and the transform coefficients are encoded.
    </p>
    <p num="6">
      In the case of television signals such as an NTSC signal, interlaced scanning is used whereby an image signal of one frame is scanned twice, once in the odd field and once in the even field.
      <br/>
      The two fields scan different but complementary spaces of an image.
      <br/>
      The fields have image information at different times but there is a relatively strong correlation therebetween because the scanned lines of the two fields are alternate and adjacent.
      <br/>
      There is a technique in which coding is carried out after combining the fields and dividing them into blocks when coding an image signal produced by the interlaced scanning.
    </p>
    <p num="7">FIG. 1 is a block diagram showing the structure of an embodiment of "High Efficiency Image Coding System" described in the Japanese Patent Public Disclosure No. 1688/1991. In FIG. 1, the coding system includes a non-interlacing section 1, a motion detecting section 2, a non-interlace blocking section 3, an individual field blocking section 4, an orthogonal transform section 5, a quantizing section 6 for quantizing a conversion coefficient at the output of the orthogonal transform section 5, and coding section 7.</p>
    <p num="8">
      In operation, a series of input image signals 100, which are produced by the interlaced scanning method and applied to each field, are converted to a noninterlaced signal 101 in the non-interlacing section 1 as indicated in FIG. 2(C).
      <br/>
      As shown, the pixels belonging to the odd field and the pixels belonging to the even field appear alternately in every other line.
    </p>
    <p num="9">
      When an object is stationary and the correlation between adjacent lines is high, it is effective to use a non-interlaced signal and to code the image signal in a block including components from both fields.
      <br/>
      FIG. 3(A) shows an example of such a condition.
      <br/>
      On the other hand, when an object is moving, the correlation between adjacent lines is lowered and it is considered to be effective to execute the coding in units of individual fields.
      <br/>
      This is because a non-interlaced signal is used for the moving object results in discontinuation as shown in FIG. 3(B), causing a power to be generated in high frequency coefficients during the transform coding. in this case, the blocking as indicated in FIG. 3(C) is adequate.
    </p>
    <p num="10">
      Thus, the motion detector 2 detects the motion of an object and changes the operation when the object is detected as being stationary by a signal 103 indicating motion, to conduct the blocking shown in FIG. 3(A) (hereinafter, this arrangement of FIG. 3(A) is called the non-interlace blocking) in the non-interlace blocking circuit 3.
      <br/>
      If the object is detected to be moving, the motion detector 2 changes the operation to conduct the blocking shown in FIG. 3(C) (hereinafter, this arrangement of FIG. 3(C) is called the individual field blocking) in the individual field blocking circuit 4.
    </p>
    <p num="11">
      The blocks obtained by changing the blocking as explained above are subjected to the discrete cosine transformation (DCT) in the orthogonal transform section 5.
      <br/>
      The transform coefficients obtained as described above are quantized in the quantizing section 6, and a variable length code is assigned in the coding section 7 in accordance with the occurrence probability of respective events.
    </p>
    <p num="12">
      Since a conventional image coding system has been structured as described above, it has been difficult to realize the blocking utilizing the correlation between fields when an object is moving.
      <br/>
      Moreover, such a system has not utilized the property of different intensities in power distribution of the coefficients after conversion caused by the difference in arrangement of pixels within the block.
      <br/>
      In addition, there is the difference in power between the stationary blocks and moving blocks. the moving blocks having a high signal power which has not been utilized.
    </p>
    <p num="13">
      FIG. 4 is a block diagram of another conventional interframe predictive coding system described, for example, in the transactions on the 3rd HDTV International Work Shop, "A Study on HDTV Signal Coding with Motion Adaptive Noise Reduction" (Vol 3, 1989).
      <br/>
      In FIG. 4, this system comprises a frame memory 21, a motion detecting section 22, a subtracter 23, a coding section 24, a local decoding section 25, an adder 26 and a multiplexing section 27.
      <br/>
      Although omitted in this figure, the encoded data is decoded at a receiving side in order to reproduce the transmitted signal.
    </p>
    <p num="14">
      In operation, the motion of an object between the current field and the field of the same type of the preceding frame is detected block by block, the block consisting of a plurality of pixels of an input image signal 201 which is provided by the interlaced scanning method and formed of frames, each frame having both odd and even fields.
      <br/>
      The motion between odd fields is detected in the motion detecting section 22 by searching the block which has the most distinctive resemblance to the currently processing block among the already encoded blocks 202, adjacent to the position corresponding to the currently processing block in the odd fields stored within the frame memory 21.
      <br/>
      The degree of resemblance is evaluated by using an absolute sum of differential values or a square sum of differential values of the corresponding pixels in both blocks.
      <br/>
      The amount of motion in both horizontal and vertical directions between the current block and the block determined to be the most similar is provided as a motion vector 203.
      <br/>
      The frame memory 21 outputs a motion compensated prediction signal 204 corresponding to this motion vector 203.
    </p>
    <p num="15">
      A prediction error signal 205 obtained In the subtracter 23 by subtracting the motion compensated prediction signal 204 from the input signal 201 is applied to the coding circuit 24 in which the spatial redundancy is removed.
      <br/>
      Since low frequency components of an image signal generally occupy a greater part of the power thereof, information can be compressed by quantizing high power portions with a large number of bits and quantizing low power portions with a small number of bits.
      <br/>
      According to an example of this information compression method, the frequency conversion is carried out for an 8 * 8 pixels block by conducting an orthogonal transform such as a discrete cosine transform to scalar-quantize the transform coefficients.
      <br/>
      The scalar-quantized coding data 206 is sent to the local decoding section 25 and to the multiplexing section 27.
      <br/>
      The multiplexing section 27 conducts multiplexing and encoding for the coding data 206 and the motion vector 203 to output these signals to a transmission line 209.
    </p>
    <p num="16">
      Meanwhile, the local decoding circuit 25 executes the inverse operation of the operation in the coding section 24, namely the inverse scalar quantization and inverse orthogonal transform to obtain a decoded error signal 207.
      <br/>
      The motion compensated prediction signal 204 is added to the decoded error signal 207 in the adder 26 and stored in the frame memory 21 to detect motion of the odd field of the next frame.
    </p>
    <p num="17">
      In addition, the motion of the even fields of the input image signal 201 with respect to the already encoded field of the frame memory 21 is also detected for the coding of the motion compensated prediction error signal.
      <br/>
      As described above, in the conventional interframe predictive coding system, redundancy with respect to time included in moving image signals is removed by the motion compensated prediction coding and redundancy with respect to space is removed by the orthogonal transform.
    </p>
    <p num="18">Since the conventional interframe predictive coding system is structured to individually encode both the odd field and even field by predicting the current (present) odd field from the odd field of the already encoded frame and predicting the current even field from the even field of the already encoded frame, the encoding efficiency is low because the spatial correlation existing between the continuous fields, produced by the interlaced scanning method, is not used.</p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="19">
      The present invention has been proposed to overcome the problems in the prior art.
      <br/>
      Therefore it is an object of the present invention not only to adaptively discriminate between a block which is effective for non-interlace blocking and a block which is effective for individual field blocking, but also to enhance coding efficiency by adding a class of blocking so that field correlation is used even for a moving image, the quantization accuracy is controlled and the scanning sequence of transform coeffecients is changed in accordance with switching of the blocking.
    </p>
    <p num="20">It is another object of the present invention to provide a coding system for searching motion from both odd and even fields of the frame which is already encoded in order to predict each present field.</p>
    <p num="21">It is a further object of the present invention to provide a coding system for enabling highly efficient coding by realizing blocking for adaptively switching the field and frame in the block coding of prediction errors.</p>
    <p num="22">
      According to the first aspect of the present invention, an adaptive blocking image coding system encodes an input image signal obtained by interlaced scanning in a unit of the block of M pixels * N lines.
      <br/>
      More specifically the adaptive blocking image coding system comprises blocking means for selectively forming a first type block including only the pixels of M pixels * N lines belonging to the odd field of the input image signal or the pixels of M pixels * N lines belonging to the even field thereof, a second type block wherein the pixels of the M pixels * N/2 lines belonging to the odd field and the pixels of the N/2 lines belonging to the even field are arranged alternately in every other line corresponding to scanning positions on a display screen, a third type block wherein the pixels of M pixels * N/2 lines belonging to the odd field are arranged in the upper or lower half of the block and the pixels of M pixels * N/2 lines belonging to the even field are arranged in the remaining half of the block, and a fourth type block wherein the pixels of M pixels * N/2 lines belonging to the odd field are arranged in the upper or lower half of the block, the pixels of M pixels * N/2 lines belonging to the even field are arranged in the remaining half of the block and the pixels of either field are inverted upside down in the vertical direction with respect to the display screen.
      <br/>
      The system further includes blocking determining means for determining the type of blocking by the blocking means, a transform means for orthogonally transforming the block formed by the blocking means, quantizing means for quantizing the transform coefficient obtained by the transform means, and coding means for encoding the quantized index obtained by the quantizing means.
    </p>
    <p num="23">
      With the structure described above, the block of the M pixels * N lines if obtained by one blocking selected from the non-interlace blocking where the pixels of M pixels * N/2 lines belonging to the odd field and the pixels of M pixels * N/2 lines belonging to the even field are arranged in every other line corresponding to the scanning positions on the display screen, an arrangement (hereinafter, called split blocking) where the pixels of M pixels * N/2 lines belonging to the odd number field are arranged in the upper half or lower half block and the pixels of M pixels * N/2 lines belonging to the even field are arranged in the remaining half block, and an arrangement (hereinafter, called inverted split blocking) where the pixels of M pixels * N/2 lines belonging to the odd field are arranged in the upper or lower half block, the pixels of M pixels * N/2 lines belonging to the even field are arranged in the remaining half block and the pixels of either field are inverted in the vertical direction with respect to the display screen.
      <br/>
      The obtained block is orthogonally transformed the transform coefficients are quantized, and then the quantization index is encoded.
    </p>
    <p num="24">According to the second aspect of the present invention, the quantizing means for quantizing the transform coefficient in the adaptive blocking image coding system variably controls the quantization accuracy in accordance with the type of arrangement blocking-processed by the blocking means.</p>
    <p num="25">More specifically, one of the arrangements including individual field blocking, non-interlace blocking, split blocking, or inverted split blocking is orthogonally transformed, the transform coefficient is quantized and the quantizing index is encoded with the quantizing accuracy in accordance with the information, indicating the selected blocking.</p>
    <p num="26">According to the third aspect of the present invention, the coding means for encoding the quantizing index produced when quantizing the transform coefficient in the adaptive blocking image coding system determines the scanning sequence (path) for quantizing the transform coefficient in accordance with the type of arrangement to be blocking-processed by the blocking means.</p>
    <p num="27">More specifically, one of the arrangements to be blocking-processed by the individual field blocking, non-interlace blocking, split blocking, or inverted split blocking is orthogonally transformed, the transform coefficient is quantized, and the quantizing index is encoded with the quantization accuracy and the scanning sequence in accordance with the information indicating the selected blocking.</p>
    <p num="28">According to the fourth aspect of the present invention, the adaptive blocking image coding system comprises blocking determining means for selecting the type of arrangement to be blocking-processed in accordance with the value obtained by multiplying a predetermined weighting coefficient with the pixels of each line included in the block and then totaling such multiplied values.</p>
    <p num="29">
      More particularly, one of the arrangements to be blocking-processed by individual field blocking, non-interlace blocking, split blocking, or inverted split blocking is selected by the value obtained by multiplying the predetermined weighting coefficient with the pixels of each line included in the block and then totaling such multiplied values.
      <br/>
      The selected block is orthogonally transformed, the transform coefficient is quantized and the quantizing index is encoded.
    </p>
    <p num="30">According to the fifth aspect of the present invention, the adaptive blocking image coding system also comprises a blocking determining means for selecting the type of arrangement which has the minimum coefficient power of a predetermined high frequency component among the transform coefficients obtained by discrete cosine transform of the block.</p>
    <p num="31">
      In other words, one of the arrangements to be blocking-processed by individual field blocking, non-interlace blocking, split blocking, or inverted split blocking is selected in such a manner that the coefficient power of the predetermined high frequency element component is the minimum among the transform coefficients obtained by discrete cosine transform of the block.
      <br/>
      The determined block is orthogonally transformed, the transform coefficient is quantized, and the quantizing index is encoded.
    </p>
    <p num="32">According to the sixth aspect of the present invention, there is provided a coding system which individually searches the motion from both odd and even fields of the already encoded frame in order to predict the field to be encoded, the system comprising the following elements:</p>
    <p num="33">
      (a) input means for inputting an input signal to be encoded;
      <br/>
      (b) a field memory for storing signals based on the input signal bad dividing it into a plurality of fields such as the odd field and even field;
      <br/>
      (c) predictive signal output means for outputting predictive signals of a plurality of types predicting the change of input signal on the basis of signal stored in the field memory;
      <br/>
      (d) a selector for selecting a predictive signal from the predictive signals provided by the predictive signal output means; and
      <br/>
      (e) coding means for encoding the input signal using the relationship between the predictive signal selected by the selector and the input signal from the input means.
    </p>
    <p num="34">With such an arrangement, the coding system can provide stabilized prediction efficiency regardless of motion of an object by making reference to both fields of the already encoded frame for the purpose of prediction.</p>
    <p num="35">According to the seventh aspect of the present invention, the coding system is structured to realize adaptive prediction from the searched two kinds of motion compensated predictive signals and a plurality of predictive signals combining interpolation signals of these motion compensated predictive signals.</p>
    <p num="36">
      Since the coding system as constructed utilizes a predictive signal produced by interpolating the predictive signals from both fields of the already encoded frame, motion at the intermediate point of time and space of the two fields used for the prediction can be considered.
      <br/>
      Moreover, this coding system also functions as a low-pass filter, whereby the prediction efficiency can be improved and the encoded image is stabilized.
    </p>
    <p num="37">
      According to the eighth aspect of the present invention, the coding system executes the encoding, for example encoding prediction error signals, by adaptively switching the encoding operation from blocking of the pixels of only the odd field or even field of the frame for encodement to blocking of both odd and even fields for encodement, the system comprising the following elements:
      <br/>
      (a) input means for inputting an input signal to be encoded by dividing into a plurality of fields such as an odd field and even field;
      <br/>
      (b) a blocking selection section for selecting, at the time of blocking and encoding the signal from the input means, a block suitable for the encoding between the block consisting of the signal of only one kind of field and the block consisting of the signal combining signals of a plurality of fields;
      <br/>
      (c) a block forming section for forming a block selected by the blocking selection section; and
      <br/>
      (d) coding means for encoding a block formed by the block forming section.
    </p>
    <p num="38">The coding system having such a structure provides high efficiency encoding by selecting the blocking method most suitable for the encoding, i.e., blocking the pixels of only either of the odd field or even field, or blocking the pixels of both odd and even fields.</p>
    <p num="39">
      According to the ninth aspect of the present invention, the coding system also comprises a concrete selecting means for adaptively switching the block selection.
      <br/>
      This selecting means includes any one of the following selecting mans:
      <br/>
      (a) selecting means for selecting the block with the least amount of encoding information from a plurality kinds of block;
      <br/>
      (b) selecting means for selecting the block with the least amount of encoding errors from a plurality kinds of block; and
      <br/>
      (c) selecting means for selecting the block with the least amount of high-frequency components in the signal to be encoded from a plurality kinds of block.
    </p>
    <p num="40">The coding system having such a structure enables adaptive switching of the blocking by selecting the blocking with less encoding information, the blocking with less encoding errors, or the blocking with less high frequency components included in the signal to be encoded, from the blocking of the pixels of one of only the odd or even field or the blocking of the pixels of both odd and even fields.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="41">
      The invention will be more fully understood from the following detailed description and the accompanying drawings in which:
      <br/>
      FIG. 1 is a block diagram of an image coding system in the prior art;
      <br/>
      FIG. 2 is a diagram for explaining non-interlace blocking;
      <br/>
      FIG. 3 is a diagram for explaining an adaptive blocking of the prior art;
      <br/>
      FIG. 4 is a block diagram showing the structure of another coding system of the prior art;
      <br/>
      FIG. 5 is a block diagram of an embodiment of the present invention;
      <br/>
      FIG. 6 is a diagram for explaining adaptive blocking in the embodiment shown in FIG. 5;
      <br/>
      FIG. 7 is a block diagram showing the structure of an adaptive field/frame coding system of another embodiment of the present invention;
      <br/>
      FIG. 8 is a diagram showing an exemplary input image signal;
      <br/>
      FIG. 9 is a block diagram showing an example of the structure of an interpolating section shown in FIG. 7;
      <br/>
      FIG. 10 is a diagram for explaining the operation of a motion detecting circuit
      <br/>
      FIG. 11 is a diagram for explaining the operation for using a motion compensated predictive signal in the embodiment shown in FIG. 7;
      <br/>
      FIG. 12 is a block diagram showing the structure of an adaptive field/frame coding system according to another embodiment of the present invention;
      <br/>
      FIG. 13 is a block diagram showing another example of the interpolating section;
      <br/>
      FIG. 14 is a block diagram showing an adaptive field/frame coding system according to embodiment of the present invention;
      <br/>
      FIG. 15 is a block diagram showing an example of the structure of the blocking selection section;
      <br/>
      FIG. 16 is a diagram showing a structural example of the block selected by the blocking selecting section;
      <br/>
      FIG. 17 is a block diagram showing a structural example of the blocking forming section;
      <br/>
      FIG. 18 is a block diagram showing a structural example of the blocking decomposing section;
      <br/>
      FIG. 19 is a block diagram showing another structural example of the blocking selecting section;
      <br/>
      FIG. 20 is a block diagram showing another structural example of the blocking selecting section;
      <br/>
      FIG. 21 is a block diagram showing a structural example of the frequency analyzing section;
      <br/>
      FIG. 22 is a diagram showing an example of the accumulated frequency components; and
      <br/>
      FIG. 23 is a block diagram showing another structural example of the present invention.
    </p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
    <p num="42">
      Referring to FIG. 5, an embodiment of the present invention is shown as an adaptive blocking image coding system.
      <br/>
      In FIG. 5, the image coding system comprises a non-interlacing section 1 for conducting non-interlace processing; a blocking determination section 8; an individual field blocking section 4; a non-interlace blocking section 3; a split blocking section 9; an inverted split blocking section 10; an orthogonal transform section 11; a quantizing section 12 and coding section 13.
      <br/>
      Such various types of blocking are shown in FIG. 6.
      <br/>
      FIGS. 6A-6D show individual field blocking non-interlace blocking, split blocking and inverted split blocking, respectively.
    </p>
    <p num="43">The operation will be explained with reference to FIG. 5 and FIGS. 6A-6D. The input. image signal series 100 which is scanned by the interlace scanning method and is inputted field by field is converted into a non-interlace signal 101 in the non-interlace section 1.</p>
    <p num="44">
      FIG. 2 shows a profile of non-interlace processing in the prior art similar to the non-interlace processing in the present invention.
      <br/>
      When (A) is defined as an input image signal from the odd field and (B) as an input image signal of the even field, the non-interlaced signal 101 shown in (C), alternately combining the lines from respective fields, can be obtained.
    </p>
    <p num="45">
      The Individual field blocking section 4 executes, as shown in FIG. 6(A), blocking in which the fields are processed individually.
      <br/>
      This blocking is effective when the correlation between the fields is not available because of quick motion.
    </p>
    <p num="46">
      The non-interlace blocking section 3 executes the blocking shown in FIG. 6(B).
      <br/>
      In the case of a stationary or still image, a continuous image can be obtained by non-interlaced processing of the fields.
      <br/>
      The wavelength of the signal thereby becomes substantially longer, resulting in power being concentrated on low frequency components in the successive transform coding.
    </p>
    <p num="47">
      The split blocking section 9 conducts the blocking as shown in FIG. 6(C).
      <br/>
      This blocking is effective in the case where the correlation between the fields exists but the fields are noncontinuous when non-interlace blocking is carried out.
    </p>
    <p num="48">
      The inverted split blocking section 10 conducts the blocking shown in FIG. 6(D).
      <br/>
      This blocking is also effective in the case where the correlation between fields exists but the fields are noncontinuous when non-interlace blocking is carried out.
      <br/>
      This blocking prevents discontinuation at the center of the block when the split. blocking method is used.
    </p>
    <p num="49">
      The blocking determinating section 8 determines the optimum blocking from a plurality of blockings as explained above and outputs a blocking arrangement selecting signal 102 for selecting the determined blocking.
      <br/>
      Here, it is important to enhance the concentration of power, on the low frequency coefficients in the transform coding.
      <br/>
      For this purpose, it is effective to evaluate the amplitude of high frequency components in each blocking and select the blocking having the minimum amplitude.
    </p>
    <p num="50">
      In one of the evaluation methods, a weight is multiplied with the pixels of each line and the obtained values are then totaled.
      <br/>
      For example, the weight of +1 is given to the lines 0, 2, 4, 6 using the line numbers shown in FIG. 6, and the weight of -1 is given to the lines 1, 3, 5, 7.
      <br/>
      Thereafter, the obtained values are totaled to obtain the absolute value of the sum.
      <br/>
      Moreover, the weight +1 is given to the lines 8, 10, 12, 14, and the weight -1 is given to the lines 9, 11, 13, 15.
      <br/>
      The obtained values are then totaled to also obtain the absolute values of the sum.
      <br/>
      Both absolute values are totaled.
      <br/>
      Thus, the weighting is inverted alternately for respective lines and it is equivalent to the evaluation of the maximum frequency component when non-interlace blocking has been conducted.
    </p>
    <p num="51">
      Further, the weight +1 is given to the lines 0, 4, 8, 12 and the weight -1 to the lines 2, 6, 10, 14.
      <br/>
      The obtained values are totaled to obtain the absolute value of the sum.
      <br/>
      In addition, the weight +1 is given to the lines 1, 5, 9, 13 and the weight -1 to the lines 3, 7, 11, 15.
      <br/>
      The obtained values are then totaled to obtain the absolute value of the sum.
      <br/>
      These absolute values are also totaled to evaluate the maximum frequency component of the individual field blocking.
    </p>
    <p num="52">
      In addition, the weight +1 is given to the lines 0, 4, 1, 5 and the weight -1 to the lines 2, 6, 3, 7.
      <br/>
      The obtained values are totaled to obtain the absolute value of the sum.
      <br/>
      The weight +1 is also given to the lines 8, 12, 9, 13 and the weight -1 to the lines 10, 14, 11, 15.
      <br/>
      The obtained values are totaled to obtain the absolute value or the sum.
      <br/>
      Both absolute values are then totaled to evaluate the maximum frequency component of the split blocking.
    </p>
    <p num="53">
      The weight +1 is given to the lines 0, 4, 7, 3 and the weight -1 to the lines 2, 6, 5, 1.
      <br/>
      The obtained values are totaled to obtain the absolute value of the sum.
      <br/>
      Moreover, the weight +1 is given to the lines 8, 12, 15, 11 and the weight -1 to the lines 10, 14, 13, 9.
      <br/>
      The obtained values are totaled to obtain the absolute value of the sum.
      <br/>
      These absolute values are totaled to evaluate the maximum frequency component of the inverted split blocking.
    </p>
    <p num="54">In another method for evaluation of each blocking, the number of orthogonal transformed coefficients having an amplitude larger than a predetermined threshold value for the respective blockings is counted, and the blocking having the minimum number is selected.</p>
    <p num="55">
      The orthogonal transform section 11 carried out the orthogonal transform of the selected block to obtain the transform coefficients.
      <br/>
      The obtained transform coefficients are quantized in a fixed sequence by the quantizing section 12.
      <br/>
      In this case, some difference lies in the power of the coefficients depending on the type of blocking.
      <br/>
      In general, non-interlace blocking tends to be selected for a stationary region and the power is comparatively stall.
    </p>
    <p num="56">
      Meanwhile, since the correlation between fields becomes small in a quick motion area, individual field blocking is often selected and the power is large.
      <br/>
      Moreover, split blocking and inverted split blocking are considered to be intermediate to the above two blockings.
      <br/>
      Therefore, efficiency can be improved by variably controlling quantization accuracy in accordance with the type of blocking.
    </p>
    <p num="57">
      The quantizing accuracy can also be controlled variably in accordance with not only the type of blocking but also the combination of actual signal power and quantization error power.
      <br/>
      In this case, it is also possible to execute variable length coding by combining the information indicating type of blocking and the information indicating quantization accuracy.
    </p>
    <p num="58">
      Indexes obtained by quantizing the coefficients are encoded in the coding section 13.
      <br/>
      In this case, the coefficients are scanned from those having a larger coefficient power to those having a smaller one in order to enhance the efficiency of encoding.
      <br/>
      For the coefficients having a power lower than a certain specified value, the encoding may cease.
      <br/>
      Therefore, it is very convenient if the power distribution can be anticipated.
      <br/>
      There is a tendency with respect to the distribution of power of the coefficients that the power is increased as the frequency is lower.
      <br/>
      However, if the blocking is adaptively changing, as in the present invention, the coefficients having lower power do not always correspond to low frequency components.
      <br/>
      Then, the coding efficiency can be improved by changing the scanning sequence or path in accordance with the type of blocking.
    </p>
    <p num="59">Since the present invention is structured as explained above, the following effects can be obtained.</p>
    <p num="60">
      The coding efficiency of transform coding is improved by switching the blocking of an image signal scanned by the interlaced scanning method into an adapted blocking.
      <br/>
      Moreover, the efficient assignment of information quantity can be realized by variably controlling the quantizing accuracy of transform coefficients correspondingly to the switching of the blocking.
      <br/>
      In addition, the encoding efficiency can also be improved in transform coding by changing the scanning sequence of the transform coefficients within the block.
    </p>
    <p num="61">
      Referring now to FIG. 7, a structural diagram of an adaptive field/frame coding system according to another embodiment of the present invention is shown.
      <br/>
      The system includes an odd field memory 28 for storing local decoded signals of odd fields, an even field memory 29 for storing local decoded signals of even fields, an interpolation section 20 for interpolating a predictive signal with motion compensated from the two fields, and a selector 21 for selecting a predictive signal which gives the optimum prediction from three signals of the signals predicted from the odd and even fields and the interpolated predictive signal.
      <br/>
      In FIG. 7, sections 200, 300 and 500 enclosed by a broken line respectively denote motion detecting means, predicting error signal output means and coding means.
    </p>
    <p num="62">
      FIG. 8 shows a profile of input image signals 201 which are scanned by the interlaced scanning method, wherein the odd and even fields are alternately applied.
      <br/>
      FIG. 8 shows the fields in the coordinates where time is plotted on the horizontal axis and vertical direction on the vertical axis.
      <br/>
      In FIG. 8, K1 indicates an odd field of the first frame, while G1, an even ficld of the first frame.
      <br/>
      In the same manner, K2 is an odd field of the second frame, while G2, an even field of the second frame.
    </p>
    <p num="63">
      FIG. 9 is a block diagram of an example of the interpolating section 20.
      <br/>
      A simple arithmetic mean of the motion compensated prediction signal 204a from the inputted odd fields and the motion compensated prediction signal 204b from the inputted even fields is obtained and is used as an interpolation predictive signal 204c.
    </p>
    <p num="64">
      The operation will be explained with reference to FIGS. 7, 8 and 9.
      <br/>
      Motion of the odd fields and even fields of the present frame in relation to the preceding frame is detected in units of blocks including pixels (n * m) in response to the input image signal 201 which is scanned by the interlace scanning method and includes the odd and even fields alternately.
      <br/>
      The motion of the odd fields between the present and the preceding frames is detected by searching, in the motion detecting section 22, the block which most resembles the currently processed block in the image signal 201 from the blocks adjacent 202a to the position corresponding to the currently encoded object in the already encoded odd fields stored within the odd field memory 28.
    </p>
    <p num="65">
      As shown in FIG. 10, for example, it is assumed that image H1 exists within one block unit (n * m) in the preceding frame, and the image moves to position H2 from position H1 in the present input image signal.
      <br/>
      The motion detecting section 22 outputs a motion vector 203 which indicates the block has moved horizontally to H2 from H1 In this case, since motion is not detected in the vertical direction, the motion vector 203 has the value of 0 with regard to vertical direction.
      <br/>
      The motion in the horizontal and vertical directions thus obtained is outputted as the motion vector 203.
    </p>
    <p num="66">
      The odd field memory 28 outputs a motion compensated prediction signal 204a corresponding to this motion vector 203.
      <br/>
      Similarly, compensation for motion of the even fields in the preceding frame is carried out in the motion detecting section 22, by searching the block resembling the currently processed block from the adjacent blocks 202b within the even field memory 29 and outputting the result as the motion vector 203.
      <br/>
      The motion compensated prediction signal 204b corresponding to this motion vector 203 is outputted from the even field memory 29.
    </p>
    <p num="67">
      The interpolation processing is carried out in the interpolating section 20 shown in FIG. 9, by using the motion compensated prediction signals 204a and 204b to generate the interpolation predictive signal 204c, signal 204a being generated by motion compensated in accordance with the motion vector 203 and provided from the odd field memory 28, and motion compensated predictive signal 204b being generated by motion compensated in accordance with the motion vector 203 and provided from the second field memory 9.
      <br/>
      A predictive signal having the minimum error signal power with respect to the currently encoding object block of the input image signal 201 is selected by the selector 21 from among the motion compensated prediction signal 204a obtained from the odd field, the motion compensated prediction signal 204b obtained from the even field, and the interpolated motion compensated prediction signal 204c, and then the predictive signal 210 is produced.
    </p>
    <p num="68">
      FIG. 11 is a diagram showing the operation explained above.
      <br/>
      It is assumed that the odd field memory 28 shown in FIG. 7 stores an odd field K1 of the preceding (previous) frame, awhile the even field memory 29 of FIG. 7 stores an even field G1 of the preceding frame.
      <br/>
      Here, the case where an odd field K2 and an even field G2 are included in the current (present) frame of the input image signal 201 will be discussed.
      <br/>
      First, when the odd field K2 is inputted, the motion compensated prediction signal. 204a from the odd field K1 of the preceding frame stored in the odd field memory 28 is provided to the selector 21.
      <br/>
      In the same manner, the even field G1 of the preceding frame stored in the even field memory 29 is provided to the selector 21 as the motion compensated prediction signal. 204b. Then, the data of K1 and G1 are applied to the interpolating section 20 and the interpolation processing as shown in FIG. 9 is conducted Thereafter, such data is supplied to the selector 21 as the motion compensated prediction signal 204c.
      <br/>
      The selector 21 compares these three kinds of motion compensated prediction signals 204a, 204b, 204c and the input image signal 201 to select the prediction signal which has the minimum error signal power.
    </p>
    <p num="69">In the same manner, the selector 21 is responsive to the even field G2 of the current frame to receive the prediction signal 204a based on the odd field K1 stored in the odd field memory 28, the motion compensated prediction signal 204b based on the even field G1 stored in the even field memory 29, and the motion compensated prediction signal 204c obtained by the interpolation process on the basis of these motion compensated prediction signals 204a, 204b based on both fields, and to select the prediction signal which has the minimum error signal power.</p>
    <p num="70">
      In this embodiment (FIG. 7), the interpolation section is provided to conduct the interpolation processing based on the motion compensated prediction signals 204a, 204b from the odd field memory 28 and even field memory 29 and thereby motion compensated prediction signal 204c is produced.
      <br/>
      However, it is also possible that the interpolation section 20 is not used as shown in FIG. 12. In this case, the motion compensated prediction signal is generated in the selector 21 on the basis of the preceding odd field K1 stored in the odd field memory 28 and the preceding even field Gi stored in the even field memory 29 and the selector 21 selects the prediction signal minimizing the error signal power in these two kinds of motion compensated prediction signals 204a, 204b.
    </p>
    <p num="71">Further, in the embodiment shown in FIG. 7, the simple arithmetic mean has been used for the interpolation section, but coding ensuring higher prediction efficiency can be realized by utilizing a weighted arithmetic mean taking into consideration field distance, as will be explained hereunder with reference to FIG. 13.</p>
    <p num="72">
      FIG. 13 is a block diagram of an example of the interpolation circuit 20.
      <br/>
      The motion compensated prediction signal 204a from the odd field is multiplied by a weight a based on the distance to the field to be encoded, and the motion compensated prediction signal 204b from the even field is multiplied by a weight  BETA  based on the distance to the field to be encoded.
      <br/>
      Thereafter, the arithmetic mean of these values is obtained and the output thereof is used as interpolation predictive signal 204c.
    </p>
    <p num="73">The practical value of the weighting by the interpolation section 20 in relation to the embodiment shown in FIG. 13 will be explained with reference to FIG. 11.</p>
    <p num="74">
      As shown in FIG. 11, when T is considered a unit of time for inputting an odd field or an even field, there is a time difference of 2T between odd field K1 and odd field K2.
      <br/>
      On the other hand, there is a time difference of T between even field G1 and odd field K2.
      <br/>
      Thus, the weights  ALPHA  and  BETA  can be determined by utilizing such time differences.
      <br/>
      For example, since the odd field K1 has a time distance of 2T, the weight  ALPHA  is set to 1.
      <br/>
      Also, since even field G1 has a time distance of T from odd field K2, the value of weight can be increased for the field having the lesser time distance by setting the value of  BETA  to 2.
      <br/>
      In the same manner, odd field K1 has a time distance of 3T from even field G2 and even field G1 has a time difference of 2T.
      <br/>
      Thus, it is possible to give the value of weight which is proportional to the time difference by setting  ALPHA  to 2 and  BETA  to 3 for weighting even field G2.
    </p>
    <p num="75">
      In the embodiment shown in FIG. 13, the weights  ALPHA  and  BETA  are determined in the interpolating section on the basis of time distance.
      <br/>
      However, it is also possible that the weight a to be given to the odd field is always set, for example, larger or smaller than weight  BETA  to be given to the even field regardless of the time distance.
      <br/>
      Further, in this embodiment, weights  ALPHA  and  BETA  used for the odd fields arc different from those used for the even fields, but the weights for the odd fields may be equal to those for the even fields.
      <br/>
      In addition, in this embodiment, only weights  ALPHA  and  BETA  are used, but the weights may be determined in accordance with the other coefficients, for example, a coefficient having a quadratic function or another function having particular characteristics.
      <br/>
      Moreover, weights  ALPHA  and  BETA  do not have to be restricted only to one kind of value; it is possible that several kinds of weights  ALPHA  and  BETA  are prepared and selected in accordance with the kind of input signal or the characteristic of input signal.
    </p>
    <p num="76">Another embodiment of the present invention will be explained with reference to FIG. 14.</p>
    <p num="77">
      The embodiment shown in FIG. 14 comprises a blocking selection section 82 for selecting between an individual blocking of a prediction error signal for the odd and even fields and a non-interlace blocking including both odd and even fields; a blocking forming section 83 for conducting the blocking in accordance with the output of the blocking selection section 82; and a blocking decomposing section 84 for decomposing the blocking to form the original field in accordance with the block selection output.
      <br/>
      Section 400 enclosed by a broken line denotes blocking means and the other sections 200, 300, 500 are similar to those shown in FIG. 7.
    </p>
    <p num="78">
      FIG. 15 is a block diagram of an example of the blocking selection section 82.
      <br/>
      The prediction error signal 205 is stored in the odd field memory 31 for the odd field and in the even field memory 32 for the even field.
      <br/>
      As shown in FIG. 16(a) and 16(b), a block of p=16, q=16 is considered.
      <br/>
      The individual field blocking section 33 executes the blocking including the pixels of either of the odd or even field within the block of (p pixels * q lines), and these pixels are encoded in a coding section 35.
      <br/>
      As shown in FIG. 16(c), a non-inter-lace blocking section 34 executes the blocking of (p pixels * q lines) included in the block by alternately arranging the pixels of both odd and even fields, and these pixels are encoded in a coding circuit 36.
      <br/>
      The information quantity comparing section 37 compares the quantity of data encoded in the coding section 35 and the coding circuit 36, and outputs a blocking selection signal 211 indicating the blocking having the least amount of information.
    </p>
    <p num="79">
      FIG. 17 is a block diagram of an example of the blocking forming section 83.
      <br/>
      The prediction error signal 205 is stored in the odd field memory 41 for the odd field and in the even field memory 42 for the even field.
      <br/>
      In accordance with the blocking selection signal 211 supplied from the blocking selection section 82, the blocking forming section 43 selects the blocking of the prediction error signals stored in the odd field memory 41 and even field memory 42 from the blocking including pixels of either of the odd or even field within the block of (p pixels * q lines) and the blocking including pixels of both odd and even fields within the block of (p pixels * q lines) , and then outputs the blocked prediction error signal.
    </p>
    <p num="80">
      FIG. 18 is a block diagram of an example of the blocking decomposing section 84.
      <br/>
      The data decoded by a local decoding circuit 25 is applied to the blocking decomposing section 44 in which the blocking is decomposed in accordance with the blocking selection signal 211 from the blocking selecting section 82, and the decomposed block is then stored in the individual field memories 45, 46.
      <br/>
      The stored data is supplied as a decoded error signal 207.
    </p>
    <p num="81">The operation of this embodiment is explained hereunder.</p>
    <p num="82">
      The prediction error signal 205 obtained by subtracting the prediction signal 210 from an input signal 201 in a difference circuit 23 is sent to the blocking forming section 83 shown in FIG. 17 and to the blocking selection section 82 shown in FIG. 15. The blocking selection section 82 produces the blocking selection signal 211 for selecting the blocking including the pixels of either the odd or even field in the block of (p pixels * q lines), or the blocking including the pixels of both odd and even fields in the block of (p pixels * q lines).
      <br/>
      The blocking forming section 83 conducts individual field blocking or non-interlace blocking in units of (p * q) blocks in accordance with the blocking selection signal 211.
      <br/>
      The blocked signal is applied to the coding circuit 24.
      <br/>
      The coding section 24 execute the orthogonal transform and sends the encoded data 206 which is a scalar-quantized transform coefficient to both the local decoding section 25 and the multiplexing section 28.
    </p>
    <p num="83">
      After the inverse scalar-quantization and inverse orthogonal transform by the local decoding section 25, the data is decomposed into the odd and even fields in the blocking decomposing section shown in FIG. 18 which decomposes the blocking into the fields in accordance with the blocking selection signal 211 in order to obtain the decoded difference signal 207.
      <br/>
      The local decoded signal 208 obtained by adding a predictive signal 210 to the decoded difference signal 207 in the adder 207 is stored in the first field memory 28 when it is the odd field or in the second field memory 29 when it is the even field, to detect the motion of each field of the next frame.
    </p>
    <p num="84">In this embodiment, a unit of blocks is formed of p=16, q=16, but it is desirable that the values of p and q have the following relationship with the block size n * m used by the motion detecting section 22 as explained in the embodiment shown in FIG. 7:</p>
    <p num="85">p=n, q=2m</p>
    <p num="86">
      Since DCT transform is often carried out in the block unit of 8 pixels * 8 lines, the size of 16 pixels * 16 lines combining four block units is selected as the values of p and q in the blocking forming section.
      <br/>
      In this example, since P=n, n=16 pixels.
      <br/>
      Also, since q=2m, m=8.
      <br/>
      Thus, it is desirable that the number of lines be reduced to 8 because the motion detecting section 22 detects motion for both the odd and even fields.
      <br/>
      Meanwhile, since it is possible to employ the blocking combining the odd field and even field in the blocking forming section, it is desirable to form a block of 16 lines including the odd and even fields.
    </p>
    <p num="87">In the embodiment shown in FIG. 14, the blocking has been selected by comparing the quantity of information generated as shown in FIG. 15, but coding based on the quality of encoding can be realized by selecting the blocking on the basis of the comparison of encoding quality as shown in FIG. 19.</p>
    <p num="88">
      FIG. 19 is a block diagram of an example of the blocking selection section 82.
      <br/>
      The predicting error signal 205 is stored in the odd field memory 51 for the odd field and in the even field memory 52 for the even field.
      <br/>
      The individual field blocking section 53 realizes the blocking including the pixels of either the odd field or the even field within the block of (p pixels * q lines), and the coding/decoding section 55 enables encoding/decoding.
      <br/>
      At the same time, the non-interlace blocking section 54 realizes the blocking including the pixels of both fields within the block of (p pixels * q lines), and the coding/decoding circuit 56 enables coding/decoding.
      <br/>
      The difference between the encoded/decoded data of the individual. field blocking and the data just before the encoding is compared with the difference between the encoded/decoded data of the combined field blocking and the data just before the encoding, by the error comparator 59 in order to select the blocking with less errors and to provide an output as the blocking selection signal 211.
    </p>
    <p num="89">
      In the embodiment shown in FIG. 14, the quantity of generated information has been compared for the selection of the block, while in the embodiment shown in FIG. 19, the encoding errors have been compared.
      <br/>
      However, encoding with higher efficiency can be realized when conducting encoding utilizing the orthogonal transform, by selecting the blocking on the basis of the comparison of frequency components produced by the difference of blocking as shown in FIG. 20.
    </p>
    <p num="90">
      FIG. 20 is a block diagram of an example of the blocking selection circuit 82.
      <br/>
      The predicting error signal 205 is stored in the odd field memory 61 for the odd field and in the even field memory 62 for the even field.
      <br/>
      The individual field blocking section 63 executes the hocking including the pixels of only either the odd field or even field within the block of (p pixels * q lines), and a frequency analyzing section 65 such as that showing in FIG. 2 executes the frequency analysis.
      <br/>
      The non-interlace blocking circuit 64 executes the blocking including pixels of both fields within the block of (p pixels * q lines), and a frequency analyzing circuit 66 such as that shown in FIG. 21 executes the frequency analysis.
      <br/>
      The blocking with fewer high-frequency components is selected from the individual field blocking and the combined field blocking to output the blocking selection signal 211.
    </p>
    <p num="91">
      FIG. 21 is a block diagram of an example of the frequency analyzing sections 65 and 66.
      <br/>
      The signal obtained by individually blocking the odd and even fields from the individual field blocking circuit 63, and the signal obtained by blocking the pixels of both odd and even fields from the non-interlace blocking section 64, are supplied to sections 65 and 66.
      <br/>
      These signals are converted to a signal in the frequency domain from a signal in the pixel domain using the orthogonal transform 68.
      <br/>
      The high-frequency components are extracted from the converted signal in the frequency domain by a high-frequency component selector 69 and the extracted high-frequency components are totaled by a high-frequency component accumulator 70.
      <br/>
      The accumulated high-frequency components are compared in a high-frequency component comparing section 67 to select the blocking with fewer amount high-frequency components.
    </p>
    <p num="92">
      FIG. 22 shows an example of the components accumulated by the high-frequency component adder 70 from the orthogonal transformed frequency domain signal.
      <br/>
      Here, eight, components, for example, having the maximum frequency component in the vertical frequency component, are selected.
    </p>
    <p num="93">In this embodiment, the coding section 24 does not use the selection information of predictive signals or the selection information of blocking, but according to another embodiment shown in FIG. 23, finer control is possible and high encoding quality can be realized by inputting an output of the selector 11 as the selection signal for the predictive signal and the blocking selection signal as the selection signal for the blocking to the coding section 24 and by controlling the encoding characteristic with the selected prediction signal and the information of the selected blocking.</p>
    <p num="94">
      As explained above, the embodiment of FIG. 7 relates to a system for realizing predictive coding of an input image signal obtained by the interlaced scanning method with the motion compensation.
      <br/>
      The system includes motion detecting means for obtaining, for the odd or even field of the input image signal, the amount of displacement, in order to carry out the individual motion compensated prediction, in units of the block of (n pixels * m lines) (n and m: positive integer) from both the odd and even fields of the already encoded frame, and the prediction error signal output means for selecting, with a selector 21, the predictive signal indicating the optimum prediction from signals including a first predictive signal 204a obtained by the motion compensation from the odd field, a second predictive signal 204b obtained by the motion compensation from the even field, and a third predictive signal 204c obtained by interpolating the first and second predictive signals in order to obtain the difference from the field of the input signal and output the result as the prediction error signal.
    </p>
    <p num="95">Moreover, the embodiment of FIG. 7 is an adaptive field/frame coding system characterized in that the interpolation means for obtaining the third predictive signal is the simple arithmetic mean of the first predictive signal and the second predictive signal.</p>
    <p num="96">Thus, the hardware can be minimized in size and encoding with higher prediction efficiency can be realized by generating an interpolation signal of the predictive signal by simply obtaining the arithmetic mean of both predicted odd and even fields with motion compensation.</p>
    <p num="97">Further, the embodiment of FIG. 13 is an adaptive field/frame coding system characterized in that the interpolation means for obtaining the third predictive signal is the weighted arithmetic mean of the first predictive signal and the second predictive signal, also considering the time distance of the field used for the prediction and the field to be encoded.</p>
    <p num="98">Thus, encoding ensuring very high prediction efficiency can be realized by generating the interpolation signal from the weighted arithmetic mean of both predicted odd and even fields with the motion compensation, while considering the time distance of the field used for the prediction and the field to be encoded.</p>
    <p num="99">The embodiment shown in FIG. 14 is an adaptive field/frame coding system comprising means for enabling encoding by selecting blocking including the pixels of either the odd field or even field within the block of (p pixels * q lines), or blocking including the pixels of both odd and even fields within the block of (p pixels * q lines), in order to encode the prediction error signal for the odd and even fields of the input image signal in units of the block of (p pixels * q lines) (p and q: positive integer).</p>
    <p num="100">Moreover, the embodiment shown in FIG. 14 is an adaptive field/frame coding system characterized in that the blocking means for enabling encoding while selecting the blocks comprises selecting means for selecting the blocking with less information for encoding from blocking including the pixels of only one of the odd field and even field within the block of (p pixels * q lines), and blocking including the pixels of both odd and even fields within the block of (p pixels * q lines).</p>
    <p num="101">The embodiment shown in FIG. 19 is an adaptive field/frame coding system characterized in that the blocking means for enabling encoding while selecting the blocks comprises means for selecting the blocking with less encoding error from blocking including the pixels of only one of the odd field and even field within the block of (p pixels * q lines), and blocking including the pixels of both odd and even fields within the block of (p pixels * q lines).</p>
    <p num="102">The embodiment shown in FIG. 20 is an adaptive field/frame coding system characterized in that the blocking means for enabling encoding while selecting the blocks comprises selecting means for selecting the blocking with less high-frequency components included in the signal to be encoded from blocking including the pixels of only one of the odd field and even field within the block of (p pixels * q lines), and blocking including the pixels of both odd and even fields within the block of (p pixels * q lines).</p>
    <p num="103">In addition, the embodiment shown in FIG. 23 is an adaptive field/frame coding system characterized by enabling encoding while selecting the quantization characteristic of the transform coefficient in accordance with the selected predictive signal and the selected blocking, in the case of employing the orthogonal transformer and carrying out encoding by the quantization of transform coefficient in the coding section for the encoding in units of the block of (p pixels * q lines).</p>
    <p num="104">
      In the above embodiments, an input image signal 201 is formed of the frame including the odd field and even field.
      <br/>
      However, the use of the odd field and even field is intended to show only an example, and the field is not restricted to the odd or even field.
      <br/>
      The present invention can be useful whenever one frame is divided into fields, the odd field and even field being only examples of such fields of a frame.
      <br/>
      For instance, the present invention can also be applied to a case of storing data by dividing the frame into two fields every two lines by, for example defining the first field as the 1st and 2nd lines and the second field as the 3rd and 4th lines, and defining the first field as the 5th and 6th lines and the second field as the 7th little and 8th line, etc.
      <br/>
      Moreover, in addition to dividing a frame into two kinds of fields, such as the odd field and the even field or the first field and the second field, the present intention can also be applied to the case of dividing a frame into more than two fields, for example, three or four kinds of fields.
      <br/>
      In such a case, the number of field memories corresponds to the number of kinds of fields, and the processing explained above is carried out for each field.
    </p>
    <p num="105">
      In the above embodiments, the blocking selection section selects the blocking from two kinds of blocking, including the blocking of the pixels of only one of the odd field and even field and the blocking of the pixels of both odd and even fields.
      <br/>
      However, the blocking may include various combinations when two or more fields are prepared in addition to the odd and even fields.
      <br/>
      The blocks shown in FIGS. 16(a), (b), (c) are only examples and various block forming methods may be used to form the block other than the blocks of FIG. 16.
    </p>
    <p num="106">
      In the above embodiments, the blocking means shown in FIG. 14 is used with the prediction error signal output means and motion detecting means.
      <br/>
      Even if the sections other than the blocking means 400 are replaced with conventional means, the 8th and 9th aspects explained above can be provided.
    </p>
    <p num="107">According to the 6th and 7th aspect explained above, a stable encoded image with high efficiency can be obtained by individually searching the motion from each field of the already encoded frame to predict each field and by conducting adaptive prediction from. the searched motion compensated predictive signals (and interpolation signals).</p>
    <p num="108">In addition, according to the 8th and 9th aspects explained above, a stable encoded image with high efficiency can also be obtained by adaptively selecting the encoding from the blocking of the pixels of only one of the fields of the frame to be encoded, and the encoding after conducting the blocking of the pixels of the respective fields when encoding the prediction error signal.</p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A predictor for a system for communicating digital video signals, the predictor producing an output predictive signal for subtraction from an input signal to produce a predictive error signal comprising:</claim-text>
      <claim-text>a video memory for storing a previously input video signal as field signals obtained by dividing a frame of said previously input signal into a plurality of fields; means for outputting a plurality of predictive signals which predict a change of the input video signal based on the signals stored in said video memory;</claim-text>
      <claim-text>and means for interpolating between at least two of the plurality of predictive signals and for providing an interpolated predictive signal which is different from other predictive signals, said interpolated predictive signal being supplied by said predictor as the output predictive signal to facilitate interpolative prediction.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The predictor of claim 1 further comprising: a switch for receiving at least one of the predictive signals from said means for outputting and the interpolated predictive signal from said means for interpolating for selecting one of said predictive signals.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The predictor of claim 1 wherein said video memory includes first and second field memories.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The predictor of claim 2 wherein said switch selects one of said predictive signals having the lowest encoded signal quantity.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The predictor of claim 1 wherein the interpolation means produces the interpolated predictive signal by computing the arithmetic mean of the plurality of the predictive signals from said means for outputting.</claim-text>
    </claim>
  </claims>
</questel-patent-document>