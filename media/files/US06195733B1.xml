<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06195733B1.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as first publication">
      <document-id>
        <country>US</country>
        <doc-number>06195733</doc-number>
        <kind>B1</kind>
        <date>20010227</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6195733</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B1</original-publication-kind>
    <application-reference family-id="24906070" extended-family-id="42028600">
      <document-id>
        <country>US</country>
        <doc-number>09176413</doc-number>
        <kind>A</kind>
        <date>19981021</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1998US-09176413</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>43054089</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>17641398</doc-number>
        <kind>A</kind>
        <date>19981021</date>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1998US-09176413</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>US</country>
        <doc-number>72339596</doc-number>
        <kind>A</kind>
        <date>19960930</date>
        <priority-linkage-type>1</priority-linkage-type>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1996US-08723395</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010227</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <term-of-grant>
      <disclaimer/>
    </term-of-grant>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G06F  13/00        20060101A I20051110RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>13</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051110</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G06F  13/12        20060101A I20051110RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>13</main-group>
        <subgroup>12</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051110</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>G06F  13/16        20060101A I20051110RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>13</main-group>
        <subgroup>16</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051110</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>711202000</text>
        <class>711</class>
        <subclass>202000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>711153000</text>
        <class>711</class>
        <subclass>153000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>711170000</text>
        <class>711</class>
        <subclass>170000</subclass>
      </further-classification>
    </classification-national>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06F-013/1657</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>13</main-group>
        <subgroup>1657</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141204</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>6</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>2</number-of-drawing-sheets>
      <number-of-figures>2</number-of-figures>
      <image-key data-format="questel">US6195733</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Method to share memory in a single chip multiprocessor system</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>LISLE RONALD J</text>
          <document-id>
            <country>US</country>
            <doc-number>5539896</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5539896</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>OSBORNE RANDY R</text>
          <document-id>
            <country>US</country>
            <doc-number>5579503</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5579503</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>GARDE DOUGLAS</text>
          <document-id>
            <country>US</country>
            <doc-number>5611075</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5611075</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>JALFON MARC, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5909702</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5909702</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <related-documents>
      <continuation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>72339596</doc-number>
              <kind>A</kind>
              <date>19960930</date>
            </document-id>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>5890013</doc-number>
              <kind>A</kind>
            </document-id>
          </parent-doc>
        </relation>
      </continuation>
    </related-documents>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Intel Corporation</orgname>
            <address>
              <address-1>Santa Clara, CA, US</address-1>
              <city>Santa Clara</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>INTEL</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Nair, N. Gopalan</name>
            <address>
              <address-1>Phoenix, AZ, US</address-1>
              <city>Phoenix</city>
              <state>AZ</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Regenold, David</name>
            <address>
              <address-1>Tempe, AZ, US</address-1>
              <city>Tempe</city>
              <state>AZ</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="3">
          <addressbook lang="en">
            <name>Hatami, Parviz</name>
            <address>
              <address-1>Santa Clara, CA, US</address-1>
              <city>Santa Clara</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="4">
          <addressbook lang="en">
            <name>Satagopan, Ramprasad</name>
            <address>
              <address-1>Chandler, AZ, US</address-1>
              <city>Chandler</city>
              <state>AZ</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Blakely, Sokoloff, Taylor &amp; Zafman LLP</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>An, Meng-Ai T.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>LAPSED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A multiprocessor data processing system includes a private data bus and a private program bus coupled to each of the processors.
      <br/>
      Coupled between the private data buses is a plurality of memory banks, each of which can be dynamically switched between the processors to move blocks of data without physically transferring the data from one bank to another.
      <br/>
      Likewise, a plurality of memory banks is coupled between the program buses.
      <br/>
      These memory banks are loaded with pages of program instructions from external memory over a shared bus.
      <br/>
      Any one of the pages can be coupled to either of the processors on its respective private program bus.
      <br/>
      When the pages are coupled to the shared bus, they appear as a contiguous address space.
      <br/>
      When a page is coupled to one of the private program buses, the addressing mode is changed so that the page is mapped to a common address space.
      <br/>
      This permits the program code to be loaded into any available page, and the processors can execute the code regardless of where it has been loaded, thereby permitting easy relocatability.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <p num="1">
      This application is a continuation of Ser.
      <br/>
      No. 08/723,395, filed Sep. 30, 1996, now U.S. Pat. No. 5,890,013.
    </p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="2">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="3">This invention relates generally to the field of data processing systems and particularly to a shared memory structure for a multiprocessor system.</p>
    <p num="4">2. Prior Art</p>
    <p num="5">
      Communications processing in modems, digital cellular phones and the like typically employs a microprocessor controller and one or more digital signal processing (DSP) co-processors.
      <br/>
      It is desirable to provide a processing system that integrates all communications processing functions on a single integrated circuit.
      <br/>
      Due to limitations on the number of pins in a package and the long access times to access data from external memory, it is a practical necessity for one or more processors in a single chip multi-processor to execute from internal memory, as well as use internal memory to maintain data.
      <br/>
      It is necessary to load program code from external memory into the internal memories and execute from them, and at the same time permit relocation of code within the pages of internal memory to facilitate runtime process switching.
    </p>
    <p num="6">
      Due to the fundamental nature of DSP computations, the integration of data and program memories with the DSP engines on a single chip can provide significant savings in cost and power dissipation.
      <br/>
      On the other hand, on-chip random access memory (RAM) is very "expensive" in terms of power requirements and silicon area.
      <br/>
      One alternative is to use programmed read only memory (ROM) for the DSP engines; however, this makes product maintenance and development more difficult.
      <br/>
      The present invention provides a unique memory architecture that addresses these conflicting requirements.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="7">
      The present invention is directed to a data processing system having at least two independent processors.
      <br/>
      Each of the processors has a private data bus and a private program bus.
      <br/>
      Coupled between the private data buses is a plurality of memory banks, each of which can be dynamically switched between the processors to move blocks of data without physically transferring the data from one bank to another.
      <br/>
      Likewise, a plurality of memory banks is coupled between the program buses.
      <br/>
      These memory banks are loaded with pages of program instructions from external memory over a shared bus.
      <br/>
      Any one of the pages can be coupled to either of the processors on its respective private program bus.
      <br/>
      When the pages are coupled to the shared bus, they appear as a contiguous address space.
      <br/>
      When a page is coupled to one of the private program buses, the addressing mode is changed so that the page is mapped to a common address space.
      <br/>
      This permits the program code to be loaded into any available page, and the processors can execute the code regardless of where it has been loaded, thereby permitting easy relocatability.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="8">
      FIG. 1 is a partial block diagram of a multiprocessor system according to the invention.
      <br/>
      FIG. 2 illustrates translation of the memory bank address space in accordance with the invention.
    </p>
    <heading>DETAILED DESCRIPTION OF THE INVENTION</heading>
    <p num="9">
      In the following description, for purposes of explanation and not limitation, specific details are set forth in order to provide a thorough understanding of the present invention.
      <br/>
      However, it will be apparent to one skilled in the art that the present invention may be practiced in other embodiments that depart from these specific details.
      <br/>
      In other instances, detailed descriptions of well-known methods, devices and circuits are omitted so as to not obscure the description of the present invention with unnecessary detail.
    </p>
    <p num="10">
      Due to limitations on the number of pins in a package and the long access times to access data from external memory, it is preferable that multiple processors in a single-chip multiprocessor execute from internal memory, as well as use internal memory to maintain data.
      <br/>
      A flexible internal memory architecture that allows multiple processors to share code and work with limited memory is necessary to make the system efficient.
    </p>
    <p num="11">
      The invented memory architecture is an extremely flexible architecture and allows multiple processors to use the limited available internal memory in an optimal manner.
      <br/>
      The memory is divided into several pages and each page can be programmed to be available to any processor.
      <br/>
      The entire available memory architecture is software configurable and so, depending on the needs of the application can be used optimally by multiple processors.
    </p>
    <p num="12">
      The presence of a common shared bus to access memory is an essential element of this invention.
      <br/>
      Also, each memory bank is software configurable by use of memory configuration registers.
      <br/>
      In a typical three processor system, memory that is used to store program code for two of the three processors is mapped to the same starting address to permit real-time allocation of available memory for scheduled process.
      <br/>
      Address shadowing (translations) are done to make the addresses contiguous on the shared bus but identical on private buses.
    </p>
    <p num="13">
      FIG. 1 illustrates a data processing system incorporating the present invention.
      <br/>
      A single chip multiprocessor is shown.
      <br/>
      Such a device may be advantageously employed, for example, as a data communication processor for use in modems, digital cellular phones, and the like.
      <br/>
      In the illustrated system, there are two digital signal processors (DSP's), designated DSP1 and DSP2.
      <br/>
      The DSP's are preferably reduced instruction set computing (RISC) processors optimized for performing the repetitive signal processing tasks associated with communications processing.
      <br/>
      However, the present invention is not limited to communications processing applications.
      <br/>
      As will be more fully appreciated by the discussion that follows, the present invention has wide applicability in multiprocessor environments.
    </p>
    <p num="14">
      The system illustrated in FIG. 1 includes an array of random access memories (RAM) or memory banks designated MB1-MB4.
      <br/>
      Each of these memory banks is coupled to a private program bus 26 for processor DSP1 and to a corresponding private programming bus 28 for processor DSP2.
      <br/>
      Each of the memory banks is also coupled to a shared bus 30 which communicates with microprocessor 32 through bus coupler 34.
      <br/>
      Microprocessor 32 is a general purpose processor which supervises operation of the multiprocessor system and, in communications applications, performs protocol and other non-repetitive processing tasks.
      <br/>
      Additional arrays of RAM MB5-MB8 are coupled to shared bus 30 and to respective private data buses 36 and 38 for DSP1 and DSP2.
      <br/>
      Although the present invention is described in terms of a multiprocessor system having two DSP's and four banks each of program and data memory, it will be appreciated that the invention is not limited in this regard.
      <br/>
      The same principles apply regardless of the number or type of processors or the number of shared memory banks.
    </p>
    <p num="15">
      DSP1 and DSP2 process data in memory banks MB5-MB8 in accordance with program instructions stored in one of memory banks MB1-MB4.
      <br/>
      Only one of the program memory banks is coupled to a processor at a particular time.
      <br/>
      Program instructions are stored in off-chip memory devices and are transferred to program memory banks MB1-MB4 over shared bus 30 under the control of a direct memory access (DMA) unit resident in bus coupler 34.
      <br/>
      Program instructions are transferred to the program memory banks in "pages" as will be more fully explained below.
      <br/>
      In an exemplary embodiment of this invention, each of program memory banks MB1-MB4 comprises a 512-word memory for a total storage capacity of 2K words.
    </p>
    <p num="16">
      Digital signal processing programs typically involve repetitive computations with little conditional branching; for example, data pump operations in a modem system.
      <br/>
      The present invention is particularly well suited for this processing environment.
      <br/>
      An appropriate page of program instructions is retrieved from the off-chip storage and loaded into an available one of program memory banks MB1-MB4.
      <br/>
      The memory bank is then coupled to the private program bus of the processor that will perform the program steps of the retrieved page.
      <br/>
      The other memory banks remain available for use by the other processor or for access to the shared bus to retrieve additional pages.
      <br/>
      Upon completion of execution of the program steps within a retrieved page, the memory bank is released from the private program bus and another memory bank, containing the program steps that are to be executed next, is coupled to the private program bus.
      <br/>
      The processors are thus provided with physical memory pages that are swapped virtually immediately without the latency associated with reloading a single dedicated program memory.
    </p>
    <p num="17">
      Each of the memory banks MB1-MR4 is single-ported, but is software configurable through memory configuration registers.
      <br/>
      A control word written into the appropriate memory configuration register selects the bus to which the memory bank in connected.
      <br/>
      In the exemplary embodiment, the control word simply comprises a 2-bit nibble for each of the memory banks to designate the shared bus +0,0}, DSP1 private bus +0,1} or DSP2 private bus +1,0}.
    </p>
    <p num="18">
      As already explained, each of the program memory banks MB1-MB4 constitutes a physical page of memory.
      <br/>
      As illustrated in FIG. 2, these pages collectively appear as a contiguous address space when coupled to the shared bus 30.
      <br/>
      In the illustrative embodiment described herein, this address space comprises 2K addresses.
      <br/>
      When the individual memory banks are coupled to one of the private program buses 26 or 28, the addressing mode is changed so that the page is mapped to a single address space of 512 addresses that is the same for each of the memory bank pages.
      <br/>
      All program code is referenced to a common zero address point and does not need to be recompiled depending on which page the code is in.
      <br/>
      Thus, depending upon the availability of a physical page, program code can be loaded into any page and the signal processor can execute the program code regardless of where it has been loaded, thereby permitting easy relocatability.
    </p>
    <p num="19">The memory architecture of the present invention may be implemented in one embodiment as follows.</p>
    <p num="20">Four banks of RAM each configured as one 512 * 16 bit segment, for use as program RAM by DSP1 and DSP2.</p>
    <p num="21">
      - (MB1, MB2, MB3, MB4) Total size: 4K Bytes, RAM
      <br/>
      Two Banks of RAM, each configured as two 256 * 16 bit segments, accessible to DSP1 and DSP2 extended data ports.
      <br/>
      - (MB5, MB6) Total size: 1K Bytes, RAM
      <br/>
      Two Banks of RAM, each configured as 256 * 16 bit segments, accessible to DSP1 and DSP2 extended data ports.
      <br/>
      - (MB7, MB8) Total size: 1K Bytes, RAM
    </p>
    <p num="22">These memory banks are configured through two memory configuration registers.</p>
    <p num="23">Memory Configuration Register 0:</p>
    <p num="24">
      --
      <br/>
      -- Bits      Description
      <br/>
      -- �15� Enable bit for MB4 Configuration bits.
      <br/>
      Write 1 to configure
      <br/>
      --           bank
      <br/>
      -- �14� Enable bit for MB3 Configuration bits.
      <br/>
      Write 1 to configure
      <br/>
      --           bank
      <br/>
      -- �13� Enable bit for MB2 Configuration bits.
      <br/>
      Write 1 to configure
      <br/>
      --           bank
      <br/>
      -- �12� Enable bit for MB1 Configuration bits.
      <br/>
      Write 1 to configure
      <br/>
      --           bank
      <br/>
      -- �11:10� Unused
      <br/>
      -- �9:8� Mc_Bnk4�2:0�: Configuration bits for MB4
      <br/>
      -- �7:6� Mc_Bnk3�2:0�: Configuration bits for MB3
      <br/>
      -- �5:4� Mc_Bnk2�2:0�: Configuration bits for MB2
      <br/>
      -- �3:2� Mc_Bnk1�2:0�: Configuration bits for MB1
      <br/>
      -- �1:0� Unused
    </p>
    <p num="25">Memory Configuration Register 1:</p>
    <p num="26">
      --
      <br/>
      -- Bits      Description
      <br/>
      -- �15� Enable bit for MB8 Configuration bits
      <br/>
      --           Active low, Write 0 to configure bank
      <br/>
      -- �14:12� Mc_Bnk8�2:0�: Configuration bits for MB8
      <br/>
      -- �11� Enable bit for MB7 Configuration bits
      <br/>
      --           Active low.
      <br/>
      Write 0 to configure bank
      <br/>
      -- �10:8� Mc_Bnk7�2:0�: Configuration bits for MB7
      <br/>
      -- �7� Enable bit for MB6 Configuration bits
      <br/>
      --           Active low.
      <br/>
      Write 0 to configure bank
      <br/>
      -- �6:4� Mc_Bnk6�2:0�: Configuration bits for MB6
      <br/>
      -- �3� Enable bit for MB5 Configuration bits Active low.
      <br/>
      Write 0
      <br/>
      --           to configure bank
      <br/>
      -- �2:0� Mc_Bnk5�2:0�: Configuration bits for MB5
    </p>
    <p num="27">Program RAM Switchable Between DSP1 and DSP2 (MB1, MB2, MB3, MB4)</p>
    <p num="28">The valid configuration bits, Mc_Bnk1, Mc_Bnk2 and Mc_Bnk3 and Mc_Bnk4 are:</p>
    <p num="29">
      --
      <br/>
      --             Bits           Description
      <br/>
      --             00             to bus 30
      <br/>
      --             01             to DSP1 Program Bus 26
      <br/>
      --             10             to DSP2 Program Bus 28
    </p>
    <p num="30">All other selections are undefined.</p>
    <p num="31">This set consists of four segments of 512K * 16-bit RAMS.</p>
    <p num="32">
      The banks can only be connected to the program bus 26 or 28 of the two DSPs or to bus 30.
      <br/>
      When connected to bus 30, the DSPs could use it for data handling, even though it could be slower in access than the dedicated blocks, due to the contention.
    </p>
    <p num="33">Data RAM Switchable Between DSP1 and DSP2 (MB5, MB6)</p>
    <p num="34">The valid configuration bits, Mc_Bnk5 and Mc_Bnk6 are:</p>
    <p num="35">
      --
      <br/>
      --           Bits           Description
      <br/>
      --           000            to bus 30
      <br/>
      --           001            to DSP1 Data Expansion Port
      <br/>
      --           010            to DSP2 Data Expansion Port
    </p>
    <p num="36">All other selections are undefined.</p>
    <p num="37">This set consists of two segments of 256 * 16 bits of RAM.</p>
    <p num="38">
      The banks can only be switched between the data expansion ports connected to buses 36 and 38 of DSP1 or DSP2, in addition to the connection to bus 30.
      <br/>
      Therefore, they cannot be used as program memory.
      <br/>
      They can be dynamically switched between the different buses for transferring blocks of data and messaging.
    </p>
    <p num="39">The enable bit for each field (the MSB of the nibble) should be set to 0 to enable a write into the appropriate bit positions.</p>
    <p num="40">Data RAM Switchable Between DSP1 and DSP2 (MB7, MB8)</p>
    <p num="41">The valid configuration bits, Mc_Bnk7 and Mc_Bnk8 are:</p>
    <p num="42">
      --
      <br/>
      --           Bits           Description
      <br/>
      --           000            to bus 30
      <br/>
      --           001            to DSP1 Data Expansion Port
      <br/>
      --           010            to DSP2 Data Expansion Port
    </p>
    <p num="43">All other selections are undefined.</p>
    <p num="44">This set consists of two segments of 256 * 16 bits of RAM.</p>
    <p num="45">
      The banks can only be switched between the data expansion ports connected to buses 36 and 38 of DSP1 or DSP2, in addition to the connection to bus 30.
      <br/>
      Therefore, they cannot be used as program memory.
      <br/>
      They can be dynamically switched between the different buses for transferring blocks of data and messaging.
      <br/>
      The enable bit for each field (the MSB of the nibble) should be set to 0 to enable a write into the appropriate bit positions.
    </p>
    <p num="46">
      It will be recognized that the above described invention may be embodied in other specific forms without departing from the spirit or essential characteristics of the disclosure.
      <br/>
      Thus, it is understood that the invention is not to be limited by the foregoing illustrative details, but rather is to be defined by the appended claims.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>We claim:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A method to share memory in a single chip multiprocessor system, the method comprising:</claim-text>
      <claim-text>presenting a shared bus coupled to a microprocessor through a bus coupler; presenting a first digital signal processor coupled to a first array of random access memories over a first private program bus, wherein the first array of random access memories is coupled to the shared bus; presenting a second digital signal processor coupled to a second array of random access memories over a second private program bus, wherein the second array of random access memories is coupled to the shared bus, wherein each of the first digital signal processor and the second digital signal processor are adapted to process data in the second array of random access memories in accordance with program instructions stored in one of first array of random access memories; loading a predetermined page of program instructions into at least a first and second available memory of the first array of random access memories; coupling the first memory to one of the first private program bus and the second private program bus; executing the program instructions in one of the first digital signal processor and the second digital signal processor; releasing the first memory from one of the first private program bus and the second private program bus; coupling the second memory to one of the first private program bus and the second private program bus; executing the program instructions in one of the first digital signal processor and the second digital signal processor;</claim-text>
      <claim-text>and releasing the second memory from one of the first private program bus and the second private program bus.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The method of claim 1, wherein loading a predetermined page of program instructions into at least a first and second available memory of the first array of random access memories includes making at least one memory of the first array of random access memories available for use by one of the first digital signal processor, the second digital signal processor, and the shared bus.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The method of claim 1, further comprising: supervising each execution of the program instructions with the microprocessor as a general purpose processor.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The method of claim 1, further comprising: performing at least one non-repetitive, communications application processing task with the microprocessor.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The method of claim 1, further comprising: storing program instructions in at least one off-chip memory device; transferring program instructions to the first array of random access memories over the shared bus under the control of a direct memory access unit resident in the bus coupler.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The method of claim 1 wherein presenting the first digital signal processor and the second digital signal processor includes presenting a reduced instruction set computing processor that is optimized to perform repetitive signal processing tasks associated with communications processing.</claim-text>
    </claim>
  </claims>
</questel-patent-document>