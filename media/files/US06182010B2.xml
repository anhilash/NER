<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06182010B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06182010</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6182010</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference family-id="22901268" extended-family-id="844956">
      <document-id>
        <country>US</country>
        <doc-number>09239243</doc-number>
        <kind>A</kind>
        <date>19990128</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1999US-09239243</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>869470</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>23924399</doc-number>
        <kind>A</kind>
        <date>19990128</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1999US-09239243</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G01C  21/00        20060101AFI20060310RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>01</class>
        <subclass>C</subclass>
        <main-group>21</main-group>
        <subgroup>00</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20060310</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G01C  21/36        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>01</class>
        <subclass>C</subclass>
        <main-group>21</main-group>
        <subgroup>36</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>G01S  19/48        20100101ALI20100101RMUS</text>
        <ipc-version-indicator>
          <date>20100101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>01</class>
        <subclass>S</subclass>
        <main-group>19</main-group>
        <subgroup>48</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>US</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20100101</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>G08G   1/0969      20060101ALI20060310RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>08</class>
        <subclass>G</subclass>
        <main-group>1</main-group>
        <subgroup>0969</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20060310</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>701441000</text>
        <class>701</class>
        <subclass>441000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>340995110</text>
        <class>340</class>
        <subclass>995110</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>340995200</text>
        <class>340</class>
        <subclass>995200</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>342357310</text>
        <class>342</class>
        <subclass>357310</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>701454000</text>
        <class>701</class>
        <subclass>454000</subclass>
      </further-classification>
      <further-classification sequence="5">
        <text>701522000</text>
        <class>701</class>
        <subclass>522000</subclass>
      </further-classification>
      <further-classification sequence="6">
        <text>701523000</text>
        <class>701</class>
        <subclass>523000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G01C-021/36G6</text>
        <section>G</section>
        <class>01</class>
        <subclass>C</subclass>
        <main-group>021</main-group>
        <subgroup>36G6</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G01C-021/3647</classification-symbol>
        <section>G</section>
        <class>01</class>
        <subclass>C</subclass>
        <main-group>21</main-group>
        <subgroup>3647</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>23</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>4</number-of-drawing-sheets>
      <number-of-figures>6</number-of-figures>
      <image-key data-format="questel">US6182010</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Method and apparatus for displaying real-time visual information on an automobile pervasive computing client</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>NIMURA MITSUHIRO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4937751</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4937751</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>MOROTO SHUZO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5121326</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5121326</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>SPAUR CHARLES W, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5732074</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5732074</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>DELORME DAVID M, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5948040</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5948040</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>FAN RODRIC C, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5959577</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5959577</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>LAPPENBUSCH RICHARD W, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5982298</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5982298</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>BECKERT RICHARD D, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>6009363</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US6009363</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>BUCKLEY STEPHEN J</text>
          <document-id>
            <country>US</country>
            <doc-number>6032089</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US6032089</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="9">
          <text>SUMITOMO ELECTRIC INDUSTRIES</text>
          <document-id>
            <country>JP</country>
            <doc-number>H09166450</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP09166450</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="10">
          <text>AISIN AW CO, et al</text>
          <document-id>
            <country>JP</country>
            <doc-number>S6417200</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP64017200</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>OGAWA MICHIMA, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4737916</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4737916</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="12">
          <text>MOROTO SHUZO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5191532</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5191532</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="13">
          <text>KAKIHARA MASAKI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5293163</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5293163</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="14">
          <text>INOUE NOBUTAKA</text>
          <document-id>
            <country>US</country>
            <doc-number>5414629</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5414629</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="15">
          <text>KANEKO SHIGEHIKO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5729109</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5729109</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="16">
          <text>MANABE KATSUHIKO</text>
          <document-id>
            <country>US</country>
            <doc-number>5859666</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5859666</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="1">
          <text>Jameel et al.; Internet multimedia on wheels: connecting cars to cyberspace; IEEE Conference-Intelligent Transportation System; Nov. 9-12 1997; pp. 637-642.</text>
        </nplcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="2">
          <text>Jameel et al; Web on wheels: toward Internet-enabled cars; IEEE Computer; Jan. 1998, vol. 31, iss. 1; pp. 69-76.</text>
        </nplcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>International Business Machines Corporation</orgname>
            <address>
              <address-1>Armonk, NY, US</address-1>
              <city>Armonk</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>IBM</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Berstis, Viktors</name>
            <address>
              <address-1>Austin, TX, US</address-1>
              <city>Austin</city>
              <state>TX</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <name>LaBaw, Jeffrey S.</name>
          </addressbook>
        </agent>
        <agent sequence="2" rep-type="agent">
          <addressbook lang="en">
            <name>Judson, David H.</name>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Zanelli, Michael J.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>GRANTED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A navigation system, preferably for use in a vehicle.
      <br/>
      The system includes a processor, and a graphical display for displaying map information.
      <br/>
      As the vehicle approaches a given location, e.g., an intersection, a visual image of the location is retrieved and displayed on the graphical display.
      <br/>
      In one embodiment, the visual image is a photograph of the location that is displayed in a pop-up window on the display screen.
      <br/>
      If desired, additional graphic images or text are superimposed on or associated with the image to facilitate navigation.
      <br/>
      Thus, for example, if the user were approaching an intersection, the invention displays a still photograph of the intersection, together with an arrow overlaid thereupon to illustrate that the user should make a given turn.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">
      1.
      <br/>
      Technical Field
    </p>
    <p num="2">This invention relates generally to in-vehicle navigation systems and, in particular, to a method and system for displaying visual images on a portable computing device to assist a user in locating traffic landmarks.</p>
    <p num="3">2. Description of the Related Art</p>
    <p num="4">
      Recently, the computer industry has sought to add computer processing and communications capabilities to devices other than what would normally be considered a traditional computer.
      <br/>
      Such devices are quite varied and include, for example, personal digital assistants (PDAs), smartphones, cellular phones, desktop screen phones, in-vehicle devices, vehicle traffic lights, kiosks, business organizers (e.g., IBM WorkPadT (tm) , PalmPilot (tm) , and the like), computer peripherals (such as printers, fax machines, and the like), handheld or palmtop computing devices, and the like.
      <br/>
      For convenience, these devices, as a class, are referred to herein as "pervasive computing" clients as they are devices that are designed to be connected to servers in a computer network and used for computing purposes regardless of their location.
    </p>
    <p num="5">
      Palmtop computers and the like are now being proposed as pervasive computing devices for use in an automobile.
      <br/>
      In-vehicle navigation systems, of course, are well-known.
      <br/>
      Representative systems are described in U.S. Pat. Nos.: 5,121,326, 5,191,532 and 5,792,109. U.S. Pat. No. 5,121,326 describes a navigation system that displays a general map of the driver's location.
      <br/>
      As the driver approaches an intersection, the display provides a detailed map of the intersection to provide further guidance to the driver.
      <br/>
      In U.S. Pat. No. 5,191,532, a navigation system is disclosed where driving directions can be provided even though the user's exact destination is not listed in the systems database.
      <br/>
      Certain geographic features such as cities and landmarks are used to approximate the destination for purposes of providing directions.
      <br/>
      In U.S. Pat. No. 5,729,109, the inventors provide a vehicle navigation system that uses speech generation to give spoken directions when the driver is approaching an intersection.
    </p>
    <p num="6">
      Although such existing in-vehicle navigation systems are useful for their intended purpose, the user interface for such devices is often fairly crude.
      <br/>
      Typically, the interface comprises a grid or map illustrating various roads, streets and intersections.
      <br/>
      Occasionally, these maps include other identifying information.
      <br/>
      Thus, while a user may be provided with some useful information from such displays, maps are often confusing, especially at some complex intersections.
      <br/>
      Moreover, these types of displays generally do not always provide sufficient information so as to enable a user to accurately determine if the vehicle has reached a given location represented on the map.
    </p>
    <p num="7">The present invention addresses the need to provide improved in-vehicle display of navigation information.</p>
    <heading>BRIEF SUMMARY OF THE INVENTION</heading>
    <p num="8">An object of the present invention is to provide accurate visual information to a driver in using a navigation system to allow the driver to more accurately assess his or her position relative to an intersection or other physical location where an action may need to be taken.</p>
    <p num="9">It is a further object to provide a vehicle navigation system with the capability of displaying a visual identification (e.g., a photograph) consistent with the driver's then-current perspective to allow for more accurate and intuitive decision making during the course of navigating a vehicle.</p>
    <p num="10">It is a yet another object of the present invention to provide a more useful in-vehicle navigation system that displays information automatically so that a user has more complete data available at an earliest possible time prior to a decision point.</p>
    <p num="11">A more general object of the present invention is to provide an improved vehicle navigation display system and interface.</p>
    <p num="12">Another general object of this invention is to provide still photographs or real-time videos of physical landmarks in conjunction with display of a navigation grid or map in a vehicle or handheld navigation system.</p>
    <p num="13">
      These and other objects of the invention are provided in a navigation system, preferably for use in a vehicle.
      <br/>
      The system includes a processor, and a graphical display for displaying map information.
      <br/>
      As the vehicle approaches a given location, e.g., an intersection, a visual image of the location is retrieved and displayed on the graphical display.
      <br/>
      In one embodiment, the visual image is a photograph of the location that is displayed in a pop-up window on the display screen.
      <br/>
      If desired, additional graphic images or text are superimposed on or associated with the image to facilitate navigation.
      <br/>
      Thus, for example, if the user were approaching an intersection, the invention displays a still photograph of the intersection, perhaps with an arrow overlaid thereupon to illustrate that the user should make a given turn.
    </p>
    <p num="14">
      Each location may have a set of photograph images associated therewith.
      <br/>
      Thus, for example, a given intersection is photographed at different times of day and/or at different times of the year.
      <br/>
      This enables the user to be provided with the most accurate representation of the location as the user approaches.
      <br/>
      If sufficient processing capability is available in the vehicle navigation system and the content is otherwise available, the system may be selectively controlled to display video images of the physical location.
      <br/>
      This would be quite helpful in the situation wherein physical elements in the scenery are consistently changing.
    </p>
    <p num="15">
      Preferably, the image content is collected by other vehicles (e.g., police cars, delivery vehicles, taxi cars, post office vehicles, etc.) and stored on given physical media within a user's vehicle (e.g., as a CD-ROM, or the like), or such information may be stored in a server.
      <br/>
      In the latter case, the in-vehicle system connects to the server (e.g., via a wireless connection) and receives the desired content for display on the user's computer.
    </p>
    <p num="16">
      The inventive display method may also be practiced in other environments.
      <br/>
      Thus, for example, the method may be implemented in a handheld or mobile computer that includes a global positioning system (GPS) or the like for displaying the position of the device.
      <br/>
      In such case, a grid or map may be displayed on the computer screen.
      <br/>
      When the user approaches some location of interest, a photographic image is displayed, e.g., in a pop-up window, as a visual association of the user's position with some actual physical location.
    </p>
    <p num="17">
      The foregoing has outlined some of the more pertinent objects and features of the present invention.
      <br/>
      These objects should be construed to be merely illustrative of some of the more prominent features and applications of the invention.
      <br/>
      Many other beneficial results can be attained by applying the disclosed invention in a different manner or modifying the invention as will be described.
      <br/>
      Accordingly, other objects and a fuller understanding of the invention may be had by referring to the following Detailed Description of the Preferred Embodiment.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="18">
      For a more complete understanding of the present invention and the advantages thereof, reference should be made to the following Detailed Description taken in connection with the accompanying drawings in which:
      <br/>
      FIG. 1 is a view of a example pervasive computing device useful for implementing the present invention;
      <br/>
      FIG. 2 is a diagram of a representative client-server architecture in which the pervasive computing client of the present invention is used;
      <br/>
      FIG. 3 is a schematic diagram of the pervasive computing device as connected in a vehicle;
      <br/>
      FIG. 4 is an illustrative display of a map provided in a representative embodiment of the present invention;
      <br/>
      FIG. 5 is the illustrative display of FIG. 4 that has been augmented to display a photographic image according to the teachings of the present invention; and
      <br/>
      FIG. 6 is a flowchart of a preferred control routine of the present invention.
    </p>
    <heading>DETAILED DESCRIPTION OF THE PREFERRED EMBODIMENT</heading>
    <p num="19">
      The present invention provides a novel navigation data processing and display device, system and method.
      <br/>
      Preferably, the invention is implemented in a mobile computer, such as a pervasive computing client, connectable to a computer network.
      <br/>
      FIG. 1 illustrates a representative pervasive computing client device 10 having a graphical display 12.
      <br/>
      The device also includes a handheld stylus 15 for inputting information to the device.
      <br/>
      A representative handheld device in which the present invention is implemented is a palmtop computer, for example, a device marketed by the IBM Corporation under the WorkPad trademark.
      <br/>
      One of ordinary skill, however, will appreciate that the principles of the invention are generally applicable to a pervasive computing client.
      <br/>
      Representative devices include a pervasive client that is x86-, PowerPC.RTM.- or RISC-based, that includes a real-time operating system such as WindRiver VXWorks (tm) , QSSL QNXNeutrino (tm) , or Microsoft Windows CE, and that includes a browser.
    </p>
    <p num="20">
      Referring now to FIG. 2, a representative pervasive computing device comprises client stack 20 including a number of components, for example, a client application framework 22, a virtual machine 24, a speech engine 26, and an industry-supplied runtime operating system (RTOS) 28. The client application framework 22 typically includes a browser 30, a user interface 32, a pervasive computing client application class library 34, a standard Java class library 36, and a communication stack 38.
      <br/>
      The pervasive computing client connects to a server platform 40 via a wireless data link 42.
    </p>
    <p num="21">
      The pervasive computing client preferably includes a global positioning system (GPS) receiver 45.
      <br/>
      Recently, such receivers have become readily available on a widespread commercial basis as integrated circuit devices.
      <br/>
      Such devices provide latitude and longitude data to within a given tenth of a second of arc.
      <br/>
      When greater accuracy is required, the accuracy of the position measurement is enhanced using differential GPS (or dGPS), a process in which a number of fixed reference points are used.
      <br/>
      In dGPS, the positions of the reference points are determined with great precision, e.g., using surveying techniques.
      <br/>
      A GPS is used to obtain the location of a given reference point, and this measurement is compared with known location to generate a correction value that is then used to correct the position of the pervasive device as measured by GPS.
    </p>
    <p num="22">
      Returning back to FIG. 2, at its lower level, the connectivity service 31 includes a gateway 33 that provides compression and encryption functions.
      <br/>
      The upper level of the connectivity service 31 is a proxy 35 that provides several different functions: transcoding, filtering, prioritization and link to device management.
      <br/>
      Transcoding refers to the translation from one source markup language to another markup language.
      <br/>
      Transcoding is required because a pervasive computing client normally does not support the full function set of an HTML Windows-based client.
      <br/>
      In such case, it is necessary to transcode the HTML-based file into a format (e.g., HDML or handheld device markup language) compatible with the pervasive client computing device so that the file may be appropriately rendered on the client.
    </p>
    <p num="23">
      The server platform 40 may be of several different types.
      <br/>
      The platform 40 may be a Web/application server 37 (a synchronous request-response type server) or a data synchronization server 39 (an asynchronous queued communication type server).
      <br/>
      The basic functions are each such server type are illustrated.
      <br/>
      Alternatively, the platform 40 may be a value-added server 41 that provides additional services such as LDAP directory/repository, awareness and notification, network management, device life cycle management, user and device registration, or billing.
    </p>
    <p num="24">
      The particular server is typically one of a plurality of servers which are accessible by clients, one of which is illustrated by the pervasive computing client having a browser, as previously noted.
      <br/>
      A representative Web server is an IBM Netfinity (tm)  server comprising a RISC-based processor, the AIX.RTM. operating system and a Web server program, such as Netscape Enterprise Server.
    </p>
    <p num="25">A representative server also includes a display supporting a graphical user interface (GUI) for management and administration, and an Application Programming Interface (API) that provides extensions to enable application developers to extend and/or customize the core functionality thereof through software programs including Common Gateway Interface (CGI) programs, plugins, servlets, active server pages, server side include (SSI) functions or the like.</p>
    <p num="26">
      The inventive functionality of the pervasive computing client 10 is preferably implemented in a software executable in a processor, namely, as a set of instructions (program code) in a code module resident in the random access memory of the computer.
      <br/>
      Until required by the computer, the set of instructions may be stored in another computer memory, for example, in a hard disk drive, or in a removable memory, or downloaded via the Internet or other computer network.
      <br/>
      This program is preferably invoked by pressing an icon 14 using the stylus 15.
    </p>
    <p num="27">
      According to a preferred embodiment, the pervasive computing client is a portable or so-called "palmtop" computer or PDA.
      <br/>
      Generally, the portable computing device of the invention is used as an in-vehicle navigation computer to display to the driver (or occupant) maps and other useful information.
      <br/>
      According to the invention, such other information preferably includes rich media content, such as a photographic image of a landmark located at an upcoming intersection or other location.
      <br/>
      Such content may be downloaded to the vehicle computer from a server in the network (as previously illustrated) or, alternatively, such content may be pre-recorded on a storage medium (e.g., CD-ROM, DVD, or the like) provided in the vehicle.
    </p>
    <p num="28">
      The in-vehicle embodiment of the present invention is now described in more detail.
      <br/>
      In particular, FIG. 3 is a block diagram of an navigation system wherein a pervasive computing device 10 is mounted on a cradle 51 which serves at least two purposes.
      <br/>
      First, the cradle is positioned in the vehicle (not shown) to allow for good visibility of graphical display 12 to the operator or navigator of the vehicle.
      <br/>
      Second, cradle 51 provides electrical connection from the pervasive computing device to other devices mounted in the vehicle.
      <br/>
      For example, vehicles are usually equipped with high capacity power storage devices.
      <br/>
      Battery 52 is connected (through an appropriate regulator, not shown) to pervasive computing device 10.
      <br/>
      Another device connected to the pervasive device via cradle 51 is mass storage device 54.
      <br/>
      In this example, mass storage device 54 is preferably a DVD type optical disk drive.
      <br/>
      DVD disks, when used for data storage, provide very large storage capacity.
      <br/>
      This capacity is valuable in storing the high quality images that are preferably used in implementing the present invention.
      <br/>
      Mass storage device may be other types of storage devices such as a CD-ROM, a high capacity hard disk drive or flash memory card.
    </p>
    <p num="29">
      Cradle 51 also allows for connection to the GPS module 45.
      <br/>
      The use of the in-vehicle global positioning system (GPS) is well-known in the art, as illustrated in U.S. Pat. No. 5,862,511.
    </p>
    <p num="30">
      According to an alternate embodiment, the inventive display routine is implemented within a handheld pervasive computing device.
      <br/>
      Such a device may include a GPS receiver or, alternatively, internal positioning devices (e.g., an accelerometer, a pedometer, a compass, and the like).
      <br/>
      Such devices may be used to provide position and direction information to the device.
      <br/>
      In addition, the device typically includes mapping routines to illustrate various characteristics of a given geographic area.
      <br/>
      Such a mapping routine, for example, would generate an overlay image illustrating physical features and characteristics, contours, property lines, dwellings, roads, waterways, and the like.
      <br/>
      A representative system of this type is described in U.S. Pat. No. 5,699,244.
    </p>
    <p num="31">
      Cradle 51 also provides a connection between pervasive computing device 10 and wireless data transceiver 58.
      <br/>
      Wireless data transceiver 58 allows for establishment of wireless data link (as seen in FIG. 2) to a data network allowing establishment of client/server communications to and from server 40.
      <br/>
      The communications link can be provided using one of several known wireless data transmission technologies such as CDMA, GSM, TDMA, CDPD, and Mobitex.
    </p>
    <p num="32">
      FIG. 4 depicts an illustrative display on graphical display 12 of the pervasive device.
      <br/>
      In this example, direction arrow 80 indicates the direction of travel along a road 82.
      <br/>
      The destination is represented, for example, by cross 84.
      <br/>
      Other features such as roads 86 and lake 88 are also depicted.
      <br/>
      Preferably, the vehicle's location along the route is displayed and updated continuously in real-time or according to some given time interval (e.g., every 5 seconds).
      <br/>
      For the sake of this example, an important location on the vehicle's desired route is intersection 90.
      <br/>
      In developing the maps displayed using this invention, certain points may be designated as difficult to navigate.
      <br/>
      Intersection 90 is one of those points in this example.
    </p>
    <p num="33">
      When the vehicle reaches a selected distance (or time) away from intersection 90, a display function in the device is invoked to fetch a photographic image 92 of intersection 90 depicting the impending scene.
      <br/>
      This image is then displayed as shown in FIG. 5.
      <br/>
      The graphical image 92 in this example provides aid to the driver of the vehicle by allowing him or her to see landmarks, such as water tower 94 and tree 96, at the critical location 90 in their natural perspective.
      <br/>
      The image may be of any convenient format (e.g., .jpeg, gif, .png. or the like) that may be readily transmitted (if required), stored and displayed.
      <br/>
      In an illustrative embodiment, the image is displayed in a pop-up window 93 on graphical display 12.
      <br/>
      Preferably, the window is generated by the device's browser.
      <br/>
      Alternatively, if the device does not include a browser, a separate window may be created by the device's operating system.
    </p>
    <p num="34">
      In accordance with the present invention, the photographic image is preferably as close as possible to the real-time conditions that the driver is encountering during the drive.
      <br/>
      Thus, for example, if the driver is approaching the location at night, or during the Winter months, the photograph displayed represents the most accurate representation of the physical area.
      <br/>
      In this way, the device provides the user with both a graphical representation or navigation map, together with an actual representation of what physical landmarks are coming into the user's field of vision.
      <br/>
      If desired, the graphical display may provide other reference aids, such as display graphics (such as arrows and pointers) or the like, to further assist the user to navigate to the desired location.
      <br/>
      Alternatively, the display system may generate a voice-over (e.g., using a text-to-speech processor) that generates an audio cue.
    </p>
    <p num="35">
      To provide a concrete example, the in-vehicle display system displays a grid, a photograph, and a visual cue.
      <br/>
      An audio overlay (e.g., "as you can see by the image, you are now arriving at the intersection of Main and Commerce.
      <br/>
      You should now turn right").
      <br/>
      As illustrated in FIG. 5, direction arrow 96 is superimposed on the graphical image to further aid to the driver.
    </p>
    <p num="36">Given images to be displayed are retrieved from data storage in the vehicle (e.g., in a CD-ROM or DVD format) or are otherwise selectively downloaded to the pervasive computing client via the wireless network.</p>
    <p num="37">
      Preferably, the given photographic image is displayed when the user reaches a given position relative to the location of interest.
      <br/>
      Thus, in the example of FIGS. 4-5, the photographic image is displayed at a certain point in time, or when the vehicle reaches a certain position in advance of the intersection, to enable the driver to have sufficient time (given the driving conditions, the speed or travel and the distance) to make an informed navigation decision.
    </p>
    <p num="38">
      These photographs can be gathered for the navigational system in a number of ways.
      <br/>
      A preferable way is the use of a digital camera (such as that shown in U.S. Pat. No. 5,859,666, which is incorporated herein by reference, mounted to vehicles which regularly travel the area, for example, police, public transportation, emergency, taxi or delivery vehicles.
      <br/>
      The use of such cameras with police vehicles is particularly advantageous because photographic evidence taken from police vehicles aids the police in their work.
    </p>
    <p num="39">
      In an illustrative embodiment, the photographs are collected as follows.
      <br/>
      Additional details regarding this technique in Applicant's copending application titled "Video Camera With Position And Orientation Recording To Assist In Authoring Virtual Reality Scenes." That application is incorporated herein by reference.
      <br/>
      It is identified as Ser.
      <br/>
      No. 09/240,925.
      <br/>
      In that technique, a video camera is provided on a tracking vehicle.
      <br/>
      The video camera is augmented with a set of accelerometers or, alternatively, accelerometers in combination with a set of gyroscopes, and, optionally, a GPS receiver.
      <br/>
      For each frame of video picture taken, the camera's location and orientation are recorded along with the picture.
      <br/>
      The video is subsequently digitized, possibly compressed, and stored in a computer's hard disk drive or other storage media.
      <br/>
      The frames are then sorted out by location and orientation and organized into an accessible data structure.
      <br/>
      This information is then subsequently used to facilitate display of the additional navigation images as has been previously described.
    </p>
    <p num="40">
      In a preferred embodiment, graphical image 92 is stored in a local mass storage device such as mass storage device 54.
      <br/>
      Preferably, mass storage device 54 is a DVD ROM device.
      <br/>
      Disks can be stored which provide the images for an entire region.
      <br/>
      Local storage of the images provides for rapid retrieval and display.
      <br/>
      An alternative is to store the images in a server system provided by server 40 (as in FIG. 3).
      <br/>
      This approach provides nearly limitless storage, but it may have lower image access rates depending on the transfer rate of the wireless data link.
    </p>
    <p num="41">
      Alternatively, the graphical image 92 may be a moving video image illustrating landmarks located at the intersection.
      <br/>
      As the driver approaches, the video will change the perspective to provide a more accurate viewpoint.
      <br/>
      This provides more accurate data to the driver, but requires more data.
      <br/>
      Thus, this alternative would increase the cost and complexity of the system.
    </p>
    <p num="42">
      FIG. 6 is a flowchart depicting the major steps of the program executed on pervasive computing device 10 in accordance with an embodiment of the present invention.
      <br/>
      The desired destination is entered at step 110.
      <br/>
      This is preferably accomplished using stylus 15 to enter an address onto graphical display 12.
      <br/>
      The next step is determination of the current location using the GPS system as shown in step 112.
    </p>
    <p num="43">
      From the current location, a map of the desired route is retrieved from mass storage device 54 or server 40 and displayed on graphical display 12 as shown in step 114.
      <br/>
      The driver then embarks on the route as shown in step 116.
      <br/>
      The program then enters a continuous loop.
      <br/>
      The first step of this loop is determining the current location as the vehicle travels as shown in step 118.
      <br/>
      A determination is made of the distance from this current location to a next intersection on the route.
      <br/>
      If this distance is greater than a selected distance stored with the intersection data, step 120 is negative and the program loops to step 118.
    </p>
    <p num="44">
      If the vehicle is within a given distance from the intersection, the image of the intersection is fetched as shown in step 122.
      <br/>
      This image may be a perspective graphical image, a photograph or a video image.
      <br/>
      This image is displayed as shown in step 124.
      <br/>
      After the image is displayed, the program loops back to determine the new current location at step 118.
      <br/>
      If the image is a moving video image, this new current location is used to fetch the new perspective image relating to the new position at step 124.
      <br/>
      In this way, the moving video image is kept in sync with the viewpoint of the vehicle until the intersection has been passed.
    </p>
    <p num="45">
      Of course, the particular image displayed on the pervasive computing client display need not be limited to a street or road.
      <br/>
      The image may be of any landmark, building, sign, road, or the like.
    </p>
    <p num="46">Although the various methods described are conveniently implemented in a general purpose computer selectively activated or reconfigured by software, one of ordinary skill in the art would also recognize that such methods may be carried out in hardware, in firmware, or in more specialized apparatus constructed to perform the required method steps.</p>
    <p num="47">
      Further, as used herein, a pervasive computing "client" should be broadly construed to mean any computer or component thereof directly or indirectly connected or connectable in any known or later-developed manner to a computer network, such as the Internet.
      <br/>
      The term Web "server" should also be broadly construed to mean a computer, computer platform, an adjunct to a computer or platform, or any component thereof.
      <br/>
      Of course, a "client" should be broadly construed to mean one who requests or gets the file, and "server" is the entity which downloads the file.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>Having thus described our invention, what we claim as new and desire to secure by Letters Patent is set forth in the following claims:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A display method operative in a pervasive computing client having a graphical display, comprising the steps of:</claim-text>
      <claim-text>displaying a map on the graphical display; plotting a user's current position on the map;</claim-text>
      <claim-text>and as the user's current position approaches a given physical landmark, displaying a photographic image of the landmark, the photographic image showing real-time conditions, to assist the user's navigation.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The display method as described in claim 1 further including the step of retrieving the photographic image prior to the step of displaying the image.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The display method as described in claim 2 wherein the photographic image is retrieved from a storage media associated with the pervasive computing client.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The display method as described in claim 2 wherein the photographic image is retrieved from a server to which the pervasive computing client is connected.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The display method as described in claim 4 wherein the pervasive computing client is connected to the server via a wireless connection.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The display method as described in claim 1 wherein the user's current position is derived from a global positioning system.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. The display method as described in claim 1 wherein the photographic image is a frame of a video.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The display method as described in claim 1 further including the step of displaying a given graphical representation indicating a desired direction of travel.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. The display method as described in claim 1 further including the step of outputting an audio cue indicating a desired direction of travel.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. A display method operative in an in-vehicle pervasive computing client having a graphical display, comprising the steps of: displaying a map on the graphical display; plotting a vehicle's current position on the map;</claim-text>
      <claim-text>and as the vehicle's current position approaches a given position relative to a physical landmark, selectively retrieving an image of the landmark, the image showing real-time conditions;</claim-text>
      <claim-text>and displaying the image.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. The display method as described in claim 10 wherein the image is retrieved from a storage media associated with the pervasive computing client.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. The display method as described in claim 10 wherein the photographic image is retrieved from a server to which the pervasive computing client is connected.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. The display method as described in claim 12 wherein the pervasive computing client is connected to the server via a wireless connection.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. The display method as described in claim 10 wherein the vehicle's current position is derived from a global positioning system.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. The display method as described in claim 10 wherein the image is a photograph.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. The display method as described in claim 15 wherein the photograph is collected in an off-line image collection process.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. The display method as described in claim 10 further including the step of displaying a given graphical representation indicating a desired direction of travel.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. The display method as described in claim 10 further including the step of outputting an audio cue indicating a desired direction of travel.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. In a pervasive computing client device having a graphical display and a browser, the improvement comprising: displaying a map on the graphical display; plotting a user's current position on the map;</claim-text>
      <claim-text>and as the user's current position approaches a given physical landmark, displaying a photographic image of the landmark in the browser, the photographic image showing real-time conditions.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. A pervasive computing client, comprising: a processor; a graphical display; means for displaying a map on the graphical display; means for plotting a user's current position on the map;</claim-text>
      <claim-text>and means responsive to the user's current position approaching a given physical landmark for displaying an image of the landmark, the image showing real-time conditions.</claim-text>
    </claim>
    <claim num="21">
      <claim-text>21. A computer program product in a computer-readable medium for use in a pervasive computing client device having a graphical display, comprising: means for displaying a map on the graphical display; means for plotting a user's current position on the map;</claim-text>
      <claim-text>and means responsive to the user's current position approaching a given physical landmark for retrieving and displaying an actual image of the landmark, the image showing real-time conditions.</claim-text>
    </claim>
    <claim num="22">
      <claim-text>22. The computer program product as described in claim 21 further including means for displaying a graphical representation of a navigation aid in conjunction with the actual image.</claim-text>
    </claim>
    <claim num="23">
      <claim-text>23. A method for displaying information in an in-vehicle pervasive computing client having a browser, comprising the steps of: displaying a map representing a current location of the vehicle; as the user approaches a given position on the map, displaying an image of a physical landmark at the given position, the image showing real-time conditions.</claim-text>
    </claim>
  </claims>
</questel-patent-document>