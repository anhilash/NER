<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06181438B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06181438</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6181438</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="26723019" extended-family-id="42107978">
      <document-id>
        <country>US</country>
        <doc-number>09072122</doc-number>
        <kind>A</kind>
        <date>19980504</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1998US-09072122</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>43164320</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>7212298</doc-number>
        <kind>A</kind>
        <date>19980504</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1998US-09072122</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>US</country>
        <doc-number>4562797</doc-number>
        <kind>P</kind>
        <date>19970505</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1997US-60045627</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>H04N   1/407       20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>407</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G06T   5/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>G06T   5/20        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>20</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>H04N   1/40        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>40</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>358001900</text>
        <class>358</class>
        <subclass>001900</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>358001200</text>
        <class>358</class>
        <subclass>001200</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>382199000</text>
        <class>382</class>
        <subclass>199000</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>382203000</text>
        <class>382</class>
        <subclass>203000</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>382218000</text>
        <class>382</class>
        <subclass>218000</subclass>
      </further-classification>
      <further-classification sequence="5">
        <text>382257000</text>
        <class>382</class>
        <subclass>257000</subclass>
      </further-classification>
      <further-classification sequence="6">
        <text>382258000</text>
        <class>382</class>
        <subclass>258000</subclass>
      </further-classification>
      <further-classification sequence="7">
        <text>382274000</text>
        <class>382</class>
        <subclass>274000</subclass>
      </further-classification>
      <further-classification sequence="8">
        <text>382308000</text>
        <class>382</class>
        <subclass>308000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G06T-005/00D</text>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>005</main-group>
        <subgroup>00D</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>G06T-005/20</text>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>20</subgroup>
      </classification-ecla>
      <classification-ecla sequence="3">
        <text>H04N-001/40S</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>001</main-group>
        <subgroup>40S</subgroup>
      </classification-ecla>
      <classification-ecla sequence="4">
        <text>H04N-001/407</text>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>407</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-001/40093</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>40093</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140224</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06K-2215/0071</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>2215</main-group>
        <subgroup>0071</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140224</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-005/008</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>008</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140221</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-005/20</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>20</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140224</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2200/28</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2200</main-group>
        <subgroup>28</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140221</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="6">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2207/10008</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2207</main-group>
        <subgroup>10008</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140221</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="7">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2207/30176</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2207</main-group>
        <subgroup>30176</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140221</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="8">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-001/407</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>1</main-group>
        <subgroup>407</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140224</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="9">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>S06K-215/00B8D</classification-symbol>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>6</number-of-claims>
    <exemplary-claim>2</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>6</number-of-drawing-sheets>
      <number-of-figures>7</number-of-figures>
      <image-key data-format="questel">US6181438</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Method and apparatus for digital image darkness control using quantized fractional pixels</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>WOBER MUNIB</text>
          <document-id>
            <country>US</country>
            <doc-number>5235434</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5235434</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>KANG HENRY R</text>
          <document-id>
            <country>US</country>
            <doc-number>5270836</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5270836</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>BARNSTEAD GEORGE W, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5321430</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5321430</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>LOCE ROBERT P</text>
          <document-id>
            <country>US</country>
            <doc-number>5359423</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5359423</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>BANTON MARTIN E, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5539866</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5539866</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>LOCE ROBERT P, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5689343</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5689343</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>LIN YING-WEI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5742703</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5742703</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>WILLIAMS CHET R</text>
          <document-id>
            <country>US</country>
            <doc-number>5754451</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5754451</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="9">
          <text>BASSETTI LARRY W, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4460909</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4460909</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="10">
          <text>BASSETTI LARRY W, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4544264</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4544264</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>BASSETTI LARRY W, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4625222</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4625222</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="12">
          <text>WARD JOSEPH W, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5091971</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5091971</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="13">
          <text>CRAWFORD JACK L, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5128698</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5128698</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="14">
          <text>MAILLOUX LOUIS D, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5282057</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5282057</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="15">
          <text>HATAYAMA SAKAE</text>
          <document-id>
            <country>US</country>
            <doc-number>5287985</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5287985</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="16">
          <text>MAILLOUX LOUIS D, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5483351</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5483351</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="17">
          <text>MAILLOUX LOUIS D</text>
          <document-id>
            <country>US</country>
            <doc-number>5555557</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5555557</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <related-documents>
      <related-publication>
        <document-id>
          <country>US</country>
          <doc-number>60/045,627</doc-number>
          <date>19970505</date>
        </document-id>
        <document-id>
          <country>US</country>
          <doc-number>60/045627</doc-number>
          <date>19970505</date>
        </document-id>
      </related-publication>
    </related-documents>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Xerox Corporation</orgname>
            <address>
              <address-1>Stamford, CT, US</address-1>
              <city>Stamford</city>
              <state>CT</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>XEROX</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Bracco, Rosario A.</name>
            <address>
              <address-1>Webster, NY, US</address-1>
              <city>Webster</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Branciforte, Michael</name>
            <address>
              <address-1>Rochester, NY, US</address-1>
              <city>Rochester</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="3">
          <addressbook lang="en">
            <name>Robinson, David C.</name>
            <address>
              <address-1>Penfield, NY, US</address-1>
              <city>Penfield</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="4">
          <addressbook lang="en">
            <name>Mitchel, James O.</name>
            <address>
              <address-1>Rochester, NY, US</address-1>
              <city>Rochester</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="5">
          <addressbook lang="en">
            <name>Robson, Thomas</name>
            <address>
              <address-1>Penfield, NY, US</address-1>
              <city>Penfield</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="6">
          <addressbook lang="en">
            <name>Loce, Robert P.</name>
            <address>
              <address-1>Webster, NY, US</address-1>
              <city>Webster</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="7">
          <addressbook lang="en">
            <name>Nguyen, Hoan N.</name>
            <address>
              <address-1>Fountain Valley, CA, US</address-1>
              <city>Fountain Valley</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="8">
          <addressbook lang="en">
            <name>Pham, Hung M.</name>
            <address>
              <address-1>San Gabriel, CA, US</address-1>
              <city>San Gabriel</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="9">
          <addressbook lang="en">
            <name>Truong, Daniel D.</name>
            <address>
              <address-1>Hawthorne, CA, US</address-1>
              <city>Hawthorne</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="10">
          <addressbook lang="en">
            <name>Mailloux, Louis D.</name>
            <address>
              <address-1>Webster, NY, US</address-1>
              <city>Webster</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="11">
          <addressbook lang="en">
            <name>Raker, Cathleen J.</name>
            <address>
              <address-1>Rochester, NY, US</address-1>
              <city>Rochester</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="12">
          <addressbook lang="en">
            <name>Lam, Sue K.</name>
            <address>
              <address-1>Rochester, NY, US</address-1>
              <city>Rochester</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="13">
          <addressbook lang="en">
            <name>Thompson, Jr., Robert R.</name>
            <address>
              <address-1>Harbor City, CA, US</address-1>
              <city>Harbor City</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="14">
          <addressbook lang="en">
            <name>Rostamian, Farhad D.</name>
            <address>
              <address-1>Malibu, CA, US</address-1>
              <city>Malibu</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="15">
          <addressbook lang="en">
            <name>Pence, Cheryl A.</name>
            <address>
              <address-1>Cypress, CA, US</address-1>
              <city>Cypress</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Rogers, Scott</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A method and apparatus for the control of darkness/lightness in a digital image rendered by a printing system.
      <br/>
      The technique preferably employs templates to selectively apply different amounts of darkening (lightening) to borders of structures detected within the image dependent upon the need for darkening (lightening).
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <p num="1">
      This application claims the benefit of U.S. Provisional Application Ser.
      <br/>
      No. 60/045,627, filed May 5, 1997.
    </p>
    <p num="2">The present invention relates generally to the control of darkness/lightness in a digital image printing system, and more particularly to the identification of image structures requiring darkness/lightness modification within a digital image and the alteration of such structures to control the perceived darkness/lightness of the output image.</p>
    <heading>BACKGROUND AND SUMMARY OF THE INVENTION</heading>
    <p num="3">
      Darkness/lightness control is a feature commonly known to be employed in xerographic reproduction systems.
      <br/>
      Specifically, it is well-known to control the darkness/lightness of an output document by altering the xerographic processes employed to generate and deposit an image on a substrate.
      <br/>
      However, such changes to the xerographic process were often imperfectly applied over an entire document, leading to user dissatisfaction, or were particularly problematic for the xerographic system, often resulting in reduced life of the xerographic components and supplies.
    </p>
    <p num="4">
      The present invention is a method and apparatus for accomplishing darkness/lightness control in a digital printing system, wherein the control is accomplished by directly controlling the image exposure system rather than by indirectly controlling the amount of marking material deposited upon an image substrate.
      <br/>
      The present invention takes advantage of the improved reliability and resolution of digital image printing systems to accomplish the real-time processing of digital image data so as to alter the data in accordance with a user-specified darkness/lightness level in a document image.
    </p>
    <p num="5">Heretofore, a number of patents and publications have disclosed bitmap image processing methods, the relevant portions of which are hereby incorporated by reference:</p>
    <p num="6">U.S. Pat. Nos. 4,460,909, 4,544,264, and 4,625,222 to Bassetti; 5,091,971 to Ward et al. issued Feb. 25, 1992; 5,282,057 to Mailloux et al., issued Jan. 25, 1994; 5,359,423 to Loce, issued Oct. 25, 1994; 5,387,985 to Loce et al., issued Feb. 7, 1995; 5,483,351 to Mailloux et al., issued Jan. 9, 1996; and 5,555,557 to Mailloux, issued Sep. 10, 1996.</p>
    <p num="7">U.S. Pat. No. 5,128,698 to Crawford et al., issued Jul. 7, 1992, for Boldness Control in an Electrophotographic Machine, employs control of the illumination intensity at edge pixels to control placement of image edges.</p>
    <p num="8">
      The book "Enhancement and Restoration of Digital Documents: Statistical design of nonlinear algorithms" by R. Loce &amp; E. Dougherty, SPIE Optical Engineering Press (1997) also describes template-based morphological operations as applied to image bitmaps.
      <br/>
      The relevant portions of the publication are hereby incorporated by reference.
    </p>
    <p num="9">
      Crawford, J. L. and C. D. Elzinga, "Improved Output Quality by Modulating Recording Power," SPSE 41st Annual Conference, May 22-26, 1988 Arlington Va., describes logic mask techniques to smooth bit map images while dilating image structures.
      <br/>
      Power modulation of the laser is employed.
    </p>
    <p num="10">In accordance with the present invention, there is provided a method of altering the darkness level of a digital image, comprising the steps of: receiving a bitmap array of image signals; isolating, within the array of image signals, image structures to be altered and storing the image structure to be altered; from the stored image structures, determining the border regions thereof to be altered; altering the border region of the stored image structure so as to change the output signal of at least one pixel along the border region; and applying the altered, stored image structure to a corresponding region in the image bitmap to alter the level of darkness of a region therein.</p>
    <p num="11">In accordance with another aspect of the present invention, there is provided a method of altering the level of darkness of an image in conjunction with increasing the resolution thereof prior to rendering the image with a marking engine, comprising the steps of: retrieving a requested darkness level; receiving an array of image signals in the form of an image bitmap at a resolution N; selecting, from the array of image signals, a window of image signals for processing, the window being centered about a target pixel; selecting, in response to the requested darkness level, one of a plurality of sets of template patterns, each set of template patterns containing a plurality of templates therein; comparing the window of image signals to each template within the selected one of the plurality of sets of template patterns to identify a match therewith; in the event of an affirmative response to the comparing step generating an output signal at a resolution M, where M is an integer multiple of N and is determined by the template matched, otherwise generating an output signal at a resolution M wherein each bit of the output signal is equivalent to the input signal level of the target pixel.</p>
    <p num="12">In accordance with yet another aspect of the present invention, there is provided an apparatus for altering the level of darkness of an image, including: means for setting a requested darkness level; image memory for storing an array of image signals in the form of an image bitmap at a resolution N; windowing circuitry for selecting, from the array of image signals, a region of image signals for processing, the region being centered about a target pixel; means for preprogramming each of a plurality of sets of template patterns, each set of template patterns containing a plurality of templates and each set of template patterns being associated with a unique darkness level; and matching circuitry for comparing the window of image signals to each template with a selected one of the plurality of sets of template patterns to identify a match therewith, wherein the selected one of the plurality of sets of template patterns is determined in response to the requested darkness level, said comparing circuitry, in the event of a match, further generating an output signal at a resolution M, where M is an integer multiple of N and is determined by the template matched, otherwise said comparing circuitry generating an output signal at a resolution M wherein each bit of the output signal is equivalent to the input signal level of the target pixel.</p>
    <p num="13">
      One aspect of the invention deals with a basic problem in printing and reproduction of images--modifying bitmap images so as to alter the perceived darkness or lightness in a digital image printing system.
      <br/>
      It has been noted that it is possible to alter the xerographic engine settings in order to accomplish such controls in a conventional manner.
      <br/>
      However, the ability to process bitmap images in real-time lends itself to the control of the darkness/lightness of the output via modification of the bitmap.
      <br/>
      Unfortunately, such controls are typically applied uniformly across an entire document, resulting in modifications to regions of a bitmap where alterations are undesirable and leading to visually displeasing output.
      <br/>
      This aspect is further based on the discovery of a technique that alleviates the need for conventional darkness lightness control while avoiding problems associated with uniform application of bitmap erosion and dilation.
      <br/>
      The technique preferably employs templates to selectively apply different amounts of darkening (lightening) to areas dependent upon the need for darkening (lightening).
      <br/>
      An added advantage of accomplishing the darkness/lightness control using this technique is that there is little variation in the xerographic controls and, therefore, improved system life and image quality.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="14">
      FIG. 1 is a block diagram of a digital printing system forming a preferred embodiment for the present invention;
      <br/>
      FIG. 2 is a an illustration of a known method of increasing darkness while printing a digital image;
      <br/>
      FIG. 3 is an illustrative example of a highly magnified region of an input image and corresponding image regions processed in accordance with the present invention;
      <br/>
      FIG. 4 is an exemplary illustration of the process of template matching employed by one embodiment of the present invention;
      <br/>
      FIG. 5 is an illustrative example of the processing of a window of input image signals and the template hierarchy used in one embodiment of the invention;
      <br/>
      FIG. 6 is an example of the template structure for a plurality of templates that may be employed to accomplish darkness control in accordance with the present invention; and
      <br/>
      FIG. 7 is a schematic data flow diagram of a VLSI circuit used to implement an embodiment of the present invention.
      <br/>
      The present invention is described in connection with a preferred embodiment, however, it is understood that there is no intent to limit the invention to the embodiments described. On the contrary, the intent is to cover all alternatives, modifications, and equivalents as may be included within the spirit and scope of the invention as defined by the appended claims.
    </p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENT</heading>
    <p num="15">
      For a general understanding of the present invention, reference is made to the drawings.
      <br/>
      In the drawings, like reference numerals have been used throughout to designate identical elements.
      <br/>
      In describing the present invention, the following term(s) have been used in the description.
    </p>
    <p num="16">
      The term "data" refers herein to physical signals that indicate or include information.
      <br/>
      When an item of data can indicate one of a number of possible alternatives, the item of data has one of a number of "values." For example, a binary item of data, also referred to as a "bit," has one of two values, interchangeably referred to as "1" and "0" or "ON" and "OFF" or "high" and "low." A bit is an "inverse" of another bit if the two bits have different values.
      <br/>
      An N-bit item of data has one of 2N values.
    </p>
    <p num="17">
      A "multi-bit" item of data is an item of data that includes more than one bit.
      <br/>
      A multi-bit item of data has a "uniform value in all of its bits" or a "uniform value in all bits" when every bit in the data item has the same value, either ON or OFF.
    </p>
    <p num="18">
      "Circuitry" or a "circuit" is any physical arrangement of matter that can respond to a first signal at one location or time by providing a second signal at another location or time.
      <br/>
      Circuitry "stores" a first signal when it receives the first signal at one time and, in response, provides substantially the same signal at another time.
      <br/>
      Circuitry "transfers" a first signal when it receives the first signal at a first location and, in response, provides substantially the same signal at a second location.
    </p>
    <p num="19">
      A "data storage medium" or "storage medium" is a physical medium that can store data.
      <br/>
      Examples of data storage media include magnetic media such as diskettes, floppy disks, and tape; optical media such as laser disks and CD-ROMs; and semiconductor media such as semiconductor ROMs and RAMs and programmable delay lines.
    </p>
    <p num="20">
      A "data processing system" is a physical system that processes data.
      <br/>
      A "data processor" or "processor" is any component or system that can process data, and may include one or more central processing units or other processing components.
      <br/>
      An "image processor" is a processor specifically designed to process data representing an image.
      <br/>
      An operation performs "image processing" when it operates on an item of data that relates to part of an image.
    </p>
    <p num="21">
      An "image" is a pattern of physical light.
      <br/>
      An image may include characters, words, and text as well as other features such as graphics.
      <br/>
      A text may be included in a set of one or more images, such as in images of the pages of a document.
      <br/>
      An image may be divided into "segments," each of which is itself an image.
      <br/>
      A segment of an image may be of any size up to and including the whole image.
    </p>
    <p num="22">
      An item of data "defines" or "represents" an image when the item of data includes sufficient information to produce the image.
      <br/>
      For example, a two-dimensional array or bitmap can define all or any part of an image, with each item of data in the array or bitmap providing a value indicating the color of a respective location of the image.
    </p>
    <p num="23">
      A "pixel" is the smallest segment into which an image is divided in a given system.
      <br/>
      In an array defining an image in which each item of data provides a value, each value indicating the color of a location may be called a "pixel value".
      <br/>
      Each pixel value is a bit in a "binary form" of an image, a gray scale value in a "gray scale form" of an image, or a set of color space coordinates in a "color coordinate form" of an image, the binary form, gray scale form, and color coordinate form each being a two-dimensional array defining an image.
    </p>
    <p num="24">
      An "image input device" is a device that can receive an image and provide an item of data defining a version of the image.
      <br/>
      A "scanner" is an image input device that receives an image by a scanning operation, such as by scanning a document.
    </p>
    <p num="25">
      An "image output device" is a device that can receive an item of data defining an image and provide the image as output.
      <br/>
      A "display" and a "printer" are examples of image output devices that provide the output image in a human viewable form.
    </p>
    <p num="26">
      The "darkness" of an image is the inverse of the perceived level of "lightness" for light reflected from the image and/or the substrate on which it is rendered.
      <br/>
      The term "darkness: is employed as an indication of the quality of an image.
      <br/>
      Darkness (lightness) is typically represented along a continuum spanning the range from white to black.
      <br/>
      The perceived darkness of a printed line segment is a function the average line density and the line width.
      <br/>
      It will be appreciated by those skilled in the art of xerography that line density may be controlled by altering the xerographic process controls while line width is controlled by the size of the region exposed on a photoresponsive member used to form a latent image.
      <br/>
      Accordingly, control of the darkness of an image may be implemented via modification of the line (structure) width--a process that is adaptable to digital images as well.
    </p>
    <p num="27">
      The image darkness/lightness enhancement method and apparatus described herein may be generally outlined using mathematical constructs.
      <br/>
      The process comprises four general steps: (a) isolating, within an image, those structures whose width is to be thickened or thinned; (b) determining on the isolated structures, the border region(s) to be altered; (c) operating on the border regions to allow for controlled growth (increased darkness) or shrinkage (increased lightness); and (d) with the border treatment modifying the image to produce a new version (darkened/lightened) of the image.
      <br/>
      Note that the operations below possess equivalent representations that can differ from the mathematic form presented, but are intended to imply all logical equivalents of the operations.
    </p>
    <p num="28">
      The step of isolating the image structures to be thickened or thinned to produce a perceived change in the image density could in the simplest case be the selection of an entire image.
      <br/>
      However, skilled artisans will recognize that the application of the darkness level control methods described herein uniformly across an entire digital image will likely lead to unacceptable image quality.
      <br/>
      Accordingly, it would be preferable to select the structures in accordance with one or more of the following criteria:
    </p>
    <p num="29">
      structure size, whereby the structures to be selected are those remaining after a morphological opening or closing operation is applied to the image data; or
      <br/>
      specific structure shapes such as thin black lines or white holes in a black region.
    </p>
    <p num="30">
      For example, the operation of selecting a thin black line is represented as
      <br/>
      L=S-(S (degree) E)   Eq. 1
    </p>
    <p num="31">
      where L is an image plane containing the isolated thin black line, S is the input image, E is a structuring element that "does not fit within" the thin lines, and  (degree)  denotes morphological opening.
      <br/>
      Note that in a binary image bitmap L has a value 1 where the feature is present and 0 otherwise.
      <br/>
      Similarly, the operation for isolating small white features in black regions is represented as:
      <br/>
      H=(S.circle-solid.E)-S   Eq. 2
    </p>
    <p num="32">
      where H is an image plane containing the isolated white image feature(s) (e.g., holes), E is a structuring element that "does not fit within" the white features, and .circle-solid. denotes morphological closing.
      <br/>
      Note that H has a value of 1 where the feature is present and 0 otherwise.
    </p>
    <p num="33">
      Once the structure is isolated, the next general step is the determination of the border region of the structure that needs to be adjusted to accomplish the thickening or thinning of the structure.
      <br/>
      The following general rules may be applied to determine the border region:
      <br/>
      (a) to thicken a black structure, find the outside border
      <br/>
      B=(L.sym.F)-L   Eq. 3
      <br/>
      (b) to thin a black feature, find the inside border
      <br/>
      B=L-(L.diamond.F)   Eq. 4
      <br/>
      (c) to widen a white region, find the outer border of the white feature
      <br/>
      B=(H.sym.F)-H   Eq. 5
      <br/>
      (d) to thin a white region, find the inner border of the white feature
      <br/>
      B=H-(H.diamond.F)   Eq. 6
    </p>
    <p num="34">
      where B denotes the border, .sym. denotes dilation, .diamond. denotes erosion, and F is a structuring element that is chosen to define the border width.
      <br/>
      In B the borders are 1-valued, all else is zero.
      <br/>
      Note that dilation is the same as logically ORing selected translates of the image and that erosion is the same as ANDing selected translates of the image.
    </p>
    <p num="35">
      Once the border region to be adjusted is identified, step (c) determines the treatment to be applied along the border region.
      <br/>
      In one embodiment (see the alternatives described later) the entire border may be used for the modification.
      <br/>
      Similarly, it is possible to modulate the border region by ANDing B with some control signal T so that
      <br/>
      B'=B+character pullout}T  Eq. 7
    </p>
    <p num="36">
      where +character pullout} denotes ANDing.
      <br/>
      The control signal may be a periodic pattern such as a checkerboard, a random pattern, or a set of pixel codes for pule-width, position-modulated output.
      <br/>
      Similarly, it is anticipated that the border B could be replicated at a higher resolution before applying the control signal T thereto.
    </p>
    <p num="37">
      After determining the treatment to be applied along the border region, the border (or preferably modulated border B' and the feature image (L or H) are employed as masks to properly modify the desired structure.
      <br/>
      For example, for the four cases outlined above, the logical operations may be represented as follows:
      <br/>
      (a) S'=S+character pullout}B' (using L);
      <br/>
      (b) S'=S+character pullout}B' (using L);
      <br/>
      (C) S'=S+character pullout}B' (using H); and
      <br/>
      (d) S'=S+character pullout}B' (using H).
    </p>
    <p num="38">
      It will be further appreciated that the specific logic operations described herein may be performed in various sequences to accomplish equivalent results, however, the method outlined above is believed to provide a robust approach to accomplishing darkness level adjustment within digital images.
      <br/>
      Similarly, resolution enhancement may be applied in a number of ways in conjunction with the process above.
      <br/>
      For example, the image may be resolution converted prior to adjusting the structure density, or simple resolution conversion operations may be applied to the non-adjusted regions of the image.
    </p>
    <p num="39">
      Having described a general process for darkness level adjustment in a digital image, a preferred hardware embodiment will now be described.
      <br/>
      In particular this following description relates to an embodiment using digital information templates in association with a pixel window, and a quarter pixel (sub-pixel) video engine, to enable digital darkness control.
      <br/>
      The preferred embodiment is an improvement on previous darkness/lightness control methods as it uses templates to selectively apply differing amounts of darkening (lightening) to areas dependent upon need.
      <br/>
      This embodiment represents a significant improvement over xerographically driven darkness control in that it extends development system life and eliminates the previously described problems of xerographic darkness control.
    </p>
    <p num="40">
      Referring to FIG. 1, displayed therein is a simple block diagram of a networked printing system providing an embodiment for the present invention.
      <br/>
      Input in the form of an image bitmap 20 is supplied to the image enhancement block 22 where it is processed and resolution converted before being passed to the marking engine 24.
      <br/>
      Image bitmap 20 may be generated from any of a plurality of input sources, including image input devices such as scanner, or may be created at workstations and supplied to the printing system via a network.
      <br/>
      It will be appreciated that the combination of the image enhancement block 22 and the dual-beam marking engine (ROS) 24 form a basic digital printing device or image output terminal (IOT) 26. An example of such a printer is the Xerox.RTM. DocuTech.RTM. Production Publishing system.
    </p>
    <p num="41">
      In the DocuTech.RTM. Production Publisher, Model 90, image darkness control is implemented in the scanline buffer, where video data was received and enhanced prior to output.
      <br/>
      In essence, the increased width of all structures on a page was accomplished by a programmable delay for the video data that was then ORed with the video data as displayed in FIG. 2.
    </p>
    <p num="42">
      In a high-speed digital printer such as that depicted schematically in FIG. 1, it is desirable to achieve output speeds greater than 120 pages per minute.
      <br/>
      To achieve this speed, it is a requirement that image processing of the input images be accomplished in real-time, with no impact to the throughput of the printing engine.
      <br/>
      Moreover, the high speeds prohibit the use of delay lines due to the increased image resolution and unacceptable tolerances of the programmable delays.
      <br/>
      Moreover, delay lines cannot be programmed in real-time, prohibiting the delay to be altered on anything less than a page-by-page or job-by-job basis.
    </p>
    <p num="43">
      To overcome these problems, the preferred embodiment employs real-time digital image manipulation to improve print quality.
      <br/>
      Preferably 600 spots per inch (spi) data is received and buffered, and based on an array of image signals surrounding any given pixel position, are enhanced to 2400 * 600 spi (2400 spi in the fast scan direction).
      <br/>
      Preferably a number of key functions are combined and executed in the image enhancement block 22.
      <br/>
      Among the preferred functions are appearance matching (AM), which aims to balance horizontal and vertical lines and boost fine line quality; halftone correction, which modifies the reproduction of halftones to remove natural xerographic distortions; and darkness adjustment, which darkens or lightens an image based on a user selected darkness level and the image input.
      <br/>
      Combining these functions in the image enhancement allows them each to be realized in an efficient manner.
    </p>
    <p num="44">
      Darkness control in a high-resolution digital printing system capitalizes upon the increased data resolution employed to render the image.
      <br/>
      Fractional pixels or subpixels (preferably quantized in quarters e.g., 600 --&gt; 2400 spi) are generated for the video image based on the input image signals, where a larger amount of black (increased structure width) is added (subtracted) along borders to achieve higher (lower) darkness levels.
    </p>
    <p num="45">
      Darkness control based on template matching affords flexibility as seen in the examples depicted in FIG. 3.
      <br/>
      In each of the highly magnified image regions, A, B and C of FIG. 3, the small squares represent single pixels at 600 spi resolution.
      <br/>
      Region A represents an input video pattern at 600 spi, whereas regions B and C represent output video generated in accordance with aspects of the preferred embodiment.
      <br/>
      In particular, region B represents a first increased darkness level, while region C represents a greater darkness level than region B. Advantages of an "intelligent" darkness control process can be seen by comparison of the regions.
      <br/>
      For example, the isolated pixel 30 in region A needs to be "grown", but the darkness control design can be such that small gaps between the isolated pixels or lines are not filled in.
      <br/>
      A single pixel vertical line 40 on the left of the regions can be treated in a different manner than the two pixel line 50 to the right, as represented by the distinctions between the equivalent portions of regions B and C. Similarly, lines parallel to the fast scan direction are preferably "grown", by a different amount than the slow scan lines, with half-bitted pixels that "smooth out" upon development of the latent electrostatic image created from the modified image signals.
    </p>
    <p num="46">
      The decisions to adjust the output video to something other than four sub-pixels at the same level as the input video are based on templates, or more appropriately, the results of comparisons with templates.
      <br/>
      A template, in one embodiment, is a 25 bit (5 * 5) expression that facilitates mapping of the input video signals to a four bit output signal.
      <br/>
      The 25 bit input represents a 5 * 5 matrix of video data surrounding a target pixel under consideration.
      <br/>
      These 25 bits must match the template exactly to trigger the output.
      <br/>
      Note, however, that as reflected by the template in FIG. 4 (Template -8) any template may have many "don't care" bits, that may represent either black or white video and still match the template.
      <br/>
      The four bit output signal 80 represents four consecutive sub-pixels that are substituted for the target pixel of the 5 * 5 window array, thereby producing an enhanced resolution output image.
      <br/>
      Referring specifically to FIG. 4, the 5 * 5 video area 60 of FIG. 3 (Area A) is shown as the input sample 60.
      <br/>
      This sample input matches template 70 and the match of the template in turn produces the output 80.
      <br/>
      This output 80 is shown in its context, the upper left corner of FIG. 2 area B as represented in FIG. 4 by image region 90.
      <br/>
      For each selectable darkness level, there is a unique set of templates and associated output data to process the input image.
    </p>
    <p num="47">
      Turning now to FIG. 5, displayed therein is yet a further enhancement of the present invention, where the templates are preferably employed in a hierarchical fashion, each template representing relatively more or less detail with respect to potential input structures than another template.
      <br/>
      FIG. 5 illustrates a small set of potential templates 110.
      <br/>
      The data in the video input buffer 108 matches three templates: 110-2, 110-4, and 110-6.
      <br/>
      Along with the four bit data output in response to a match, each template signals the match (MATCH).
      <br/>
      Furthermore, each template has a weight defining its importance relative to the other templates in the set for a particular darkness adjustment level.
      <br/>
      If multiple templates are triggered by a single input pattern, then the template with the highest weight is given preference and determines the output signal.
      <br/>
      Often, the more distinct templates, with fewer "don't care" bits, carry higher weights.
      <br/>
      If no templates are matched, then the target pixel signal level is delivered directly to all four bits of the output signal.
      <br/>
      In order to implement the hierarchy, it is further required that all templates of one priority level be mutually exclusive.
      <br/>
      For example, templates 110-1 and 110-2 in FIG. 5 could have the same priority level, as could pairs 110-3 and 110-4, and 110-5 and 110-6.
      <br/>
      It will be further appreciated that although described with respect to a 5 * 5 rectangular template, the present invention may employ larger or smaller templates, or templates of different shapes so as to maximize the ability of the templates to identify certain structures, while minimizing the hardware required to implement the templates.
    </p>
    <p num="48">
      In one embodiment the templates are employed to flexibly identify those border regions of structures that will be altered in order to control the darkness level perceived in the output image.
      <br/>
      It is further noted that a plurality of sets of templates are employed, each set representing a predetermined darkness level, wherein control logic is used to "select" the set of templates as a function of the darkness level selected by a user.
      <br/>
      Any convention means may be employed to enable a user to select the darkness level, including control panels, etc.
      <br/>
      Similarly, in a printing system, the darkness level may be defined by the image data received for printing, and may be modified for particular segments within the image as well.
      <br/>
      Hence the template selection, may be accomplished or altered on a pixel-by-pixel basis so that the selected darkness levels within an image may be varied.
    </p>
    <p num="49">
      Alternatively, a common set or subset of templates could be used for the different darkness levels, where the template output is then employed to "select" the output signals based upon the selected or desired darkness level.
      <br/>
      The present description, while directed to independent template sets is intended to represent aspects of this alternative embodiment as well.
    </p>
    <p num="50">
      An example of a template set is illustrated in FIG. 6.
      <br/>
      The template structure illustrated is one which may be employed for synthesis of the template matching logic in a gate array.
      <br/>
      In particular, the input states for the 25 pixel positions are indicated on the left side of each row entry (200).
      <br/>
      The 4-bit output states are in the middle (202).
      <br/>
      The last column contains a border enable bit 204.
      <br/>
      Some templates may match halftone areas and modify them in a way that distorts a halftone region, especially across a sweep.
      <br/>
      For example, they could introduce reversals (when one halftone level is perceived as being lighter on paper than the next lighter halftone), so a method of preventing modification is preferably applied.
      <br/>
      Considering a 7 * 7 array of video data, when a 5 * 5 array is represented in the center, there are 24 remaining pixel or "border" bits representing the rest of the data within the array.
      <br/>
      These outermost bits have their own set of templates which search for halftone patterns.
      <br/>
      If a halftone is detected by the templates for the border pixels and the 5 * 5 template matched by the input has the border enable bit 204 set then the 5 * 5 template will be disabled and the output will be a uniform value representing the center pixel.
      <br/>
      It will be further appreciated that while the present embodiment implements the templates within a gate array, equivalent template storage mechanisms include look-up tables, system memory or other programmable digital logic device.
    </p>
    <p num="51">
      Referring next to FIG. 7, depicted therein is a schematic data flow diagram of a VLSI implementation of an image enhancement chip incorporating aspects of the present invention.
      <br/>
      In general, the chip operates to convert a stream of binary pixels (video) provided to a first-in, first-out (FIFO) buffer 310, into multi-bit pixels (DECODE BIT 4:0) and a match bit indicating that a match was found.
      <br/>
      Following an initialization period necessary to build appropriate context in the data buffers, the image enhancement chip 312 converts the incoming binary data into grayscale or high-addressability pixel signals, preferably a 4-bit output.
      <br/>
      In one embodiment, chip 312 operates at a rate greater than 10 MHz accomplishing real-time processing by a highly pipelined architecture.
      <br/>
      Local buffer 314 preferably includes twelve 7-bit shift registers to hold sufficient image signal data to be operated on by the appearance matching (AM) blocks 316.
      <br/>
      Once FIFO buffer 310 is active and the local buffer 314 has sufficient context, the 5 * 5 arrays of image data are provided to the plurality of parallel appearance matching blocks 316.
      <br/>
      It is within the appearance matching blocks that the previously described template matching operations are executed.
    </p>
    <p num="52">
      The AM blocks 316 represent the templates to be compared to the input image data (video), and identify matches therein.
      <br/>
      When a match is detected, the template matching and selection logic 320 receives the signals.
      <br/>
      As previously described, selection logic block 320 is employed to not only arbitrate in the event that more than one template is matched, but to act as a multiplexer for the output data as well.
      <br/>
      It will be further appreciated that in order to further increase the throughput of an image processing system employing the pipelined image enhancement chip 312, it is possible to utilize a plurality of the chips in parallel, along with appropriate control logic.
      <br/>
      Alternatively, the template match output may be employed as a code or index to select a pulse-width, position modulated (PWPM) waveform.
    </p>
    <p num="53">
      In yet another alternative embodiment, the aspects of the present invention may be accomplished in a straightforward manner by applying a uniform darkness treatment to a region of an image.
      <br/>
      Specifically, the image region for which the darkness level is to be altered is replicated in a second memory, separate from where the input image is stored.
      <br/>
      The second image is shifted relative to the position of the first image by a predefined amount, preferably a single pixel in both the horizontal and vertical directions.
      <br/>
      In a simple application, the images within the two memories are then logically ORed together to produce an image where all structures within the affected regions are increased by a single pixel in size.
    </p>
    <p num="54">
      This alternative approach may also be implemented by logically ANDing the image stored in the second memory with a periodic pattern mask such as a checkerboard and then ORing the result with the original image, thereby producing a half-bitting effect around the image structure.
      <br/>
      It will be appreciated by those skilled in the art that a change to the duty cycle (period) of the pattern mask will provide further control over the amount of darkening that may be achieved by this embodiment.
      <br/>
      It is also possible to lighten the images by employing additional shifting and logical operations.
      <br/>
      One skilled in the art will recognize that this alternative embodiment may be employed as an empirical process with which templates may be determined as well.
    </p>
    <p num="55">
      In recapitulation, the present invention is a method and apparatus for the control of darkness/lightness in a digital image rendered by a printing system.
      <br/>
      The system alleviates the need for conventional xerographic darkness lightness control while avoiding problems associated with the application of bitmap erosion and dilation operations to a digital image.
      <br/>
      The technique preferably employs templates to selectively apply different amounts of darkening (lightening) to areas dependent upon the need for darkening (lightening).
      <br/>
      An added advantage of accomplishing the darkness/lightness control using this technique is that there is little variation in the xerographic controls and, therefore, improved system life and image quality.
    </p>
    <p num="56">
      It is, therefore, apparent that there has been provided, in accordance with the present invention, a method and apparatus for controlling the darkness/lightness level of a digital image during printing.
      <br/>
      While this invention has been described in conjunction with preferred embodiments thereof, it is evident that many alternatives, modifications, and variations will be apparent to those skilled in the art.
      <br/>
      Accordingly, it is intended to embrace all such alternatives, modifications and variations that fall within the spirit and broad scope of the appended claims.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>We claim:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A method of altering a darkness level of a digital image, comprising the steps of:</claim-text>
      <claim-text>receiving a bitmap array of image signals; isolating, within the array of image signals, image structures to be altered and storing the image structure to be altered; from the stored image structures, determining the border regions thereof to be altered; altering the border region of the stored image structure so as to change the output level of at least one pixel along the border region;</claim-text>
      <claim-text>and applying the altered, stored image structure to a corresponding region in the image bitmap to alter the level of darkness of a region therein.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. A method of altering a level of darkness of an image in conjunction with increasing the resolution thereof prior to rendering the image with a marking engine, comprising the steps of: retrieving a requested darkness level; receiving an array of image signals in the form of an image bitmap at a resolution N; selecting, from the array of image signals, a window of image signals for processing, the window being centered about a target pixel; selecting, in response to the requested darkness level, one of a plurality of sets of template patterns, each set of template patterns containing a plurality of templates therein; comparing the window of image signals to each template within the selected one of the plurality of sets of template patterns to identify a match therewith; in the event of an affirmative response to the comparing step generating an output signal at a resolution M, where M is an integer multiple of N and is determined by the template matched, otherwise generating an output signal at a resolution M wherein each bit of the output signal is equivalent to the input signal level of the target pixel.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The method of claim 2, wherein the step of comparing the window of image signals to each template within the selected one of the plurality of sets of template patterns, further comprises identifying at least two templates that match the pattern of pixels within the window of image signals, and where the step of generating an output signal at a resolution M, includes: predetermining a hierarchy for the template patterns within each of the plurality of sets of template patterns; generating an output signal from each of the at least two templates which match the pattern of pixels within the window of image;</claim-text>
      <claim-text>and based upon the hierarchy, selecting for output only one of the output signals.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The method of claim 2, wherein the method is applied independently to bitmaps representing each of a plurality of color separations of the image.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The method of claim 2, wherein M=4.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. An apparatus for altering the level of darkness of an image, including: means for setting a requested darkness level; image memory for storing an array of image signals in the form of an image bitmap at a resolution N; windowing circuitry for selecting, from the array of image signals, a region of image signals for processing, the region being centered about a target pixel; means for preprogramming each of a plurality of sets of template patterns, each set of template patterns containing a plurality of templates and each set of template patterns being associated with a unique darkness level;</claim-text>
      <claim-text>and matching circuitry for comparing the window of image signals to each template with a selected one of the plurality of sets of template patterns to identify a match therewith, wherein the selected one of the plurality of sets of template patterns is determined in response to the requested darkness level, said comparing circuitry, in the event of a match, further generating an output signal at a resolution M, where M is an integer multiple of N and is determined by the template matched, otherwise said comparing circuitry generating an output signal at a resolution M wherein each bit of the output signal is equivalent to the signal level of the target pixel.</claim-text>
    </claim>
  </claims>
</questel-patent-document>