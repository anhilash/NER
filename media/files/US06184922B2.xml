<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06184922B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06184922</doc-number>
        <kind>B2</kind>
        <date>20010206</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6184922</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="26515789" extended-family-id="50727985">
      <document-id>
        <country>US</country>
        <doc-number>09126249</doc-number>
        <kind>A</kind>
        <date>19980730</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1998US-09126249</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>22077085</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>JP</country>
        <doc-number>20667897</doc-number>
        <kind>A</kind>
        <date>19970731</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1997JP-0206678</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>JP</country>
        <doc-number>20812297</doc-number>
        <kind>A</kind>
        <date>19970801</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1997JP-0208122</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010206</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>A61B   1/04        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>1</main-group>
        <subgroup>04</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>H04N   5/225       20060101A N20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>225</subgroup>
        <classification-value>N</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>H04N   5/232       20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>232</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>348065000</text>
        <class>348</class>
        <subclass>065000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>348075000</text>
        <class>348</class>
        <subclass>075000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>348E05044</text>
        <class>348</class>
        <subclass>E05044</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>600109000</text>
        <class>600</class>
        <subclass>109000</subclass>
      </further-classification>
    </classification-national>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-005/232</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>5</main-group>
        <subgroup>232</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130903</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>A61B-001/00048</classification-symbol>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>1</main-group>
        <subgroup>00048</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130903</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>A61B-001/00114</classification-symbol>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>1</main-group>
        <subgroup>00114</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130903</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>A61B-001/04</classification-symbol>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>1</main-group>
        <subgroup>04</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130903</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>A61B-001/042</classification-symbol>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>1</main-group>
        <subgroup>042</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130903</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="6">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/60</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>60</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="7">
        <classification-scheme office="EP" scheme="CPC">
          <date>20141101</date>
        </classification-scheme>
        <classification-symbol>H04N-019/61</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>19</main-group>
        <subgroup>61</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20141108</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="8">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>H04N-2005/2255</classification-symbol>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>2005</main-group>
        <subgroup>2255</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130903</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>27</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>15</number-of-drawing-sheets>
      <number-of-figures>29</number-of-figures>
      <image-key data-format="questel">US6184922</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Endoscopic imaging system in which still image-specific or motion picture-specific expansion unit can be coupled to digital video output terminal in freely uncoupled manner</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>UEHARA MASAO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5592216</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5592216</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>KONOMURA YUTAKA, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5697885</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5697885</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>DIANNA ANDREAS E, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5801762</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5801762</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>THOMPSON ROBERT LEE</text>
          <document-id>
            <country>US</country>
            <doc-number>5980450</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5980450</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>ITO KEIJI</text>
          <document-id>
            <country>US</country>
            <doc-number>5993381</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5993381</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="6">
          <text>KANNO MASAHIDE, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4727417</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4727417</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="7">
          <text>HIYAMA KEIICHI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5124789</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5124789</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Olympus Optical Co., Ltd.</orgname>
            <address>
              <address-1>JP</address-1>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>OLYMPUS OPTICAL</orgname>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Saito, Katsuyuki</name>
            <address>
              <address-1>Sagamihara, JP</address-1>
              <city>Sagamihara</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Mochida, Akihiko</name>
            <address>
              <address-1>Hino, JP</address-1>
              <city>Hino</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="3">
          <addressbook lang="en">
            <name>Ogasawara, Kotaro</name>
            <address>
              <address-1>Tokyo, JP</address-1>
              <city>Tokyo</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="4">
          <addressbook lang="en">
            <name>Kusamura, Noboru</name>
            <address>
              <address-1>Hachioji, JP</address-1>
              <city>Hachioji</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="5">
          <addressbook lang="en">
            <name>Tsunakawa, Makoto</name>
            <address>
              <address-1>Chofu, JP</address-1>
              <city>Chofu</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="6">
          <addressbook lang="en">
            <name>Tashiro, Hideki</name>
            <address>
              <address-1>Yokohama, JP</address-1>
              <city>Yokohama</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="7">
          <addressbook lang="en">
            <name>Yamashita, Shinji</name>
            <address>
              <address-1>Fuchu, JP</address-1>
              <city>Fuchu</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="8">
          <addressbook lang="en">
            <name>Matsumoto, Kanichi</name>
            <address>
              <address-1>Hino, JP</address-1>
              <city>Hino</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="9">
          <addressbook lang="en">
            <name>Ohno, Wataru</name>
            <address>
              <address-1>Sagamihara, JP</address-1>
              <city>Sagamihara</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="10">
          <addressbook lang="en">
            <name>Hagihara, Masahiro</name>
            <address>
              <address-1>Hachioji, JP</address-1>
              <city>Hachioji</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="11">
          <addressbook lang="en">
            <name>Nakatsuchi, Kazutaka</name>
            <address>
              <address-1>Hino, JP</address-1>
              <city>Hino</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="12">
          <addressbook lang="en">
            <name>Kami, Kuniaki</name>
            <address>
              <address-1>Machida, JP</address-1>
              <city>Machida</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Ostrolenk, Faber, Gerb &amp; Soffen, LLP</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Britton, Howard</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>REVOKED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A camera control unit for processing a signal output from an imaging device incorporated in an endoscope is provided with an analog video signal output terminal through which a video signal is output to a monitor, and a digital video signal output terminal to which a still image-specific or motion picture-specific expansion unit is coupled in a freely detachable manner.
      <br/>
      By handling a release switch, a still image or motion picture can be recorded digitally.
      <br/>
      Even when the recorded image data is edited or subjected to any other processing, deterioration of image quality can be prevented.
      <br/>
      An imaging system having these advantages can be realized on a small scale.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="2">The present invention relates to an endoscopic imaging system in which a still image-specific or motion picture-specific expansion unit can be coupled in a freely detachable manner to a digital video output terminal of a camera control unit for processing a signal sent from an imaging device incorporated in an endoscope.</p>
    <p num="3">2. Description of the Related Art</p>
    <p num="4">
      In recent years, endoscopes have been widely adopted in the fields of medicine and industries alike.
      <br/>
      Moreover, an endoscopic imaging system has come to be adopted widely.
      <br/>
      In the endoscopic imaging system, a TV camera-mounted endoscope having a TV camera which includes an imaging means mounted on an eyepiece unit of an optical endoscope, or an electronic endoscope including an imaging means in a distal part thereof is used to produce an endoscopic image, and the endoscopic image is displayed on a monitor.
    </p>
    <p num="5">
      Assume that such an endoscopic imaging system is used, for example, to conduct an endoscopic examination in the field of medicine.
      <br/>
      In this case, an operator often records images (photographs an object) using a photography unit or produces hard copies of endoscopic images by outputting image data to a video printer so that he/she can utilize them for future diagnosis.
    </p>
    <p num="6">Moreover, image data may be output to an image filing system for recording of endoscopic images.</p>
    <p num="7">Moreover, a video tape recorder (VTR) has been adopted for recording a motion picture.</p>
    <p num="8">
      However, when the photography unit is employed, it takes much time to complete development of a film.
      <br/>
      In addition, a request for checking an image right away cannot be met, as is possible when the video printer is employed.
      <br/>
      However, as far as the photography unit or video printer is concerned, management of developed films or print sheets is a nuisance.
      <br/>
      Since it is hard to retrieve the films or print sheets, the films or print sheets are usually manually filed.
      <br/>
      This brings about a drawback that the filing (using an image scanner) is time-consuming.
    </p>
    <p num="9">
      Moreover, when an image filing system is employed, image retrieval can be achieved readily.
      <br/>
      However, a system including the image filing system becomes large in scale.
      <br/>
      Such a system can be installed only in a hospital that is somewhat large in scale.
      <br/>
      Furthermore, a location in which such retrieval is carried out is restricted.
    </p>
    <p num="10">
      Moreover, in some clinical cases, image data of a motion picture is recorded.
      <br/>
      However, there is a drawback that when the VTR is used to dub films or to edit or manipulate the image data, image quality deteriorates.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="11">An object of the present invention is to provide an endoscopic imaging system making it possible to readily retrieve or edit image data of even a still image or a motion picture, and to suppress deterioration of image quality.</p>
    <p num="12">Another object of the present invention is to provide an endoscopic imaging system designed compactly and capable of providing endoscopic image data that can be readily retrieved or edited.</p>
    <p num="13">Still another object of the present invention is to provide an endoscopic imaging system including a simply structured external storage and capable of readily fetching digital image data.</p>
    <p num="14">An endoscopic imaging system of the present invention comprises:</p>
    <p num="15">an endoscope including an illumination optical system located at and end of an elongated insertion unit for emitting illumination light, an objective optical system located at the distal end of the insertion unit for forming an optical image of an object illuminated with the illumination light, and an imaging device for photoelectrically converting the optical image directly or the optical image that has been transmitted through the insertion unit;</p>
    <p num="16">a signal processing apparatus for driving the imaging device, processing an image signal output from the imaging device, producing digital and analog video signals, and outputting the digital and analog video signals through a digital video signal output terminal and analog video signal output terminal, respectively;</p>
    <p num="17">a monitor for displaying an object image represented by the analog video signal in response to an input of the analog video signal output through the analog video signal output terminal; and</p>
    <p num="18">an expansion unit to be coupled to the digital video signal output terminal in a freely detachable manner, and including at least one of a compression unit for compressing the digital video signal and a PC card slot to which a PC card, in which a motion picture digital video signal representing a motion picture whose data has been compressed by the compression unit and a digital video signal representing a still image whose data has been compressed by the compression unit are stored, can be coupled in the freely detachable manner.</p>
    <p num="19">
      An operator should merely connect an expansion unit specific to still images or motion pictures according to the kind of image to be recorded.
      <br/>
      Thus, image data can be compressed and recorded digitally.
      <br/>
      Retrieval, editing, and manipulation of the image data can therefore be carried out easily.
      <br/>
      Even if manipulation or the like is repeated, resultant deterioration of image quality can be minimized.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="20">
      FIGS. 1 to 8B relate to a first embodiment of the present invention;
      <br/>
      FIG. 1 is an oblique view showing a configuration of an endoscopic imaging system of the first embodiment;
      <br/>
      FIG. 2 is a block diagram showing an internal configuration of a CCU and the like;
      <br/>
      FIG. 3 is a block diagram showing a configuration of a still image-specific expansion unit;
      <br/>
      FIGS. 4A and 4B are block diagrams showing configurations of JPEG compression circuits of the lossy and lossless coding types;
      <br/>
      FIG. 5 is a block diagram showing a configuration of a compression circuit specific to motion pictures;
      <br/>
      FIGS. 6A to 6D are diagrams showing small memory cards including a compact flash memory card;
      <br/>
      FIGS. 7A and 7B are diagrams showing adapters used to couple a small memory card to a PC card slot;
      <br/>
      FIGS. 8A and 8B are diagrams showing examples of use of small memory cards for explaining the operations thereof;
      <br/>
      FIG. 9A is a block diagram showing a configuration of a CCU and the like in a variant of the first embodiment;
      <br/>
      FIG. 9B is a block diagram showing a configuration of an endoscopic imaging system of a second embodiment of the present invention;
      <br/>
      FIG. 10 is an oblique view showing a configuration of an endoscopic imaging system of a third embodiment of the present invention;
      <br/>
      FIG. 11 is a plan view showing a structure of a connector spliced to an end of a cable;
      <br/>
      FIG. 12 is a side view showing a structure of a connector spliced to an end of a cable in a fourth embodiment of the present invention;
      <br/>
      FIGS. 13A and 13B are plan views showing in enlargement the shapes of a card bus and its pins in a PC card slot in accordance with a fifth embodiment of the present invention;
      <br/>
      FIGS. 14 to 17 relate to a sixth embodiment of the present invention;
      <br/>
      FIG. 14 is a diagram showing a configuration of an endoscopic imaging system of the sixth embodiment;
      <br/>
      FIG. 15 is a diagram showing a configuration of a digital interface unit shown in FIG. 1;
      <br/>
      FIG. 16 is a timing chart of a digital video signal to be input to the digital interface unit shown in FIG. 2;
      <br/>
      FIG. 17 is a diagram showing an example of extracting a clock signal (CLK) from a horizontal synchronizing signal (H-SYNC) shown in FIG. 16;
      <br/>
      FIG. 18 is a diagram showing a configuration of a digital interface unit in accordance with a seventh embodiment of the present invention;
      <br/>
      FIG. 19 is a diagram showing a configuration of a digital interface unit in accordance with a eighth embodiment of the present invention;
      <br/>
      FIG. 20 is a diagram showing a configuration of a digital interface unit in accordance with a ninth embodiment of the present invention; and
      <br/>
      FIG. 21 is a diagram showing a configuration of a digital interface unit in accordance with a tenth embodiment of the present invention.
    </p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
    <p num="21">The first embodiment of the present invention will be described with reference to FIGS. 1 to 8.</p>
    <p num="22">As shown in FIG. 1, an endoscopic imaging system 1 of the first embodiment of the present invention comprises: a TV camera-mounted endoscope 4 having a TV camera 3 mounted on a rigid endoscope 2; a light source apparatus 5 for supplying illumination light to the rigid endoscope 2; a camera control unit (hereinafter a CCU) 6 serving as an endoscopic imaging apparatus for processing a signal sent from an imaging means in the TV camera 3; a color monitor 7 for displaying an image represented by a video signal output from the CCU 6; a still image-specific expansion unit 9 and motion picture-specific expansion unit 10 selectively coupled to a digital video output terminal 8 of the CCU 6 through which a digital video signal is output so that the selected expansion unit can be uncoupled freely; and a personal computer 14 having a PC card slot 13 to which a PC card 12, such as a flash memory card, which can be coupled to a PC card slot 11 of the still image-specific expansion unit 9 in a freely detachable manner, is coupled in the freely detachable manner.</p>
    <p num="23">
      What is referred to as a PC card is peripheral equipment sized like a credit card in conformity with the PC Card Standard.
      <br/>
      The PC card was standardized by the Personal Computer Memory Card International Association and the Japan Electric Industry Development Association in 1995.
    </p>
    <p num="24">
      The still image-specific expansion unit 9 and motion picture-specific expansion unit 10 are provided with cables 15 and 16, respectively, having connectors 15A and 16A, respectively, spliced to one end thereof.
      <br/>
      The connectors 15A and 16A are coupled to a digital video output terminal 8 of the CCU 6 so that they can be uncoupled freely.
      <br/>
      One of the still image-specific expansion unit 9 and motion picture-specific expansion unit 10 can be selected and connected to the CCU 6.
    </p>
    <p num="25">
      Alternatively, a still image &amp; motion picture-specific expansion unit 97 can be selectively connected to the CCU 6.
      <br/>
      The still image &amp; motion picture-specific expansion unit 97 is a unit into which the still image-specific expansion unit 9 and motion picture-specific expansion unit 10 are integrated (that is, having the ability to compress still-image data and record resultant data on a PC card 12 that is loaded into a PC card slot 11', and also having the ability to compress motion-picture data and output resultant data through a digital video output terminal 17').
      <br/>
      The still image &amp; motion picture-specific expansion unit 97 is also provided with a cable 98 having a connector 98A spliced to an end thereof.
      <br/>
      The connector 98A is coupled to the digital video output terminal 8 of the CCU 6 so that it can be uncoupled freely.
    </p>
    <p num="26">
      Moreover, the still image-specific expansion unit 9 and motion picture-specific expansion unit 10 are provided with the PC card slot 11 and digital video output terminal 17, respectively.
      <br/>
      The PC card 12 is loaded into the PC card slot 11 so that it can be unloaded freely.
      <br/>
      Still-image data compressed by a still image compressing means incorporated in the still image-specific expansion unit 9 can be recorded on the PC card 12.
    </p>
    <p num="27">
      Moreover, a digital video disk (DVD) drive (DVD-RAM drive or DVD-R drive), not shown, having a recording facility may be connected to the motion picture-specific expansion unit 10 through the digital video output terminal 17 through which compressed motion-picture data is output.
      <br/>
      In this case, motion-picture data compressed by a motion picture compressing means incorporated in the motion picture-specific expansion unit 10 can be recorded.
    </p>
    <p num="28">Moreover, the data may be input to the personal computer 14 and edited.</p>
    <p num="29">
      The rigid endoscope 2 includes an elongated insertion unit 21, a hand-held unit 22 formed at the back end of the insertion unit 21, and an eyepiece unit 23 formed at the back end of the hand-held unit 22.
      <br/>
      The hand-held unit 22 has a light guide base and is connected to the light source apparatus 5 over a light guide cable 24.
    </p>
    <p num="30">
      As shown in FIG. 2, white illumination light emanating from a lamp 25 in the light source apparatus 5 is converged by a condenser and supplied to a light guide in the light guide cable 24.
      <br/>
      The illumination light is propagated through a light guide 26 in the rigid endoscope 2, and emitted forward through the distal end of the light guide fitted in an illumination window in the distal part of the insertion unit 21.
      <br/>
      An object such as a lesion is thus illuminated.
    </p>
    <p num="31">
      An objective lens 27 is fitted in an observation window adjacent lens to the illumination window.
      <br/>
      The objective forms an object image at the image formation position thereof.
      <br/>
      The formed image is transmitted by a system of relay lenses 28 arranged in the insertion unit 21 and opposed to the objective lens 27.
      <br/>
      The system of relay lenses forms an image near the eyepiece unit 23.
      <br/>
      The image is re-formed on a solid-state imaging device or specifically a charge-coupled device (hereinafter a CCD) 32 by means of an eyepiece 29 included in the eyepiece unit 23 and an image formation lens 31 in the TV camera 3 which is opposed to the eyepiece 29.
    </p>
    <p num="32">
      A mosaic filter 32a is placed in front of the image plane (photoelectric conversion plane) of the CCD 32.
      <br/>
      Color components of light input to each pixel are optically separated from one another.
      <br/>
      This means that the imaging means of this embodiment is a simultaneous imaging means for producing a color image signal under white-light illumination.
    </p>
    <p num="33">
      The CCD 32 is connected to the CCU 6 over a camera cable 33.
      <br/>
      With application of a CCD driving signal from a CCD driver 34 in the CCU 6 to the CCD 32, a CCD output signal (image signal) photoelectrically converted and output by the CCD 32 is input to a preamplifier 35 in the CCU 6.
      <br/>
      The signal amplified by the preamplifier 35 is then input to the pre-processing circuit 36.
    </p>
    <p num="34">
      The CCD output signal input to the pre-processing circuit 36 is pre-processed by performing correlation double sampling (CDS) or sample-and-hold (S/H).
      <br/>
      A resultant signal is input to an A/D converter 37 and converted into a digital signal.
      <br/>
      The digital signal is input to a Y/C separation circuit 38.
    </p>
    <p num="35">
      The digital signal input to the Y/C separation circuit 38 is recomposed according to the line-sequential color imaging.
      <br/>
      Digital signals Y, Cr, and Cb of three channels are then separated from one another, and input to an RGB matrix circuit 39.
    </p>
    <p num="36">The digital signals Y, Cr, and Cb input to the RGB matrix circuit 39 are converted into a digital signal RGB according to the matrix algebra.</p>
    <p num="37">
      On the succeeding side of the RGB matrix circuit 39, there is a white balance/black balance (abbreviated to WB/BB in FIG. 2) adjustment circuit 41.
      <br/>
      The digital signal RGB converted according to the matrix algebra is input to the white balance/black balance adjustment circuit 41.
      <br/>
      After the signal undergoes the given balance adjustment, it is input to a digital video processing circuit 42.
    </p>
    <p num="38">
      The digital video processing circuit 42 carries out digital processing such as enhancement, gamma correction, and character convolution.
      <br/>
      A resultant signal is input to a D/A converter 43.
      <br/>
      The digital signal input to the D/A converter 43 is converted into an analog signal, and then converted into a standard video signal by a post-processing circuit 44.
      <br/>
      The standard video signal is output to a color monitor 7 through an analog video output terminal.
    </p>
    <p num="39">
      Moreover, an output of the digital video processing circuit 42 is stored temporarily in a frame memory 45.
      <br/>
      The digital video signal stored in the frame memory 45 is output to the expansion unit 9 or 10 coupled to the digital video output terminal 8 through the digital video output terminal 8.
    </p>
    <p num="40">
      Moreover, for example, a front panel 46 of the CCU 6 is provided with a display LED 47 for indicating the number of frames of a still image to be recorded or a recording time of a motion picture, and a release switch 48.
      <br/>
      The release switch 48 is connected to the CPU 49.
      <br/>
      A release instruction signal generated by handling the release switch 48 is transmitted to the CPU 49.
    </p>
    <p num="41">In response to the release instruction signal, the CPU 49 sends a release signal to a control means (for example, a CPU 9a (10a)) in the expansion unit 9 or 10 through a communication line 51 over which a control signal is transmitted.</p>
    <p num="42">Incidentally, the CPU 49 has a facility for recognizing whether an expansion unit coupled to the digital video output terminal 8 is the still image-specific expansion unit 9 or the motion picture-specific expansion unit 10, i.e., a connected unit identification facility 49a.</p>
    <p num="43">
      For example, the control means in the expansion unit 9 or 10 is instructed to send a unit identification signal used to identify the expansion unit 9 or 10 over the communication line 51.
      <br/>
      The control means in the expansion unit 9 or 10 returns a unit identification signal over the communication line 51.
      <br/>
      Based on the unit identification signal, a connected expansion unit is recognized as the still image-specific expansion unit 9 or motion picture-specific expansion unit 10.
      <br/>
      When the still image &amp; motion picture-specific expansion unit 97 is connected, a unit identification signal associated with the still image &amp; motion picture-specific expansion unit 97 is returned to the CPU 49.
    </p>
    <p num="44">
      Alternatively, instead of employing the foregoing identification means, different resistors or the like may be connected to the contact pins of the connectors 15A and 16A.
      <br/>
      In this case, when the connector 15A or 16A is coupled to the digital video output terminal 8 of the CCU 6, the resistances of the resistors are checked.
      <br/>
      Thus, a connected expansion unit is recognized as the still image-specific expansion unit 9 or motion picture-specific expansion unit 10.
    </p>
    <p num="45">
      The CPU 49 has the facility for identifying an expansion unit coupled to the digital video output terminal 8 as the still image-specific expansion unit 9 or the motion picture-specific expansion unit 10.
      <br/>
      When the release switch 48 is handled, the CPU 49 carries out an associated control operation.
    </p>
    <p num="46">
      When a unit coupled to the digital video output terminal 8 is the still image-specific expansion unit 9, the release signal is sent to CPU 49, whereupon image data of a still image is stored in the frame memory 45 (writing is inhibited).
      <br/>
      The still image-specific expansion unit 9 carries out releasing, that is, compresses image data of a still image input through the digital video output terminal 8 and records the image data on the PC card 12 loaded into the PC card slot 11.
      <br/>
      Thereafter, the control means in the still image-specific expansion unit 9 reports the fact that data of a still image of one frame has been recorded to the CPU 49 over the communication line 51.
    </p>
    <p num="47">The CPU 49 uses a font generator 52 to control display of the display LED 47 so that the number of frames set before the release switch 48 is handled will be incremented by one and displayed.</p>
    <p num="48">
      Moreover, assume that a unit coupled to the digital video output terminal 8 is the motion picture-specific expansion unit 10.
      <br/>
      When the release signal is received, image data of a motion picture input from the frame memory 45 through the digital video output terminal 8 is compressed.
      <br/>
      The release signal is sent to peripheral equipment such as a DVD coupled to the digital video output terminal 17 through the digital video output terminal 17.
      <br/>
      The peripheral equipment carries out the process of starting a recording of compressed image data.
      <br/>
      The peripheral equipment then sends a signal indicating that recording has been started to the CPU 49 over the communication line 51.
    </p>
    <p num="49">
      The CPU 49 then displays a message saying that recording of a motion picture has started (for example, a message of "Picture recording").
      <br/>
      The CPU 49 controls the display LED 47 via the font generator 52 so that the display LED 47 will display a recording time having elapsed since a recording start time instant 0.
    </p>
    <p num="50">Incidentally, when the motion picture-specific expansion unit 10 is connected, the CPU 49 updates (writes or reads) image data existent in the frame memory 45 at intervals of a certain time frame.</p>
    <p num="51">
      As mentioned above, when the CPU 49 receives the release instruction signal, it sends a release signal to the expansion unit 9 or 10 over the communication line 51 so that image data will be fetched from the frame memory 45 and recorded.
      <br/>
      The expansion unit 9 or 10 reports the fact that releasing has been carried out to the CPU 49 over the communication line 51.
      <br/>
      The CPU 49 displays the number of received frames or the like on the display LED 47.
    </p>
    <p num="52">
      When the release switch 48 is pressed, a still image or motion picture is recorded automatically according to the result of the automatic identification performed by the connected unit identification facility 49a, that is, according to whether a connected expansion unit is the still image-specific expansion unit 9 or the motion picture-specific expansion unit 10.
      <br/>
      Alternatively, automatic identification may be omitted.
      <br/>
      Instead, a still image-specific release switch 48a or a motion picture-specific release switch 48b, which is part of the large release switch 49, may be handled in order to given an instruction for recording a still image or motion picture.
      <br/>
      In particular, when the still image &amp; motion picture-specific expansion unit 97 is connected, the still image-specific release switch 48a or motion picture-specified release switch 48b should be employed.
    </p>
    <p num="53">Incidentally, the CPU 49 controls the operations performed by the white balance/black balance adjustment circuit 41 and the read or write operation relative to the frame memory 45.</p>
    <p num="54">
      As shown in FIG. 3, the still image-specific expansion unit 9 consists of a JPEG (Joint Photographic Coding Group) compression circuit 54 and a PC card driver 55.
      <br/>
      The JPEG compression circuit 54 falls into either a lossless coding type of compressing data of a color still image according to the lossless coding and a lossy coding type of compressing it according to the lossy coding.
    </p>
    <p num="55">
      As far as data compressed according to the lossless coding is concerned, decompression can restore it to its original information quality.
      <br/>
      By contrast, data compressed according to the lossy coding cannot be fully restored to its original information quality.
    </p>
    <p num="56">
      The spatial predictive coding is adopted as the former lossless coding.
      <br/>
      In this case, the level of compressibility is lower than that permitted by the lossy coding.
      <br/>
      However, since original image quality can be retained, if deterioration of image quality cannot be accepted, this coding would be effective.
    </p>
    <p num="57">
      On the other hand, the DCT (discrete cosine transform) coding is a baseline of the lossy coding.
      <br/>
      Although an original image cannot be reproduced exactly, decoded data representing an image of quality that is good enough for practical use can be produced.
    </p>
    <p num="58">
      FIG. 4A shows a configuration of the JPEG compression circuit 54 adopting the DCT coding which is employed in this embodiment.
      <br/>
      As shown in FIG. 4A, digital image data is input to a DCT circuit 61 in units of a block of 8 by 8 pixels, and transformed or computed according to the two-dimensional DCT.
      <br/>
      This results in a DCT coefficient composed of a DC component and AC components.
    </p>
    <p num="59">
      The DCT coefficient is input to a quantization circuit 62, whereby the DC component and AC components are quantized independently of each other.
      <br/>
      Image data resulting from quantization is input to an entropy encoder 64, and encoded as entropy (variable length data) using a Huffman coding table 65 or the like.
    </p>
    <p num="60">
      FIG. 4B shows a configuration of the JPEG compression circuit 54 of the lossless coding type.
      <br/>
      Digital image data is input to a predictor 66.
      <br/>
      The process of combining three adjoining pixels and calculating a predictive value is carried out.
      <br/>
      The predictive value is input to an entropy encoder 67.
      <br/>
      The entropy encoder 67 uses a Huffman coding table 68 to encode as entropy a value calculated by subtracting the predictive value from the value of a pixel to be encoded, or in short, a predictive error.
      <br/>
      Compared with the DCT coding, this coding suffers a low level of compressibility but enables image compression without deterioration of image quality.
    </p>
    <p num="61">FIG. 5 shows a configuration of the motion picture-specific expansion unit 10 including an MPEG (Moving Picture Experts Group) compression circuit (or an MPEG coder) 69.</p>
    <p num="62">Input digital image signals R, G, and B are input to a frame rearrangement circuit 70 via a signal conversion circuit for converting each signal into a luminance signal (signal Y) and chrominance signals (signals Cr and Cb).</p>
    <p num="63">
      The MPEG compression circuit 69 divides one sequence of a motion picture into a group of pictures (GOP) consisting of a plurality of frames (pictures), and encodes the GOP.
      <br/>
      The GOP is composed of an intra-picture (I picture), predictive pictures (P pictures) that are predictive from a temporally preceding frame whose data has already been encoded, and bi-directionally predictive pictures (B pictures) that are predictive from two temporally preceding and succeeding frames.
    </p>
    <p num="64">The GOP composed of the I, P, and B pictures is subdivided into layers such as adjoining macroblocks.</p>
    <p num="65">
      Due to introduction of the plurality of picture types, the frame rearrangement circuit 70 is used to rearrange frames of an input image by picture type.
      <br/>
      Thereafter, each resultant image data is input to a motion prediction circuit 71 and subtractor 72.
    </p>
    <p num="66">
      Each frame data is encoded in units of a macroblock.
      <br/>
      For each macroblock, it is judged whichever of a motion compensation prediction mode or intra-picture encoding mode should be set.
      <br/>
      For the motion compensation prediction mode, the motion prediction circuit 71 compares input image data with image data provided by a frame memory/predictor 82 according to a matching method, and thus calculates forward and backward vectors.
      <br/>
      The forward and backward vectors are output to the frame memory/predictor 82.
      <br/>
      Consequently, predicted image data in which a motion has been compensated and predicted is produced and output to a multiplexer 76.
    </p>
    <p num="67">
      Prediction of a motion is carried out in units of a macroblock.
      <br/>
      Specifically, assuming that one block is regarded as 8 by 8 pixels, one macroblock consists of four adjoining blocks of signals Y, and one block of a signal Cr and one block of a signal Cb which are coincident with the four blocks.
      <br/>
      The subtractor 72 calculates a difference and produces a predictive error signal.
      <br/>
      The predictive error signal is input to a DCT circuit 73.
    </p>
    <p num="68">Moreover, for the intra-picture encoding mode in which compensation and prediction of a motion is not carried out, image data in which frames have been rearranged is input to the DCT circuit 73.</p>
    <p num="69">
      The DCT circuit 73 performs two-dimensional DCT in units of one block of 8 pixels by 8 lines.
      <br/>
      An output (transform coefficient) of the DCT circuit 73 is input to a quantization circuit 74.
      <br/>
      The quantization circuit 74 re-quantizes the transform coefficient with respect to a given quantization coefficient, thus minimizing the redundancy of a signal representing one block.
    </p>
    <p num="70">
      Quantized data output from the quantization circuit 74 is input to a variable length coder 75.
      <br/>
      The variable length coder 75 encodes the data according to the Huffman coding according to the statistics of quantized output.
      <br/>
      Specifically, a short bit is assigned to data whose frequency of occurrence is high, and a long bit is assigned to data whose frequency of occurrence is low.
      <br/>
      Thus, an amount of transmitted data is reduced.
    </p>
    <p num="71">
      An output of the variable length coder 75 is input to the multiplexer 76.
      <br/>
      Signals Y, Cr, and Cb are multiplexed.
      <br/>
      Coded data is then output as a bit stream through a buffer 77.
      <br/>
      The coded data is input to a quantization control unit 78.
      <br/>
      The quantization control unit 78 monitors an amount of coded data, controls a quantization coefficient set in the quantization circuit 74, and thus adjusts an amount of output data.
    </p>
    <p num="72">
      Moreover, quantized data output from the quantization circuit 74 is used as reference image data for motion compensation and prediction.
      <br/>
      The quantized data is therefore input to an inverse quantization circuit 79 and inversely quantized.
      <br/>
      Resultant data is input to an inverse DCT circuit 80 and subjected to inverse DCT.
      <br/>
      Thus, the processing of restoring the data to original image data is carried out.
    </p>
    <p num="73">
      An output of the inverse DCT circuit 80 is input to an adder 81.
      <br/>
      If necessary, the output is added to image data representing a difference and residing in the frame memory/predictor 82.
      <br/>
      Resultant data is stored in a frame memory in the frame memory/predictor 82.
      <br/>
      Reference image data in which a motion has been compensated and predicted is produced and utilized for motion compensation and prediction.
    </p>
    <p num="74">Aside from a flash memory card and a hard disk of type III, small memory cards shown in FIGS. 6A, 6B, 6C, and 6D may be used as the PC card 12 to be loaded into the PC card slot 11 of the still image-specific expansion unit 9 so that it can be unloaded freely, and to be used to store (record) a still image.</p>
    <p num="75">
      FIGS. 6A, 6B, 6C, and 6D show a compact flash memory card 12A, a miniature card 12B, a smart medium 12C, and a small PC card 12D respectively.
      <br/>
      The storage capacities shown in FIGS. 6A, 6B, and 6D are the storage capacities of locally procurable cards and are presented as practical examples of the capacities thereof.
    </p>
    <p num="76">
      These small memory cards have dimensions smaller than the dimensions (size) of an ordinary PC card.
      <br/>
      The small memory cards are commercialized as recording media to be used when cards smaller than the ordinary PC card are needed.
      <br/>
      When the small memory cards are used as PC cards, they are loaded into the PC card slot 11 using adapters.
      <br/>
      By attaching the adapters, the small memory cards become nearly equivalent to the PC card serving as a flash memory.
    </p>
    <p num="77">
      For example, as shown in FIG. 7A, the smart medium 12C is loaded via a smart medium adapter 85C.
      <br/>
      The small PC card 12D shown in FIG. 7B is loaded via a small PC card adapter 85D.
      <br/>
      The same applies to the other small cards.
    </p>
    <p num="78">
      In this embodiment, as mentioned above, the CCU 6 is provided with the digital video output terminal 8 to which the connector 15A or 16A of the still image-specific expansion unit 9 or motion picture-specific expansion unit 10 is coupled.
      <br/>
      When the still image-specific expansion unit 9 is connected, still image data can be recorded on the PC card 12.
      <br/>
      When the motion picture-specific expansion unit 10 is connected, motion picture data can be recorded on a DVD or the like through the digital output terminal 17 of the motion picture-specific expansion unit 10.
    </p>
    <p num="79">
      In FIG. 2, the CCU 6 has the frame memory 45.
      <br/>
      Alternatively, the frame memory 45 may be incorporated in the still image-specific expansion unit 9.
      <br/>
      In this case, only a digital signal representing a motion picture is output from the CCU 6 to the expansion unit.
    </p>
    <p num="80">The operations of the thus configured first embodiment will be described below.</p>
    <p num="81">
      For example, when the abdomen is operated on under endoscopic observation, the TV camera 3 is, as shown in FIG. 1, mounted on the rigid endoscope 2.
      <br/>
      The light guide cable 24 and camera cable 33 are coupled to the light source apparatus 5 and CCU 6 respectively.
      <br/>
      The color monitor 7 is connected to the CCU 6 over a monitor cable.
    </p>
    <p num="82">
      Moreover, the connector 15A of the cable 15 extending from, for example, the still image-specific expansion unit 9 is coupled to the digital video output terminal 8 of the CCU 6.
      <br/>
      The PC card 12 such as a hard disk of type III or the small memory card shown in FIG. 6A is coupled to the PC card slot 11 via an adapter.
    </p>
    <p num="83">The small-scale system configuration enables construction of an endoscope system having a facility for recording digital data of a still image.</p>
    <p num="84">
      The insertion unit 21 of the rigid endoscope 2 is thrust into the patient's abdomen by piercing the abdominal wall with a trocar and cannula.
      <br/>
      This makes it possible to observe a lesion in an organ or the like in the abdomen through the objective lens 27.
      <br/>
      An (endoscopic) image is then displayed on the color monitor 7.
      <br/>
      An operator views the image.
      <br/>
      When the operator judges that surgery is required, if he/she wants to record the image as a pre-operative image, he/she presses the release switch 48 or still-image release switch 48a.
    </p>
    <p num="85">
      A release instruction signal is input to the CPU 49.
      <br/>
      The CPU 49 inhibits writing of image data in the frame memory 45.
      <br/>
      Thus, a still image-preserved state is established.
      <br/>
      A release signal used to record a still image is sent to the still image-specific expansion unit 9 over the communication line 51.
    </p>
    <p num="86">
      The still-image expansion unit 9 compresses image data of a still image existent in the frame memory 45, and records resultant data on the PC card 12.
      <br/>
      The recorded information is sent to the CPU 49 over the communication line 51.
      <br/>
      The CPU 49 releases inhibition of writing of image data in the frame memory 45, and displays a message saying that one frame has been recorded on the display LED 47.
    </p>
    <p num="87">Thus, for example, a plurality of frame images can be recorded.</p>
    <p num="88">
      Moreover, a treatment instrument may be thrust into the abdomen for treatment of a lesion.
      <br/>
      During surgery or at the completion of surgery, a plurality of frame images can be recorded.
      <br/>
      Moreover, when an endoscopic examination is conducted in order to evaluate the cured state of the lesion at the completion of surgery, the images can be recorded in the same manner.
    </p>
    <p num="89">FIG. 8A shows a state in which the hard disk 12e of type III on which a still image is recorded is inserted (as the PC card 12) in the PC card slot 13 of the personal computer 14, and data of the still image is edited or manipulated.</p>
    <p num="90">
      The hard disk 12e of type III on which a still image is stored (recorded) by the still image-specific expansion unit 9 is inserted (loaded) into the PC card slot 13 of the personal computer 14.
      <br/>
      Image data compressed and stored on the hard disk 12e of type III is stretched or decoded by the personal computer 14 having the capability of a JPEG stretching circuit (or a JPEG decoder) in the form of software, and thus restored.
      <br/>
      An endoscopic image 91 represented by the resultant image data is, as shown in FIG. 8A, displayed in, for example, the right-hand area on the display surface 14A.
    </p>
    <p num="91">
      The ID number of a patient associated with the endoscopic image 91 is entered at the keyboard.
      <br/>
      Necessary patient data 92 is superimposed on the endoscopic image on the display surface 14A.
      <br/>
      Thus, the patient's clinical record can be created readily.
      <br/>
      The patient's clinical record can be stored on a recording means such as a hard disk incorporated in the personal computer 14 or a large-capacity hard disk 94 or magneto-optical disk (not shown) capable of being coupled to the personal computer 14 so that it can be uncoupled freely.
      <br/>
      Alternatively, a hard copy of the clinical record can be produced using a printer.
    </p>
    <p num="92">
      Moreover, when slides or the like must be created for use at a medical association, they can be created readily.
      <br/>
      For compiling image data as a data base, editing such as sorting of images or deletion of an image can be achieved readily.
      <br/>
      Moreover, filing can be achieved more readily than filing of photographs taken according to a prior art device or outputs of a video printer.
      <br/>
      Moreover, retrieval of any image can be achieved readily.
      <br/>
      Besides, even when re-editing or re-manipulation must be performed afterward, it can be achieved readily.
    </p>
    <p num="93">
      As mentioned above, recorded data of still images can be edited or manipulated readily.
      <br/>
      At this time, image quality will not be deteriorated.
      <br/>
      Moreover, when a notebook-type or portable personal computer is used as the personal computer 14, editing can be carried out at almost any place.
      <br/>
      Moreover, data of still images is compressed and stored.
      <br/>
      Image data acquired during one ordinary examination can be stored on the small PC card 12 or even a smaller small memory card.
    </p>
    <p num="94">
      Moreover, a general-purpose image compression circuit rather than a special image compression circuit is employed.
      <br/>
      Image compression can be achieved at low cost.
      <br/>
      Editing of image data by the personal computer 14 can be achieved readily.
    </p>
    <p num="95">
      Furthermore, the CCU 6 is configured in such a way that the expansion unit 9 or 10 is not incorporated in the CCU 6 but can be coupled to the digital video output terminal 8 in a freely detachable manner.
      <br/>
      The CCU 6 can be realized at cost not largely different from an existing CCU.
      <br/>
      The CCU 6 can be provided for users at a low price.
    </p>
    <p num="96">
      A user can select any of the expansion units 9, 10, and 97 for actual use.
      <br/>
      Moreover, when the components of the expansion unit 9, 10, or 97 are modified, the modification involves only the expansion unit 9, 10, or 97.
      <br/>
      This is advantageous.
      <br/>
      Thus, innovation can be achieved readily.
    </p>
    <p num="97">
      When image data recorded on the PC card 12 is stored on a recording medium such as the hard disk 94 or magneto-optical optical disk, the image data recorded on the PC card 12 is deleted.
      <br/>
      The PC card 12 can then be used to record new image data.
    </p>
    <p num="98">
      Moreover, a plurality of endoscopic images whose data has been stored on the recording medium can be displayed on the display surface 14A of the personal computer 14.
      <br/>
      For example, as shown in FIG. 8B, a pre-operative image 95A, a post-operative (immediately after surgery) image 95B, and an image 95C produced in three months after surgery may be, as shown in FIG. 8B, displayed side by side.
      <br/>
      This makes it possible to clearly observe a temporal change in a lesion cured by conducting surgery.
    </p>
    <p num="99">
      When a plurality of images are thus displayed side by side, the image data may be manipulated so that a portion of each image other than a portion depicting a region of interest concerned will be cut out, and images depicting the region of interest alone will be displayed.
      <br/>
      A comment or the like may be superimposed on the images.
    </p>
    <p num="100">
      Even when image data is thus stored (copied into) on another recording means or recording medium, image quality will not deteriorate.
      <br/>
      Moreover, when image data is manipulated, unlike when analog image data is manipulated, deterioration of image quality can be avoided nearly completely.
    </p>
    <p num="101">
      Furthermore, when the motion picture-specific expansion unit 10 is connected to the CCU 6 for use, motion picture data can be recorded on a DVD or the like with little deterioration of image quality.
      <br/>
      Moreover, the motion picture data recorded on the DVD may be input to the personal computer 14 and edited or manipulated.
      <br/>
      In this case, since the data is digital image data, unlike when analog image data is handled, editing will hardly deteriorate image quality.
    </p>
    <p num="102">
      According to this embodiment, unlike a prior art device according to which motion picture data is recorded on an analog basis, the motion picture data is recorded digitally.
      <br/>
      The motion picture data can therefore be recorded with little deterioration of image quality.
      <br/>
      Even editing will hardly deteriorate image quality.
    </p>
    <p num="103">
      Moreover, when the personal computer 14 or the like is employed, editing or manipulation of still image data or motion picture data can be achieved readily.
      <br/>
      Unlike when photographs are handled, recorded data of a still image can be reproduced shortly.
    </p>
    <p num="104">
      When the circuitry shown in FIG. 4B is adopted for the JPEG compression circuit 54, a level of compressibility is, as mentioned above, lowered.
      <br/>
      However, decompression results in perfect restoration into an image whose data has not been compressed.
    </p>
    <p num="105">
      According to the first embodiment, the release switch 48 is included in the CCU 6.
      <br/>
      Alternatively, the release switch 48 may be included in an endoscope or, for example, the TV camera 3.
      <br/>
      In another example, foot switch may be spliced to a cord extending from the CCU 6, whereupon a release signal may be generated by handling the foot switch to help an operator carry out releasing.
    </p>
    <p num="106">
      According to the first embodiment, the TV camera-mounted endoscope 4 is adopted as an endoscope including an imaging means.
      <br/>
      A simultaneous electronic endoscope in which a CCD 32 having a mosaic filter 32a or the like is located at the image formation position of the objective lens 27 in the rigid endoscope 2 shown in FIG. 2 may be substituted for the TV camera-mounted endoscope 4.
    </p>
    <p num="107">
      Incidentally, according to the first embodiment, the MPEG compression circuit 69 is used to compress motion picture data.
      <br/>
      The present invention is not limited to the MPEG compression circuit.
      <br/>
      For example, DV-format compression where intra-frame compression based on DCT is carried out (almost the same as the JPEG compression based on DCT.
      <br/>
      However, the length of data of each frame is not variable but fixed so that the data can be readily recorded on a tape-like recording medium) may be adopted.
      <br/>
      A DV terminal conformable to, for example, the IEEE 1394 may be used as the digital output terminal 17.
    </p>
    <p num="108">
      FIG. 9A shows a configuration of the CCU 6 and other apparatuses in accordance with a variant of the present invention.
      <br/>
      According to this variant, two frame memories 45A and 45B are substituted for the frame memory 45 in the CCU 6 shown in FIG. 2.
      <br/>
      Moreover, a still-image digital video output terminal 8A coupled to an output terminal of the frame memory 45A and a motion-picture digital video output terminal 8B coupled to an output terminal of the frame memory 45B are substituted for the digital video output terminal 8 coupled to the output terminal of the frame memory 45.
      <br/>
      Thus, the still image-specific expansion unit 9 and motion picture-specific expansion unit 10 can be connected simultaneously.
    </p>
    <p num="109">Moreover, the CPU 49 is designed to be able to communicate bi-directionally with CPUs 9a and 10a in the still image-specific expansion unit 9 and motion picture-specific expansion unit 10 over communication lines 51A and 51B.</p>
    <p num="110">
      According to this embodiment, the CCU 6 is provided with a hard disk 40 connected to the CPU 49.
      <br/>
      The CPU 49 receives image data, which has been compressed and stored on the PC card 12, from the CPU 9a in the still image-specific expansion unit 9 over the communication line 51A.
      <br/>
      The CPU 49 then stores the image data on the hard disk 40.
    </p>
    <p num="111">
      Moreover, according to this embodiment, a still image release switch 48a-1 or 48a-2 and a motion picture-specific release switch 48b are included.
      <br/>
      By handling the still image release switch 48a-1, the release signal instructing storage of image data, which has been compressed according to the lossy coding by means of the circuitry shown in FIG. 4A, on the PC card 12 is generated.
      <br/>
      By handling the still image release switch 48a-2, the release signal instructing storage of image data, which has been compressed according to the lossless coding by means of the circuitry shown in FIG. 4B, on the PC card 12 is generated.
    </p>
    <p num="112">In short, for recording a still image, an operator can select either of the circuitry shown in FIG. 4A and that shown in FIG. 4B for compression.</p>
    <p num="113">
      The other components are identical to those shown in FIG. 2.
      <br/>
      The major operation performed by this variant will be described below.
    </p>
    <p num="114">
      When an endoscopic examination is conducted in a connected state shown in FIG. 9A, image data of the same frame of a motion picture is usually stored in the two frame memories 45A and 45B.
      <br/>
      In this state, when an operator handles the still image release switch 48a-1, the release signal instructing storage of image data which has been compressed according to the lossy coding on the PC card 12 is output.
      <br/>
      The CPU 49 brings the frame memory 45A alone to a write-inhibited state and establishes a state in which still image data is recorded in the frame memory 45A.
      <br/>
      The CPU 49 then sends the release signal to the CPU 9a in the still image-specific expansion unit 9 over the communication line 51A.
    </p>
    <p num="115">
      Image data of a still image recorded in the frame memory 45A is compressed according to the lossy coding and stored on the PC card 12.
      <br/>
      When the storage operation is completed, the CPU 9a sends a completion signal to the CPU 49 over the communication line 51A.
      <br/>
      The CPU 49 releases the still image-preserved state of the frame memory 45.
      <br/>
      Specifically, write-inhibition is released, and the frame memory 45A is reset to a state in which motion picture data is recorded.
      <br/>
      Moreover, the CPU 49 displays a message saying that one frame has been recorded on the display LED 47.
    </p>
    <p num="116">
      Moreover, according to this embodiment, the CPU 49 instructs the CPU 9a to transfer image data, which has been compressed and recorded on the PC card 12, over the communication line 51A.
      <br/>
      The CPU 9a transfers the image data, which has been compressed and recorded on the PC card 12, to the CPU 49 over the communication line 51A at a given transfer rate according to the serial data transmission.
    </p>
    <p num="117">
      The CPU 49 transfers the transferred image data to the hard disk 40.
      <br/>
      Upon completion of transfer of image data of one frame, the CPU 9a sends a completion signal to terminate image data transfer.
    </p>
    <p num="118">
      In this embodiment, image data recorded on the PC card 12 is recorded as a backup copy on the hard disk 40 in the CCU 6.
      <br/>
      Supposing the storage capacity of the PC card 12 is exceeded by recording image data, no data would be lost.
    </p>
    <p num="119">
      The other operations are nearly identical to those of the first embodiment.
      <br/>
      The description of those operations will thus be omitted.
    </p>
    <p num="120">
      Incidentally, when still image data is recorded by releasing the still image-preserved state, the still image-specific expansion unit 9 may calculate an amount of compressed image data, of the still image and send the information to the CPU 49 over the communication line 51A.
      <br/>
      The CPU 49 may display on the display LED 47 the number of frames as well as an amount of frame data recorded (an amount of used data) or an amount of recordable capacity remaining on the PC card 12.
    </p>
    <p num="121">
      Information such as the number of recorded frames is displayed on the display LED 47 of the CCU 6.
      <br/>
      The information may also be displayed on the display surface of the color monitor 7 viewed by an operator.
      <br/>
      In this case, a superimposition circuit is installed in the output side of the post-processing circuit 44 to which an output of the font generator 52 is sent.
      <br/>
      Information such as the number of frames is superimposed on data represented by a video signal output from the post-processing circuit 44.
    </p>
    <p num="122">Next, a second embodiment of the present invention will be described with reference to FIG. 9B. An endoscopic imaging system 101 of this embodiment shown in FIG. 9B comprises an electronic endoscope 102 of a surface sequential imaging type, a light source unit 103 of the surface sequential type for supplying illumination light to a light guide 119 in the electronic endoscope 102, a CCU 104 of the surface sequential type for processing a signal sent from a solid-state imaging device (118) incorporated in the electronic endoscope 102, a color monitor 105, and an expansion unit 107 coupled to a digital video output terminal 106 of the CCU 104.</p>
    <p num="123">
      The electronic endoscope 102 has an elongated insertion unit 111.
      <br/>
      A large-diameter operation unit 112 is formed at the back end of the insertion unit 111.
      <br/>
      A universal cord 113 and light guide cord 114 are extending laterally from the operation unit 112.
      <br/>
      A connector 115 capable to being coupled to the CCU 104 is spliced to the proximal end of the universal cord 113.
    </p>
    <p num="124">
      A rigid distal part 116 and a bending portion capable of being angled and formed adjacently behind the distal part 116 together form the distal portion of the insertion unit 111.
      <br/>
      The operation unit 112 is provided with an angling knob that is not shown.
      <br/>
      By turning the angling knob, the bending portion can be angled in vertical and lateral directions.
    </p>
    <p num="125">
      Moreover, an objective lens 117 and SID 118 are incorporated in the distal part 116.
      <br/>
      A light guide 119 over which illumination light is propagated lies through the insertion unit 111.
    </p>
    <p num="126">
      The light source unit 103 to which a connector spliced to one end of the light guide cord 114 is coupled has a white light source 121 such as a xenon lamp.
      <br/>
      White light emitted from the white light source 121 is converged by a lens 122.
      <br/>
      The white light is then recomposed into sequential light rays of red, green, and blue by a rotary filter 123 that rotates at a speed agreeing with the frame frequency of a video signal (29.97 Hz in the NTSC system).
      <br/>
      The light rays are irradiated to an object 124 such as an intracorporeal organ to be observed by way of the light guide 119 and a light distribution lens 120 opposed to the distal end of the light guide 119.
    </p>
    <p num="127">Rotation of a motor 125 for rotating the rotary filter 123 is controlled by a motor servo circuit 126 so that the rotating speed will agree with the frame frequency of a video signal.</p>
    <p num="128">
      Light reflected from the object 124 passes through the objective lens 117 and forms an image on the image plane of the SID 118.
      <br/>
      With application of a clock signal for use in reading by a driver 127, the optical image is photoelectrically converted.
      <br/>
      Surface sequential signals R, G, and B are then output.
    </p>
    <p num="129">
      An SID driving signal sent from an SID timing signal generator 129, to which a reference clock generated by a synchronizing (hereinafter sync) signal generator 128 is input, is input to the driver 127 via an isolation photocoupler 130.
      <br/>
      A reference signal (not shown) is supplied from the sync signal generator 128 to the motor servo circuit 126.
      <br/>
      Thus, all signals (operations) are phased and synchronized with one another.
    </p>
    <p num="130">
      The surface sequential signals R, G, and B output from the SID 118 are amplified by a preamplifier 131 in the CCU 104.
      <br/>
      Resultant signals are input to a reset noise canceling circuit 134 via an isolation drive circuit 132 and an isolation high-frequency transformer 133 for protecting a patient from an electric shock or the like.
      <br/>
      Unnecessary components are removed from the surface sequential signals by means of a low-pass filter (LPF) 135. Resultant signals are then subjected to vertical contour correction by a vertical contour correction circuit 136 and to gamma correction by a gamma correction circuit 137.
    </p>
    <p num="131">
      Output signals of the gamma correction circuit 137 are converted into digital signals by an A/D converter 138.
      <br/>
      Signals read under the red, green, and blue rays of illumination light and constituting one frame are stored in a red (R) memory 139R, green (G) memory 139G, and blue (B) memory 139B which are associated with the light rays used for surface-sequential imaging.
    </p>
    <p num="132">
      The signals stored in the red memory 139R, green memory 139G, and blue memory 139B are read simultaneously to be timed color signals.
      <br/>
      The color signals are converted into analog signals by D/A converters 140.
      <br/>
      A conversion rate at which the A/D converter 138 converts an analog signal into a digital signal, and writing and reading of data into or from the red memory 139R, green memory 139G, and blue memory 139B are controlled with an output signal of a memory control circuit 141.
    </p>
    <p num="133">
      The analog color signals R, G, and B output from the D/A converters 140 have unnecessary components thereof removed by LPFs 142.
      <br/>
      Resultant signals are input to horizontal contour correction circuits 143.
      <br/>
      After subjected to horizontal contour correction, the signals are amplified by output amplifiers 144.
      <br/>
      Resultant signals are output as three elementary color signals R, G, and B, of which output impedance is, for example, 75 OMEGA , to a monitor 105 or the like through the red, green, and blue output terminals.
      <br/>
      Moreover, a sync signal generated by the sync signal generator 128 is also amplified by an output amplifier 145, and output as a sync signal SYNC, of which output impedance is, for example, 75 OMEGA , to the monitor 105 or the like through a sync output terminal.
    </p>
    <p num="134">
      Moreover, the signals R, G, and B that have been timed and subjected to horizontal contour correction are used to produce a luminance signal Y by means of a Y matrix circuit 146.
      <br/>
      The luminance signal Y and color signal R are used to produce a chrominance signal R-Y by means of an R-Y matrix circuit 147.
      <br/>
      The luminance signal Y and color signal B are used to produce a chrominance signal B-Y by means of a B-Y matrix circuit 148.
    </p>
    <p num="135">
      The chrominance signals R-Y and B-Y are subjected to balanced modulation, where subcarriers (having a frequency of 3.1129545 MHz and being 90 (degree)  out of phase) are employed, by means of encoders 149 and 150.
      <br/>
      Resultant signals are synthesized into vector by an adder 151.
      <br/>
      This results in a chrominance signal C. The chrominance signal C is multiplexed with the luminance signal Y by a synthetic output amplifier 152.
      <br/>
      Furthermore, a composite sync signal and color burst are appended to the multiplexed signal.
      <br/>
      Consequently, a composite video signal that is an NTSC signal is produced and output to the monitor through an NTSC output pin of a connector 153.
    </p>
    <p num="136">
      By the way, a patient circuit unit 154 composed of the driver 127, preamplifier 131, and isolation drive circuit 132 in the CCU 104 is shielded by a shield case 155.
      <br/>
      A signal input/output unit 156 on the succeeding side of the patient circuit unit, which is isolated by the photocoupler 130 and high-frequency transformer 133 which serve as an isolation means, is also shielded with a shield case 157 separately from the shield case 155.
    </p>
    <p num="137">
      Moreover, outputs of the red memory 139R, green memory 139G, and blue memory 139B are output to an expansion unit 107 through a digital video output terminal 106.
      <br/>
      A CPU, which is not shown, in the expansion unit 107 is connected to the CPU 155 in the CCU 104 over a bi-directional communication line 156.
    </p>
    <p num="138">Either a still image-specific expansion unit or a motion picture-specific expansion unit can be connected as the expansion unit 107 as described in the first embodiment.</p>
    <p num="139">
      Moreover, for example, a front panel 157 of the CCU 104 is provided with a release switch 158.
      <br/>
      When the release switch 158 is turned on, the CPU 155 sends a release signal to the expansion unit 107 over the communication line 156.
      <br/>
      The expansion unit 107 carries out an image recording operation.
    </p>
    <p num="140">
      In this case, when the expansion unit 107 is a still image-specific expansion unit, still image data of one frame is stored on a PC card loaded into the still image-specific expansion unit.
      <br/>
      By contrast, when the expansion unit 107 is a motion picture-specific expansion unit, motion picture data is compressed and output to peripheral equipment such as a DVD coupled to the digital output terminal of the motion picture-specific expansion unit through the digital output terminal.
      <br/>
      A release signal is also output to the peripheral equipment.
    </p>
    <p num="141">Incidentally, the CCU 104 shown in FIG. 9B may be provided with the display LED 47 shown in FIG. 2.</p>
    <p num="142">
      The first embodiment adopts the simultaneous imaging type imaging system (comprising, particularly, the light source apparatus 5 for outputting white light, the simultaneous imaging type TV camera-mounted endoscope 4, and the CCU 6 serving as a simultaneous imaging type signal processing means).
      <br/>
      By contrast, this embodiment adopts the surface sequential imaging type imaging system (comprising the light source unit 103 for outputting surface-sequential light, the surface sequential imaging type electronic endoscope 102, and the CCU 104 serving as a signal processing means for processing a signal sent from the surface sequential imaging type imaging means).
    </p>
    <p num="143">Consequently, the operations and advantages other than those of a portion for illuminating and visualizing an object surface-sequentially and a portion for processing a signal are identical those of the first embodiment.</p>
    <p num="144">Next, a third embodiment of the present invention will be described with reference to FIGS. 10 and 11.</p>
    <p num="145">
      An endoscopic imaging system 201 of the third embodiment shown in FIG. 10 has the same fundamental configuration as the first embodiment shown in FIG. 1.
      <br/>
      The endoscopic imaging system 201 comprises a TV camera-mounted endoscope 4 having a TV camera 3 mounted on a rigid endoscope 2, a light source apparatus 5 for supplying illumination light to the rigid endoscope 2, a CCU 6 for processing a signal sent from an imaging means in the TV camera 3, a color monitor 7 for displaying an image represented by a video signal output from the CCU 6, a still image-specific expansion unit 9 and motion picture-specific expansion unit 10 which are attachable to a digital video output terminal 8 (not shown in FIG. 10) of the CCU 6 so that they can be uncoupled freely, and a personal computer, which is not shown, having a PC card slot into which a PC card 12 is designed to be loaded into a PC card slot 11 of the still image-specific expansion unit 9 so that it can be unloaded freely.
    </p>
    <p num="146">
      In this embodiment, the TV camera 3 is provided with a release switch 205.
      <br/>
      When the release switch 205 is turned on, a release instruction signal is input to the CPU 49 (See FIG. 2) in the CCU 6 over a camera cable 33.
      <br/>
      According to this embodiment, in addition to a release switch 48 of the CCU 6, the release switch 205 is included in the endoscope 4.
    </p>
    <p num="147">Moreover, in this embodiment, a connector 202A spliced to an end of a still image-specific expansion unit cable 202, which has the other end thereof spliced to the still image-specific expansion unit 9, is coupled to the digital video output terminal 8 of the CCU 6 in a manner in which the connector 202A can be freely uncoupled therefrom.</p>
    <p num="148">Moreover, a connector 203A spliced to an end of a motion picture-specific expansion unit cable 203, which has the other end thereof spliced to the motion picture-specific expansion unit 10, can be coupled to the digital video output terminal 8 of the CCU 6 in a manner in which the connector 203A can be freely uncoupled therefrom.</p>
    <p num="149">
      Moreover, in this embodiment, the CCU 6 can transfer digital data to or from the expansion unit 9 or 10 by parallel data transmission.
      <br/>
      The connector 202A serving as an interface for interfacing the CCU 6 with the still image-specific expansion unit 9 over the still image-specific expansion unit cable 202 has a structure shown in FIG. 11.
    </p>
    <p num="150">
      The cable 202 is, for example, a flat cable.
      <br/>
      The card edge type connector 202A is spliced to the end of the cable 202.
      <br/>
      Signal pins 211, 212, and 213 formed by plating an insulating substrate 210 with copper in the form of bands are exposed from the distal end of the connector 202A having the proximal end thereof spliced to the flat cable.
      <br/>
      In this embodiment, these signal pins 211, 212, and 213 are jutting out by different lengths according to the type of a signal applied to associated signal pins (specifically, data, power, or ground-level voltage).
    </p>
    <p num="151">
      In FIG. 11, all the signal pins 211, 212, and 213 are exposed.
      <br/>
      This is intended to clearly show the connector 202A.
      <br/>
      In reality, the signal pins are covered to prevent being touched directly with a finger or the like.
    </p>
    <p num="152">
      As shown in FIG. 11, the lengths of the signal pins 211, 212, and 213 formed on the upper side or lower side of the insulating substrate 210 are determined so that the length P1 of the ground pins 211 will be longer than the length P2 of the power pins 212, and the length P2 will be longer than the length P3 of the data pins 213.
      <br/>
      Two pieces of equipment (specifically, the CCU 6 and static image-specific expansion unit 9) are linked through the ground pins 211, power pins 212, and data pins 213 in that order.
      <br/>
      This results in improved safety.
    </p>
    <p num="153">In FIG. 11, when the CCU 6 and expansion unit 9 are linked, power is supplied from the CCU 6 to the expansion unit 9 via the power pins 212.</p>
    <p num="154">
      For the structure of the connector, a power cable extending from the CCU 6 is shown in FIG. 10. The plug at an end of the power cable is fitted into an electrical outlet such as a wall socket.
      <br/>
      Thus, electrical power is supplied to the CCU 6.
      <br/>
      The CCU 6 allows an internal power circuit that is not shown to generate direct current (DC) necessary for operating circuits.
    </p>
    <p num="155">
      By contrast, an electrical connection cable may be extended from the expansion unit 9.
      <br/>
      The expansion unit 9 may be provided with a facility for allowing an internal power circuit to supply electrical power to the internal circuits thereof.
      <br/>
      In this case, the power pins 212 shown in FIG. 11 may be excluded.
    </p>
    <p num="156">
      In this case, linkage is established through the ground pins 211 and then through the data pins 213.
      <br/>
      The connector 203 of the motion picture-specific expansion unit 10 has the same structure of signal pins.
      <br/>
      Specifically, the length of the ground pins is longer than that of the power pins, and the length of the power pins is larger than that of the data pins.
      <br/>
      Similarly, the power pins may be omitted when the expansion unit 10 is provided with an internal power supply facility.
    </p>
    <p num="157">
      Moreover, this embodiment has been described with reference to the card edge type connector 202A as an example.
      <br/>
      All parallel data transfer modes conceivable with the employment of the connector may be used in accordance with the present invention.
    </p>
    <p num="158">
      According to this embodiment, for transmitting digital data in the parallel transmission mode, owing to the aforesaid structure, linkage can be established through the ground pins 211, power pins 212, and data pins 213 in that order, or through the ground pins 211 and data pins 213 in that order.
      <br/>
      The safety of peripheral equipment of an endoscope to be linked mutually will improve.
      <br/>
      Eventually, the probability of failure or breakage of equipment can be minimized.
    </p>
    <p num="159">
      In FIG. 10, one end of each of the still image-specific expansion unit cable 202 and motion picture-specific expansion unit cable 203 are spliced to the still image-specific expansion unit 9 and motion picture-specific expansion unit 10, respectively, without intervention of a connector.
      <br/>
      The present invention is not limited to this form.
      <br/>
      A form in which the still image-specific expansion unit cable and motion picture-specific expansion unit cable are spliced to the still image-specific expansion unit 9 and motion picture-specific expansion unit 10 with connectors between them is also consistent with the concept of the present invention.
      <br/>
      In this case, when the connectors are structured as shown in FIG. 11, the aforesaid operations and advantages can be exerted.
    </p>
    <p num="160">
      Next, a fourth embodiment of the present invention will be described with reference to FIG. 12. In the third embodiment, the cables 202 and 203 are designed to transfer digital data in the parallel transfer mode.
      <br/>
      In this embodiment, the CCU 6 is provided with a digital data output terminal through which digital data is transferred in the serial transfer mode.
      <br/>
      Digital data is transferred to or from an expansion unit over a cable 221 having a connector 221A thereof coupled to the digital data output terminal.
    </p>
    <p num="161">
      As shown in FIG. 12, the connector 221A at one end of the cable 221 is coupled to the digital data output terminal of the CCU 6 in a manner in which it can be uncoupled freely therefrom.
      <br/>
      A connector 221B at the other end of the cable 221 is coupled to an expansion unit.
      <br/>
      Alternatively, the cable 221 may extend directly from the expansion unit rather than being spliced to the other end of the cable.
    </p>
    <p num="162">In this embodiment, like the third embodiment, the lengths of the signal pins are differentiated depending on the type of a signal to be transmitted through a signal pin.</p>
    <p num="163">
      Specifically, the lengths of a ground pin 231, power pin 232, and data pin 233 are determined so that the length P4 of the ground pin 231 will be longer than the length P5 of the power pin 232, and the length P5 will be longer than the length P6 of the data pin 233.
      <br/>
      Consequently, linkage between the CCU 6 and the expansion unit is established through the ground pin 231, power pin 232, and data pin 233 in that order.
    </p>
    <p num="164">
      When the cable 221 has the foregoing structure, a connector cover 234 is, as shown in FIG. 12, used to protect the signal pins.
      <br/>
      In this case, the length P of the connector cover 234 is designed to be a little smaller than the length P4 of the ground pin 231.
      <br/>
      Owing to this design, for example, even if the cable 221 is handled with an electrically charged finger 235, the finger will touch the ground pin 231.
      <br/>
      Therefore, even if the end of the cable 221 is coupled to equipment, static electricity existent at the finger flows out to the ground.
      <br/>
      Thus, the equipment can be used more safely.
    </p>
    <p num="165">
      Moreover, in FIG. 12, the expansion unit is designed to receive power supplied from the CCU 6.
      <br/>
      A power cable is therefore incorporated as a conductor in the cable 221 linking the CCU 6 and expansion unit.
      <br/>
      If the expansion unit itself has a facility for receiving power externally, the power cable may be excluded from the dedicated cable.
    </p>
    <p num="166">
      For transmitting digital data in the serial transmission mode, owing to the aforesaid structure, linkage of equipment can be established through the ground pin 231, power pin 232, and data pin 233 in that order.
      <br/>
      The safety of equipment therefore improves.
      <br/>
      Eventually, the probability of failure and breakage of equipment can be minimized.
    </p>
    <p num="167">
      The form shown in FIG. 12 may be adapted to a structure including a control signal line over which a control signal is transmitted by parallel transmission in addition to the data lines.
      <br/>
      In this case, a control signal may be sent bi-directionally.
      <br/>
      For this purpose, two control signal lines may be included.
    </p>
    <p num="168">Next, a fifth embodiment of the present invention will be described with reference to FIG. 13. A fundamental configuration of this embodiment is identical to the one of the third embodiment shown in FIG. 10. Like the third embodiment, in this embodiment, the parallel transfer mode is adopted.</p>
    <p num="169">FIGS. 13A and 13B show a card bus 241 serving as a card edge type interface terminal (connector) as a simple example of this aspect of the present invention.</p>
    <p num="170">Unlike the aforesaid third and fourth embodiments, in this embodiment, the edge of the PC card 12 is coupled to the card bus 241 in the PC card slot 11 of the still image-specific expansion unit 9 shown in FIG. 10 so that the edge can be uncoupled freely.</p>
    <p num="171">
      The card bus 241 has two rows of 34 finely projected pins.
      <br/>
      The lengths of the pins of the card bus 241 are determined depending on a signal associated with each pin in such a manner that the length P7 of a ground pin 251 is longer than the length P8 of power pins 252 and the length P8 is longer than the length P9 of data pins 253.
      <br/>
      The lengths of the signal pins are thus different from one another.
      <br/>
      When the PC card 12 is inserted into the expansion unit 9, linkage is established through the ground pin 251, power pins 252, and data pins 253 in that order.
      <br/>
      Consequently, electrical breakdown occurring by coupling the PC card 12 can be prevented.
      <br/>
      This leads to improved reliability.
    </p>
    <p num="172">When digital data is recorded on the PC card 12 or the like, the foregoing structure helps reduce failure and breakage of equipment and improve reliability.</p>
    <p num="173">
      FIG. 5 shows briefly the configuration of an MPEG1 (ISO 11172 Video)-conformable compression circuit 69.
      <br/>
      A motion picture-specific expansion unit including an MPEG2-conformable compression circuit may be connected to record a motion picture.
    </p>
    <p num="174">
      For example, in the first embodiment, the still image-specific expansion unit 9 has one PC card slot 11.
      <br/>
      Alternatively, the still image-specific expansion unit 9 may be provided with two or more PC card slots 11.
    </p>
    <p num="175">Moreover, the still image-specific expansion unit 9 may be designed so that not only the PC card 12 can be coupled to (mounted in) the PC card slot 11 but also a recording medium (or memory) on which still image data is recorded can be coupled in a freely detachable manner or incorporated in the expansion unit 9.</p>
    <p num="176">
      Assume that the still image-specific expansion unit 9 is designed as mentioned above.
      <br/>
      In this case, when the storage capacity of the PC card 12 coupled to the PC card slot 11 is exceeded by recording still image data, excessive data may be recorded on the recording medium (or memory).
      <br/>
      Alternatively, when the storage capacity of the PC card 12 coupled to the PC card slot 11 is exceeded by recording still image data, a message saying that the PC card should be replaced with a new one may be displayed on the display LED 47 or on the color monitor 7.
      <br/>
      Moreover, when an amount of recorded data approaches the storage capacity of the PC card 12, a message saying that the PC card should be replaced with a new one because an amount of recorded data is close to the storage capacity of the PC card 12 may be displayed.
    </p>
    <p num="177">
      Moreover, the CCU 6 may be provided with a digital video output terminal through which a still-image digital video signal is output, and a digital video input terminal through which a still-image digital video signal whose data has been compressed and output from the still image-specific expansion unit 9 input.
      <br/>
      In this case, a recording medium on which the compressed still image data is recorded may be able to be coupled to the CCU 6 in a freely detachable manner, or may be incorporated therein.
    </p>
    <p num="178">Additionally, an amount of still image data exceeding the storage capacity of the PC card 12 loaded into the PC card slot may be able to be recorded by compressing the data.</p>
    <p num="179">
      Moreover, the CCU 6 may be provided with a modem or a communication means for handling serial data, which is connectable to the personal computer 14 or the like.
      <br/>
      Thus, image data recorded on a PC card coupled to the PC card slot of the CCU 6 may be able to be transferred to a large-capacity hard disk in the personal computer 14.
      <br/>
      Otherwise, image data recorded on the PC card 12 loaded into the PC card slot 11 of the expansion unit may be able to be transferred to the large-capacity hard disk in the personal computer 14.
    </p>
    <p num="180">
      For example, the endoscopic imaging system may be configured so that image data recorded on the PC card 12 loaded into the PC card slot 11 can be transferred to another recording means via a communication means even during an endoscopic examination.
      <br/>
      In this case, the transferred image data can be deleted from the PC card 12, and the PC card 12 can be used to record new image data The PC card 12 can therefore be used to record a large amount of image data irrespective of the storage capacity of the PC card 12.
    </p>
    <p num="181">
      In this case, when the communication means is used to transfer data, image data of one frame is temporarily buffered.
      <br/>
      Thereafter, the image data is transferred by the communication means designed for serial transmission.
      <br/>
      When it is instructed to record still image data even during data transfer, the still image data can be recorded immediately.
    </p>
    <p num="182">
      The present invention is not limited to the structure of the CCU 6 having the digital video input and output terminals through which the CCU and still image-specific expansion unit 9 are linked.
      <br/>
      Alternatively, the CCU 6 may be provided with a digital video output terminal through which a motion-picture digital video signal is output, and a digital video input terminal through which a motion-picture digital video signal whose data has been compressed and output from the motion picture-specific expansion unit 10 is input.
      <br/>
      The CCU 6 may then be structured so that a motion picture recording device such as a DVD can be coupled to the CCU 6 in a freely detachable manner.
    </p>
    <p num="183">
      As mentioned above, according to the first through fifth embodiments, endoscopic image data can be compressed and stored or recorded.
      <br/>
      Retrieval, editing, and manipulation of image data can therefore be achieved readily.
      <br/>
      Repeated manipulation will little deteriorate image quality.
      <br/>
      Moreover, an endoscopic imaging system can be realized on a small scale at low cost.
    </p>
    <p num="184">
      Next, a sixth embodiment of the present invention will be described.
      <br/>
      The sixth embodiment and thereafter provide endoscopic imaging systems having configurations in which endoscopic image data can be stored or recorded on an external storage device which has a simple structure.
    </p>
    <p num="185">
      As shown in FIG. 14, an endoscopic imaging system 301 of this embodiment comprises a TV camera-mounted endoscope 304 having a TV camera 303 mounted on a rigid endoscope 302, a light source apparatus 305 for supplying illumination light to the rigid endoscope 302, a camera control unit (CCU) 307 for processing a signal sent from a charge-coupled device (CCD) 306 that is a solid-state imaging device incorporated in the TV camera 303, a color monitor 308 for displaying an endoscopic image represented by a video signal output from the CCU 307, and a digital interface unit 309 to be coupled to the CCU 307 so that it can also be detachable therefrom.
      <br/>
      An external storage 310, for example, a PC card is coupled to the digital interface unit 309 so that it can be detached freely.
    </p>
    <p num="186">
      The rigid endoscope 302 includes an elongated insertion unit 321, a hand-held unit 322 formed at the back end of the insertion unit 321, and an eyepiece unit 323 formed at the back end of the hand-held unit 322.
      <br/>
      The hand-held unit 322 is provided with a light guide base 324, and connected to the light source apparatus 305 over a light guide cable 325.
    </p>
    <p num="187">
      Illumination light emanating from a lamp in the light source apparatus 305 is converged by a condenser and supplied to an incident end surface of a light guide lying through the light guide cable 325, though it is not illustrated.
      <br/>
      The illumination light propagates through the light guide in the rigid endoscope 302.
      <br/>
      The illumination light is then emitted forward through the distal end of the light guide which is fitted in an illumination window in the distal part of the insertion unit 321.
      <br/>
      An object such as a lesion is thus illuminated.
    </p>
    <p num="188">
      Moreover, an objective lens is fitted in an observation window adjacent to the illumination window in the distal part of the insertion unit 321.
      <br/>
      The objective lens forms an object image at the image formation position thereof.
      <br/>
      The formed image is transmitted by a system of relay lenses arranged in the insertion unit 321 and opposed to the objective lens.
      <br/>
      An image is re-formed near the eyepiece unit 323.
      <br/>
      The image is then re-formed on the CCD 306 by means of an eyepiece included in the eyepiece unit 323 and an image formation lens 326 in the TV camera 303 opposed to the eyepiece.
    </p>
    <p num="189">
      A mosaic filter that is not shown is located in front of the image plane (photoelectric conversion plane) of the CCD 306.
      <br/>
      Color components of light incident on each pixel are optically separated from one another by the mosaic filter.
      <br/>
      In other words, the imaging means of this embodiment is a simultaneous imaging means for producing a color image signal under illumination of white light.
    </p>
    <p num="190">
      The CCD 306 in the TV camera 303 is connected to the CCU 307.
      <br/>
      When a CCD driving signal is applied from a CCD driver 331 in the CCU 307 to the CCD 306, a CCD output signal (image signal) photoelectrically converted and output by the CCD 306 is input to an amplifier 332 in the CCU 7.
      <br/>
      The signal amplified by the preamplifier 332 is input to a pre-processing circuit 333.
    </p>
    <p num="191">
      The CCD output signal input to the pre-processing circuit 333 is pre-processed by performing correlation double sampling (CDS) and sample-and-hold (S/H), and then input to an A/D converter 334.
      <br/>
      After being converted into a digital signal, the CCD output signal is input to a digital signal processor (DSP) 335.
    </p>
    <p num="192">
      The DSP 335 recomposes the input digital signal into digital signals Y, Cr, and Cb of three channels according to a line-sequential imaging.
      <br/>
      The digital signals are separated from one another, and converted into a digital signal RGB according to the matrix algebra.
      <br/>
      The digital signal RGB converted according to the matrix algebra is adjusted in white balance and black balance, and then processed digitally by performing enhancement, gamma correction, and character convolution.
      <br/>
      A resultant signal is input to a D/A converter 336.
    </p>
    <p num="193">
      The digital signal input to the D/A converter 336 is converted into an analog signal, and then converted into a standard video signal by a post-processing circuit 337.
      <br/>
      A resultant signal is output to a color monitor 308.
    </p>
    <p num="194">
      Moreover, a digital video signal output from the DSP 335 is also output to a digital output circuit 339 under the control of the CPU 338.
      <br/>
      The digital video signal is output to the digital interface unit 309 via the digital output circuit 339.
    </p>
    <p num="195">
      Moreover, the CCU 307 is provided with a sync signal generator 340 that is controlled by the CPU 338.
      <br/>
      The CCD driver 331 drives the CCD 306 synchronously with a sync signal generated by the sync signal generator 340.
      <br/>
      The sync signal generated by the sync signal generator 340 is output to each of the pre-processing circuit 333, A/D converter 334, DSP 335, D/A converter 336, and digital output circuit 339.
      <br/>
      The CCD output signal (image signal) output from the CCD driver 331 is processed synchronously with the sync signal.
    </p>
    <p num="196">
      As shown in FIG. 15, the digital interface unit 309 inputs a digital video signal from digital output circuit 339 input from the DSP 335 via a digital input unit 341, and stores it in a memory 342.
      <br/>
      A digital video signal stored in the memory 342 is output to an external recording device 310 loaded into the digital interface unit 309 via a data output interface 343.
    </p>
    <p num="197">
      The read or write operation to be performed on a digital video signal in the memory 342 is controlled with a memory control signal generated by a memory control signal generator 344.
      <br/>
      Generation of the memory control signal by the memory control signal generator 344 is controlled by a control unit 345.
    </p>
    <p num="198">
      During a write operation, a vertical sync signal (V-SYNC), a horizontal sync signal (H-SYNC), a field signal (even/odd), a vertical blanking signal (V-BLNK), and a clock signal (CLK) and horizontal blanking signal (H-BLNK) which are illustrated in FIG. 16 in enlargement relative to one pulse of the horizontal sync signal, are input to the memory control signal generator 344.
      <br/>
      These signals are, as shown in FIG. 16, input together with a digital video signal (Data) sent from the DSP 335 via digital output circuit 339.
      <br/>
      The clock signal (CLK) is also input to the control unit 345.
    </p>
    <p num="199">
      The control unit 345 controls the memory control signal generator 344 synchronously with the clock signal (CLK) in response to an ON signal sent from a switch 346 included in the digital interface unit 309.
      <br/>
      This causes the memory control signal generator 344 to output a memory control signal that is a write signal to the memory 342.
      <br/>
      Consequently, the digital video signal is stored in the memory 342.
    </p>
    <p num="200">
      During a read operation, an address signal and control signal sent from the external recording device 310 are input to an address input interface 347 and a control signal interface 348.
      <br/>
      The address signal and control signal sent from the address input interface 347 and control signal interface 348 are input to the memory control signal generator 344.
      <br/>
      The control signal sent from the control signal interface 348 is also input to the control unit 345.
    </p>
    <p num="201">
      The control unit 345 controls the memory control signal generator 344 according to the control signal.
      <br/>
      This causes the memory control signal generator 344 to output a memory control signal that is a read signal to the memory 342.
      <br/>
      Consequently, a digital video signal is read from the memory 342, and output to the external recording device 310 via the data output interface 343.
    </p>
    <p num="202">
      Incidentally, a signal sent from the switch 346 is input to the control unit 345.
      <br/>
      With the input, generation of a write signal is controlled.
      <br/>
      Alternatively, generation of a write signal may be controlled responsively to a control signal sent from the CPU 338 in the CCU 307.
    </p>
    <p num="203">
      Moreover, the clock signal (CLK) is input into the digital interface unit 309 together with the digital video signal (Data) sent from the DSP 335 via the digital output circuit 339.
      <br/>
      Alternatively, as shown in FIG. 17, a PLL 351 may extract the clock signal (CLK) from the horizontal sync signal (H-SYNC).
      <br/>
      Next, the operations of the endoscopic imaging system 301 of this embodiment having the foregoing components will be described.
    </p>
    <p num="204">
      For example, when the abdomen is operated on under endoscopic observation, the TV camera 303 is mounted on the rigid endoscope 302, and connected to the light source apparatus 305 and CCU 307.
      <br/>
      The color monitor 308 is connected to the CCU 307.
      <br/>
      Moreover, the digital interface unit 309 is connected to the CCU 307, and the external recording device 310 is connected to the digital interface unit 309.
    </p>
    <p num="205">
      The insertion unit 321 of the rigid endoscope 302 is thrust into the patient's abdomen by piercing the abdominal wall with a trocar and cannula, so that a lesion in or on, for example, an organ in the abdomen can be observed.
      <br/>
      An (endoscopic) image is then displayed on the color monitor 308.
      <br/>
      An operator views the image.
      <br/>
      When an image the operator wants to record is displayed on the color monitor 308, the operator handles the switch 346 to record the image data in the memory 342 in the digital interface unit 309.
      <br/>
      By handling a hand release switch or foot switch that is not shown, the operator can record endoscopic image data on the external recording device 310 such as a PC card.
      <br/>
      Moreover, the operator can utilize the recorded image data at a personal computer in the future.
    </p>
    <p num="206">
      Incidentally, handling of the switch 346 may be interlocked with handling of the hand release switch or foot switch.
      <br/>
      Alternatively, one switch may be used exclusively.
      <br/>
      In this case, a switch signal is controlled by the CPU 338 and control unit 345, so that image data will be recorded on the external recording device 310 such as a PC card after it is confirmed that the image data has been written in the memory 342 in the digital interface unit 309.
    </p>
    <p num="207">
      A digital video signal sent from the DSP 335 is output to the digital output circuit 339 under the control of the CPU 338.
      <br/>
      The digital video signal is thus output to the digital interface unit 309 via the digital output circuit 339.
    </p>
    <p num="208">
      During a write operation, a vertical sync signal (V-SYNC), a horizontal sync signal (H-SYNC), a field signal (even/odd), a vertical blanking signal (V-BLNK), and a clock signal (CLK) and horizontal blanking signal (H-BLNK) which are illustrated in enlargement relative to one pulse of the horizontal sync signal are input to the memory control signal generator 344 in the digital interface unit 309.
      <br/>
      The clock signal (CLK) is also input to the control unit 345.
      <br/>
      The control signal 345 controls the memory control signal generator 344 synchronously with the clock signal (CLK) in response to the clock signal (CLK) and an ON signal sent from the switch 346 included in the digital interface unit 309.
      <br/>
      This causes the memory control signal generator 344 to output a memory control signal that is a write signal to the memory 342.
      <br/>
      The digital video signal is then stored in the memory 342.
    </p>
    <p num="209">
      During a read operation, an address signal and control signal sent from the external recording device 310 are input to the memory control generator 344.
      <br/>
      The control signal is input to the control unit 345.
      <br/>
      The control unit 345 controls the memory control signal generator 344 according to the control signal.
      <br/>
      This causes the memory control signal generator 344 to output a memory control signal that is a read signal to the memory 342.
      <br/>
      The digital video signal is then read from the memory 342, and output to the external recording device 310 via the data output interface 343.
    </p>
    <p num="210">
      Thus, the read and write operations to be performed on a digital video signal relative to the memory 342 are controlled with a memory control signal generated by the memory control signal generator 344 controlled by the control unit 345.
      <br/>
      This embodiment provides advantages described below.
    </p>
    <p num="211">
      As mentioned above, the endoscopic imaging system 301 of this embodiment has the memory 342, in which image data is stored, included in the digital interface unit 309.
      <br/>
      A digital video signal stored in the memory 342 can be read according to an address signal and control signal sent from the external recording device 310.
      <br/>
      This obviates the necessity of providing an image memory for the external recording device 310.
      <br/>
      Moreover, the digital video signal stored in the memory 342 can be read merely by designating an address.
      <br/>
      Thus, image data can be stored or recorded readily.
    </p>
    <p num="212">
      FIG. 18 shows a configuration of a digital interface unit in a seventh embodiment of the present invention.
      <br/>
      The seventh embodiment is nearly identical to the sixth embodiment.
      <br/>
      Only the difference will be described below.
      <br/>
      The same reference numerals will be assigned to the components which are the same as in the sixth embodiment.
      <br/>
      The description of those the components will therefore be omitted.
    </p>
    <p num="213">A digital interface unit 309a in this embodiment comprises, as shown in FIG. 18, a sync signal generator 361 for receiving as input a clock signal (CLK), horizontal sync signal, and vertical sync signal, which are input together with a digital video signal sent from the DSP 335, via digital output circuit 339 to generate a sync signal, and a TV signal generator 362 for receiving input the digital video signal that has been stored in the memory 342 and read according to an address signal and control signal sent from the external recording device 310, and generating a standard TV signal synchronously with a sync signal generated by the sync signal generator 361.</p>
    <p num="214">
      The other components are identical to those of the sixth embodiment.
      <br/>
      Next, the operations of this embodiment will be described.
    </p>
    <p num="215">
      In this embodiment, like the sixth embodiment, an address signal and control signal sent from the external recording device 310 are input to the address input interface 347 and control signal interface 348.
      <br/>
      The control signal sent from the control signal interface 348 is input to the control unit 345.
    </p>
    <p num="216">
      The control unit 345 controls the memory control signal generator 344 according to the control signal.
      <br/>
      This causes the memory control signal generator 344 to output a memory control signal that is a read signal to the memory 342 and read a digital video signal from the memory 342.
      <br/>
      The digital video signal is output to the external recording device 310 via the data output interface 343.
    </p>
    <p num="217">
      At this time, the sync signal generator 361 generates a sync signal using a clock signal (CLK), horizontal sync signal, and vertical sync signal which are input together with a digital video signal sent from the DSP 335.
      <br/>
      The TV signal generator 362 inputs the digital video signal that has been stored in the memory 342 and read according to an address signal and control signal sent from the memory control signal generator 344.
      <br/>
      The TV signal generator 362 then generates a standard TV signal according to the sync signal generated by the sync signal generator 361.
      <br/>
      An image whose data is output to the external recording device 310 is checked on the monitor that is not shown.
    </p>
    <p num="218">
      Except when data is recorded on the external recording device 310 (when no input signal is sent from the external recording device 310 to the control signal interface 348 and address input interface 347), data is read from the memory 342 according to the clock signal (CLK).
      <br/>
      When an input signal is sent, data is read according to signals sent from the control signal interface 348 and address input interface 347.
      <br/>
      The other operations are identical to those of the sixth embodiment.
      <br/>
      This embodiment provides advantages described below.
    </p>
    <p num="219">
      This embodiment can provide the same advantage as the sixth embodiment.
      <br/>
      Additionally, since image data represented by a digital video signal output to the external recording device 310 is output to the monitor by the TV signal generator 362, an image represented by the image data can be checked readily.
      <br/>
      After it is confirmed that the image is a desired image, the digital video signal can be recorded on the external recording device 310.
    </p>
    <p num="220">FIG. 19 shows a configuration of a digital interface unit in an eighth embodiment of the present invention.</p>
    <p num="221">
      The eighth embodiment is nearly identical to the sixth embodiment.
      <br/>
      Only the difference will be described below.
      <br/>
      The same reference numerals will be assigned to the same components.
      <br/>
      The description of those components will therefore be omitted.
    </p>
    <p num="222">
      In the sixth embodiment, a digital video signal stored in the memory 342 is read according to an address signal and control signal sent from the external recording device 310.
      <br/>
      In this embodiment, a digital interface unit 309b includes the external recording device 310 and an output interface 371 capable of carrying out serial data transmission according to the RS-232C in place of the address input interface 347, control signal interface 348, and data output interface 343.
      <br/>
      Incidentally, the output interface 371 may be an SCSI interface.
    </p>
    <p num="223">
      The other components are identical to those of the sixth embodiment.
      <br/>
      Next, the operations of the eight embodiment will be described.
    </p>
    <p num="224">
      In this embodiment, the control unit 345 communicates with the external recording device 310 via the output interface 371 during a read operation.
      <br/>
      The control unit 345 reads a digital video signal stored in the memory 342 in response to a command sent from the external recording device 310, and outputs the digital video signal to the external recording device 310 via the output interface 371.
      <br/>
      The other operations are identical to those of the sixth embodiment.
      <br/>
      This embodiment provides an advantage described below.
    </p>
    <p num="225">
      In this embodiment, as mentioned above, the control unit 345 communicates with the external recording device 310 via the output interface 371.
      <br/>
      A digital video signal stored in the memory 342 is read under the control of the control unit 345.
      <br/>
      Even when the external recording device 310 is slow at fetching data, a digital video signal stored in the memory 342 can be fetched reliably under the control of the control unit 345.
    </p>
    <p num="226">FIG. 20 shows a configuration of a digital interface unit in a ninth embodiment of the present invention.</p>
    <p num="227">
      The ninth embodiment is nearly identical to the eighth embodiment.
      <br/>
      Only the difference will be described.
      <br/>
      The same reference numerals will be assigned to the same components.
      <br/>
      The description of those components will thus be omitted.
    </p>
    <p num="228">According to this embodiment, as shown in FIG. 20, a digital interface unit 309c comprises a sync signal generator 381 for receiving a clock signal (CLK) that is input together with a digital video signal sent from the DSP 335, and for generating a sync signal, and a TV signal generator 382 for receiving a digital video signal that has been stored in the memory 342 and read according to an address signal and control signal sent from the external recording device 310, and for generating a standard TV signal synchronous with a sync signal generated by the sync signal generator 381.</p>
    <p num="229">
      The other components are identical to those of the sixth embodiment.
      <br/>
      Next, the operations of the ninth embodiment will be described.
    </p>
    <p num="230">
      In this embodiment, like the eighth embodiment, the control unit 345 communicates with the external recording device 310 via the output interface 371 during a read operation.
      <br/>
      The control unit 345 reads a digital video signal stored in the memory 342 in response to a command sent from the external recording device 310, and outputs the digital video signal to the external recording device 310 via the output interface 371.
    </p>
    <p num="231">
      At this time, the sync signal generator 381 receives a clock signal (CLK) that is input together with a digital video signal sent from the DSP 335, and generates a sync signal.
      <br/>
      The TV signal generator 382 receives a digital video signal that has been stored in the memory 342 and read according to an address signal and control signal sent from the memory control signal generator 344, and generates a standard TV signal synchronously with a sync signal generated by the sync signal generator 381.
      <br/>
      An image whose data is output to the external recording device 310 can be checked on a monitor that is not shown.
    </p>
    <p num="232">
      The other operations are identical to those of the sixth embodiment.
      <br/>
      This embodiment provides advantages described below.
    </p>
    <p num="233">
      This embodiment provides the same advantage as the eighth embodiment.
      <br/>
      Additionally, image data represented by a digital video signal to be output to the external recording device 310 is output to the monitor by the TV signal generator 382.
      <br/>
      An image represented by the image data can be checked readily.
      <br/>
      After it is confirmed that the image is a desired image, the digital video signal can be recorded on the external recording device 310.
    </p>
    <p num="234">FIG. 21 shows a configuration of a digital interface unit in a tenth embodiment of the present invention.</p>
    <p num="235">
      The tenth embodiment is nearly identical to the sixth embodiment.
      <br/>
      Only the difference will be described below.
      <br/>
      The same reference numerals will be assigned to the same components.
      <br/>
      The description of those components will thus be omitted.
    </p>
    <p num="236">According to this embodiment, as shown in FIG. 21, a digital interface unit 309d comprises a sync signal generator 391 for receiving a clock signal (CLK) that is input together with a digital video signal sent from the DSP 335 and generating a sync signal, for an image synthesizer 392 for receiving a digital video signal that has been stored in the memory 342 and read according to an address signal and control signal sent from the external recording device 310 and a current digital video signal input from the digital input unit 341, and for synthesizing the digital video signal stored in the memory 342 with the current digital video signal input from the digital input unit 341 so as to generate synthetic image data in a picture-in-picture form, and a TV signal generator 393 for receiving the synthetic image data generated by the image synthesizer 392 and generating a standard TV signal synchronously with the sync signal generated by the sync signal generator 391.</p>
    <p num="237">
      The other components are identical to those of the sixth embodiment.
      <br/>
      Next, the operations of the tenth embodiment will be described.
    </p>
    <p num="238">
      In this embodiment, like the sixth embodiment, an address signal and control signal sent from the external recording device 310 are input to the address input interface 347 and control signal interface 348 during a read operation.
      <br/>
      The address signal and control signal sent from the address input interface 347 and control signal interface 348 are input to the memory control signal generator 344.
      <br/>
      The control signal sent from the control signal interface 348 is also input to the control unit 345.
    </p>
    <p num="239">
      The control unit 345 controls the memory control signal generator 344 according to the control signal.
      <br/>
      This causes the memory control signal generator 344 to output a memory control signal that is a read signal to the memory 342.
      <br/>
      A digital video signal is read from the memory 342 and output to the external recording device 310 via the data output interface 343.
    </p>
    <p num="240">
      At this time, the sync signal generator 391 receives a clock signal (CLK) that is input together with a digital video signal sent from the DSP 335 and generates a sync signal.
      <br/>
      The image synthesizer 392 synthesizes a digital video signal stored in the memory 342 with a current digital video signal input from the digital input unit 341 so as to generate synthetic image data in a picture-in-picture form.
      <br/>
      The TV signal generator 393 receives the synthetic image data generated by the image synthesizer 392 and generates a standard TV signal synchronously with the sync signal generated by the sync signal generator 391.
      <br/>
      Consequently, the synthetic image having the image whose data is output to the external recording device 310 inlet in the picture-in-picture form can be checked on a monitor that is not shown.
    </p>
    <p num="241">The other operations are identical to those of the sixth embodiment.</p>
    <p num="242">
      As mentioned above, this embodiment provides the same advantage as the sixth embodiment.
      <br/>
      Additionally, synthetic image data having image data, which is represented by a digital video signal to be output to the external recording device 310, inlet in the picture-in-picture form can be output to a monitor by the TV signal generator 393.
      <br/>
      An image represented by the digital video signal to be output to the external recording device 310 can be checked readily.
      <br/>
      After it is confirmed that the image is a desired image, the digital video signal can be recorded on the external recording device 310.
    </p>
    <p num="243">
      The sixth to tenth embodiments have been described with reference to the TV camera-mounted endoscope 304 having the TV camera 303 mounted on the rigid endoscope 302 as an example.
      <br/>
      The present invention is not limited to this type of endoscope.
      <br/>
      A TV camera-mounted soft endoscope having the TV camera 303 mounted on a soft endoscope or an electronic endoscope having a CCD incorporated in the distal part of an insertion unit thereof may also be used in accordance with the present invention.
    </p>
    <p num="244">
      As described so far, according to the endoscopic imaging systems of the sixth to tenth embodiments, a storage means stores a digital signal, and a control means controls the storage means.
      <br/>
      This brings about the advantages that an external storage has a simple structure and that digital image data can be fetched readily.
    </p>
    <p num="245">Incidentally, further embodiments to be constructed by combining parts of the aforesaid embodiments will belong to the present invention.</p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>An endoscopic imaging system, comprising:</claim-text>
      <claim-text>an endoscope including an elongated insertion unit having a terminal portion. an illumination optical system located at the terminal portion of the elongated insertion unit for emitting illumination light, an objective optical system located at the terminal portion of said insertion unit for forming an optical image of an object illuminated with the illumination light, and an imaging device for photoelectrically converting the optical image either directly upon formation or after being transmitted through the insertion unit; a signal processing apparatus for driving said imaging device, processing an image signal output from said imaging device, generating a digital video signal and an analog video signal, and outputting the video signals through a digital video signal output terminal and analog video signal output terminal, respectively; a monitor for displaying an object image represented by the analog video signal in response to input of the analog video signal output through said analog video signal output terminal;</claim-text>
      <claim-text>and an expansion unit to be coupled to said digital video signal output terminal in a freely detachable manner, the expansion unit being provided with at least one of a compression unit for compressing data represented by the digital video signal and a PC card slot to which a PC card on which a digital video signal representing a still image whose data has been compressed by said compression unit is stored can be coupled in the freely detachable manner.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. An endoscopic imaging system according to claim 1, wherein said PC card is a small memory card selected from the group consisting of a smart medium, a compact flash memory card, A miniature card, a small PC card, an adapter card to be coupled to said PC card slot in a freely detachable manner with a small memory card freely detachably attached thereto, and a hard disk of type III.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. An endoscopic imaging system according to claim 1, wherein said digital video signal output terminal is used to provide an output signal conformable to the IEEE 1394 standard.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. An endoscopic imaging system according to claim 1, wherein said signal processing apparatus includes a communication line over which a control signal is transmitted to said expansion unit.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. An endoscopic imaging system according to claim 1, wherein said signal processing apparatus includes a display elements for displaying a number of still images that have been recorded using said expansion unit.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. An endoscopic imaging system according to claim 4, wherein said communication line has the ability to transmit information sent from said expansion unit, and the transmitted information is displayed during said signal processing.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. An endoscopic imaging system according to claim 1, wherein said endoscope is an electronic endoscope having said imaging device located at an image formation position of said objective optical system.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. An endoscopic imaging system according to claim 1, wherein said endoscope is an optical endoscope including an image transmitter for transmitting an optical image formed by said objective optical system, in which said imaging device is incorporated or mounted on said optical endoscope in a freely detachable manner.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. An endoscopic image system according to claim 1, wherein said signal processing apparatus includes a frame memory into which the digital video signal is written temporarily, such that when the digital video signal read from said frame memory, the digital video signal is output through said digital video signal output terminal.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. An endoscopic imaging system according to claim 1, wherein said expansion unit is a still image-specific expansion unit including said compression unit and said PC card slot.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. An endoscopic imaging system according to claim 1, wherein said expansion unit is a motion picture-specific expansion unit including said compression unit and a motion picture digital video signal output terminal.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. An endoscopic imaging system according to claim 1, wherein said expansion unit is a still image and motion picture-specific expansion unit including said compression unit, said PC card slot, and a motion picture digital video signal output terminal.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. An endoscopic imaging system according to claim 1, further comprising an identification unit for recognizing an expansion unit coupled to said digital video signal output terminal as either a motion picture-specific expansion unit or a still image-specific expansion unit.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. An endoscopic imaging system according to claim 13, further comprising a release switch, wherein when said release switch is handled, said signal processing apparatus outputs either image data of a still image to said still image-specific expansion unit or image data of a motion picture to said motion picture-specific expansion unit through said digital video signal output terminal according to the result of the recognition process performed by said identification unit.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. An endoscopic imaging system according to claim 10, wherein said still image-specific expansion unit further includes a first compression unit of a lossless coding type and a second compression unit of a lossy coding type, and an instruction element for instructing which of said first compression unit and said second compression unit should be selected for recording a still image.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. An endoscopic imaging system according to claim 1, wherein said signal processing apparatus has a digital video output terminal to which a still image-specific expansion unit and motion picture-specific expansion unit can be coupled simultaneously.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. An endoscopic imaging system according to claim 1, further comprising a recording elements for transferring and recording image data to be recorded on said PC card.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. An endoscopic imaging system according to claim 1, further comprising a recording element for recording image data of a compressed still image on a medium other than a PC card loaded into said expansion unit.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. An endoscopic imaging system according to claim 1, wherein a connection between said digital video signal output terminal and an input terminal of said expansion unit is configured to provide ground-level voltage, power, and data connections in the listed order.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. An endoscopic image system according to claim 19, wherein when power is supplied from a unit other than said signal processing apparatus to said expansion unit, a connection between said digital video signal output terminal is configured to provide the ground-level voltage and data connections in the listed order.</claim-text>
    </claim>
    <claim num="21">
      <claim-text>21. An endoscopic imaging system according to claim 19, wherein the connection between said digital video signal output terminal and said input terminal of said expansion unit is established through pins, and wherein the length of a ground pin is the longest and the length of a power pin is shorter than the length of the ground pin and longer than the length of a data transfer pin.</claim-text>
    </claim>
    <claim num="22">
      <claim-text>22. An endoscopic imaging system according to claim 20, wherein the connection between said digital video signal output terminal and said input terminal of said expansion unit is established through pins, and wherein the length of a ground pin is longest of all the pins, and the length of a data transfer pin is shorter than the length of any other type of pin.</claim-text>
    </claim>
    <claim num="23">
      <claim-text>23. An endoscopic imaging system according to claim 1, further comprising a plurality of contact points for a ground line, a power line, and a data line, respectively, which are enclosed in a bus at said digital video signal output terminal and which are positioned such that the ground line will come into contact with said expansion unit first, the power line will come into contact therewith second, and the data line will come into contact therewith last when said bus is connected to said expansion unit.</claim-text>
    </claim>
    <claim num="24">
      <claim-text>24. An endoscopic imaging system, comprising: an endoscope including an elongated insertion unit having a terminal portion. an illumination optical system located at the terminal portion of the elongated insertion unit for emitting illumination light, an objective optical system located at the terminal portion of said insertion unit for forming an optical image of an object illuminated with the illumination light, and an imaging device for photoelectrically converting the optical image either directly upon formation or after being transmitted through the insertion unit; a signal processing apparatus for driving said imaging device, processing an image signal output from said imaging device, producing a digital video signal and an analog video signal, and outputting the video signals through a digital video signal output terminal and analog video signal output terminal, respectively; a monitor for displaying an object image represented by the analog video signal in response to input of the analog video signal output through said analog video signal output terminal; a digital interface unit to be coupled to said digital video signal output terminal in a freely detachable manner, the digital interface unit including a memory in which said digital video signal is stored temporarily, a controller for controlling a read operation and a write operation to be performed relative to said memory, and a digital interface output unit for outputting the digital video signal upon being read from said memory in a form acceptable by an external device;</claim-text>
      <claim-text>and an external storage/recording device coupled to said digital video output terminal for storing or recording said digital video signal.</claim-text>
    </claim>
    <claim num="25">
      <claim-text>25. An endoscopic imaging system according to claim 24, wherein said controller is incorporated in said digital interface unit.</claim-text>
    </claim>
    <claim num="26">
      <claim-text>26. An endoscopic imaging system according to claim 24, further comprising a video signal generator for generating a video signal using said digital video signal stored in said memory.</claim-text>
    </claim>
    <claim num="27">
      <claim-text>27. An endoscopic imaging system according to claim 24, further comprising an image synthesizer for synthesizing said digital video signal produced by said signal processing apparatus and said digital video signal stored in said memory, so as to produce synthetic image data;</claim-text>
      <claim-text>and a synthetic video signal generator for generating a video signal using the synthetic image data produced by said image synthesizer.</claim-text>
    </claim>
  </claims>
</questel-patent-document>