<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06182276B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06182276</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6182276</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="21875529" extended-family-id="42109149">
      <document-id>
        <country>US</country>
        <doc-number>09034297</doc-number>
        <kind>A</kind>
        <date>19980304</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1998US-09034297</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>43165833</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>3429798</doc-number>
        <kind>A</kind>
        <date>19980304</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1998US-09034297</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G06F   9/44        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>9</main-group>
        <subgroup>44</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>717109000</text>
        <class>717</class>
        <subclass>109000</subclass>
      </main-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G06F-008/38</text>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>8</main-group>
        <subgroup>38</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>G06F-009/44W</text>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>009</main-group>
        <subgroup>44W</subgroup>
      </classification-ecla>
      <classification-ecla sequence="3">
        <text>G06F-009/54A</text>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>009</main-group>
        <subgroup>54A</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06F-009/541</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>9</main-group>
        <subgroup>541</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20180210</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06F-008/38</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>8</main-group>
        <subgroup>38</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20180210</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20180201</date>
        </classification-scheme>
        <classification-symbol>G06F-009/451</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>F</subclass>
        <main-group>9</main-group>
        <subgroup>451</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20180203</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>15</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>5</number-of-drawing-sheets>
      <number-of-figures>5</number-of-figures>
      <image-key data-format="questel">US6182276</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Host application presentation space recognition producing asynchronous events</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>HSIA HANNA</text>
          <document-id>
            <country>US</country>
            <doc-number>5862341</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5862341</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>HSIA HANNA</text>
          <document-id>
            <country>US</country>
            <doc-number>5961592</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5961592</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>STEDMAN STEVEN MATTHEW, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5968119</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5968119</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>BRIM DAVID NEAL, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>6049832</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US6049832</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>EASTWICK MICHAEL W, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>6052685</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US6052685</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="1">
          <text>Sherrington. How to migrate legacy system from mainframe to open system technology, Dec. 1994. pp. 1-3.</text>
        </nplcit>
      </citation>
      <citation srep-phase="examiner">
        <nplcit num="2">
          <text>Neumann. Evolution process for legacy system transformation. 1994. pp. 57-62.</text>
        </nplcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>International Business Machines Corporation</orgname>
            <address>
              <address-1>Armonk, NY, US</address-1>
              <city>Armonk</city>
              <state>NY</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>IBM</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Brawn, Thomas J.</name>
            <address>
              <address-1>Apex, NC, US</address-1>
              <city>Apex</city>
              <state>NC</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Gilgen, David Blair</name>
            <address>
              <address-1>Raleigh, NC, US</address-1>
              <city>Raleigh</city>
              <state>NC</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="3">
          <addressbook lang="en">
            <name>McMillan, Mark Anthony</name>
            <address>
              <address-1>Raleigh, NC, US</address-1>
              <city>Raleigh</city>
              <state>NC</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="4">
          <addressbook lang="en">
            <name>Webb, Brian Thomas</name>
            <address>
              <address-1>Raleigh, NC, US</address-1>
              <city>Raleigh</city>
              <state>NC</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <name>Ray-Yarletts, Jeanine S.</name>
          </addressbook>
        </agent>
        <agent sequence="2" rep-type="agent">
          <addressbook lang="en">
            <name>Doubet, Marcia L.</name>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Hafiz, Tariq R.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A technique, system, and computer program for enabling workstation software applications to efficiently and reliably use legacy host application data streams, without requiring change to the host applications.
      <br/>
      This is achieved by defining attributes of presentation spaces (screens or parts of screens) that are of interest to the workstation application, defining target objects to process the legacy host data, registering these attribute definitions and corresponding target objects with a screen recognition object, using the screen recognition object to monitor the host data streams for occurrence of a registered screen, and generating an asynchronous event to invoke the target object when a registered screen is detected.
      <br/>
      The efficiency is obtained because the workstation application programmer no longer has to write code to monitor the host data streams for the screens of interest.
      <br/>
      The reliability is obtained because the application programmer now reliably knows when a screen of interest appears in the host data stream.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="2">
      The present invention relates to a computer system, and deals more particularly with a method and apparatus for operating such a computer system attached to a host data stream, such that the computer system can automatically recognize the presence of a host application presentation space in the data stream coming from the host application.
      <br/>
      Using the present invention, the programmer defines attributes of a presentation space he is interested in, then registers that presentation space definition.
      <br/>
      The present invention monitors the data stream, and generates an asynchronous notification if that presentation space appears in the host data stream.
      <br/>
      This notification automatically invokes software to process the presentation space information.
    </p>
    <p num="3">2. Description of the Related Art</p>
    <p num="4">
      One of the challenges facing information services ("IS") professionals today is the difficulty of bridging legacy mainframe host data to modern PC-based user interfaces.
      <br/>
      Most legacy host applications present their data in text-based user interfaces designed for use on specific, obsolete character-based terminals.
      <br/>
      The legacy applications were written with this character-based terminal presentation space as the only interface format in which the host data output is created, and in which host data input is expected. "Presentation space" is a term used abstractly to refer to the collection of information that together comprises the information to be displayed on a screen, as well as the control data that conveys how and where that information is to represented.
    </p>
    <p num="5">
      A typical character-based terminal is the IBM Model 327X. (IBM is a registered trademark of the International Business Machines Corporation.) This terminal model was designed to display information in a matrix of characters, where the matrix consisted of 24 rows each having 80 columns.
      <br/>
      When programs were written expecting this display format, programmers would specify placement of information on the screen using specific row and column locations.
      <br/>
      Information formatted for this display is sent as a "data stream" to the mechanism in the display hardware that is responsible for actually displaying the screen contents.
      <br/>
      The phrase "data stream" refers to the fact that the data is sent as a linear string, or stream, of characters.
      <br/>
      This stream of characters contains both the actual textual information to be displayed on the screen, as well as information specifying where and how the text is to be displayed. "Where" consists of the row and column where the text is to begin, and "how" consists of a limited number of presentation attributes such as what color (typically either green or white) to use when displaying that text.
      <br/>
      While the Model 327X is a specific type of IBM display hardware, data formatted for any display having similar characteristics became a de facto standard format referred to as a "3270 data stream".
      <br/>
      Similarly, the IBM Model 525X. is another type of character-based terminal.
      <br/>
      This terminal displays data in a slightly different manner from the IBM 327X, and consequently uses a different data stream format.
      <br/>
      The "5250 data stream" also became a de facto standard format for displays having similar characteristics.
      <br/>
      A third type of data stream format commonly used by legacy host applications is referred to simply as an "ASCII data stream".
      <br/>
      While an ASCII data stream is not formatted for a specific model of display screen, a data stream in this format has certain predefined characteristics (for example, the manner in which a control character indicates the line spacing to be used).
    </p>
    <p num="6">
      The displays used with modern computer workstations (including personal computers, network computers, etc.) support graphics and video, in addition to text characters.
      <br/>
      These displays do not use a character-based row and column matrix approach to screen layout.
      <br/>
      Instead, the programmer has access to thousands of tiny display elements, allowing the various types of information to be placed virtually anywhere on the display screen.
    </p>
    <p num="7">
      When the modem computer workstation is used to access a legacy host application running on a mainframe, the output data created by that host application is typically still formatted as one of the character-based data streams.
      <br/>
      The workstation has access to the host application using mainframe emulator software.
      <br/>
      An example of mainframe emulator software is the Personal Communications product from IBM.
      <br/>
      Emulator software runs on the workstation.
      <br/>
      This software provides facilities to establish a telecommunications connection between the workstation and the host computer, to invoke execution of a software application stored on that host, and to transfer information between the host and the workstation as the application runs.
      <br/>
      When a legacy application is accessed using an emulator, it appears to the host as if the host was interacting with a so-called "dumb terminal", instead of an intelligent workstation.
      <br/>
      The emulator takes care of reformatting the character-based data sent by the host, for display on a modern display screen.
    </p>
    <p num="8">
      Currently, there is movement in the computer information industry away from using mainframe emulators as the primary user interface to the host applications.
      <br/>
      Therein lies the problem.
      <br/>
      When an emulator is no longer used, the emulator's complicated interface logic for translating between the character-based data stream and the modern workstation display screen layout must be performed by some other service running on the workstation.
    </p>
    <p num="9">
      One solution to this problem of obsolete data stream formats is to rewrite the host applications, so that they create their output in a format recognized by modern displays.
      <br/>
      For most companies, this rewrite of host applications represents a monumental task.
      <br/>
      Not only are there literally millions of lines of code to rewrite, the skills that are required to program host applications (ability to use the COBOL programming language, for example) are in short supply.
    </p>
    <p num="10">
      There is an alternative solution to rewriting the host applications, which many IS professionals have chosen.
      <br/>
      The user interface facilities of many modern application programs accept the existing host presentation space format when retrieving data from the host application, but do not show the data to the user in this format.
      <br/>
      The new user interface facilities "scrape" (that is, extract) data from the host presentation space, and present it to the user in a form that is appropriate for the display screen device used with the computer system.
      <br/>
      By convention, this form tends to be a graphical user interface where information is presented in a window-based layout.
      <br/>
      The user interacts with the application using this graphical user interface.
      <br/>
      When data needs to be returned to the application computer, for example in response to the user's input, the user interface facility converts this information automatically into a format that is recognized by the host application.
    </p>
    <p num="11">
      This solves the problem of having to rewrite the host application, but it presents a new problem.
      <br/>
      Presentation spaces appear asynchronously in the data stream sent from the host application, so using the presentation space format as the expected format for user interface data becomes unpredictable.
      <br/>
      Whether it is due to network traffic, host application response time, etc., there is no set time when a presentation space will begin arriving from the host application, and no specific period of time in which the entire screen contents will be transmitted.
      <br/>
      What is needed is a program that automates host presentation space interaction.
      <br/>
      This program should constantly monitor the data stream coming from the host to see if a particular presentation space appears.
      <br/>
      When the presentation space does appear, this program should asynchronously notify a software routine that embodies knowledge of how the presentation space is formatted, and how the information contained in that presentation space is to be presented to the user.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="12">An object of the present invention is to provide a technique whereby modem user interface facilities are able to efficiently and reliably retrieve legacy host application data from a data stream that is formatted as a host presentation space.</p>
    <p num="13">Another object of the present invention is to provide a technique whereby these modem user interface facilities can retrieve the legacy host application data without rewriting the host application.</p>
    <p num="14">A further object of the present invention is to provide a technique whereby the retrieved application data is made available to a software routine that reformats it for presentation using a modem, non-character based user interface display device.</p>
    <p num="15">Additionally, it is an object of the present invention to provide a technique whereby the programmer can register a set of attributes that will be used by a screen recognition object to automatically recognize the presence of a presentation space in the data stream, and a target object to process the recognized presentation space.</p>
    <p num="16">
      A further object of the present invention is to provide a technique for asynchronously monitoring the data stream, and asynchronously generating a notification to the target object when a specific presentation space appears.
      <br/>
      By allowing these processes to operate asynchronously, the workstation software can proceed on to other tasks without having to suspend processing to wait for appearance of a presentation space.
    </p>
    <p num="17">
      An embodiment of the present invention will use definitions of presentation spaces (that is, screens or portions thereof) that may appear in a host application data stream, registering those definitions with a presentation space recognition object.
      <br/>
      This registration includes identifying one or more data streams to be monitored, each relevant presentation space definition, and a target object to be asynchronously notified if the presentation space appears.
      <br/>
      The target object contains the logic to process the presentation space: it understands the data stream format used, and knows what to do with the elements it contains.
      <br/>
      For example, the target object will typically scrape the data from the presentation space, and reformat it for display.
      <br/>
      Additionally, the preferred embodiment will contain logic to unregister a presentation space, which causes the registration object to stop monitoring the data stream for that screen.
    </p>
    <p num="18">This invention may be used with any data stream format that has a well-defined format, and well-defined codes indicating the attribute types used in the data stream.</p>
    <p num="19">
      By using this asynchronous notification technique, programs executing on a modem workstation will have an efficient, reliable way in which to receive and process presentation spaces from legacy host applications that are formatted for obsolete character-based terminals.
      <br/>
      The technique is efficient because the programmer no longer has to include code in workstation-based programs to monitor host data streams for presentation spaces.
      <br/>
      The technique is reliable because the workstation-based program now reliably knows, by way of the asynchronous event notification, when a presentation space of interest has arrived.
    </p>
    <p num="20">Other objects and advantages of the present invention will be set forth in part in the description and in the drawings which follow and, in part, will be obvious from the description or may be learned by practice of the invention.</p>
    <p num="21">The present invention will now be described with reference to the following drawings, in which like reference numbers denote the same element throughout.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="22">
      FIG. 1 is a block diagram of a computer workstation environment in which the present invention may be practiced;
      <br/>
      FIG. 2 is a diagram of a networked computing environment in which the present invention may be practiced;
      <br/>
      FIG. 3 illustrates a flow chart which sets forth the logic involved when the programmer defines the attributes of a presentation space (or some portion thereof) that will enable automatic recognition of that presentation space by an embodiment of the present invention;
      <br/>
      FIG. 4 illustrates a flow chart which sets forth the logic involved when registering screen definitions and associated target objects with the screen recognition object; and
      <br/>
      FIG. 5 illustrates a flow chart which sets forth the logic involved with the present invention when a recognized presentation space is detected in a data stream.
    </p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENT</heading>
    <p num="23">
      FIG. 1 illustrates a representative workstation hardware environment in which the present invention may be practiced.
      <br/>
      The environment of FIG. 1 comprises a representative single user computer workstation 10, such as a personal computer, including related peripheral devices.
      <br/>
      The workstation 10 includes a microprocessor 12 and a bus 14 employed to connect and enable communication between the microprocessor 12 and the components of the workstation 10 in accordance with known techniques.
      <br/>
      The workstation 10 typically includes a user interface adapter 16, which connects the microprocessor 12 via the bus 14 to one or more interface devices, such as a keyboard 18, mouse 20, and/or other interface devices 22, which can be any user interface device, such as a touch sensitive screen, digitized entry pad, etc.
      <br/>
      The bus 14 also connects a display device 24, such as an LCD screen or monitor, to the microprocessor 12 via a display adapter 26.
      <br/>
      The bus 14 also connects the microprocessor 12 to memory 28 and long-term storage 30 which can include a hard drive, diskette drive, tape drive, etc.
    </p>
    <p num="24">
      The workstation 10 may communicate via a communications channel 32 with other computers or networks of computers.
      <br/>
      The workstation 10 may be associated with such other computers in a local area network (LAN) or a wide area network, the workstation 10 can be a client in a client/server arrangement with another computer, etc.
      <br/>
      All of these configurations, as well as the appropriate communications hardware and software, are known in the art.
    </p>
    <p num="25">
      FIG. 2 illustrates a data processing network 40 in which the present invention may be practiced.
      <br/>
      The data processing network 40 includes a plurality of individual networks, including LANs 42 and 44, each of which includes a plurality of individual workstations 10.
      <br/>
      Alternatively, as those skilled in the art will appreciate, a LAN may comprise a plurality of intelligent workstations coupled to a host processor.
    </p>
    <p num="26">
      Still referring to FIG. 2, the data processing network 40 may also include mainframe computers or servers, such as a mainframe computer 46, which may be preferably coupled to the LAN 44 by means of a communications link 48.
      <br/>
      The mainframe computer 46 may be implemented utilizing an Enterprise Systems Architecture/370, or an Enterprise Systems Architecture/390 computer available from IBM.
      <br/>
      Depending on the application, a mid-range computer, such as an Application System/400 (also known as an AS/400) may be employed. "Enterprise Systems Architecture/370" is a trademark of IBM; "Enterprise Systems Architecture/390", "Application System/400", and "AS/400" are registered trademarks of IBM.
    </p>
    <p num="27">
      The mainframe computer 46 may also be coupled to a storage device 50, which may serve as remote storage for the LAN 44.
      <br/>
      Similarly, the LAN 44 may be coupled to a communications link 52 through a subsystem control unit/communication controller 54 and a communications link 56 to a gateway server 58.
      <br/>
      The gateway server 58 is preferably an individual computer or intelligent workstation which serves to link the LAN 42 to the LAN 44.
    </p>
    <p num="28">
      Those skilled in the art will appreciate that the mainframe computer 46 may be located a great geographic distance from the LAN 44, and similarly, the LAN 44 may be located a substantial distance from the LAN 42.
      <br/>
      For example, the LAN 42 may be located in California, while the LAN 44 may be located in Texas, and the mainframe computer 46 may be located in New York.
    </p>
    <p num="29">
      Software programming code which embodies the present invention is typically accessed by the microprocessor 12 of the workstation 10 from long-term storage media 30 of some type, such as a CD-ROM drive or hard drive.
      <br/>
      In a client-server environment, such software programming code may be stored with storage associated with a server.
      <br/>
      The software programming code may be embodied on any of a variety of known media for use with a data processing system, such as a diskette, hard drive, or CD-ROM.
      <br/>
      The code may be distributed on such media, or may be distributed to users from the memory or storage of one computer system over a network of some type to other computer systems for use by users of such other systems.
      <br/>
      Alternatively, the programming code may be embodied in the memory 28, and accessed by the microprocessor 12 using the bus 14.
      <br/>
      The techniques and methods for embodying software programming code in memory, on physical media, and/or distributing software code via networks are well known and will not be further discussed herein.
    </p>
    <p num="30">
      The reformatted data resulting from use of the present invention may be displayed on any of the various display devices 24.
      <br/>
      The user interacts with the data using any type of interface device such as a keyboard 18, mouse 20, and/or other interface devices 22 (such as a touch sensitive screen, digitized entry pad, etc.).
    </p>
    <p num="31">The preferred embodiment of the present invention will now be discussed with reference to FIGS. 3 through 5.</p>
    <p num="32">
      In the preferred embodiment, the present invention is implemented as a computer software program.
      <br/>
      The implementation of the invention may be used with any software application that displays data using a non-character-based user interface, such as a graphical user interface, but which interacts with a host application that uses a character-based display format.
      <br/>
      The application may execute entirely on the user's computer, as a stand-alone software package, or it may execute partly on the user's computer and partly on a remote computer, such as a middle-tier server.
      <br/>
      In the latter scenario, the remote computer may be connected to the user's computer through a LAN or a WAN that is part of a network owned or managed internally to the user's company, or the connection may be made through the Internet using an Internet Service Provider.
    </p>
    <p num="33">
      The present invention allows the programmer to register presentation space definitions for monitoring by a screen recognition object, to specify which data stream(s) should be monitored for the presence of the registered presentation spaces, and to specify the software routine (referred to herein as the "target") to receive a notification when a registered presentation space appears in the data stream.
      <br/>
      The present invention then monitors the data streams(s) asynchronously, and generates an asynchronous notification to the appropriate target software routine when a registered presentation space is detected in the data stream.
      <br/>
      The notified target routine then processes the presentation space.
      <br/>
      Further, the present invention includes features by which the programmer can indicate that monitoring for a specific presentation space should cease.
    </p>
    <p num="34">
      In the preferred embodiment, the invention will be implemented using object-oriented programming languages and techniques.
      <br/>
      However, the invention can be implemented using conventional programming languages that are not object-oriented, without deviating from the inventive concepts.
      <br/>
      Use of the term "object" herein is not to be construed as limiting the invention to object-oriented techniques.
    </p>
    <p num="35">
      The preferred embodiment is described using references to a 3270 data stream.
      <br/>
      However, the inventive concepts of the present invention are not limited to 3270 data stream formats: any data stream format may be equivalently used, as previously discussed.
    </p>
    <p num="36">
      FIG. 3 illustrates the logical steps that may be performed by a programmer to define the attributes of a presentation space that will enable automatic recognition of that presentation space by a screen recognition object in an embodiment of the present invention.
      <br/>
      The specific technique of defining the attributes does not form part of the present invention.
      <br/>
      A number of ways of specifying attributes could be used.
      <br/>
      For example, a programmer could include programming language statements in a workstation application that uses the present invention, where those programming language statements would specify attributes for each screen of interest.
      <br/>
      These programming language statements would then become part of the executable workstation application.
      <br/>
      Alternatively, a software routine could be written which prompts the programmer to specify attributes of each screen of interest.
      <br/>
      That software routine would then record the programmer's entries, for example by storing them in a file on a medium such as a disk.
      <br/>
      This prompting software could be part of the workstation application, or it could be a stand-alone program.
      <br/>
      What is required for the present invention is that the screen attributes are somehow defined, and made available in a format expected by the recognition object. (As the particular details of the data stream format change, the recognition logic may need to be changed accordingly.
      <br/>
      Details of how a screen is recognized by the screen recognition object do not form part of the present invention.) The steps shown in FIG. 3 would apply equally to the process a programmer goes through when writing programming language statements, and to the process that would be implemented in a software prompting technique.
      <br/>
      The steps will be described as if implemented in the latter form.
    </p>
    <p num="37">
      The process begins at Step 100, where the programmer begins defining the attributes of a specific screen.
      <br/>
      When the data stream being used with the present invention is a 3270 data stream, six different types of attributes may be used to define a screen.
      <br/>
      While the preferred embodiment will be described with reference to these specific attribute types, the inventive concepts of the present invention apply equally to presentation spaces that use additional or different attributes.
      <br/>
      What is required is that the attribute types used in the data stream, as well as their possible values, are known by the programmer so that he can specify the definition of the presentation spaces in which he is interested in terms of those attributes.
    </p>
    <p num="38">
      Step 100 indicates that the programmer will define attributes of the presentation space for a "screen".
      <br/>
      Alternatively, the attributes may represent some portion of a screen.
      <br/>
      The logic of FIG. 3 applies equally to defining the attributes of a full screen or a partial screen, and thus the term "screen" will be used hereinafter to represent either situation.
    </p>
    <p num="39">
      The programmer will be required to assign some type of identifier to the collection of attributes that have been used to define a particular screen.
      <br/>
      This identifier can be specified at any time during the attribute definition process for a screen.
      <br/>
      According to the preferred embodiment, that information will be specified at Step 100.
      <br/>
      This identifier will typically be the screen name.
      <br/>
      It will be used in the processes represented by FIGS. 4 and 5.
    </p>
    <p num="40">
      At Step 120, the programmer begins a process of specifying which attributes are of interest for this particular screen.
      <br/>
      The inquiries shown at Steps 120, 150, 180, 210, 240, and 270 represent the six attribute types of a presentation space recognized by the preferred embodiment.
      <br/>
      As discussed earlier, the inventive concepts of the present invention will apply equally well if additional attribute types, or different attribute types, are used.
      <br/>
      It will be obvious to one skilled in the art how the logic shown in FIG. 3 can be extended to include more attribute types, or changed to use different attribute types.
    </p>
    <p num="41">
      At Step 120, the programmer is asked if he wishes to specify one of the types of attribute, shown here as the "text" attribute.
      <br/>
      If the answer is positive, then at Step 130 the programmer specifies the text string of interest.
      <br/>
      When screen recognition logic in the screen recognition object is later attempting to recognize a text string in the host application data stream, it will typically perform a pattern-matching operation with the text string the programmer entered as an attribute, comparing the data that appears in the data stream against the characters in the text string.
      <br/>
      The programmer may indicate additional information about the text string, such as whether the pattern-matching operation should treat the text string as case-sensitive.
      <br/>
      Additionally, the programmer may specify that a certain row and column position is the only starting position of interest for this text string.
      <br/>
      When the text string and any of these additional descriptors has been specified, Step 140 asks if there are more text strings to be used as attributes for this screen.
      <br/>
      As an example, the programmer might specify text that appears as a screen heading as one text attribute.
      <br/>
      If the screen has a sub-heading, the text of the sub-heading could be specified as a second text attribute.
      <br/>
      If there are more text strings to be specified, control returns to Step 130.
    </p>
    <p num="42">
      Control reaches Step 150 when the programmer has finished specifying text string attributes, or when the programmer indicated (at Step 120) that he did not wish to specify any text attributes.
      <br/>
      At Step 150, the programmer is asked if he wants to specify attributes of the second type, shown here as "fields" attributes.
      <br/>
      If the answer is positive, then at Step 160 the programmer specifies information that will allow the field of interest to be later recognized by screen recognition logic.
      <br/>
      For example, in the 3270 data stream, a field can be designated as "display only" by using a certain hexadecimal value as a field attribute.
      <br/>
      The programmer may specify this hexadecimal value as a field attribute if he wishes the screen recognition object to detect such a field.
      <br/>
      When the field has been specified, Step 170 asks if there are more field attributes to be defined for this screen.
      <br/>
      If there are more field attributes to be specified, control returns to Step 160.
    </p>
    <p num="43">
      Control reaches Step 180 when the programmer has finished specifying field attributes, or when the programmer indicated (at Step 150) that he did not wish to specify any field attributes.
      <br/>
      At Step 180, the programmer is asked if he wants to specify attributes of the third type, shown here as "extended fields" attributes.
      <br/>
      In the 3270 data stream, extended field attributes are indicators of such things as reverse video, highlighting, etc.
      <br/>
      If the answer is positive, then at Step 190 the programmer specifies the extended field of interest.
      <br/>
      When the extended field has been specified, Step 200 asks if there are more extended field attributes to be defined for this screen.
      <br/>
      If there are more extended fields to be specified, control returns to Step 190.
    </p>
    <p num="44">
      Control reaches Step 210 when the programmer has finished specifying extended field attributes, or when the programmer indicated (at Step 180) that he did not wish to specify any extended field attributes.
      <br/>
      At Step 210, the programmer is asked if he wants to specify attributes of the fourth type, shown here as "colors" attributes.
      <br/>
      If the answer is positive, then at Step 220 the programmer specifies the color of interest.
      <br/>
      The programmer will also specify which row and column the color must be associated with, in order for a successful match against the data stream when screen recognition logic is later attempting to match this screen definition against a presentation space occurring in the host application data stream.
      <br/>
      When the color attribute has been specified, Step 230 asks if there are more colors to be used as attributes for this screen.
      <br/>
      As an example, the programmer might specify the color red to be used as an attribute.
      <br/>
      Then he might specify the color yellow as a second color attribute, so that screens containing both red and yellow at specific locations could be detected.
      <br/>
      If there are more colors attributes to be specified, control returns to Step 220.
    </p>
    <p num="45">
      Control reaches Step 240 when the programmer has finished specifying color attributes, or when the programmer indicated (at Step 210) that he did not wish to specify any color attributes.
      <br/>
      At Step 240, the programmer is asked if he wants to specify attributes of the fifth type, shown here as a "cursor position" attribute.
      <br/>
      This attribute type is used when the programmer wants to detect when the cursor is positioned at a specific row and column.
      <br/>
      If the answer is positive, then at Step 250 the row and column of interest are specified. (Since the cursor can only be at one row and column on a screen, the programmer is not entering multiple cursor position attributes.
      <br/>
      However, an alternative embodiment might allow the programmer to indicate that the presence of the cursor at any number of alternative positions should be detected.
      <br/>
      In that situation, a test would be added after Step 250, asking whether there are more positions of interest, and transferring back to Step 250 to allow entry of each position if the response is positive.) When the cursor position information has been specified, control transfers to Step 270.
    </p>
    <p num="46">
      Control reaches Step 270 when the programmer has finished specifying the cursor position attribute, or when the programmer indicated (at Step 240) that he did not wish to specify a cursor position.
      <br/>
      At Step 270, the programmer is asked if he wants to specify attributes of the final type used for the preferred embodiment, shown here as "operator intervention condition" attributes.
      <br/>
      If the answer is positive, then at Step 280 the programmer specifies the condition of interest.
      <br/>
      An operator intervention condition, as defined in the 3270 data stream, is a hexadecimal code appearing in the data stream that indicates such things as "input inhibited".
      <br/>
      When the condition attribute has been specified, Step 290 asks if there are more conditions to be defined as attributes for this screen.
      <br/>
      If there are more conditions to be specified, control returns to Step 280.
    </p>
    <p num="47">
      While the above descriptions discuss multiple attributes of one type being used in conjunction (as in an "AND" operation) to specify screen requirements, alternatively these attributes may be used disjunctively (as in an "OR" operation) to indicate that a screen matches the definition when it has any of the attributes.
      <br/>
      Additional steps may be added to the process shown in FIG. 3, to enable the programmer to specify whether AND or OR is desired when multiple attributes are being defined.
      <br/>
      It will be obvious to one of ordinary skill in the art how to add such additional steps to FIG. 3.
    </p>
    <p num="48">When the programmer has finished specifying attributes that will define the screen of interest, control transfers to Step 300.</p>
    <p num="49">
      At Step 300, the programmer is asked whether he wishes to define the attributes of more screens.
      <br/>
      If so, then control transfers to Step 100, to begin the definition process for another screen.
      <br/>
      Otherwise, the definition process ends.
    </p>
    <p num="50">
      FIG. 4 illustrates the logic involved in configuring an embodiment of the present invention to monitor one or more specific data streams for the occurrence of the screens having the attributes that were defined using a process such as shown in FIG. 3.
      <br/>
      This configuration process is referred to herein as "registration"--that is, the screen definitions to be detected, the target object to process each detected screen, and the data streams to be monitored, are registered with the screen recognition object.
      <br/>
      This design for the screen recognition object enables it to function as a generic monitor, which can monitor for anything registered to it: it is not limited to a predefined, hardcoded set of screen definitions.
      <br/>
      This effectively separates the screen recognition process from the data contained in the screens.
    </p>
    <p num="51">
      Step 400 indicates that a screen recognition object will either be created or updated.
      <br/>
      In the preferred embodiment, the screen recognition object is created when the workstation application begins execution, and therefore the object persists only for the duration of the application.
      <br/>
      The present invention contemplates that an initial set of screen definitions may be registered with the screen recognition object at the time of its creation.
      <br/>
      Further on during the execution of the host and workstation applications, additional screen definitions may be registered.
      <br/>
      The initially-registered definitions would typically be for the screens expected when a host application is beginning, and later-registered definitions would be for screens expected later on during the interaction.
      <br/>
      Depending on the particular host application, however, it may be desirable to register the entire set of screen definitions at one time.
      <br/>
      The present invention includes either approach, where all screen definitions may be registered initially, or some may be registered initially and others registered later.
      <br/>
      Thus, FIG. 4 refers to both creating the recognition object, and updating it.
      <br/>
      The term "recognition object" is used to indicate the software that (1) contains screen recognition logic that processes the attribute definitions created previously, (2) monitors the host application data streams of interest for registered screens, and (3) notifies the "target object" (described below) when a registered presentation space appears in a monitored host data stream.
      <br/>
      This software may be an object, in an object-oriented programming environment, or it may be a routine or module implemented in a non-object-oriented programming language.
    </p>
    <p num="52">
      At Step 410, the programmer specifies which particular data streams should be monitored by this recognition object.
      <br/>
      The particular manner in which a data stream is identified to the recognition object, and in which the recognition object locates the appropriate data stream at execution time, do not form part of the present invention.
      <br/>
      Such techniques are known by those of ordinary skill in the art.
      <br/>
      A programmer writing a workstation application that interacts with a host application will specify, in his workstation application, a session to be used for communications between the two applications.
      <br/>
      The present invention then uses an identifier for that already-created session (for example, a pointer returned from a function call that created the session) in the registration process at Step 410.
    </p>
    <p num="53">
      At Step 420, the programmer specifies the information to be registered for a particular screen.
      <br/>
      The information for each screen comprises the identifier used to name the collection of attributes that enable recognition of this screen (as was described above in reference to FIG. 3), and the target object associated with this screen.
      <br/>
      A target object is an object (when using object-oriented programming), or a code routine or module (when using non-object-oriented programming), that contains code to process a particular legacy host screen.
      <br/>
      This processing typically will include scraping the data stream for this screen, to extract relevant data.
      <br/>
      The scraped data will then typically be reformatted for presentation with a modem user interface such as a windowing environment.
      <br/>
      However, the specific details of the logic included in the target object will be application-specific, as defined by the programmer of the workstation-based application, and do not form a part of the present invention. (For example, some parts of the legacy information may not be displayed in the new presentation format; some parts may be displayed in different areas of the new screen; etc.) What is required for the present invention is that an executable target object is defined, and that it is identified to the registration object at this step so that it can be invoked by an asynchronous event (using the process described for FIG. 5).
    </p>
    <p num="54">
      The preferred embodiment allows the programmer to "unregister" a screen and its target object as well.
      <br/>
      As an example of how the registration and unregistration processes occur, the registration process may create a table of entries in a disk file, containing the associations of screens and their target objects.
      <br/>
      The unregistration process would then delete a specified entry from this table.
      <br/>
      The table entries would be used by the monitoring process described in FIG. 5.
      <br/>
      Alternatively, the screen and target associations may be treated as dynamic information, which does not persist beyond the execution of the code embodying the monitoring process.
      <br/>
      In that situation, the associations would be stored internally, within the memory or disk space allocated to the executing program.
      <br/>
      Unregistration would typically occur at some point later in execution from the point where registration occurred, and would involve removing the association from that memory or allocated disk space.
    </p>
    <p num="55">
      At Step 420, a test is made as to whether there are more screen definition and target object associations to register.
      <br/>
      Any number of such associations can be registered in the preferred embodiment.
      <br/>
      If the test has a positive response, then control returns to Step 420.
      <br/>
      Otherwise the registration process is complete, and the process shown in FIG. 4 ends.
    </p>
    <p num="56">
      As with FIG. 3, multiple ways of indicating the information required for the registration process of FIG. 4 may be used.
      <br/>
      Programming language statements may be included in a workstation-based application that will create or update a recognition object, and register screen and target information with it.
      <br/>
      In this situation, the target may be an object (or a subroutine in a conventional programming language) within the application, or it may be a standalone executable program.
      <br/>
      Or, the registration process may operate using a programmer prompting technique such as that discussed for FIG. 3.
      <br/>
      If prompting is used for the registration process, the prompting code logic may or may not be embodied in the same code that implements the definition process of FIG. 3.
      <br/>
      The logic represented in FIG. 4 applies to both the programming statement and the prompting approach to registration.
    </p>
    <p num="57">FIG. 5 describes the preferred embodiment of the present invention in operation (that is, after the definition and registration processes have been completed), monitoring data streams for the appearance of registered screens.</p>
    <p num="58">
      Step 500 indicates that the monitoring process begins.
      <br/>
      The recognition object, with which screen definitions were registered in FIG. 4, receives the data in the data streams it has been configured to monitor.
      <br/>
      In absence of the present invention, these data streams would be processed directly by a workstation application, which application would be required to include data stream monitoring logic.
      <br/>
      With the present invention in place, the data streams are processed by the screen recognition object.
      <br/>
      This recognition object monitors all data arriving in the data stream from the host application.
    </p>
    <p num="59">
      Control transfers to Step 510 when an update to the data stream coming from the host application is detected.
      <br/>
      The manner of detecting this update does not form part of the present invention.
      <br/>
      Facilities for detecting updates are known by those of ordinary skill in the art.
      <br/>
      A programmer writing a workstation application that interacts with a host application will either write code to check for updates coming from the host, or use prewritten code from a code library that is designed to detect such updates.
      <br/>
      The present invention takes advantage of that existing code, and receives the update notification.
    </p>
    <p num="60">
      As shown in Step 520, the screen recognition object then compares the data in the data stream to the definition of the registered screens, to determine if a screen of interest has appeared.
      <br/>
      This comparison uses the sets of attributes that were defined according to FIG. 3, enabling a particular screen to be recognized.
      <br/>
      For example, if the registered definition for a screen includes just one text string required to appear at a specific row and column, then the recognition object looks for that text string at that position each time it detects a new screen in the data stream.
      <br/>
      Or, if the registered definition includes multiple attributes, of multiple types, then the recognition object does a comparison between each of the requirements of that definition and the contents of the screen in the data stream, every time a screen appears.
      <br/>
      This type of comparison is performed for each registered screen definition, each time a screen appears in the data stream, until either a registered screen is recognized (that is, a positive response to the test at Step 520), or until it is determined that this is not a registered screen.
      <br/>
      When a screen in the data stream matches one of the registered screens, control transfers from Step 520 to Step 530.
      <br/>
      Otherwise, if there is no match, control returns to Step 500 to await the occurrence of another screen in the data stream.
    </p>
    <p num="61">
      At Step 530, an asynchronous event notification is generated to the target object that was registered for the screen which was detected at Step 520.
      <br/>
      The manner of generating this event notification does not form part of the present invention.
      <br/>
      Facilities of the workstation operating system are used, according to processes that are known in the art.
    </p>
    <p num="62">
      At Step 540, the target object receives the asynchronous event notification, and executes the logic defined by the programmer of the target object.
      <br/>
      The event notification is received using operating system facilities according to processes known in the art, and does not form part of the present invention.
      <br/>
      As has been previously described, the logic executed by the target object is application-specific.
      <br/>
      In a multi-tasking operating system, the target object may execute its screen processing logic concurrently with the execution of the recognition object.
      <br/>
      FIG. 5 indicates this by showing a dotted line for the event notification (indicating that one part of the control flow leaves the monitoring routine shown), and also by showing that control returns to monitoring the data stream(s) at Step 500 (which is done by the recognition object, at the same time the target object is invoked).
      <br/>
      The asynchronous event notification in a multi-tasking environment, as specified by the present invention, enables this concurrent processing to occur.
    </p>
    <p num="63">
      The process of FIG. 5 is shown as an unending loop of monitoring for screens, and processing registered screens when they are detected.
      <br/>
      It will be obvious to one skilled in the art that this process continues only so long as the workstation application software is executing, even though no end has been depicted in FIG. 5.
      <br/>
      Further, FIG. 5 does not show a return of control from Step 540 back to any of the other steps of the figure.
      <br/>
      This indicates that the target object executes independently, and is invoked anew each time its associated screen is detected.
    </p>
    <p num="64">
      While the preferred embodiment of the present invention has been described, additional variations and modifications in that embodiment may occur to those skilled in the art once they learn of the basic inventive concepts.
      <br/>
      Therefore, it is intended that the appended claims shall be construed to include both the preferred embodiment and all such variations and modifications as fall within the spirit and scope of the invention.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>We claim:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>In a computing environment, computer readable code for implementing an efficient and reliable technique for recognizing occurrence of a presentation space in a host data stream and asynchronously notifying a target routine, said computer readable code embodied on one or more computer-readable media and comprising:</claim-text>
      <claim-text>a subprocess for creating a screen recognition object; a subprocess for registering at least one recognition tuple with said recognition object, each of said tuples comprising a screen description and a corresponding target routine; a subprocess for specifying at least one data stream to be monitored by said recognition object;</claim-text>
      <claim-text>and a subprocess for causing said recognition object to monitor said at least one data stream, further comprising:</claim-text>
      <claim-text>- a subprocess for detecting when an update has occurred, creating an updated presentation space; - a subprocess for comparing said updated presentation space to each of said screen descriptions in said registered tuples until detecting a match;</claim-text>
      <claim-text>and - a subprocess for firing an asynchronous notification event to said corresponding target routine upon said match detection.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. Computer readable code for implementing the technique according to claim 1, further comprising a subprocess for unregistering at least one of said recognition tuples with said recognition object.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. Computer readable code for implementing the technique according to claim 1, wherein said target routine further comprises a subprocess for executing screen processing logic concurrently with said subprocess for monitoring.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. Computer readable code for implementing the technique according to claim 1, wherein said screen description comprises one or more of:</claim-text>
      <claim-text>(1) one or more text string attributes;</claim-text>
      <claim-text>(2) one or more field attributes;</claim-text>
      <claim-text>(3) one or more extended field attributes;</claim-text>
      <claim-text>(4) one or more color attributes;</claim-text>
      <claim-text>(5) a cursor position attribute;</claim-text>
      <claim-text>and (6) one or more operator intervention condition attributes.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. A system for implementing a fast and efficient technique for recognizing occurrence of a presentation space in a host data stream and asynchronously notifying a target routine, said system comprising: means for creating a screen recognition object; means for registering at least one recognition tuple with said recognition object, each of said tuples comprising a screen description and a corresponding target routine; means for specifying at least one data stream to be monitored by said recognition object;</claim-text>
      <claim-text>and means for causing said recognition object to monitor said at least one data stream, further comprising: - means for detecting when an update has occurred, creating an updated presentation space; - means for comparing said updated presentation space to each of said screen descriptions in said registered tuples until detecting a match;</claim-text>
      <claim-text>and - means for firing an asynchronous notification event to said corresponding target routine upon said match detection.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The system for implementing the technique according to claim 5, further comprising means for unregistering at least one of said recognition tuples with said recognition object.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. The system for implementing the technique according to claim 5, wherein said target routine further comprises means for executing screen processing logic concurrently with said means for monitoring.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The system for implementing the technique according to claim 5, wherein said screen description comprises one or more of:</claim-text>
      <claim-text>(1) one or more text string attributes;</claim-text>
      <claim-text>(2) one or more field attributes;</claim-text>
      <claim-text>(3) one or more extended field attributes;</claim-text>
      <claim-text>(4) one or more color attributes;</claim-text>
      <claim-text>(5) one or more cursor position attributes;</claim-text>
      <claim-text>and (6) one or more operator intervention condition attributes.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. A method for implementing a fast and efficient technique for recognizing occurrence of a presentation space in a host data stream and asynchronously notifying a target routine, said method comprising the steps of: creating a screen recognition object; registering at least one recognition tuple with said recognition object, each of said tuples comprising a screen description and a corresponding target routine; specifying at least one data stream to be monitored by said recognition object;</claim-text>
      <claim-text>and causing said recognition object to monitor said at least one data stream, further comprising the steps of: - detecting when an update has occurred, creating an updated presentation space; - comparing said updated presentation space to each of said screen descriptions in said registered tuples until detecting a match;</claim-text>
      <claim-text>and - firing an asynchronous notification event to said corresponding target routine upon said match detection.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. The method for implementing the technique according to claim 9, further comprising the step of enabling unregistration of at least one of said recognition tuples with said recognition object.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. The method for implementing the technique according to claim 9, wherein said target routine further comprises executing screen processing logic concurrently with said monitoring step.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. The method for implementing the technique according to claim 9, wherein said screen description comprises one or more of:</claim-text>
      <claim-text>(1) one or more text string attributes;</claim-text>
      <claim-text>(2) one or more field attributes;</claim-text>
      <claim-text>(3) one or more extended field attributes;</claim-text>
      <claim-text>(4) one or more color attributes;</claim-text>
      <claim-text>(5) a cursor position attribute;</claim-text>
      <claim-text>and (6) one or more operator intervention condition attributes.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. In a computing environment, computer readable code for efficiently and reliably recognizing occurrence of a presentation space in a host data stream and asynchronously notifying a target routine, said computer readable code embodied on one or more computer-readable media and comprising: a subprocess for creating a screen recognition object; a subprocess for registering at least one recognition tuple with said recognition object, each of said tuples comprising a screen description and a corresponding target routine, wherein said screen description comprises one or more of:</claim-text>
      <claim-text>(1) one or more text string attributes;</claim-text>
      <claim-text>(2) one or more field attributes;</claim-text>
      <claim-text>(3) one or more extended field attributes;</claim-text>
      <claim-text>(4) one or more color attributes;</claim-text>
      <claim-text>(5) one or more cursor position attributes;</claim-text>
      <claim-text>and (6) one or more operator intervention condition attributes;a subprocess for specifying at least one data stream to be monitored by said recognition object;</claim-text>
      <claim-text>and a subprocess for monitoring said at least one data stream by said recognition object, further comprising: - a subprocess for detecting when an update has occurred, creating an updated presentation space; - a subprocess for comparing said updated presentation space to each of said screen descriptions in said registered tuples until detecting a match;</claim-text>
      <claim-text>and - a subprocess for firing an asynchronous notification event to said corresponding target routine upon said match detection.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. A system for efficiently and reliably recognizing occurrence of a presentation space in a host data stream and asynchronously notifying a target routine, comprising: means for creating a screen recognition object; means for registering at least one recognition tuple with said recognition object, each of said tuples comprising a screen description and a corresponding target routine, wherein said screen description comprises one or more of:</claim-text>
      <claim-text>(1) one or more text string attributes;</claim-text>
      <claim-text>(2) one or more field attributes;</claim-text>
      <claim-text>(3) one or more extended field attributes;</claim-text>
      <claim-text>(4) one or more color attributes;</claim-text>
      <claim-text>(5) a cursor position attribute;</claim-text>
      <claim-text>and (6) one or more operator intervention condition attributes;means for specifying at least one data stream to be monitored by said recognition object;</claim-text>
      <claim-text>and means for monitoring, by said recognition object, said at least one data stream, further comprising: - means for detecting when an update has occurred, creating an updated presentation space; - means for comparing said updated presentation space to each of said screen descriptions in said registered tuples until detecting a match;</claim-text>
      <claim-text>and - means for firing an asynchronous notification event to said corresponding target routine upon said match detection.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. A method of efficiently and reliably recognizing occurrence of a presentation space in a host data stream and asynchronously notifying a target routine, comprising the steps of: creating a screen recognition object; registering at least one recognition tuple with said recognition object, each of said tuples comprising a screen description and a corresponding target routine, wherein said screen description comprises one or more of:</claim-text>
      <claim-text>(1) one or more text string attributes;</claim-text>
      <claim-text>(2) one or more field attributes;</claim-text>
      <claim-text>(3) one or more extended field attributes;</claim-text>
      <claim-text>(4) one or more color attributes;</claim-text>
      <claim-text>(5) a cursor position attribute;</claim-text>
      <claim-text>and (6) one or more operator intervention condition attributes;specifying at least one data stream to be monitored by said recognition object;</claim-text>
      <claim-text>and monitoring, by said recognition object, said at least one data stream, further comprising the steps of: - detecting when an update has occurred, creating an updated presentation space; - comparing said updated presentation space to each of said screen descriptions in said registered tuples until detecting a match;</claim-text>
      <claim-text>and - firing an asynchronous notification event to said corresponding target routine upon said match detection.</claim-text>
    </claim>
  </claims>
</questel-patent-document>