<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06185338B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06185338</doc-number>
        <kind>B2</kind>
        <date>20010206</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6185338</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference family-id="13411967" extended-family-id="13725019">
      <document-id>
        <country>US</country>
        <doc-number>08828291</doc-number>
        <kind>A</kind>
        <date>19970321</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1997US-08828291</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>14021068</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>JP</country>
        <doc-number>6975696</doc-number>
        <kind>A</kind>
        <date>19960326</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1996JP-0069756</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010206</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>B60R  13/10        20060101AFI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>B</section>
        <class>60</class>
        <subclass>R</subclass>
        <main-group>13</main-group>
        <subgroup>10</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G06K   9/20        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>9</main-group>
        <subgroup>20</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>382229000</text>
        <class>382</class>
        <subclass>229000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>382105000</text>
        <class>382</class>
        <subclass>105000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>382177000</text>
        <class>382</class>
        <subclass>177000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G06K-009/20R</text>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>009</main-group>
        <subgroup>20R</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06K-009/2054</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>9</main-group>
        <subgroup>2054</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150409</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06K-2209/01</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>2209</main-group>
        <subgroup>01</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20150407</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>12</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>8</number-of-drawing-sheets>
      <number-of-figures>9</number-of-figures>
      <image-key data-format="questel">US6185338</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Character recognition using candidate frames to determine character location</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>METCALF TRAVIS W</text>
          <document-id>
            <country>US</country>
            <doc-number>4567609</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4567609</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>DAVIS ELLIOT</text>
          <document-id>
            <country>US</country>
            <doc-number>4802231</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4802231</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>YOSHIDA NAOKO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5065440</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5065440</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="4">
          <text>JONES III CREED F, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5081685</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5081685</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="5">
          <text>KIM JOONKI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5285505</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5285505</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="6">
          <text>KUMAGAI RYOHEI</text>
          <document-id>
            <country>US</country>
            <doc-number>5315664</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5315664</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="7">
          <text>HWANG CHUNG-MU, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5425108</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5425108</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="8">
          <text>IKEMURE YUMIKO</text>
          <document-id>
            <country>US</country>
            <doc-number>5502777</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5502777</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="9">
          <text>HAGITA NORIHIRO</text>
          <document-id>
            <country>US</country>
            <doc-number>5600736</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5600736</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="10">
          <text>FRAZIER JAMES F, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5651075</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5651075</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="11">
          <text>ARAI TSUNEKAZU, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5734750</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5734750</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="12">
          <text>TAKAHASHI KINYA, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5754685</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5754685</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="13">
          <text>TANAKA TETSUOMI</text>
          <document-id>
            <country>US</country>
            <doc-number>5784501</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5784501</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="14">
          <document-id>
            <country>DE</country>
            <doc-number>4135881</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>DE4135881</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="15">
          <text>NEDERLANDEN STAAT</text>
          <document-id>
            <country>EP</country>
            <doc-number>0045549</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>EP--45549</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="16">
          <text>NIPPON TELEGRAPH &amp; TELEPHONE</text>
          <document-id>
            <country>JP</country>
            <doc-number>H02206894</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP02206894</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="17">
          <text>NIPPON TELEGRAPH &amp; TELEPHONE</text>
          <document-id>
            <country>JP</country>
            <doc-number>H06131492</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP06131492</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="18">
          <text>UNISYS CORP, et al</text>
          <document-id>
            <country>WO</country>
            <doc-number>9206449</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>WO9206449</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Sharp Kabushiki Kaisha</orgname>
            <address>
              <address-1>Osaka, JP</address-1>
              <city>Osaka</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>SHARP</orgname>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Nakamura, Mitsuaki</name>
            <address>
              <address-1>Yamatokooriyama, JP</address-1>
              <city>Yamatokooriyama</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Nixon &amp; Vanderhye, P.C.</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Bella, Matthew C.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>LAPSED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A character recognition method for recognizing characters on an article having multiple character-bearing areas, such as a license plate, first involves obtaining image data from an image of the article.
      <br/>
      The method then assigns at least one parameter to a selected character-bearing area on the article.
      <br/>
      The method then attempts to obtain a correct frame which expresses the correct positional relationship between the selected character-bearing area on the article with other character-bearing areas of the article, and then uses that correct frame to perform character recognition with respect to each of the character-bearing areas of the article.
      <br/>
      To obtain the correct frame, the invention compares the image data of the article with plural candidate frames.
      <br/>
      The plural candidate frames are calculated using the predetermined positional correlation between (1) the selected character-bearing area [as represented by the at least one parameter] and (2) other character-bearing areas of the article.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">
      I.
      <br/>
      Field of the Invention
    </p>
    <p num="2">The present invention concerns character recognition.</p>
    <p num="3">II. Related Art and Other Considerations</p>
    <p num="4">Japanese Laid-Open Patent Publication No. 2-206894 proposes a character recognition method that recognizes characters of, e.g., a license plate of an automobile by binarizing an image of character areas on the license plate and seeking a 4-digit serial number composed of relatively large characters included in the binary image by key features (e.g., width of characters and gap between characters) of the license plate.</p>
    <p num="5">Japanese Laid-Open Patent Publication No. 6-131492 proposes a character recognition method that searches an area by relative positions determined from information on position of a 4-digit serial number and then recognizes characters in each of the determined character areas.</p>
    <p num="6">In the former method it is difficult to accurately determine the position of a serial number if any positional information on any digit of the 4-digit serial number could not correctly be obtained due to (1) noise caused by an incorrect positioning or conditioning of an image-taking camera or (2) the obtained serial number containing only 1 digit or 2 digits, i.e., a reduced number of large-size characters.</p>
    <p num="7">
      The latter method also requires the accurate determination of the serial number because its location is a key to determine areas of the other character areas.
      <br/>
      For example, in this latter method it is difficult to correctly presume character areas in an image of a license plate if the input image lacks a part of a license plate or does not indicate a part of a serial number due to an obstruction or it includes noise signals caused by both side frames, an indicator lamp and so on.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="8">The present invention relates to a character recognizing method which is used for extracting characters (including numerals) indicated for example on a license plate of an automobile and recognizing the extracted characters.</p>
    <p num="9">In view of the foregoing drawbacks of the conventional character recognizing method which extracts serial number and presumes other character areas on the basis of relative positions of the extracted serial number area, the present invention is made to provide a character recognition method which is capable of accurately recognizing all characters contained in an object image of, e.g., a license plate by means of previously setting a certain number of area-frame candidates according to known arrangement of serial-number digit areas, a use-code area, a land-transport administration branch office-name/classification number area, selecting one of the area-frame candidates, which has the minimum inconformity in relative positions of characters in respective character areas, determining respective character areas on the selected area-frame and then recognizing each character in each character area.</p>
    <p num="10">
      An object of the present invention is to provide a character recognizing method which comprises the steps of: extracting information on each of rectangles circumscribing respective characters contained in an inputted binary quantized image; selecting least disagreed one of candidates of area frames preset according to a known format of character areas on a recognition object by comparing each of the candidates with the extracted character-circumscribed rectangles as to inconformity (contradiction) in relative arrangement of the rectangles to character areas on an area frame; and recognizing characters indicated in the s elected character areas respectively.
      <br/>
      A character recognition object (e.g., a license plate of an automobile) has a certain known format of character areas.
      <br/>
      However, the same character-recognition objects may have a variety of sizes and relative positions of character areas as well as a plurality of area-frame candidates.
      <br/>
      As this method compares each of area-frame candidates with extracted information on character-circumscribing rectangles and selects such an area-frame candidate that has the least inconformity of positions of their character areas relative to the rectangles, the selected character areas may have a correct relation with the extracted rectangles even if an input image does not include a part of the character recognition object or lacks a part of information due to an obstruction or it contains noise signals from peripheral portion of the object.
      <br/>
      Thus, the method can attain a high accuracy of character recognition since it recognizes each of characters on the character area candidate selected according to the least inconformity criterion.
    </p>
    <p num="11">
      Another object of the present invention is to provide a character recognition method which includes the content of the invention above mentioned and is further featured in that the step of selecting least disagreed one of area-frame candidates consists of calculating a degree of inconformity in properties and conditions of character areas of candidate to the extracted information on character-circumscribed rectangles, determining a total of the calculated inconformity values of the character areas and selecting an area frame having the least inconformity.
      <br/>
      This method can attain a considerably improved accuracy of selecting a correct area frame.
    </p>
    <p num="12">
      A further object of the present invention is to provide a character recognition method which includes the content of the invention first-mentioned and is further featured in that the step of recognizing a string of characters selects a character string having the largest average value of similarities of compare d characters.
      <br/>
      A character string consists of a known and considerable limited combination of characters.
      <br/>
      Therefore, this method can attain an increased accuracy of recognizing a character string owing to selecting a character string whose characters have the largest value of similarity with those of the previously determined character string.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="13">
      FIG. 1 is a block diagram showing a construction of an apparatus for realizing a character recognition method of recognizing characters on a license plate, which is a first embodiment of the present invention.
      <br/>
      FIG. 2 is a flow chart describing a processing procedure of the method of recognizing characters on a license plate in the first embodiment of the present invention.
      <br/>
      FIG. 3 shows a register table for storing information on character-circumscribing rectangles in the first embodiment.
      <br/>
      FIG. 4 is a view indicating sizes and positions of respective character areas in a license plate frame to be recognized by the first embodiment of the present invention.
      <br/>
      FIG. 5 is a flow chart describing the steps of processing a license plate frame by the first embodiment of the present invention.
      <br/>
      FIG. 6 is a flow chart describing the steps of processing a license plate frame by the first embodiment of the present invention (continuation of FIG. 5 ).
      <br/>
      FIG. 7 shows a correct plate frame to be selected and a presumed (temporary) plate frame in the first embodiment of the present invention.
      <br/>
      FIG. 8 shows a table wherein character strings obtained by a second embodiment of the present invention for an area of an administration branch office-name and a classification number are arranged in a descending order of similarity.
      <br/>
      FIG. 9 shows a method of determining an administration branch office-name by average similarity value of a character string according to the second embodiment of the present invention.
    </p>
    <heading>PREFERRED EMBODIMENT OF THE INVENTION</heading>
    <p num="14">
      Preferred embodiments of the present invention will be described below in detail with reference to the accompanying drawings.
      <br/>
      In the following description, character recognizing methods are applied, by way of example, to recognizing characters indicated on a license plate of an automobile.
    </p>
    <p num="15">�Embodiment 1�</p>
    <p num="16">
      FIG. 1 is a block diagram showing a construction of a license-plate character recognizing system which is based on the character recognizing method according to the present invention.
      <br/>
      In FIG. 1, the system is composed of image inputting means 101 (e.g., a CCD camera) for inputting an image of a license plate, an A/D converter 102 for converting analog signals of the input image into digital signals, a frame memory 103 for storing multivalued image digitized by the A/D converter 102, binary-quantizing means 104 for converting the multivalued image of the license plate into a binary image, character-circumscribing rectangle information extracting means 105 for extracting character-circumscribing rectangle information from the binary image, plate frame presuming means 106 for presuming a frame of a license plate according to the character-circumscribing rectangle information, a plate character dictionary 107 for looking up characters contained in an image of the license plate, serial number recognizing means 108 for recognizing characters in areas N1 to N4 (shown in FIG. 4) for a serial number, use-code recognizing means 109 for recognizing a Japanese Hiragana character in a use-code area Y, classification number recognizing means 110 for recognizing numerals in a classification number area (.left brkt-top.58.right brkt-bot. shown in FIG. 7), land-transport administration branch office-name recognizing means 111 for recognizing characters (Japanese kanji characters  *  .left brkt-top.+character pullout} +character pullout}.right brkt-bot. shown in FIG. 7) in an area for a name code of a Land-Transport Administration branch office, and result outputting means 112 for outputting results of recognition made by respective recognizing means 108 to 111.
    </p>
    <p num="17">
      FIG. 2 is a flow chart describing a procedure of recognizing characters on an image of a license plate by a character recognition method which is the first embodiment of the present invention.
      <br/>
      The procedure includes the steps of extracting each character-circumscribing rectangle information (Step S101), presuming a plate frame (Step S102), recognizing a serial number (Step S103), recognizing a use-code (Step S104), recognizing a classification number (Step S105), recognizing a name of land-transport administration branch office (Step S106).
    </p>
    <p num="18">
      A license-plate image inputted by the image input means 101 converted by the A/D converter 102 into a multivalued image which is then stored in the frame memory 103.
      <br/>
      The multivalued image is further converted by the binary-quantizing means 104 into a binary image which is transmitted to the character-circumscribing rectangle information extracting means 105.
      <br/>
      The binary-quantizing means 101 may binarize the multivalued image by discriminant analysis or any other method that can not impair the character information.
    </p>
    <p num="19">The character-circumscribing rectangle information extracting means 105 performs the processing step S101 for extracting information on rectangles circumscribing respective characters in the manner described below:</p>
    <p num="20">
      The binary image of the license plate is processed by labeling.
      <br/>
      Namely, characters and background are distinguished from each other by giving different values to them.
      <br/>
      Each of the labeled characters is circumscribed by a rectangle.
      <br/>
      Coordinates of left top, right bottom and center points of each rectangle are extracted as character-circumscribing rectangle information and are registered in a table 105a as shown in FIG. 3.
    </p>
    <p num="21">At this stage, noise caused by binarizing the multivalued image and by a plate frame is judged from positions and sizes of the rectangles and may be omitted from the table.</p>
    <p num="22">
      In FIG. 3, the first (1st) Line or the second (2nd) line correspond to the 1st line area and the 2nd line area, respectively, of FIG. 4.
      <br/>
      Characters contained in a license plate image are divided by a boundary line V into characters in an upper area R (i.e., a name of the administration branch office-name and classification number in the area R) and characters in lower areas (i.e., use-code in area Y and a serial-number figures in areas N1 to N4 ).
      <br/>
      In the plate frame 300, an area of upper character string and an area of the lower character string are hereinafter referred to as the 1st line area 301 and the 2nd line area 302 respectively.
    </p>
    <p num="23">
      The boundary V can be easily determined from an image with vertical edges extracted by horizontally differentiating the multivalued license-plate image or from a horizontal integration of optical density values of the binarized image of the multivalued license-plate image.
      <br/>
      In the latter case, the boundary V lies on the bottom between two peaks of the vertically distributing integration values, which corresponds to a blank space between the 1st line and the 2nd line on the license plate (see FIG. 4).
      <br/>
      The top end Ptop and the bottom end Pbottom can be easily presumed from the shape of vertically distributing integration values.
    </p>
    <p num="24">The plate frame presuming means 106 performs the processing step S102 of presuming the license plate frame in the manner described below:</p>
    <p num="25">
      A license plate has a plate frame 300 which has a particular format as shown in FIG. 4 arranging serial-number digit areas N1 to N4, a hyphen area H and use-code area Y in the 2nd line and an area R for an administration branch office-name and a classification number in the 1st line in a particular format as shown in FIG. 4.
      <br/>
      In the plate frame 300 of FIG. 4, coordinates of the left-end point, the right-end point or the center point of any one of areas N1 to N4, Y, H and R and width w of any one of the serial-number digit areas N1 to N4 are determined, so positions and configurations of the other areas can be uniquely determined.
      <br/>
      Namely, by determining a position and a width of a certain area on a plate it is possible to determine all other areas thereon.
      <br/>
      A whole area varies depending upon a position and a width of the same determined area.
    </p>
    <p num="26">
      Using known positional correlation between the serial number area N1 to N4, the hyphen area H, the use-code area Y and the administration branch office-name and classification number area R, several candidates of plate frames 300 are prepared in advance to be compared with information of character-circumscribing rectangles extracted from an input image of a license plate.
      <br/>
      Namely, one of the candidates, which is least disagreed from the input image information, is searched and selected.
    </p>
    <p num="27">
      It is then assumed that a plurality of candidate plate-frames 300 is set by using combinations of positions and width values of the areas N1 to N4 for a 4-digit serial number.
      <br/>
      One of the candidates, which best corresponds to an input image of a plate-frame, is determined by a method shown in flowcharts of FIGS. 5 and 6.
    </p>
    <p num="28">
      Now, it is assumed that a rectangle circumscribing an i-th character in the 2nd line is placed in a serial number area Nk (k=1, 2, 3, 4) and a center point coordinate of the serial number area Nk is considered as a center point coordinate of said rectangle.
      <br/>
      The width is expressed by w which may be limited in a certain range, i.e., wmin &lt;w&lt;wmax (Step S201).
      <br/>
      For example, wmin may be a minimal width of a character (figure) composing the serial number and wmax may be a maximal width of a character composing the serial number or wmin may be a width of the i-th character-circumscribing rectangle in the 2nd line and wmax may be equal to the left-end coordinate of an (i+1)-th character-circumscribing rectangle minus a right-end coordinate of an (i-1)-th character circumscribing rectangle. umin is an initial inconformity value of each character-circumscribing rectangle in each character area of a plate frame (Step S201).
    </p>
    <p num="29">
      As the serial number area Nk consists of four divisions (digit areas)(k=1 to 4), an initial value is set as k=1 (Step S202).
      <br/>
      A table 150a (FIG. 3) of character-circumscribing rectangle information extracting means 105 contains n pieces of the circumscribing rectangles.
      <br/>
      An initial value of the i-th rectangle is set as i=1 (Step S203).
    </p>
    <p num="30">
      As a character string to be possibly entered into the serial number area Nk (k=1, 2, 3, and 4) is a character string to be entered into an area 302 in the 2nd line, the rectangle number i is examined whether it exists in the 2nd line area 302 (Step S204).
      <br/>
      If so, the rectangle is further examined as to inconformity (Steps S205 to S212).
      <br/>
      No examination is made for the rectangle if its number i exists in the 1st line area (the process is skipped to Step S213).
    </p>
    <p num="31">
      A plate-frame can be set by determining any one of serial-number digit areas Nk and selecting a certain value of its width w (Step S206).
      <br/>
      Since several candidates of plate frames are prepared, a total u of inconformity values of character-circumscribing rectangles to character areas of each plate frame (candidate) is calculated changing a variable w from the minimal value wmin to the maximal value wmax (Step S207).
      <br/>
      For this purpose, the processing procedure includes Step S205 for setting the variable w to wmin, Step S211 for incrementing the variable w and Step S212 for changing the variable w to wmax.
    </p>
    <p num="32">
      The part (a) in FIG. 7 shows a plate frame 400 which is finally considered to be correct relative to an inputted binary image and the part (b) in FIG. 7 shows a plate frame 401 which is temporarily set by the plate-frame presuming means 106 at Step S206 in the flow chart.
      <br/>
      The presumed plate frame 401 has a serial number area Nk (i.e., k=1) of width w.
    </p>
    <p num="33">
      The temporarily presumed plate frame 401 may contain a variety of disagreement (inconformity) in areas other than the serial number area N1 as shown in the part (b) in FIG. 7.
      <br/>
      Accordingly, inconformity of each area to the correct one is numerically estimated by using the below-described criteria and a total of inconformity values of respective areas is considered as a degree of inconformity of the plate frame 401 (Step S207).
    </p>
    <p num="34">
      (i) Degree of total inconformity: The temporarily presumed plate frame 401 must include a character-circumscribing rectangle in each character area.
      <br/>
      Accordingly, a certain inconformity value is given if there is any character-circumscribing rectangle being out of its area.
      <br/>
      In the shown example numeral "7" in the serial number and numeral "8" in the classification number are out of their respective areas.
      <br/>
      (ii) Degree of inconformity in the use-code area: The use-code area Y must include one character of Japanese Hiragana whose height is within 1/3 to 1/2 of that of each figure in the serial number.
      <br/>
      If a character-circumscribing rectangle of the above-mentioned size is resting on the use-code area Y, a difference between center positions of the use-code area Y and the rectangle gives a certain value of inconformity.
      <br/>
      A larger character-circumscribing rectangle entering into the use-code area Y is estimated by giving a certain but not-so large inconformity value because the rectangle may sometimes contain the effect of a plate-frame line and shading.
      <br/>
      (iii) Degree of inconformity in the hyphen area: Concerning a character-circumscribing rectangle having a small height in the hyphen area, a difference of the center position of the hyphen area H from the center of the small rectangle is estimated for giving a certain value of inconformity.
      <br/>
      A large character-circumscribing rectangle being entering into the hyphen area H and jointed by a noise signal to the second digit figure or the third digit figure of the serial number may be wider than each digit figure.
      <br/>
      Such inconformity value is not so large estimated.
      <br/>
      In case if the rectangle is sufficiently narrower than the width w, it may well be a digit figure of the serial number and is given an increased value of inconformity.
      <br/>
      (iv) Degree of inconformity in the serial-number areas: Each digit area Nk must contain a high rectangle circumscribing any one of figures "0" to "9" or a small rectangle circumscribing a small dot " ". In this case, a difference of a digit area center position from a rectangle center position and/or a difference between the size of an area and the size of the rectangle gives a certain value of inconformity.
      <br/>
      (v) Degree of inconformity estimated by contradictions of the use-code area and the serial number areas: Besides the estimation of a value of inconformity (difference of positions and difference of respective areas from respective rectangles, any contradiction in the properties of the plate is estimated and given a certain additional value of inconformity, which is added to a total inconformity of the candidate plate to increase an accuracy of the degree of total inconformity.
      <br/>
      (a) The hyphen is placed only in a 4-digit serial number.
      <br/>
      Accordingly, a certain additional inconformity value is given if there is found such a contradiction that a character-circumscribing rectangle exists in the hyphen area H and a small-dot-circumscribing rectangle in the serial-number digit area.
      <br/>
      (b) One figure of the 4-digit serial number is sure to be circumscribed by one rectangle with no noise signal.
      <br/>
      Accordingly, a certain additional inconformity value is given to such a contradiction that two or more character-circumscribing rectangles exist in a serial-number digit area.
      <br/>
      (c) In a case that a string of serial number figures is composed without using 4-digit figures area, it is required that the string of number figures be shifted to right with the rightmost figure being out of the presumed plate-frame and with the small dot placed in a vacant digit area.
      <br/>
      So, if there occurs such a contradiction that a small dot " " exists in a right area to a serial number existing area, it is given a certain additional inconformity value.
      <br/>
      (vi) Degree of inconformity in the number of characters contained in character areas of the plate frame: Name of a branch office (of the land-transport administration) may consist of one to four Kanji characters (e.g., .left brkt-top.+character pullout}.right brkt-bot. or .left brkt-top.+character pullout}.right brkt-bot. to .left brkt-top.+character pullout}.right brkt-bot.) and a fixing screw may sometimes be on a part of the character area.
      <br/>
      Furthermore, a large-size license plate in distinction from a standard-size license plate has a considerably different size ratio of the branch office-name relative to figures of the serial number and unspecified positions of the use-code and the serial number.
      <br/>
      These facts make it impossible to finely define a degrees of inconformity of the parameters.
      <br/>
      Accordingly, a certain value of inconformity is given in case if the area R of a registration branch name plus a classification number contains not more than three character-circumscribing rectangles.
      <br/>
      Similarly, a certain value of inconformity is given if the use-code area Y plus the serial number areas Nk contains 4 or less character-circumscribing rectangles because it must include at least 5 character-circumscribing rectangles.
    </p>
    <p num="35">The above-described criteria are taken as an example and does not limit the invention thereto.</p>
    <p num="36">
      As described above, inconformity degrees of respective areas are estimated according to the criteria (i) to (vi) and summed up to obtain a total inconformity u (Step S207).
      <br/>
      The obtained total inconformity u is compared with a preceding minimal sum of inconformity values (Step S208) and is set as a new minimal sum of inconformity values umin (Step S209) if it is smaller than the preceding minimal sum of inconformity values umin.
      <br/>
      At step 210, the number k of the serial number area is set in a variable ko, a rectangle number i is set in a variable i(,) and the width w is set in a variable wo.
    </p>
    <p num="37">Steps S206 to S210 relate to processings for setting a temporarily presumed plate frames 401 and comparing with several reference plate-frames to seek a plate-frame having the least inconformity to correct one of known reference plate frames.</p>
    <p num="38">
      The width w is increased with a small increment (Step S211) until it reaches the maximal width wmax (Step S212).
      <br/>
      A new temporary plate frame 401 is set and processed in the same manner as described above to find a new temporary plate-frame 401 of the least inconformity.
    </p>
    <p num="39">
      The number i of a rectangle is changed from 1 to n (through Steps S213, S214) and the same processings as described above are conducted to find a temporary least-inconformity plate-frame 401 at the number k of the serial-number digit area.
      <br/>
      A variety of temporary plate-frames is set by changing the number of the serial-number area from 1 to 4 with an increment of 1 to find respective temporary least-inconformity plate-frames 401.
      <br/>
      Finally, a correct plate-frame 400 is determined on the basis of finally obtained values of the variables ko, io and wo.
      <br/>
      The correct or most-approximated thereto plate-frame must exist among the temporary plate-frames 401 which have been set with all specified values w at all positions of the serial-number digit areas Nk (k=1, 2, 3 and 4).
      <br/>
      The correct or most-approximated plate-frame must have the least inconformity at every character area.
      <br/>
      Namely, the temporary plate-frame 401 of the least inconformity, which has been found through Steps S206 to S210, is least contradictory to the input binary image and therefore determined as the correct plate-frame 400 shown in the part (a) in FIG. 7 (Step S217).
    </p>
    <p num="40">
      The serial-number areas Nk (k=1, 2, 3 and 4), the use-code area Y and the branch office-name/classification-number area R on the license plate-frame are thus determined by the plate-frame presuming means 106 and, then, the processing advances to steps of recognizing characters in respective areas on the plate frame:
      <br/>
      (3) The serial-number recognizing means 108 performs Step S103 (FIG. 2) of recognizing the serial number in the following manner:
    </p>
    <p num="41">
      The serial number consists of four figures which are represented by four character-circumscribing rectangles respectively and placed in corresponding digit areas N1, N2, N3 and N4.
      <br/>
      Accordingly, one of these four character-circumscribing rectangles, which center point exists close to the center of the digit area of the serial-number, is first selected and information of the selected rectangle is referred to only figures in the plate-character dictionary 107.
      <br/>
      The most similar figure found in the dictionary is determined as a recognition result.
      <br/>
      Similarly, other rectangles are processed one by one to determine a correct serial number in the serial-number digit areas.
      <br/>
      A small dot " " that appears in the case of a serial number consisting of less than four figures can be recognized by its size (small rectangle) and therefore determined as a small dot without looking up in the plate-character dictionary.
      <br/>
      (4) The use-code recognizing means performs processing for recognizing a use-code (Step S104 in FIG. 2) as follows:
    </p>
    <p num="42">
      As the use-code area Y contains only one Hiragana character, the use-code recognizing means 109 compares to Hiragana characters in the plate-character dictionary, find a character being most similar to the use-code and recognizes the found character as a correct use-code.
      <br/>
      (5) The classification number recognizing means 110 performs processing step of recognizing a classification number (Step S105 in FIG. 2) as follows:
    </p>
    <p num="43">
      The classification number (e.g., "58" in the part (a) in FIG. 7) consists of two figures of the same height, which is placed to the right side in the area R (for a branch office-name and a classification number) in the 1st line area 301 as shown in FIG. 4.
      <br/>
      Using the above-mentioned condition, the classification number recognizing means 301 reads each of two character-circumscribing rectangles having the substantially same height on the right side of the area R (starting the rightmost rectangle in the 1st line) and looks up the most similar one of reference figures "0" to "9" in the plate character dictionary 107.
      <br/>
      The two figures thus found in the dictionary are finally recognized as a correct classification number.
      <br/>
      (6) The land-transport administration branch office-name recognizing means 111 performs processing for recognizing a registration branch name of the land-transportation administration (Step S106 in FIG. 2) as follows:
    </p>
    <p num="44">
      The classification number (e.g., "58" in the part (a) in FIG. 7) has been determined by the classification number recognizing means.
      <br/>
      The branch office-name, therefore, relates to rectangles other than two right-side rectangles (the classification number) in a character string in the character area R. Accordingly, the land-transport administration branch office-name recognizing means 111 compares information on each of the remaining character-circumscribing rectangles to Kanji and Hiragana characters in the plate-character dictionary to find the most similar characters.
      <br/>
      The characters thus determined are finally recognized as a correct branch office-name.
    </p>
    <p num="45">
      In the above-described embodiment, the character recognition steps were conducted in the order of the serial number, use-code, classification number and registration branch name.
      <br/>
      However, the order of performing the steps can be optionally changed since all character areas on the license plate have been already determined by Step S102 of presuming the plate frame.
    </p>
    <p num="46">
      As described above, all characters in all character areas are correctly recognized through the plate-frame presuming step and the respective character recognizing steps.
      <br/>
      Character recognition results are now outputted by the recognition result outputting means 112.
    </p>
    <p num="47">�Embodiment 2�</p>
    <p num="48">
      A second embodiment of the present invention concerns a license-plate character recognizing method which comprises the steps S101 to S106 of FIG. 2 and conducts the steps S101 to S105 (i.e., all steps excepting the step S106 of recognizing a branch office-name) in the same way as described before for the first embodiment.
      <br/>
      A least contradictory one of candidates is determined as a correct plate-frame 400 wherein a serial number and a use-code are then looked up in a plate-character dictionary 107 and most similar characters are finally recognized as a serial number and a use-code.
    </p>
    <p num="49">
      The branch office-name indicated in a character-string area on the license plate frame may consist of one character (e.g., .left brkt-top.+character pullout}.right brkt-bot., .left brkt-top.+character pullout}.right brkt-bot.) to four characters (e.g., .left brkt-top.+character pullout}.right brkt-bot.).
      <br/>
      Any multicharacter name is composed of a known limited combination of Kanji characters.
      <br/>
      The second embodiment uses the above-mentioned condition to increase the accuracy of recognizing branch office-names that could not be recognized at a high accuracy because of a large number of names and small sizes of characters.
    </p>
    <p num="50">The land-transport administration branch office-name recognizing means 111 performs the processing step (S106 in FIG. 2) for recognizing a branch office-name in the following manner:</p>
    <p num="51">
      A classification number in the area R (for a branch office-name and a classification number) is already determined by classification number recognizing means 110.
      <br/>
      Accordingly, the branch office-name relates to the rest part (other than right-hand characters of classification number) of the character string in the area R. The rest character string is now processed as follows:
    </p>
    <p num="52">
      FIG. 8 shows a table wherein character strings obtained by referring characters in a 1st line area 301 (in FIG. 4) to the plate-character dictionary 107 are arranged in the descending order of similarity.
      <br/>
      Referring to FIG. 9, the branch office-name recognizing means 111 reads each character string excepting a classification number (in the area R in FIG. 4) in the table starting from the top thereof and compares the character string to all reference character strings or a part of characters comprising all known branch office-names in the plate-character dictionary 107, arranges combinations of characters in the descending order of average values of similarity.
      <br/>
      A character string having the largest average value of similarity is finally selected as the branch office-name.
      <br/>
      By doing so, it is possible to realize high-accuracy character recognition of the branch office-name indicated on the license plate.
    </p>
    <p num="53">
      In practice, a character string .left brkt-top.+character pullout}.right brkt-bot. of the top rank of similarity in the table (a) in FIG. 9 is referred to branch office-names in plate-character dictionary 107 and a candidate of .left brkt-top.+character pullout}.right brkt-bot. (the key character is .left brkt-top.+character pullout}.right brkt-bot. in this case) is extracted.
      <br/>
      The character .left brkt-top.+character pullout}.right brkt-bot. in the candidate does not meet with the character .left brkt-top.+character pullout}.right brkt-bot. and, therefore, it is looked up in the table.
      <br/>
      Since the character .left brkt-top.+character pullout}.right brkt-bot. is found in the second rank character string in the table, the character string .left brkt-top.+character pullout}.right brkt-bot. is obtained and its average value of similarity is equal to 35 by averaging the similarity value 50 and 35 of two characters (see FIG. 9).
    </p>
    <p num="54">
      The table (a) in FIG. 9 contains a character .left brkt-top.+character pullout}.right brkt-bot. (not shown) with a similarity value of 14 as a first character of the 14th rank character-string, a characters .left brkt-top.+character pullout}.right brkt-bot. (not shown) with a similarity value of 10 as a second character of the same rank character-string and a character .left brkt-top.+character pullout}.right brkt-bot. (not shown) with a similarity value of 10 in the 10th rank character-string.
      <br/>
      Accordingly, further similar operations can obtain character strings .left brkt-top.+character pullout}.right brkt-bot. (with an average similarity value of 27), .left brkt-top.+character pullout}.right brkt-bot. (with an average similarity value of 21) and .left brkt-top.+character pullout}.right brkt-bot. (with an average similarity value of 15) as shown in the table (b) in FIG. 9.
      <br/>
      Thus, the table (b) in FIG. 9 registers therein candidates of the branch office-name in the descending order of the average similarity values and the character string .left brkt-top.+character pullout}.right brkt-bot. having the largest average value of similarity is selected as the correct branch office-name.
    </p>
    <p num="55">Although the above-mentioned method uses the average similarity as a criterion of recognizing the branch office-name, the present invention is not limited to the average similarity criterion and allows use of other criteria such as relative positions of characters, the number of characters, ranks of candidates and the like.</p>
    <p num="56">Although the above-described embodiments 1 and 2 of the present invention are applied for recognizing characters on a license plate for an automobile, the present invention is not limited to the embodiments and can be also applied for recognizing characters of any character image having a specified format, for example, ship name plates, road signs and so on.</p>
    <p num="57">
      The character recognition method according to the present invention comprises the steps of extracting information on each of rectangles circumscribing respective characters contained in an inputted binary quantized image and selecting least disagreed (inconformity) one of area-frame candidates preset according to a known format of character areas on a recognition object by means of comparing each of the candidates with the extracted character-circumscribing rectangles as to inconformity (contradiction) of relative arrangement of the rectangles to character areas on the character frame and recognizing characters indicated in the selected character areas respectively.
      <br/>
      As this method compares each of area-frame candidates with an extracted information on character-circumscribing rectangles and selects such an area-frame candidate that is least disagreed with the rectangles as to positions of their character areas relative to the rectangles, the selected character areas may have a correct relation with the extracted rectangles even if an input image does not include a part of the character recognition object or lacks a part of information due to an obstruction or contains noise signals from peripheral portion of the object.
      <br/>
      Thus, the method can attain a high accuracy of character recognition since it recognizes each of characters on the character area candidate selected by the least disagreed principle.
    </p>
    <p num="58">
      The character recognition method according to the present invention is featured in that the step of selecting least disagreed one of area-frame candidates includes calculating a degree of disagreement in properties and conditions of character areas of candidate with the extracted information on character-circumscribing rectangles, determining a total of the calculated disagreements of the character areas and selecting an area frame having the least inconformity.
      <br/>
      Thus, the method can attain a considerably improved accuracy of selecting a correct area frame.
    </p>
    <p num="59">
      The character recognition method according to the present invention is featured in that the step of recognizing a string of characters selects a character string having a largest average value of similarity of compared characters.
      <br/>
      A character string composed of a combination of characters is known and considerably restricted.
      <br/>
      This method can attain an increased accuracy of recognizing a character string by selecting a character string having the largest average similarity, which is composed of characters each having a largest value of similarity to each of the restricted character strings.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A character recognition method comprising the steps of:</claim-text>
      <claim-text>obtaining, from an input binary-quantized image, an input pattern of plural rectangles, each rectangle having a rectangle position and circumscribing a respective character-bearing area; collectively comparing, for each of plural candidate frames, the rectangle positions of the plural rectangles of the input pattern with respective plural predetermined rectangle positions of the plural candidate frames; selecting one of the candidate frames having the least inconformity with the input pattern as a selected candidate frame;</claim-text>
      <claim-text>and then recognizing characters in the input pattern based on the rectangle positions of the selected candidate frame.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. A character recognition method as defined in claim 1, wherein the step of selecting the selected candidate frame includes: for each candidate frame:</claim-text>
      <claim-text>- calculating a degree of inconformity with respect to each rectangle position in the input pattern, - determining a total of the calculated inconformity values over all rectangle positions of the input pattern, and using the total to select the selected candidate frame.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. A character recognition method as defined in claim 1, wherein the step of recognizing characters includes recognizing a string of characters by selecting a character string having a largest average value of similarity of component characters.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The method of claim 1, wherein the input pattern is obtained from an article having multiple character-bearing areas circumscribed by respective ones of the plural rectangles, and wherein the method further comprises: assigning at least one parameter to a selected character-bearing area on the article; calculating the plural candidate frames using a predetermined positional correlation between the selected character-bearing area as represented by the at least one parameter and other character-bearing areas of the article.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The method of claim 4, further comprising assigning a position parameter and a width parameter to the selected character-bearing area.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The method of claim 4, wherein the at least one parameter is assigned by iterating between a maximum and a minimum value of the at least one parameter, and wherein for each iterated value of the parameter the comparing step is performed with the candidate frames being prepared using the predetermined positional correlation between the selected character-bearing area as represented by the iterated value of the parameter and the other character-bearing areas of the article, and wherein the correct frame is obtained considering all iterations of the parameter.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. The method of claim 6, wherein the iterated at least one parameter is area width.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The method of claim 4, wherein the comparing step involves determining a degree of inconformity of each of the plural candidate frames with respect to predetermined criteria.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. The method of claim 8, wherein the predetermined criteria includes criteria pertaining to plural ones of the character-bearing areas.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. The method of claim 8, wherein the correct frame has a least inconformity with respect to each of the character-bearing areas.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. The method of claim 1, wherein the input image is obtained from a license plate.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. The method of claim 11, wherein the selected character-bearing area is in a predetermined portion of the license plate.</claim-text>
    </claim>
  </claims>
</questel-patent-document>