<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06184682B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06184682</doc-number>
        <kind>B2</kind>
        <date>20010206</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6184682</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="27491656" extended-family-id="1220513">
      <document-id>
        <country>US</country>
        <doc-number>09290817</doc-number>
        <kind>A</kind>
        <date>19990413</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1999US-09290817</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>43170343</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>29081799</doc-number>
        <kind>A</kind>
        <date>19990413</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1999US-09290817</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>US</country>
        <doc-number>10970498</doc-number>
        <kind>P</kind>
        <date>19981124</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1998US-60109704</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="3">
        <country>US</country>
        <doc-number>8186498</doc-number>
        <kind>P</kind>
        <date>19980415</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="3">
        <doc-number>1998US-60081864</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="4">
        <country>US</country>
        <doc-number>10948898</doc-number>
        <kind>P</kind>
        <date>19981123</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="4">
        <doc-number>1998US-60109488</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010206</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G06T   5/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>324309000</text>
        <class>324</class>
        <subclass>309000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>324300000</text>
        <class>324</class>
        <subclass>300000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>324307000</text>
        <class>324</class>
        <subclass>307000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G06T-005/00D</text>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>005</main-group>
        <subgroup>00D</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-005/003</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>003</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140220</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-005/10</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>10</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140220</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-005/50</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>50</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140220</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2207/10016</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2207</main-group>
        <subgroup>10016</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140220</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2207/10088</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2207</main-group>
        <subgroup>10088</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140220</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="6">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2207/20056</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2207</main-group>
        <subgroup>20056</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140220</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="7">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2207/30004</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2207</main-group>
        <subgroup>30004</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140220</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="8">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2207/30168</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2207</main-group>
        <subgroup>30168</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20140220</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>9</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>3</number-of-drawing-sheets>
      <number-of-figures>3</number-of-figures>
      <image-key data-format="questel">US6184682</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Correction of MR images for motion artifacts using navigator echoes and autocorrection</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>SACHS TODD S, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5427101</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5427101</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>FU ZHUO F, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5539312</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5539312</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="3">
          <text>HOFLAND LENNART, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5800354</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5800354</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="4">
          <text>CHARLES HAL C, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4567893</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4567893</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="5">
          <text>PELC NORBERT J, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4663591</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4663591</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="6">
          <text>PELC NORBERT J, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4706026</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4706026</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="7">
          <text>GLOVER GARY H, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4731583</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4731583</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="8">
          <text>EHMAN RICHARD L, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4937526</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4937526</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="9">
          <text>SECR DEFENCE, et al</text>
          <document-id>
            <country>WO</country>
            <doc-number>9801828</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>WO9801828</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="1">
          <text>Automatic Compensation of Motion Artifacts In MRI, MRM 41:163-170 (1999), Atkinson, et al.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="2">
          <text>An Autofocus Algorithm for the Automatic Correction of Motion Artifacts in MR Images,pp. 341-354, David Atkinson, et al.</text>
        </nplcit>
      </citation>
    </references-cited>
    <related-documents>
      <related-publication>
        <document-id>
          <country>US</country>
          <doc-number>60/109,704;</doc-number>
          <date>19981124</date>
        </document-id>
        <document-id>
          <country>US</country>
          <doc-number>60/109704</doc-number>
          <date>19981124</date>
        </document-id>
        <document-id>
          <country>US</country>
          <doc-number>60/081864</doc-number>
          <date>19980415</date>
        </document-id>
        <document-id>
          <country>US</country>
          <doc-number>60/109488</doc-number>
          <date>19981123</date>
        </document-id>
      </related-publication>
    </related-documents>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Mayo Foundation for Medical Education and Research</orgname>
            <address>
              <address-1>Rochester, MN, US</address-1>
              <city>Rochester</city>
              <state>MN</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>MAYO FOUNDATION FOR MEDICAL EDUCATION &amp; RESEARCH</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Ehman, Richard L.</name>
            <address>
              <address-1>Rochester, MN, US</address-1>
              <city>Rochester</city>
              <state>MN</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Felmlee, Joel P.</name>
            <address>
              <address-1>Rochester, MN, US</address-1>
              <city>Rochester</city>
              <state>MN</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="3">
          <addressbook lang="en">
            <name>Manduca, Armando</name>
            <address>
              <address-1>Rochester, MN, US</address-1>
              <city>Rochester</city>
              <state>MN</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="4">
          <addressbook lang="en">
            <name>McGee, Kiaran P.</name>
            <address>
              <address-1>Rochester, MN, US</address-1>
              <city>Rochester</city>
              <state>MN</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Quarles &amp; Brady, LLP</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Oda, Christine K.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>GRANTED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      Navigator echo signals are acquired during an MRI scan in which image data is acquired.
      <br/>
      The navigator echo signals are used to estimate an initial correction of the acquired image data for patient motion during the scan.
      <br/>
      The initially corrected image data is then autocorrected in an iterative process which measures image quality and makes further corrections to the image data until the measured image quality is within tolerance.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <p num="1">
      This application is based upon U.S Provisional Pat. application Ser.
      <br/>
      Nos. 60/109,704; 60/081,864 and 60/109,488 filed on Nov. 24, 1998; Apr. 15, 1998 and Nov. 23, 1998, respectively.
    </p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="2">
      The field of the invention is nuclear magnetic resonance imaging methods and systems.
      <br/>
      More particularly, the invention relates to the correction of motion artifacts in MR images.
    </p>
    <p num="3">
      When a substance such as human tissue is subjected to a uniform magnetic field (polarizing field B0), the individual magnetic moments of the spins in the tissue attempt to align with this polarizing field, but precess about it in random order at their characteristic Larmor frequency.
      <br/>
      If the substance, or tissue, is subjected to a magnetic field (excitation field B1) which is in the x-y plane and which is near the Larmor frequency, the net aligned moment, Mz, may be rotated, or "tipped", into the x-y plane to produce a net transverse magnetic moment Mt.
      <br/>
      A signal is emitted by the excited spins after the excitation signal B1 is terminated, this signal may be received and processed to form an image.
    </p>
    <p num="4">
      When utilizing these signals to produce images, magnetic field gradients (Gx Gy and Gz) are employed.
      <br/>
      Typically, the region to be imaged is scanned by a sequence of measurement cycles in which these gradients vary according to the particular localization method being used.
      <br/>
      The resulting set of received NMR signals are digitized and processed to reconstruct the image using one of many well known reconstruction techniques.
    </p>
    <p num="5">
      Object motion during the acquisition of NMR image data produces both blurring and "ghosts" in the phase-encoded direction.
      <br/>
      Ghosts are particularly apparent when the motion is periodic, or nearly so.
      <br/>
      For most physiological motion each view of the NMR signal is acquired in a period short enough that the object may be considered stationary during the acquisition window.
      <br/>
      In such case the blurring and ghosting is due to the inconsistent appearance of the object from view to view.
      <br/>
      Motion that changes the appearance between views such as that produced by a patient moving, by the respiration or the cardiac cycle, or by peristalsis, is referred to hereinafter as "view-to-view motion".
      <br/>
      Motion may also change the amplitude and phase of the NMR signal as it evolves during the pulse sequence and such motion is referred to hereinafter as "in-view motion".
    </p>
    <p num="6">
      Both blurring and ghosting can be reduced if the data acquisition is synchronized with the functional cycle of the object to reduce view-to-view motion.
      <br/>
      This method is known as gated NMR scanning, and its objective is to acquire NMR data at the same point during successive functional cycles so that the object "looks" the same in each view.
      <br/>
      The drawback of gating is that NMR data may be acquired only during a small fraction of the object's functional cycle, and even when the shortest acceptable pulse sequence is employed, the gating technique can significantly lengthen the data acquisition.
    </p>
    <p num="7">
      Another proposed method for eliminating ghost artifacts is disclosed in U.S. Pat. No. 4,567,893, issued on Feb. 4, 1986. This prior patent teaches that the distance in the image between the ghosts and the object being imaged is maximized when the NMR pulse sequence repetition time is an odd multiple of one-fourth of the duration of the periodic signal variation.
      <br/>
      This can be used to alleviate ghosts due to respiratory motion.
      <br/>
      While this method, indeed, improves image quality, it does impose a constraint on the NMR pulse sequence repetition time and it often results in a longer total scan time.
      <br/>
      It also assumes that the motion is periodic.
    </p>
    <p num="8">
      Yet another method for reducing the undesirable effects due to periodic signal variations is disclosed in U.S. Pat. No. 4,706,026 issued on Nov. 10, 1987 and entitled "A Method For Reducing Image Artifacts Due To Periodic Variations In NMR Imaging." In one embodiment of this method, an assumption is made about the signal variation period (e.g. due, for example, to patient respiration) and the view order is altered from the usual monotonically increasing phase-encoding gradient to a preselected order.
      <br/>
      For a given signal variation period, a view order is chosen so as to make the NMR signal variation as a function of the phase-encoding amplitude be at a desired frequency.
      <br/>
      In one embodiment, the view order is selected such that the variation period appears to be equal to the total NMR scan time (low frequency) so that the ghost artifacts are brought as close to the object being imaged as possible.
      <br/>
      In another embodiment (high frequency), the view order is chosen to make the variation period appear to be as short as possible so as to push the ghost artifacts as far from the object as possible.
    </p>
    <p num="9">
      This prior method is effective in reducing artifacts, and is in some respects ideal if the variation is rather regular and at a known frequency.
      <br/>
      On the other hand, the method is not very robust if the assumption made about the motion temporal period does not hold (e.g., because the patient's breathing pattern changes or is irregular).
      <br/>
      If this occurs, the method loses some of its effectiveness because the focusing of the ghosts, either as close to the object or as far from the object as possible, becomes blurred.
      <br/>
      A solution to this problem is disclosed in U.S. Pat. No. 4,663,591 which is entitled "A Method For Reducing Image Artifacts Due To Periodic Signal Variations in NMR Imaging." In this method, the non-monotonic view order is determined as the scan is executed and is responsive to changes in the period so as to produce a desired relationship (low frequency or high frequency) between the signal variations and the gradient parameter.
      <br/>
      The effectiveness of this method, of course, depends upon the accuracy of the means used to sense the patient motion, and particularly, any variations in the periodicity of that motion.
    </p>
    <p num="10">
      Yet another method for reducing motion artifacts in NMR images is referred to in the art as "gradient moment nulling".
      <br/>
      This method requires the addition of gradient pulses to the pulse sequence which cancel, or null, the effect on the NMR signal phase caused by spins moving in the gradients employed for position encoding.
      <br/>
      Such a solution is disclosed, for example, in U.S. Pat. No.4,731,583 entitled "Method For Reduction of NMR Image Artifacts Due To Flowing Nuclei By Gradient Moment Nulling".
    </p>
    <p num="11">
      The most successful method for correcting MR images for motion artifacts employs navigator signals acquired during the scan.
      <br/>
      As described in U.S. Pat. No. 4,937,526, such navigator signals are acquired periodically during the scan, and the information in these signals may be used to correct the image data for patient motion.
      <br/>
      Unfortunately, acquisition of the navigator signals increases the scan time.
    </p>
    <p num="12">
      More recently, an automatic correction method has been proposed by D. Atkinson et al., "Information Processing in Medical Imaging", P.341-354,1997.
      <br/>
      This method is an adaptive motion correction algorithm that does not require an in vivo measurement of the motion record, but instead, applies motion correction estimates to the k-space data.
      <br/>
      The entropy of the reconstructed image is examined as a focus criterion by which to iteratively adjust the motion estimate.
      <br/>
      This prior method, due to the properties of entropy, works mostly by making dark areas as dark as possible (thus removing ghosting), but does not use much information from the bright areas of the image.
      <br/>
      As a consequence, MR images processed in this manner often do not become as sharp as they should be.
      <br/>
      While this method works well on simple test images, it requires extended processing time when used to correct clinical images.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="13">
      The present invention relates to a significant improvement in the autocorrection approach which makes it a practical tool for the correction of clinical images.
      <br/>
      More specifically, the present invention is an improved autocorrection method in which a navigator echo signal is acquired and used to measure patient position, image data is acquired by sampling regions of k-space, correcting the regions of k-space data are corrected using the measured position to calculate an initial correction estimate; and performing an autocorrection of the k-space data by iteratively estimating corrections to the k-space data, reconstructing an image using the corrected k-space data, measuring the quality of the reconstructed image and repeating the autocorrection until image quality is within tolerance.
      <br/>
      By "seeding" the autocorrection of the k-space data based on measured patient position determined from a navigator echo signal, the process rapidly converges to the best image quality possible.
    </p>
    <p num="14">
      A general object of the invention is to reduce the time required to autocorrect an image.
      <br/>
      By increasing the scan time by a small amount in order to acquire one or more of navigator echo signals, the processing time required to produce the best image possible is significantly reduced.
      <br/>
      In a preferred embodiment, the processing time required to perform autocorrection of an image was reduced by 50% when an initial motion correction based on navigator signal position information was made.
    </p>
    <p num="15">
      The foregoing and other objects and advantages of the invention will appear from the following description.
      <br/>
      In the description, reference is made to the accompanying drawings which form a part hereof, and in which there is shown by way of illustration a preferred embodiment of the invention.
      <br/>
      Such embodiment does not necessarily represent the full scope of the invention, however, and reference is made therefore to the claims herein for interpreting the scope of the invention.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="16">
      FIG. 1 is a block diagram of an MRI system which employs the present invention;
      <br/>
      FIG. 2 is a flow chart which illustrates the steps performed by the MRI system of FIG. 1 to practice the preferred embodiment of the invention; and
      <br/>
      FIG. 3 is a pictorial representation of how acquired image data is corrected using navigator signal information.
    </p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENT</heading>
    <p num="17">
      Referring first to FIG. 1, there is shown the major components of a preferred MRI system which incorporates the present invention.
      <br/>
      The operation of the system is controlled from an operator console 100 which includes a keyboard and control panel 102 and a display 104.
      <br/>
      The console 100 communicates through a link 116 with a separate computer system 107 that enables an operator to control the production and display of images on the screen 104.
      <br/>
      The computer system 107 includes a number of modules which communicate with each other through a backplane.
      <br/>
      These include an image processor module 106, a CPU module 108 and a memory module 113, known in the art as a frame buffer for storing image data arrays.
      <br/>
      The computer system 107 is linked to a disk storage 111 and a tape drive 112 for storage of image data and programs, and it communicates with a separate system control 122 through a high speed serial link 115.
    </p>
    <p num="18">
      The system control 122 includes a set of modules connected together by a backplane.
      <br/>
      These include a CPU module 119 and a pulse generator module 121 which connects to the operator console 100 through a serial link 125.
      <br/>
      It is through this link 125 that the system control 122 receives commands from the operator which indicate the scan sequence that is to be performed.
      <br/>
      The pulse generator module 121 operates the system components to carry out the desired scan sequence.
      <br/>
      It produces data which indicates the timing, strength and shape of the RF pulses which are to be produced, and the timing of and length of the data acquisition window.
      <br/>
      The pulse generator module 121 connects to a set of gradient amplifiers 127, to indicate the timing and shape of the gradient pulses to be produced during the scan.
      <br/>
      The pulse generator module 121 also receives patient data from a physiological acquisition controller 129 that receives signals from a number of different sensors connected to the patient, such as ECG signals from electrodes or respiratory signals from a bellows.
      <br/>
      And finally, the pulse generator module 121 connects to a scan room interface circuit 133 which receives signals from various sensors associated with the condition of the patient and the magnet system.
      <br/>
      It is also through the scan room interface circuit 133 that a patient positioning system 134 receives commands to move the patient to the desired position for the scan.
    </p>
    <p num="19">
      The gradient waveforms produced by the pulse generator module 121 are applied to a gradient amplifier system 127 comprised of Gx, Gy and Gz amplifiers.
      <br/>
      Each gradient amplifier excites a corresponding gradient coil in an assembly generally designated 139 to produce the magnetic field gradients used for position encoding acquired signals.
      <br/>
      The gradient coil assembly 139 forms part of a magnet assembly 141 which includes a polarizing magnet 140 and a whole-body RF coil 152. a transceiver module 150 in the system control 122 produces pulses which are amplified by an RF amplifier 151 and coupled to the RF coil 152 by a transmit/receive switch 154.
      <br/>
      The resulting signals radiated by the excited nuclei in the patient may be sensed by the same RF coil 152 and coupled through the transmit/receive switch 154 to a preamplifier 153.
      <br/>
      The amplified NMR signals are demodulated, filtered, and digitized in the receiver section of the transceiver 150.
      <br/>
      The transmit/receive switch 154 is controlled by a signal from the pulse generator module 121 to electrically connect the RF amplifier 151 to the coil 152 during the transmit mode and to connect the preamplifier 153 during the receive mode.
      <br/>
      The transmit/receive switch 154 also enables a separate RF coil (for example, a head coil or surface coil) to be used in either the transmit or receive mode. 20 The NMR signals picked up by the RF coil 152 are digitized by the transceiver module 150 and transferred through a backplane 118 to a memory module 160 in the system control 122.
      <br/>
      When the scan is completed and an entire array of data has been acquired in the memory module 160, an array processor 161 operates to Fourier transform the data into an array of image data.
      <br/>
      This image data is conveyed through the serial link 115 to the computer system 107 where it is stored in the disk memory 111.
      <br/>
      In response to commands received from the operator console 100, this image data may be archived on the tape drive 112, or it may be further processed by the image processor 106 and conveyed to the operator console 100 and presented on the display 104.
    </p>
    <p num="20">For a more detailed description of the transceiver 150, reference is made to U.S. Pat. Nos. 4,952,877 and 4,992,736 which are incorporated herein by reference.</p>
    <p num="21">
      The hypothesis of this invention is that navigator echoes and 35 autocorrection can be combined into a single correction approach which combines the advantages and reduces the disadvantages of either technique alone.
      <br/>
      To understand how a single navigator echo can be used to determine the position of an object during imaging, first consider a basic 2DFT spin-echo imaging sequence.
      <br/>
      In this situation, the k-space signal is described by:
      <br/>
      Mxy (kx, ky)=.intg..intg.mxy (x,y)e-2 PI ikx x e-2 PI iky y dxdy   (1)
    </p>
    <p num="22">
      where mxy (x,y) is the spatial distribution of magnetization and kx and ky are the k-space spatial frequency terms which are proportional to the gradients Gx and Gy respectively.
      <br/>
      A navigator (NAV) echo is obtained by acquiring an image echo without phase encoding resulting in the signal:
      <br/>
      NAV(k)=Mxy (kx,0)=.intg..intg.mxy (x,y)dye- PI ikx x dx   (2)
    </p>
    <p num="23">
      Eq. 2 is a version of the central slice theorem and states that the Fourier transform of the projection of the object is equal to the k-space image data where ky is equal to zero.
      <br/>
      When the readout gradient direction for the navigator echo is reversed then Eq. 2 becomes:
      <br/>
      NAV(k)=Mxy (0,ky)=.intg..intg.mxy (x,y)dxe-2 PI iky y dy   (3)
    </p>
    <p num="24">and the navigator echo is now sensitized along the phase encoding direction of the acquired k-space image data of equation (1).</p>
    <p num="25">
      When rigid body motion occurs along the phase encoding direction during image acquisition, an extra phase term is added to each k-space view according to:
      <br/>
      Mxy (kx,ky)=Mxy (kx,ky)e i DELTA  PHI (ky )  (4)
    </p>
    <p num="26">
      where ei DELTA  PHI (ky ) is the phase term, which is constant for a given view.
      <br/>
      In an ideal situation, this term can be isolated from the motion corrupted data set by calculating the k-space phase difference between a navigator echo signal as expressed in equation (3) and the corrupted image data for the sample at kx =0.
      <br/>
      That is:
      <br/>
      DELTA  PHI (ky)=arg�Mxy (0,ky)�-arg�NAV(k)�  (5)
    </p>
    <p num="27">
      where arg represents the phase of the complex signal.
      <br/>
      Once  DELTA  PHI (ky) is determined, motion induced artifacts can be reduced by correction of the acquired k-space image data with the view-to-view phase term - DELTA  PHI (ky).
    </p>
    <p num="28">
      This initial correction of one view of acquired k-space image data is illustrated in FIG. 3.
      <br/>
      The view 10 to be corrected is at a particular ky phase encoding and is comprised of samples along the ky imaging readout gradient axis.
      <br/>
      The navigator signal 12 has no phase encoding (i.e. kx =0) and it is comprised of samples along the ky navigator signal readout gradient axis.
      <br/>
      Ideally, the phase  PHI  of the signal samples at the intersection 14 should be the same, and the phase difference  DELTA  PHI  is the correction estimate in equation (5).
    </p>
    <p num="29">
      The application of Eq. 5 to determine view-to-view phase corrections requires that the image acquisition sequence sample the DC term (in this instance, kx =0) for all image views.
      <br/>
      However, in routine image acquisition this term is not acquired and values of Kx =.+- 0 (slashed zero) 5 cycles/FOV are acquired instead due to the requirements of an even number of sample points imposed by the fast Fourier transform.
      <br/>
      To ensure that the actual DC term is centered, an extra prephasor gradient pulse may be used in some applications along the phase encoding and frequency encoding directions.
      <br/>
      These gradients do not add any extra time to the acquisition.
      <br/>
      For the frequency encoding direction, the extra gradient is included as part of the prephasor of the readout gradient.
      <br/>
      For the phase encoding direction the extra gradient is added as a constant for all phase encoding values.
      <br/>
      Since the resolution of the frequency bin is related to the field of view in any direction by:  (Equation image '1' not included in text)
    </p>
    <p num="30">
      an increment of  DELTA k/2 along the kx, or ky axes is easy to compute and implement.
      <br/>
      The effect of shifting the echo in this manner has no effect on the reconstructed magnitude image.
    </p>
    <p num="31">
      The autocorrection method is employed to reduce image artifacts in k-space image data sets acquired with the MRI system of FIG. 1.
      <br/>
      In the preferred embodiment a scan is performed using the chosen NMR pulse sequence to acquire both image data and navigator data as indicated at process block 200.
      <br/>
      The navigator data is acquired during a prescan in which the readout gradient is switched to the direction of the imaging pulse sequence phase encoding gradient, and as many as ten navigator signals are acquired and averaged together.
      <br/>
      The imaging data is then acquired in the usual manner and stored as a k-space image data set.
    </p>
    <p num="32">
      As indicated at process block 201, the acquired image data is then corrected using the phase information in the navigator signal.
      <br/>
      As indicated above, this is a phase correction as indicated in equation (5) which is made to each view of the k-space image data set.
      <br/>
      That is, the phase difference ( DELTA  PHI ) between the central sample (i.e. kx =0) of each image data view and the phase of the "intersecting" navigator sample is calculated.
      <br/>
      Then, each sample of the image data view is initially corrected by shifting its phase by this amount.
      <br/>
      This initial correction of the image data using an estimate based on the navigator signal measurement of patient position "seeds" the autocorrection process.
    </p>
    <p num="33">
      After this seeding, the iterative autocorrection process begins by selecting, an initial block of image data k-space views as indicated at process block 202.
      <br/>
      In the preferred embodiment 64 views are selected in this initial block.
      <br/>
      The views in this block are then phase shifted as indicated at process block 204 based on an initial motion estimate.
      <br/>
      The altered k-space data set is then Fourier transformed as indicated at process block 206 to produce an image.
      <br/>
      As indicated at process block 208, the image metric is then calculated using this reconstructed image.
      <br/>
      In the preferred embodiment the image metric (F1) applies a one-dimensional gradient operator along the image direction of greatest motion and then calculates the entropy of this gradient.  (Equation image '2' not included in text)
    </p>
    <p num="34">
      If the calculated metric is minimized to within a preset tolerance as determined at decision block 210, the block of 64 views has been corrected and the next block of 64 views is selected as indicated at process block 212 and the process repeats.
      <br/>
      Otherwise, the motion estimate for this block is adjusted at process block 214 and the process is repeated to evaluate the image metric with the corresponding adjusted phase shift.
    </p>
    <p num="35">
      All blocks of k-space views are separately adjusted in phase starting at the center of k-space and working outward.
      <br/>
      When the last block has been corrected as determined at decision block 216, the block size is reduced in size as indicated at process block 218 and the system branches back to process block 202 to repeat the steps on the smaller block size.
      <br/>
      The process is repeated and the block size is reduced until the minimum block size has been processed as determined at decision block 220.
      <br/>
      In the preferred embodiment block size is divided by two after each iteration, and the minimum block size is one view.
      <br/>
      The corrected k-space data set is then Fourier transformed to reconstruct an optimal image as indicated at process block 222.
    </p>
    <p num="36">
      It should be apparent that the autocorrection method can be employed on one, two or three axes of motion.
      <br/>
      In many clinical applications of the method, it has been discovered that processing only a single axis of motion is necessary.
      <br/>
      This reduces the processing time considerably.
      <br/>
      For example, if the motion is primarily along the phase encoding direction, a one dimensional FFT along the readout gradient direction can be performed once on the acquired k-space image data set before the autocorrection method is applied.
      <br/>
      The phase corrections in process 204 are made on this hybrid-space data set and the Fourier transform in process 206 can be a one-dimensional FFT along the phase encoding gradient direction.
    </p>
    <p num="37">
      Also, in many clinical applications only a small portion of the reconstructed image is clinically important.
      <br/>
      The autocorrection method may be modified in this situation to evaluate the image metric in process block 208 only in the selected region of interest.
      <br/>
      That is, the operator identifies the pixels in the region of interest and the image metric is calculated only on these pixels.
      <br/>
      This reduces processing time and in some cases improves the resulting image in the critical region.
    </p>
    <p num="38">
      For example, the complete image many contain 256 columns of pixels which must be Fourier transformed each time the metric is to be calculated.
      <br/>
      If the region selected by the operator extends over only 64 columns of pixels, then only those 64 columns need be Fourier transformed during each evaluation iteration.
      <br/>
      This reduces the processing time by a factor of four.
    </p>
    <p num="39">
      The synergistic use of the central slice and autocorrection appear to reduce all visible artifacts in both phantom and in-vivo data.
      <br/>
      Phantom data indicates that a 50% reduction in computation can be achieved as compared to autocorrection alone.
      <br/>
      The initial in-vivo data indicate the clinical feasibility of this technique.
      <br/>
      We postulate that the clinical applications of this technique include situations where the acquisition of interleaved navigator echoes perturb the magnetization history of the imaging sequence.
      <br/>
      If the acquisition of a limited number of navigator echoes is performed as part of a standard prescanning protocol, no extra time will be added to the scanning sequence and spin perturbations from navigator echoes will be eliminated.
      <br/>
      This technique may also have further applications in key-hole imaging where the phase correction term derived from the central slice theorem can be used to correct for motion occurring during the repetitive acquisition of the low frequency views.
    </p>
    <p num="40">
      The number of navigator echoes acquired during a scan and the manner in which they are interleaved with the imaging pulse sequences will depend on the particular application.
      <br/>
      Only a single navigator whose signal may be acquired at the beginning, middle or end of the image acquisition, or as many as ten or more may be acquired during the acquisition.
      <br/>
      One navigator echo signal may be acquired for per shot for a multi-shot acquisition, or navigator echoes may be acquired on demand if image quality looks bad.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A method for correcting a medical image for artifacts, the steps comprising:</claim-text>
      <claim-text>a) acquiring a navigator signal; b) acquiring a series of views to form an image data set; c) comparing the navigator signal with views in the image data set; d) correcting the views in the image data set based on the comparison in step c); e) reconstructing an image from the acquired image data set; f) evaluating the quality of the reconstructed image by calculating a metric based on the image; g) iteratively minimizing the metric by making further corrections to views in the image data set and repeating steps e) and f).</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The method as recited in claim 1 in which the artifacts are caused by patient motion.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. A method for correcting an MRI image for artifacts caused by patient motion, the steps comprising: a) acquiring an NMR navigator signal which has phase information indicative of patient positioning; b) acquiring a k-space image data set as a series of views; c) comparing phase information in the NMR navigator signal with phase information in acquired views; d) correcting views in the k-space image data set based on the comparison in step c); e) reconstructing an MR image from the k-space image data set; f) evaluating the quality of the MR image by calculating a metric based on the MR image; g) iteratively minimizing the metric by making further corrections to views in the k-space image data set and repeating steps e) and f).</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The method as recited in claim 3 in which each view is acquired with a pulse sequence which includes producing a phase encoding gradient directed along one axis and producing a readout gradient directed along an orthogonal axis, each of said views differs by the amount of the phase encoding gradient, and the NMR navigator signal is acquired with a pulse sequence which includes producing a readout gradient directed along said one axis.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The method as recited in claim 4 in which a plurality of NMR navigator signals are acquired and the steps include: calculating the average of the acquired NMR navigator signals for use in step c).</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The method as recited in claim 3 in which the phase of a signal sample in the NMR navigator signal is compared with the phase of a signal sample in each of said views.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. The method as recited in claim 6 in which the correction of each view in step d) is based on the difference in phase of said signal samples.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The method as recited in claim 3 in which all the views in the k-space data set are compared in step c) and corrected in step d).</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. The method as recited in claim 3 in which calculating the metric in step f) includes calculating the MR image gradient.</claim-text>
    </claim>
  </claims>
</questel-patent-document>