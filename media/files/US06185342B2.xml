<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06185342B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06185342</doc-number>
        <kind>B2</kind>
        <date>20010206</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6185342</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="24823641" extended-family-id="59081314">
      <document-id>
        <country>US</country>
        <doc-number>09398521</doc-number>
        <kind>A</kind>
        <date>19990915</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1999US-09398521</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>60313844</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>39852199</doc-number>
        <kind>A</kind>
        <date>19990915</date>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1999US-09398521</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>US</country>
        <doc-number>70302496</doc-number>
        <kind>A</kind>
        <date>19960826</date>
        <priority-linkage-type>1</priority-linkage-type>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1996US-08703024</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010206</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <term-of-grant>
      <disclaimer/>
    </term-of-grant>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>H04N   7/18        20060101AFI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>H</section>
        <class>04</class>
        <subclass>N</subclass>
        <main-group>7</main-group>
        <subgroup>18</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G06T   3/00        20060101ALI20051220RMJP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>3</main-group>
        <subgroup>00</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <generating-office>
          <country>JP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051220</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>G06T  11/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>11</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>G06T  15/50        20110101A I20150217RMEP</text>
        <ipc-version-indicator>
          <date>20110101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>15</main-group>
        <subgroup>50</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20150217</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>382284000</text>
        <class>382</class>
        <subclass>284000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>382283000</text>
        <class>382</class>
        <subclass>283000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>382294000</text>
        <class>382</class>
        <subclass>294000</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>382302000</text>
        <class>382</class>
        <subclass>302000</subclass>
      </further-classification>
      <further-classification sequence="4">
        <text>382305000</text>
        <class>382</class>
        <subclass>305000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G06T-011/00</text>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>11</main-group>
        <subgroup>00</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>G06T-015/50B</text>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>015</main-group>
        <subgroup>50B</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-015/503</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>15</main-group>
        <subgroup>503</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-011/00</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>11</main-group>
        <subgroup>00</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>18</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>3</number-of-drawing-sheets>
      <number-of-figures>6</number-of-figures>
      <image-key data-format="questel">US6185342</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Adjustment layers for composited image manipulation</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>HAMBURG MARK, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5974198</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5974198</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="2">
          <text>OKA TATEKI</text>
          <document-id>
            <country>US</country>
            <doc-number>4608327</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4608327</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="3">
          <text>PARKYN DEREK J</text>
          <document-id>
            <country>US</country>
            <doc-number>4675725</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4675725</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="4">
          <text>SAITOU NORIO, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5162240</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5162240</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="5">
          <text>DADOURIAN ARPAG</text>
          <document-id>
            <country>US</country>
            <doc-number>5343252</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5343252</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="6">
          <text>LEVIEN RAPHAEL L</text>
          <document-id>
            <country>US</country>
            <doc-number>5388517</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5388517</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="7">
          <text>MARSH DONALD M, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5487145</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5487145</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="8">
          <text>KORSZUN HENRY A</text>
          <document-id>
            <country>US</country>
            <doc-number>5680528</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5680528</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="9">
          <text>RANK CINTEL LTD</text>
          <document-id>
            <country>GB</country>
            <doc-number>2246933</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>GB2246933</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="10">
          <text>EASTMAN KODAK CO</text>
          <document-id>
            <country>WO</country>
            <doc-number>9307554</doc-number>
            <kind>A1</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>WO9307554</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="1">
          <text>Blatner, David et al., Real World Photoshop 3 Industrial Strength Production Techniques , pp. 453-455 (1996).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="2">
          <text>FITS Imaging et al., Live Picture ,pp. 108-111 (1994).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="3">
          <text>Wolberg, George, Digital Image Warping , pp. 52-56, 214-219 (1990).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="4">
          <text>Meyers, Scott, More Effective C++ ,pp. 190-194 (1996).</text>
        </nplcit>
      </citation>
    </references-cited>
    <related-documents>
      <continuation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>70302496</doc-number>
              <kind>A</kind>
              <date>19960826</date>
            </document-id>
          </parent-doc>
        </relation>
      </continuation>
    </related-documents>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Adobe Systems Incorporated</orgname>
            <address>
              <address-1>San Jose, CA, US</address-1>
              <city>San Jose</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>ADOBE SYSTEMS</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Hamburg, Mark</name>
            <address>
              <address-1>Scotts Valley, CA, US</address-1>
              <city>Scotts Valley</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Bartell, Jason</name>
            <address>
              <address-1>Mountain View, CA, US</address-1>
              <city>Mountain View</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Fish &amp; Richardson PC</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Bella, Matthew C.</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A method and system for compositing graphical images, wherein an advanced adjustment layer may be applied during a compositing process to a set of image layers 1 . . . n, or to any subordinate subset of such image layers.
      <br/>
      One or more adjustment layers are applied to an intermediate merged image, generated by compositing previous image layers, and the adjusted result is stored as a temporary image.
      <br/>
      The temporary image is then in turn composited with the intermediate merged image.
      <br/>
      Any remaining image layers are then composited in with the intermediate merged image to generate a final merged image.
      <br/>
      The invention allows a user to apply a vast array of effects without requiring significant new knowledge on the part of the user.
      <br/>
      For example, if there are "A" adjustments and "T" transfer modes, the present invention allows AxT effects which leverage existing knowledge of the user of only A+T functions.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <p num="1">
      This is a continuation of U.S. application Ser.
      <br/>
      No. 08/703,024, filed Aug. 26, 1996 (pending).
    </p>
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="2">
      1.
      <br/>
      Field of the Invention
    </p>
    <p num="3">This invention relates to graphical image manipulation systems, and more particularly to a method and system for compositing graphical images.</p>
    <p num="4">2. Description of Related Art</p>
    <p num="5">
      A number of graphic image manipulation computer programs build up a final image by compositing several image layers together.
      <br/>
      An example of one such program is Adobe Photoshop 3.0, from Adobe Systems, Inc. of Mountain View, Calif.
    </p>
    <p num="6">
      Referring to FIG. 1, each image layer 10 typically comprises the actual image information 12, compositing parameters 14, and, optionally, a mask 16.
      <br/>
      As is known in the art, the image 12 generally comprises a set of pixels in an m * n array.
      <br/>
      The compositing parameters 14 generally include such information as a transfer mode (e.g., color model), global opacity information, color-based restrictions on which areas are subject to blending, and other information known in the art.
    </p>
    <p num="7">
      A number of image layers, 1 . . . n, are merged to form a composite image.
      <br/>
      In the merge process, each pixel generally is independent of the other pixels of the image 12 within each image layer 10, so an implementing system can equally well calculate pixel data for the entire final image, or just a piece of the final image.
      <br/>
      FIG. 2 is a block diagram showing diagrammatically that a set of image layers 20 are subjected to a compositing operation 22 to generate a merged image 24, in known fashion.
      <br/>
      The process of merger may also be represented by the following pseudocode:
    </p>
    <p num="8">PROCEDURE CalculateMergedData (layers: ARRAY OF ImageLayer; result: Image);</p>
    <p num="9">VAR I: INTEGER;</p>
    <heading>BEGIN</heading>
    <p num="10">InitializeMergedData (result);</p>
    <p num="11">FOR I=1 TO LEN(layers) DO</p>
    <p num="12">CompositeImageIntoImage (</p>
    <p num="13">
      - layers�i�.image,
      <br/>
      - layers�i�.compositingParameters,
      <br/>
      - layers�i�.mask, result)
    </p>
    <heading>END FOR</heading>
    <p num="14">END CalculateMergedData;</p>
    <p num="15">In the pseudocode above, the final image, "result", can be initialized either to a solid color or to a value representing transparency.</p>
    <p num="16">
      In existing image manipulation programs, there is a large class of useful image effects based upon functions that are applied to each pixel of an image independently.
      <br/>
      These functions include operations like inverting the color at a pixel, increasing the brightness of all pixels, etc.
      <br/>
      Such functions typically are known as "adjustments", and are selectable via a user interface (e.g., menu or icons) of an implementing program, such as Adobe Photoshop 3.0 referenced above.
      <br/>
      A key property that sets these functions apart from filters (such as blurring operations), is that each pixel in the result only depends on the spatially corresponding pixel in the source image.
      <br/>
      Adjustment operations generally involve applying a particular function to some pixels based on some global parameters.
      <br/>
      In addition, frequently a mask is specified to constrain the effect.
      <br/>
      An adjustment operation is typically invoked by a call to a function such as the following, which specifies an adjustment function and parameters and the mask constraining that function:
    </p>
    <p num="17">
      ApplyAdjustmentToImage (
      <br/>
      adjustmentfunction,
      <br/>
      adjustmentparameters,
      <br/>
      mask,
      <br/>
      image)
    </p>
    <p num="18">
      When applying an adjustment function, the mask is frequently accounted for by using separate images for the initial and adjusted data, and then using the mask to compute a weighted average of the two images.
      <br/>
      This may require the use of a temporary buffer to hold a copy of the initial image, or to hold the adjusted data before blending it into the original data.
      <br/>
      This could, for example, result in a code path like the following:
    </p>
    <p num="19">ApplyAdjustmentNoMaskFromImageToImage (</p>
    <p num="20">adjustmentFunction,</p>
    <p num="21">adjustmentParameters,</p>
    <p num="22">image,</p>
    <p num="23">tmpImage);</p>
    <p num="24">BlendImages (tmpImage, image, mask, image);</p>
    <p num="25">
      FIG. 3A is a block diagram showing an image 30 to which is applied one or more adjustments 32 to generate an adjusted image 34, in accordance with the prior art.
      <br/>
      Thus, for example, an image X may be color corrected by an adjustment to generate image X'.
    </p>
    <p num="26">
      FIG. 3B is a block diagram showing diagrammatically the application of a simple adjustment to a merged image, in accordance with the prior art.
      <br/>
      The adjustment data may be stored, for convenience, as a "pseudo-layer" 36, so that the data is part of the array of actual image layers 1 . . . n. The image layers 20 are merged by the application of a compositing operation 22 into a merged image 24.
      <br/>
      The adjustment function 36 is then applied 38 to the merged image 24 to generate an adjusted merged image 24'. Accordingly, adjustment operations can be readily incorporated into a conventional layer merging process in accordance with the following pseudocode:
    </p>
    <p num="27">
      --
      <br/>
      -- TYPE
      <br/>
      --      Layer= OBJECT
      <br/>
      --                    mask: Image
      <br/>
      --                END;
      <br/>
      --      ImageLayer= OBJECT EXTENDING Layer
      <br/>
      --                    image: Image;
      <br/>
      --                    compositingParameters: CompositingParameters
      <br/>
      --                END;
      <br/>
      --      SimpleAdjustmentLayer=
      <br/>
      --                OBJECT EXTENDING Layer
      <br/>
      --                    adjustmentFunction: AdjustmentFunction;
      <br/>
      --                    adjustmentParameters: AdjustmentParameters
      <br/>
      --                END;
      <br/>
      -- PROCEDURE CalculateMergedData (layers: ARRAY OF Layer; result: Image);
      <br/>
      -- VAR I: INTEGER;
      <br/>
      -- BEGIN
      <br/>
      --      InitializeMergedData (result);
      <br/>
      --      FOR I = 1 TO LEN(layers) DO
      <br/>
      --         IF layers�i� IS ImageLayer DO
      <br/>
      --                WITH layers�i� AS ImageLayer DO
      <br/>
      --                    CompositeImageIntoImage (
      <br/>
      --                       layers�i�.image,
      <br/>
      --                       layers�i�.compositingParameters,
      <br/>
      --                       layers�i�.mask,
      <br/>
      --                       result )
      <br/>
      --                END WITH
      <br/>
      --         ELSEIF layers�i� IS SimpleAdjustmentLayer DO
      <br/>
      --                WITH layers�i� AS SimpleAdjustmentLayer DO
      <br/>
      --                    ApplyAdjustmentToImage (
      <br/>
      --                       layers�i�.adjustmentFunction,
      <br/>
      --                       layers�i�.adjustmentParameters,
      <br/>
      --                       layers�i�.mask,
      <br/>
      --                       result )
      <br/>
      --                END WITH
      <br/>
      --         ELSE
      <br/>
      --                (* Unexprected layer type� *)
      <br/>
      --         END IF
      <br/>
      --      END FOR
      <br/>
      -- END CalculateMergedData;
    </p>
    <p num="28">
      (In the above pseudocode, types declared as OBJECTs are polymorphic records, which are generally accessed via pointers.
      <br/>
      When an object is declared as EXTENDING another OBJECT type, the object inherits all of the fields of the extended object type.
      <br/>
      Thus, in the example above, OBJECTs "ImageLayers" and "SimpleAdjustmentLayers" have "mask" fields which they inherit from OBJECT "Layer".
      <br/>
      The IS expression tests whether a particular object is really a specified extension of its declared type.
      <br/>
      The WITH statement casts an object to an extension, allowing the program to access fields only defined in that extension--the IS test indicates that it is safe perform this cast.)
    </p>
    <p num="29">
      In the above pseudocode, for each conventional image layer 1 . . . n (having type "ImageLayer"), conventional compositing 22 is performed to generate the merged image 24.
      <br/>
      When the simple adjustment layer 36 (having type "SimpleAdjustmentLayer") is detected, the adjustment function is applied 38 to the entire merged image 24 stored in variable "result" to generate the adjusted merged image 24'.
    </p>
    <p num="30">
      A drawback of the prior products implementing simple adjustment layers is that they do not allow the system to edit the data underneath an adjustment "layer" while viewing the adjustment as applied to the final result.
      <br/>
      That is, the adjustment function does not truly have characteristics of an image layer.
      <br/>
      Further, the range of effects presented is generally quite limited.
    </p>
    <p num="31">
      Accordingly, it would be useful to have greater flexibility in applying adjustments to composited images.
      <br/>
      The present invention provides the system and method for allowing such flexibility.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="32">
      The present invention provides an advanced adjustment layer that may be applied during the compositing process to a set of image layers 1 . . . n, or to any subordinate subset of such image layers.
      <br/>
      One or more adjustment layers are applied to an intermediate merged image, generated by compositing previous image layers, and the adjusted result is stored as a temporary image.
      <br/>
      The temporary image is then in turn composited with the intermediate merged image.
      <br/>
      Any remaining image layers are then composited in with the intermediate merged image to generate a final merged image.
    </p>
    <p num="33">
      The invention allows a user to apply a vast array of effects without requiring significant new knowledge on the part of the user.
      <br/>
      For example, if there are "A" adjustments and "T" transfer modes, the present invention allows A * T effects which leverage existing knowledge of the user of only A+T functions.
    </p>
    <p num="34">
      The details of the preferred embodiment of the present invention are set forth in the accompanying drawings and the description below.
      <br/>
      Once the details of the invention are known, numerous additional innovations and changes will become obvious to one skilled in the art.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="35">
      FIG. 1 is a diagram of a prior art image layer, showing the actual image information, compositing parameters, and a mask.
      <br/>
      FIG. 2 is a block diagram showing diagrammatically that a set of image layers are subjected to a compositing operation to generate a merged image, in accordance with the prior art.
      <br/>
      FIG. 3A is a block diagram showing an image to which is applied one or more adjustments to generate an adjusted image, in accordance with the prior art.
      <br/>
      FIG. 3B is a block diagram showing diagrammatically the application of a simple adjustment to a merged image, in accordance with the prior art.
      <br/>
      FIG. 4 is a diagram of an adjustment layer comprising an adjustment function and adjustment parameters, in accordance with the present invention.
      <br/>
      FIG. 5 is a block diagram showing application of the present invention to a set of image layers 1 . . . n, of which at least one layer A is an adjustment layer in accordance with the present invention.
      <br/>
      Like reference numbers and designations in the various drawings indicate like elements.
    </p>
    <heading>DETAILED DESCRIPTION OF THE INVENTION</heading>
    <p num="36">Throughout this description, the preferred embodiment and examples shown should be considered as exemplars, rather than as limitations on the present invention.</p>
    <p num="37">
      In the present invention, instead of thinking of adjustments as operations that change pixels in a result image, adjustments can be thought of as producing new image data amenable to all of the compositing options available for manipulating image layers.
      <br/>
      Thus, the present invention uses an advanced image layer that permits great flexibility in controlling the adjustment and compositing process.
    </p>
    <p num="38">
      FIGS. 4 and 5 are block diagrams depicting the architecture and use of the present invention.
      <br/>
      FIG. 4 shows that an adjustment layer 40 in accordance with the present invention comprises an adjustment function 44 (for example, a color correction function) and optional adjustment parameters 46 (for example, parameters specifying the amount of the color correction).
      <br/>
      Each adjustment layer 40 would also include all inherited structures inherent in being a layer (i.e., mask and compositing parameters).
      <br/>
      In some instances, or as a matter of design choice, adjustment layers 40 may comprise only an adjustment function 44, with no adjustment parameters (an example would be simple color inversion for a specific color model).
      <br/>
      However, it is generally preferable to separate adjustment parameters from adjustment functions so that the parameters are readily re-editable.
    </p>
    <p num="39">
      An adjustment layer 40 is created in conventional fashion by allowing a user to select (e.g., by selecting from a menu or selecting an icon) an adjustment function (e.g., a color correction) and associated parameters.
      <br/>
      In the preferred embodiment, compositing parameters and adjustment parameters are re-editable after the creation of an adjustment layer.
      <br/>
      Thus, a user can change the effect of an adjustment at any time.
    </p>
    <p num="40">
      In FIG. 5, a set of image layers 52 comprises 1 . . . n layers, of which at least one layer A is an adjustment layer.
      <br/>
      The hierarchical position of the adjustment layer A within the set of image layers 1 . . . n determines which image layers are operated on by the adjustment layer A. In operation, image layers 1 . . . (A-1) are composited 53 into an intermediate merged image 54.
      <br/>
      The adjustments 55 defined by adjustment layer A are then applied to the intermediate merged image 54 and the results are stored in a temporary buffer 56.
      <br/>
      The compositing operation 57 then continues, compositing the contents of temporary buffer 56 with the remaining image layers (A+1) . . . n into a final merged adjusted image 58.
      <br/>
      Note that the process is iterative if more than one adjustment layer A exists, and that image representation of the final merged adjusted image 58 may differ from the representation used for the image layers 52.
    </p>
    <p num="41">The operations depicted in FIG. 5 may also be described by the following pseudo-code:</p>
    <p num="42">
      --
      <br/>
      -- TYPE
      <br/>
      --      Layer= OBJECT
      <br/>
      --                       compositingParameters: CompositingParameters;
      <br/>
      --                       mask: Image
      <br/>
      --                END;
      <br/>
      --      ImageLayer= OBJECT EXTENDING Layer
      <br/>
      --                       image: Image;
      <br/>
      --                END;
      <br/>
      --      AdjustmentLayer=
      <br/>
      --                OBJECT EXTENDING Layer
      <br/>
      --                       adjustmentFunction: AdjustmentFunction;
      <br/>
      --                       adjustmentParameters: AdjustmentParameters
      <br/>
      --                END;
      <br/>
      -- VAR tempImage: Image; (* A temporary image needed while merging.
      <br/>
      This is
      <br/>
      --                       presented outside of the procedure below to indicate
      <br/>
      --  that
      <br/>
      --                       it may be allocated once at program initialization if
      <br/>
      --  it is
      <br/>
      --                       deemed too expensive to allocate a temporary image
      <br/>
      --  every
      <br/>
      --                       time the merge code is entered.*)
      <br/>
      -- PROCEDURE CalculateMergedData (layers: ARRAY OF Layer; result: Image);
      <br/>
      -- VAR  I: INTEGER;
      <br/>
      --      srcImage: Image;   (* srcImage is the image that will be composited
      <br/>
      --  into the
      <br/>
      --                         result.
      <br/>
      Note that Image is assumed to be a
      <br/>
      --  reference - i.e.,
      <br/>
      --                         a pointer type - and hence assigning to a variable
      <br/>
      --  of type
      <br/>
      --                         Image is cheap. *)
      <br/>
      -- BEGIN
      <br/>
      --      InitializeMergedData (result);
      <br/>
      --      FOR I = 1 TO LEN(layers) DO
      <br/>
      --                IF layers�i� IS ImageLayer DO
      <br/>
      --                    WITH layers�i� AS ImageLayer DO
      <br/>
      --                       srcImage = layers�i�.image
      <br/>
      --                    END WITH
      <br/>
      --                ELSEIF layers�i� IS AdjustmentLayer DO
      <br/>
      --                    WITH layers�i� AS AdjustmentLayer DO
      <br/>
      --                       ApplyAdjustmentNoMaskFromImageToImage (
      <br/>
      --                           layers�i�.adjustmentFunction,
      <br/>
      --                           layers�i�.adjustmentParameters,
      <br/>
      --                           result,
      <br/>
      --                           tempImage );
      <br/>
      --                       srcImage = tempImage
      <br/>
      --                    END WITH
      <br/>
      --                ELSE
      <br/>
      --                    (* Unexpected layer type� *)
      <br/>
      --                END IF
      <br/>
      --                CompositeImageIntoImage (
      <br/>
      --                    srcImage,
      <br/>
      --                    layers�i�.compositingParameters,
      <br/>
      --                    layers�i�.mask,
      <br/>
      --                    result )
      <br/>
      --      END FOR
      <br/>
      -- END CalculateMergedData;
    </p>
    <p num="43">
      In accordance with the above pseudocode, if an image layer is detected as being of type "ImageLayer", then it is simply composited in conventional fashion into "result".
      <br/>
      However, if an image layer is of type "AdjustmentLayer", then the adjustment function defined within that layer is applied to the intermediate merged image 54 as it exists to that point in time.
      <br/>
      Of course, more than one adjustment layer may exist within the set of image layers 52, and the actual adjustment layer information may be stored in other forms and other locations.
      <br/>
      The results of the application of the adjustment layer are stored in a temporary buffer (variable "tempImage" in the pseudocode above), and then composited into the intermediate merged image (variable "result").
      <br/>
      The process continues until all image layers (including adjusted intermediate images) are composited.
    </p>
    <p num="44">
      The invention allows a user to apply a vast array of effects without requiring significant new knowledge on the part of the user.
      <br/>
      For example, if there are "A" adjustments and "T" transfer modes, the present invention allows A * T effects which leverage existing knowledge of the user of only A+T functions.
    </p>
    <p num="45">
      As an example of using the present invention, an implementing system can create an effect based on inverting the color information in an image and then blending that result in such a way that the luminosity of the original color is preserved.
      <br/>
      As another example, a solarization-like effect can be accomplished by inverting the color in an image and multiplying the color with itself.
      <br/>
      By using color restrictions on compositing, an implementing system can limit an adjustment effect to a dynamically calculated mask that can depend on either the pre-adjustment data, the post-adjustment data, or both.
      <br/>
      An implementing system can also gain code compactness by being able to mix and match adjustment logic with compositing logic.
    </p>
    <p num="46">
      As should be apparent, the invention allows for hierarchical compositing in which sub-ranges in the stack of image layers 52 are composited together and the results are then composited in a next level of the hierarchy.
      <br/>
      When used with adjustment layers A, this ability allows the system to restrict the effect of an adjustment layer so that it does not affect the entire image without having to create a special mask to do so.
    </p>
    <p num="47">
      As another aspect of the present invention, the compositing parameters may be used to mask the compositing effect based on pixel-by-pixel properties of either the incoming image or the image to be merged (e.g, the adjusted incoming image).
      <br/>
      For example, masking can be based on ranges of color values.
      <br/>
      As an illustration, such masking can select pixels with at least a certain luminance in the image for merging, or protect pixels with at least a certain level of color in the incoming image.
      <br/>
      Other masking functions can be used, like restricting compositing to colors inside or outside a printable gamut.
      <br/>
      Thus, one can create an adjustment layer that applies a desaturation adjustment to any colors that are too saturated to print.
    </p>
    <p num="48">
      While the preferred embodiment uses adjustment functions that are applied on a one to one basis to each pixel, the concept of the invention can be applied to multi-pixel adjustment functions, such as blurring, where each pixel is adjusted based upon the values of other pixels, such as adjacent pixels.
      <br/>
      However, multi-pixel adjustment functions do impose some costs, in that in implementing more generalized filtering operations as layers it becomes harder to calculate subareas within a merge image since the filter may require input areas that are larger than the area to be calculated and that a series of filtering layers will produce a cascade effect in which the expanded supports add to each other.
      <br/>
      When building an entire merged image, these issues are not a problem since all of the data is available, but they could impose processing costs when calculating small areas.
    </p>
    <p num="49">Implementation</p>
    <p num="50">
      The invention may be implemented in hardware or software, or a combination of both.
      <br/>
      However, preferably, the invention is implemented in computer programs executing on programmable computers each comprising at least one processor, a data storage system (including volatile and non-volatile memory and/or storage elements), at least one input device, and at least one output device.
      <br/>
      Program code is applied to input data to perform the functions described herein and generate output information.
      <br/>
      The output information is applied to one or more output devices, in known fashion.
    </p>
    <p num="51">
      Each program is preferably implemented in a high level procedural or object oriented programming language to communicate with a computer system.
      <br/>
      However, the programs can be implemented in assembly or machine language, if desired.
      <br/>
      In any case, the language may be a compiled or interpreted language.
    </p>
    <p num="52">
      Each such computer program is preferably stored on a storage media or device (e.g, ROM or magnetic diskette) readable by a general or special purpose programmable computer, for configuring and operating the computer when the storage media or device is read by the computer to perform the procedures described herein.
      <br/>
      The inventive system may also be considered to be implemented as a computer-readable storage medium, configured with a computer program, where the storage medium so configured causes a computer to operate in a specific and predefined manner to perform the functions described herein.
    </p>
    <p num="53">
      A number of embodiments of the present invention have been described.
      <br/>
      Nevertheless, it will be understood that various modifications may be made without departing from the spirit and scope of the invention.
      <br/>
      Accordingly, it is to be understood that the invention is not to be limited by the specific illustrated embodiment, but only by the scope of the appended claims.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A method for applying at least one adjustment during a process of compositing a set of ordered image layers, the set having a logical top layer and a logical bottom layer, into a final merged image, comprising the steps of:</claim-text>
      <claim-text>(a) creating a blank current intermediate merged image; (b) defining at least one adjustment layer, each logically ordered within the ordered image layers according to a user selection, each adjustment layer comprising at least one adjustment function; (c) compositing each image layer occurring</claim-text>
      <claim-text>- (1) logically between a current adjustment layer and any previous adjustment layer or - (2) logically before the current adjustment layer if there is no previous adjustment layer, into the current intermediate merged image; (d) applying the adjustment function of a current adjustment layer to the current intermediate merged image to generate a current adjusted temporary image; (e) temporarily storing the current adjusted temporary image in a compositable form; (f) compositing the stored current adjusted temporary image into the current intermediate merged image; (g) repeating steps (c) through (f) for each adjustment layer; (h) compositing any remaining image layers into the current intermediate merged image to create a final merged adjusted image,</claim-text>
      <claim-text>where the set of ordered image layers and at least one adjustment layer are preserved, and where compositing is performed using masks and compositing parameters.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The method of claim 1, wherein said at least one adjustment function includes a color inversion function.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The method of claim 1, wherein said adjustment layer further includes adjustment parameters.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The method of claim 3, wherein said at least one adjustment function includes a color correction function and said adjustment parameters specify the amount of the color correction.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The method of claim 3, wherein said adjustment parameters are re-editable after creating the adjustment layer, thereby allowing a user to change the effect of an adjustment.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The method of claim 3, wherein said adjustment parameters are used to mask the compositing effect based on pixel-by-pixel properties of either an incoming image or an image to be merged.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. The method of claim 6, wherein said adjustment function of masking is based on ranges of color values.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The method of claim 7, wherein said masking includes selecting pixels with at least a particular luminance in an image for merging.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. The method of claim 7, wherein said masking includes protecting pixels with at least a particular level of color in an incoming image.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. The method of claim 1, wherein said adjustment function is applied on a one to one basis to each pixel of an image.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. The method of claim 1, wherein said adjustment function is applied to multiple pixels.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. The method of claim 11, wherein said adjustment function applies blurring to each pixel by adjusting the pixel based upon values of adjacent pixels.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. A system for applying at least one adjustment during a process of compositing a set of ordered image layers, the set having a logical top layer and a logical bottom layer, into a final merged image, comprising: (a) means for creating a blank current intermediate merged image; (b) means for defining at least one adjustment layer, each logically ordered within the ordered image layers according to a user selection, each adjustment layer comprising at least an adjustment function; (c) means for compositing each image layer occurring - (1) logically between a current adjustment layer and any previous adjustment layer or - (2) logically before the current adjustment layer if there is no previous adjustment layer, into the current intermediate merged image; (d) means for applying the adjustment function of a current adjustment layer to the current intermediate merged image to generate a current adjusted temporary image; (e) means for temporarily storing the current adjusted temporary image in a compositable form; (f) means for compositing the stored current adjusted temporary image into the current intermediate merged image; (g) means for repeating steps (c) through (f) for each adjustment layer; (h) means for compositing any remaining image layers into the current intermediate merged image to create a final merged adjusted image, where the set of ordered image layers and at least one adjustment layer are preserved;</claim-text>
      <claim-text>and</claim-text>
      <claim-text>where means for compositing includes masks and compositing parameters.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. The method of claim 13, wherein said at least one adjustment function includes a color inversion function.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. The method of claim 13, wherein said adjustment layer further includes adjustment parameters.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. The method of claim 15, wherein said at least one adjustment function includes a color correction function and said adjustment parameters specify the amount of the color correction.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. The method of claim 15, wherein said adjustment parameters are re-editable after creating the adjustment layer, thereby allowing a user to change the effect of an adjustment.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. The method of claim 13, wherein said adjustment function is applied on a one to one basis to each pixel of an image.</claim-text>
    </claim>
  </claims>
</questel-patent-document>