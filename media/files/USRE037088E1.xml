<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="USRE037088E1.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Reissue">
      <document-id>
        <country>US</country>
        <doc-number>RE037088</doc-number>
        <kind>E1</kind>
        <date>20010306</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>USRE37088</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>E1</original-publication-kind>
    <application-reference family-id="26648522" extended-family-id="13334687">
      <document-id>
        <country>US</country>
        <doc-number>09078378</doc-number>
        <kind>A</kind>
        <date>19980513</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1998US-09078378</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>13616264</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>7837898</doc-number>
        <kind>A</kind>
        <date>19980513</date>
        <priority-active-indicator>N</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1998US-09078378</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>NO</country>
        <doc-number>943214</doc-number>
        <kind>A</kind>
        <date>19940830</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1994NO-0003214</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="3">
        <country>US</country>
        <doc-number>37920596</doc-number>
        <kind>A</kind>
        <date>19960127</date>
        <priority-linkage-type>5</priority-linkage-type>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="3">
        <doc-number>1996US-08379205</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010306</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G01S   7/52        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>01</class>
        <subclass>S</subclass>
        <main-group>7</main-group>
        <subgroup>52</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G01S  15/89        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>01</class>
        <subclass>S</subclass>
        <main-group>15</main-group>
        <subgroup>89</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>600440000</text>
        <class>600</class>
        <subclass>440000</subclass>
      </main-classification>
    </classification-national>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G01S-015/8993</classification-symbol>
        <section>G</section>
        <class>01</class>
        <subclass>S</subclass>
        <main-group>15</main-group>
        <subgroup>8993</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>A61B-008/486</classification-symbol>
        <section>A</section>
        <class>61</class>
        <subclass>B</subclass>
        <main-group>8</main-group>
        <subgroup>486</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G01S-007/52066</classification-symbol>
        <section>G</section>
        <class>01</class>
        <subclass>S</subclass>
        <main-group>7</main-group>
        <subgroup>52066</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G01S-007/52071</classification-symbol>
        <section>G</section>
        <class>01</class>
        <subclass>S</subclass>
        <main-group>7</main-group>
        <subgroup>52071</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G01S-007/52074</classification-symbol>
        <section>G</section>
        <class>01</class>
        <subclass>S</subclass>
        <main-group>7</main-group>
        <subgroup>52074</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>50</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>5</number-of-drawing-sheets>
      <number-of-figures>10</number-of-figures>
      <image-key data-format="questel">USRE37088</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Method for generating anatomical M-mode displays</invention-title>
    <references-cited>
      <citation srep-phase="applicant">
        <patcit num="1">
          <text>EGGLETON REGINALD C</text>
          <document-id>
            <country>US</country>
            <doc-number>3955561</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US3955561</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="2">
          <text>SPECHT DONALD F, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4271842</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4271842</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="3">
          <text>VAN KEMENADE MARTINUS J C</text>
          <document-id>
            <country>US</country>
            <doc-number>4413521</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4413521</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="4">
          <text>HONGO HIRONOBU</text>
          <document-id>
            <country>US</country>
            <doc-number>4501277</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4501277</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="5">
          <text>TAKASUGI WASAO</text>
          <document-id>
            <country>US</country>
            <doc-number>4735211</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4735211</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="6">
          <text>COLEMAN D JACKSON, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>4932414</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US4932414</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="7">
          <text>YAMADA ISAMU, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5097836</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5097836</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="8">
          <text>SHIKATA HIROYUKI</text>
          <document-id>
            <country>US</country>
            <doc-number>5105813</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5105813</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="9">
          <text>DAIGLE RONALD E</text>
          <document-id>
            <country>US</country>
            <doc-number>5127409</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5127409</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="10">
          <text>MELTON JR HEWLETT E, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5195521</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5195521</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="11">
          <text>ARENSON JAMES W, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5285788</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5285788</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="12">
          <text>IIZUKA MIYUKI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5355887</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5355887</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="13">
          <text>SHIMIZU YUTAKA</text>
          <document-id>
            <country>US</country>
            <doc-number>5375599</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5375599</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="1">
          <text>Foley, et al., "Computer Graphics: Principles And Practice," Addison Wesley USA (1990) (only bibliographic pages included).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="2">
          <text>Olstad, B., "Maximizing Image Variance In Rendering Of Columetric Data Sets", Journal Of Electronic Imaging, 1:256-265, Jul. 1992.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="3">
          <text>Borgefors, G., "Distance Transformations In Digital Images"., Computer Vision, Graphics And Image Processing 34, 1986, pp. 344-371.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="4">
          <text>Seitz, P., "Optical Superresolution Using Solid State Cameras And Digital Signal Processing", Optical Engineering 27(7) Jul. 1998, pp. 535-540.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="5">
          <text>R. Omoto, Y. Yokote, et al. "B/M Conversion System With Free Setting Of Cursor Line: Clinical Applications Thereof", 41-PA-31, 3pgs. (Saitama Medical School).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="6">
          <text>R. Omoto, Y. Yokote, et al. "New System for Converting From Tomogram Echocardiography To M-Mode Freely Set Cursor Line", 40-C-51, 2pgs. (Saitama Medical School).</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="7">
          <text>"New Transforming System From Tomogram Echocardiography To M-Mode", 40-C-5.1, 7pgs.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="8">
          <text>R. Omoto, Y. Yokote, et al. "B/M Conversion System with Free Setting of Cursor Line: Clinical Applications Thereof ", 41-PA-31, 3pp.</text>
        </nplcit>
      </citation>
      <citation srep-phase="applicant">
        <nplcit num="9">
          <text>R. Omoto, Y. Yokote, et al. "New System For Converting From Tomogram Echocardiography To M-Mode Freely Set Cursor Line", 40-C-51, 2pp.</text>
        </nplcit>
      </citation>
    </references-cited>
    <related-documents>
      <reissue>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>37920596</doc-number>
              <kind>A</kind>
              <date>19960127</date>
            </document-id>
          </parent-doc>
        </relation>
        <relation>
          <parent-doc>
            <document-id>
              <country>US</country>
              <doc-number>05515856</doc-number>
              <date>19960514</date>
            </document-id>
          </parent-doc>
        </relation>
      </reissue>
    </related-documents>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Vingmed Sound A/S</orgname>
            <address>
              <address-1>Horten, NO</address-1>
              <city>Horten</city>
              <country>NO</country>
            </address>
          </addressbook>
          <nationality>
            <country>NO</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>VINGMED SOUND</orgname>
          </addressbook>
          <nationality>
            <country>NO</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Olstad, Bjorn</name>
            <address>
              <address-1>Ranheim, NO</address-1>
              <city>Ranheim</city>
              <country>NO</country>
            </address>
          </addressbook>
          <nationality>
            <country>NO</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Holm, Eivind</name>
            <address>
              <address-1>Horten, NO</address-1>
              <city>Horten</city>
              <country>NO</country>
            </address>
          </addressbook>
          <nationality>
            <country>NO</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="3">
          <addressbook lang="en">
            <name>Ashman, James</name>
            <address>
              <address-1>Braunstone, GB</address-1>
              <city>Braunstone</city>
              <country>GB</country>
            </address>
          </addressbook>
          <nationality>
            <country>GB</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Blakely, Sokoloff, Taylor &amp; Zafman, LLP</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Manuel, George</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      A method for generating anatomical M-Mode displays for ultrasonic investigation of living biological structures during movement of the structure, for example a heart function, employing an ultrasonic transducer (21) comprises the acquisition of a time series of 2D or 3D ultrasonic images (22), arranging said time series so as to constitute data sets, providing at least one virtual M-Mode line (23) co-registered with said data sets, subjecting said data sets to computer processing on the basis of said at least one virtual M-Mode line, whereby interpolation along said at least one virtual M-Mode line is effected, and displaying the resulting computed anatomical M-Mode display (24) on a display unit.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">This invention relates to a method for generating anatomical M-Mode displays in ultrasonic investigation of living biological structures during movement, for example a heart function, employing an ultrasonic transducer.</p>
    <p num="2">
      The invention describes a technique for obtaining anatomically meaningful M-Mode displays by data extraction from 2D (two dimensional) and 3D (three dimensional) ultrasonic imaging.
      <br/>
      Conventional M-Mode is acquired along one acoustical beam of an ultrasonic transducer employed, displaying the .�.tide-variant.�.  time-variant data in a display unit with time along the x-axis and depth along the y-axis.
      <br/>
      The localization of the M-Mode line in conventional M-Mode is limited to the set of beam directions that can be generated (scanned) by the transducer.
    </p>
    <p num="3">
      In cardiology, the use of the M-Mode method is fairly standardized, requiring specific cuts through the heart at standard positions and angles.
      <br/>
      To be able to perform a good M-Mode measurement, important criteria are:
    </p>
    <p num="4">
      1.
      <br/>
      Image quality.
      <br/>
      The borders and interfaces between different structures of the heart must be clearly visible.
      <br/>
      One of the most important factors to achieve this, is to position the ultrasound transducer on the body concerned at a point where the acoustic properties are optimum.
      <br/>
      These places are often referred to as "acoustic windows".
      <br/>
      On older patients, these windows are scarce, and hard to find.
      <br/>
      2. Alignment. The standardized M-Mode measurements require that the recording is taken at specific angles, usually 90 degrees relative to the heart structure being investigated.
      <br/>
      3. Motion. As the heart moves inside the chest during contraction and relaxation, a correct M-Mode line position at one point in the heart cycle may be wrong at another point in the same heart cycle.
      <br/>
      This is very difficult to compensate for manually, since the probe must be moved synchronous to the heartbeats.
      <br/>
      Therefore, most sonographers settle for a fixed, compromise direction of the M-Mode line, i.e. transducer beam.
      <br/>
      4. Wall thickening analysis.
      <br/>
      With coronary diseases, an important parameter to observe is the thickening of the left ventricular muscle at various positions.
    </p>
    <p num="5">
      In many cases there can be problems getting the correct alignment at a good acoustical window.
      <br/>
      Often, the good acoustic windows give bad alignment, and vice versa.
      <br/>
      Hence, the sonographer or user spends much time and effort trying to optimize the image for the two criteria (alignment, image quality).
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="6">
      With the advent of high-performance digital front-end control for phased transducer array probes, the possibility exists for acquiring 2D images at very high framerates (&lt;10 ms per 2D image).
      <br/>
      These 2D data are stored in a computer RAM, with storage capacity enough to hold one or more full heart cycles worth of 2D data recordings. M-Mode displays can be generated based on these recordings with an adequate temporal resolution.
      <br/>
      According to the present invention this allows for complete flexibility in the positioning of the M-Mode lines.
      <br/>
      The invention describes how this flexibility can be utilized to improve the anatomical information content in the extracted M-Mode displays.
    </p>
    <p num="7">
      The invention also applies to extraction of M-Mode displays from a time series with 3D images.
      <br/>
      In 3D it is possible to compensate for the true 3D motion of the ventricle.
      <br/>
      Based on 2D recordings the operator will be limited to compensate for the movements that can be measured in the imaged plane.
      <br/>
      The invention also describes how local M-Mode information extracted from 3D acquisitions can be utilized to obtain a color encoding of the ventricle wall providing information about wall thickening.
    </p>
    <p num="8">
      The anatomical M-Mode displays can be generated in real-time during scanning of a 2D image or during real-time volumetric scanning.
      <br/>
      The invention then describes how multiple M-Mode displays can be maintained together with the live 2D or 3D image.
      <br/>
      These M-Mode displays can also be freely positioned and even allowed to track the location and direction of the ventricle wall during the cardiac cycle.
      <br/>
      During real-time scanning, time resolution of anatomical M-Mode displays may be increased by constraining the 2D or volumetric scanning to the area defined by the ultrasound probe and the M-Mode line.
      <br/>
      This requires complete control of the ultrasound scanner front-end.
    </p>
    <p num="9">
      The anatomical M-Mode can also be used as a post-processing tool, where the user acquires the 2D/3D image sequence at super-high framerates, without making any M-Mode recordings.
      <br/>
      As long as the 2D data includes an adequate cut/view through the heart, the user may use the anatomical M-Mode to do the M-Mode analysis later.
    </p>
    <p num="10">
      The computer processing of data sets are previously known, as for example described in: J. D. Foley, A van Dam, S. K. Seiner, J. F. Hughes "Computer Graphics: Principles and Practice", Addison Wesley U.S.A. (1990).
      <br/>
      Among other things line drawing algorithms are described in this reference.
      <br/>
      Thus, such computer processing, operations and steps are not explained in detail in the following description.
      <br/>
      Other references relating more specifically to techniques of particular interest here are the following:
      <br/>
      B.
      <br/>
      Olstad, "Maximizing image variance in rendering of volumetric data sets," Journal of Electronic Imaging, 1:245-265, July 1992.
    </p>
    <p num="11">
      E. Steen and B. Olstad, "Volume rendering in medical ultrasound imaging".
      <br/>
      Proceedings of 8th Scandinavian Conference on Image Analysis.
      <br/>
      Troms.o slashed., Norway May 1993.
    </p>
    <p num="12">G. Borgefors, "Distance transformations in digital images", Computer vision, graphics and image processing 34, 1986, pp. 344-371.</p>
    <p num="13">Peter Seitz, "Optical Superresolution Using Solid State Cameras and Digital Signal Processing", Optical Engineering 27(7) July 1988.</p>
    <p num="14">
      On the background of known techniques this invention takes as a starting-point methods for computation of conventional M-Mode and established clinical procedures for utilization of M-Mode imaging.
      <br/>
      The invention includes new techniques for the computation of anatomical M-Mode displays based on a time series of 2D or 3D ultrasonic images.
      <br/>
      The anatomical M-Mode is derived as a virtual M-Mode measurement along an arbitrary or virtual, tilted M-Mode line.
      <br/>
      What is novel and specific in the method according to the invention is defined more specifically in the appended claims.
    </p>
    <p num="15">
      Some of the advantages obtained with this invention can be summarized as follows: Multiple M-Mode displays with arbitrary positioning can be computer on the basis of a 2D or 3D acquisition.
      <br/>
      The position of the M-Mode line is not limited to the scanning geometry and can be freely positioned.
      <br/>
      Global heart movements can be compensated for by moving the M-Mode line according to the motion of the heart during the cardiac cycle.
      <br/>
      Wall thickening analysis is improved due to the possibility of keeping the M-Mode line perpendicular to the ventricle wall during the entire cardiac cycle.
      <br/>
      Reference points in the scene can be fixed at a given y-coordinate in the M-Mode display, hence improving the visual interpretability of relative motion/thickening phenomenons. 3D acquisitions can be visualized by mapping properties extracted from local M-Mode lines in a color encoding of the ventricle wall.
    </p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="16">
      The invention shall be described in more detail in the following description of various embodiments with reference to the drawings, in which:
      <br/>
      FIG. 1 schematically illustrates the computation of M-Mode displays according to the prior art.
      <br/>
      FIG. 2 schematically illustrates the inventive concept of a tilted anatomical or virtual M-Mode line for computation of corresponding M-Mode displays.
      <br/>
      FIG. 3 indicates a setting with multiple M-Mode lines, according to an embodiment of this invention.
      <br/>
      FIG. 4 illustrates how movement of the position of the M-Mode line as a function of the position in the cardiac cycle can be used to obtain motion correction.
      <br/>
      FIG. 5 illustrates an anatomical M-Mode whereby no reference point is specified.
      <br/>
      FIG. 6 illustrates an anatomical M-Mode line when a reference point has been specified and fixed to given vertical position in the display of the anatomical M-Mode.
      <br/>
      FIG. 7 illustrates wall thickening analysis in a setting with 3 simultaneous anatomical M-Mode displays.
      <br/>
      FIG. 8 indicates how the anatomical M-Mode displays are computed in a situation where the position of the M-Mode line is fixed during the cardiac cycle.
      <br/>
      FIG. 9 schematically illustrates how a color encoding of the ventricle wall representing wall thickening can be computed in 4D ultrasonic imaging.
      <br/>
      FIG. 10 schematically illustrates how the acquisition of the ultrasound data can be optimized for used in anatomical M-Mode, reducing the amount of data used for each image, enabling more images to be acquired during a given time span.
    </p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
    <p num="17">
      FIG. 1 illustrates conventional M-Mode imaging.
      <br/>
      An ultrasound transducer 11 is schematically indicated in relation to an ultrasonic image 12 obtained by angular scanning of the acoustical beam of the transducer.
      <br/>
      In this conventional method by the M-Mode line or corresponding acoustical beam 13 is fixed at a given position and the ultrasonic signal along the beam is mapped as a function of time in the M-Mode display 14.
      <br/>
      Extreme temporal resolution can be achieved with this prior art because a new time sample can be generated as soon as the data for one beam has been gathered.
      <br/>
      This prior art for M-Mode imaging will on the other hand limit the positioning of the M-Mode line 13 according to the acoustic windows and scanning geometry.
    </p>
    <heading>TILTED M-MODE LINES</heading>
    <p num="18">
      This invention relates to how M-Mode images can be generated by extraction of interpolated displays from time series of 2D or 3D images.
      <br/>
      The concept of a "tilted" M-Mode display 24 is illustrated in FIG. 2.
      <br/>
      The "virtual" M-Mode line 23 is in this case freely moveable, not being restricted to coincide with one acoustic beam (transducer 21) originating at the top of the 2D image(s) 22.
    </p>
    <heading>MULTIPLE M-MODE LINES</heading>
    <p num="19">
      FIG. 3 illustrates an example where two tilted M-Mode displays 34A, 34B have been computed or calculated from a single 2D sequence or image 32, with corresponding virtual, tilted M-Mode lines indicated at 33A and 33B respectively.
      <br/>
      Basing the generation of M-Mode displays on 2D or 3D images, any sector number of M-Mode displays can be generated, enabling analysis of various dimensions from the same heartbeat.
      <br/>
      Thus, acquired time series as indicated at 1, 2, 3, 4 in FIG. 2 are arranged to constitute data sets, at least one virtual M-Mode line 23 or 33A, 33B in FIG. 3, are provided and co-registered with the data sets, and these are then subjected to computer processing with interpolation along the virtual M-Mode line concerned.
      <br/>
      The importance of interpolation will be explained further below.
    </p>
    <heading>MOTION CORRECTION</heading>
    <p num="20">
      As the heart moves inside the chest during contraction and relaxation, a correct M-Mode line position at one point in the heart cycle may be wrong at another point in the same heart cycle.
      <br/>
      This is very difficult to compensate for manually, the probe must be moved synchronous to the heartbeats.
    </p>
    <p num="21">
      The anatomical M-Modes according to this invention can compensate for this motion.
      <br/>
      FIG. 4 illustrates this concept.
      <br/>
      The user defines the position of the M-Mode line 43A and 43B respectively, at different points in the heart cycle such as by scrolling a 2D cineloop and fixing a new M-Mode line position.
      <br/>
      Appropriate computer operations or software are available and known to those of ordinary skill in this field, as shown in the above references, is utilized to interpolate the M-Mode line positions between the "fixed" M-Mode lines 43A and 43B, and generates an M-Mode display 44 where each vertical line in the M-Mode display is extracted along the local definition of the M-Mode line.
    </p>
    <p num="22">In this manner the position and/or orientation of the virtual M-Mode line can be movable in response to other rhythmic movements in the biological structure or body concerned, other than the heartbeats referred to in the description of FIG. 4.</p>
    <heading>MOTION REFERENCE POINTS</heading>
    <p num="23">
      When studying an organ's time-variant dimensions in a living body, there is often a wish to study the different structures' dimensions relative to each other, without observing the whole organ's displacement inside the body.
      <br/>
      This is especially interesting when looking at the heart's ventricular contractions and relaxations, where the thickening of the muscle tissue is the important parameter to observe.
    </p>
    <p num="24">
      To enhance the relative variations, according to an embodiment of this invention, the user can define a reference point on the "fixed" M-Mode lines described in the previous paragraph on motion correction.
      <br/>
      Typically, this point will correspond to an easily defined clinical structure.
      <br/>
      FIGS. 5 and 6 illustrate M-Mode generation without and with a fixation of a given reference point 66 in the imaged scene 62.
      <br/>
      Thus, on the basis of the reference point 66 associated with the interpolated M-Mode line positions 63A to 63B shown in FIG. 6, there is generated a M-Mode display 64 with this point 66 appearing as a straight line 67 (no motion) i.e. at a chosen vertical coordinate in the display.
      <br/>
      Alternatively, a given y-coordinate can be tracked in the M-Mode display and the M-Mode display regenerated by sliding the position of the M-Mode lines at the various time locations such that the tracked image structure appears as a horizontal structure in the final M-Mode display.
    </p>
    <heading>WALL THICKENING ANALYSIS</heading>
    <p num="25">
      With coronary diseases, an important parameter to observe is the thickening of the left ventricular muscle at various positions.
      <br/>
      Combining the techniques described in previous paragraphs, this invention provides a specially useful tool for left ventricle thickening analysis, as illustrated by FIG. 7.
    </p>
    <p num="26">
      Each M-Mode display 74A, 74B and 74C represents the regional wall thickening and contraction of one part of the ventricle 70, each part being penetrated by a corresponding virtual M-Mode line 73A, 73B and 73C respectively.
      <br/>
      FIG. 7 shows a short axis view of the left ventricle 70 and three anatomical M-Mode displays 74A, 74B, 74C generated with the techniques described in the previous paragraphs.
    </p>
    <heading>IMPLEMENTATION</heading>
    <p num="27">
      The sequence of 2D/3D frames is stored in the scanner/computer employed as a 3- or 4-dimensional array or data set(s) of ultrasound samples.
      <br/>
      This array may have different geometric properties, depending on the transducer probe geometry used, and whether images have been scanconverted to a rectangular format prior to storing.
      <br/>
      For illustration, in the setting shown in FIG. 8, we use an example where the 2D sector data have been scanconverted previously (typically using an ultrasound scanner's hardware scanconverter) and stored to disk/memory in a rectangular data set format, as a 3D-array 82 of samples with the dimensions being �x,y,t�.
    </p>
    <p num="28">
      Generating an M-Mode display 84 can then be viewed upon as cutting a plane 88 through the 3D data set 82, interpolating and resampling the data to fit into the desired display rectangle 84.
      <br/>
      The motion correction techniques described above will modify the cutting plane 88 to a curved surface that is linear in the intersections with the �x,y� planes.
      <br/>
      It is of primary importance that adequate interpolation techniques are applied both in the spatial and temporal dimension.
      <br/>
      Such interpolation can to some extent compensate for inferior resolution compared with conventional M-Mode along the acoustical beams generated by the transducer as shown in FIG. 1.
    </p>
    <p num="29">
      Temporal resolution of the M-Mode displays may be increased by controlling the image acquisition to encompass only the necessary area.
      <br/>
      In FIG. 10, the virtual M-Mode line 101 defines the minimum necessary image area 104.
      <br/>
      By controlling the front-end of the ultrasound scanner to only acquire the necessary acoustical beams 102, and not acquiring the data 103 outside the virtual M-Mode line, the ultrasound scanner uses less time for acquiring the image, and this time is used to improve the temporal resolution of the time series.
      <br/>
      This special enhancement can be done at the cost of freely positioning other virtual M-Mode lines during post-processing.
    </p>
    <p num="30">According to an embodiment of the invention it is an additional and advantageous step to let the result of the above computer processing including interpolation, be subjected to an image processing as known per se for edge enhancement, to produce the resulting computed anatomical M-Mode display.</p>
    <p num="31">3D ULTRASONIC IMAGING</p>
    <p num="32">All the techniques described here apply both to a sequence of 2D and a sequence of 3D ultrasonic images. 3D acquisitions further improves the potential of motion correction described, because the true 3D motion of the heart can be estimated.</p>
    <p num="33">
      In addition to the actual generation of M-Mode displays the techniques according to this invention can be further utilized to extract anatomical M-Modes for all points across the endocard surface in the left ventricle.
      <br/>
      This setting is illustrated with an example in FIG. 9.
      <br/>
      A 4 dimensional ultrasound data set 92 is assumed consisting of m short axis planes and n 3D cubes recorded during the cardiac cycle.
      <br/>
      For simplicity in the figure only three virtual M-Mode lines 93A, 93B, 93C with the associated M-Mode displays 94A, 94B and 94C, respectively, have been drawn, but similar M-Mode displays should be associated with every point or position on the endocard surface in the ventricle 90.
    </p>
    <p num="34">
      Each of the individual M-Mode displays 94A, 94B, 94C . . . , are then processed in order to obtain a characterization that can be visualized as a color encoding of the associated location on the ventricle wall.
      <br/>
      The mapping strategy is illustrated in FIG. 9 and is similar to the approach found in ref. B. Olstad, "Maximizing image variance in rendering of volumetric data sets," Journal of Electronic Imaging, 1:245-265, July 1992 and E. Steen and B. Olstad, "Volume rendering in medical ultrasound imaging".
      <br/>
      Proceedings of 8th Scandinavian Conference on Image Analysis.
      <br/>
      Troms.o slashed., Norway May 1993 identified previously.
      <br/>
      The characterization routine thus operates on an anatomical M-Mode display and generates a single value or a color index that reflects physiological properties derived in the M-Mode image.
      <br/>
      One of these properties is a quantification of wall thickening by estimation of thickening variations during the cardiac cycle.
      <br/>
      Each of the anatomical M-Mode displays 94A, 94B and 94C are in this case analyzed.
      <br/>
      The wall is located in the said M-Mode displays methods such as those described in Peter Seitz, "Optical Superresolution Using Solid State Cameras and Digital Signal Processing", Optical Engineering 27(7) July 1988 for superresolution edge localization at the various time instances in the M-Mode displays and the thickness variations are used to define the said estimated quantification of wall thickening.
      <br/>
      A second property is given by a characterization of the temporal signal characteristics at a given spatial coordinate or for a range of spatial coordinates in the M-Mode displays 94A, 94B and 94C.
    </p>
    <p num="35">
      A second alternative is to use only two cubes that are either temporal neighbors or that are located at End-Systole and End-Diastole.
      <br/>
      The associated M-Modes will in this case reduce to simply two samples in the temporal direction.
      <br/>
      This approach is more easily computed and will provide differential thickening information across the ventricle wall if the cubes are temporal neighbors.
      <br/>
      The wall thickening analysis is in this case a comparison of two one dimensional signals where thickenings can be estimated with the methods described in Peter Seitz, "Optical Superresolution Using Solid State Cameras and Digital Signal Processing", Optical Engineering 27(7) July 1988 for superresolution edge localization.
    </p>
    <p num="36">
      The color encodings described for 3D also applies to 2D imaging, but the color encodings are in this case associated with the boundary of the blood area in the 2D image.
      <br/>
      FIG. 7 illustrates such a 2D image sequence.
      <br/>
      The figure includes only three virtual M-Mode lines 73A, 73B and 73C with the associated M-Mode displays 74A, 74B and 74C, respectively, but similar M-Mode displays should be associated with every point or position on the endocard surface in the ventricle 70.
      <br/>
      Each of the individual M-Mode displays 74A, 74B and 74C are then processed with the same techniques as described above for the corresponding M-Mode displays 94A, 94B and 94C in the three-dimensional case.
    </p>
    <p num="37">
      The M-Mode lines in this embodiment of the invention are associated with each point or position identified on the surface of the ventricle wall and the direction is computed to be perpendicular to the ventricle wall.
      <br/>
      The direction of the local M-Modes are computed as the direction obtained in a 2- or 3-dimensional distance transform of a binary 2- or 3-dimensional binary image representing the position of the points on the ventricle wall.
      <br/>
      See ref. G. Borgefors, "Distance transformations in digital images", Computer vision, graphics and image processing 34, 1986, pp. 344-371 for information on a suitable distance transform.
    </p>
    <p num="38">
      In summary this invention as described above provides a method for computation of anatomical M-Mode displays based on a time series of 2D or 3D ultrasonic images.
      <br/>
      The method is used for the investigation of living biological structures during movement, for example a heart function.
      <br/>
      The main application will be in hospitals and the like.
      <br/>
      The anatomical M-Mode displays can be computed in real-time during the image acquisition or by postprocessing of a 2D or 3D cineloop.
      <br/>
      The anatomical M-Mode is derived as a virtual M-Mode measurement along an arbitrary tilted M-Mode line.
      <br/>
      Multiple, simultaneous M-Mode lines and displays can be specified.
      <br/>
      The arbitrary positioning of the M-Mode line allows for anatomically meaningful M-Mode measurements that are independent of acoustic windows that limit the positioning of M-Modes in the prior art.
      <br/>
      The positioning of the M-Mode line can be changed as a function of time to compensate for global motion.
      <br/>
      The M-Mode line can in this way be made perpendicular to the heart wall during the entire heart cycle.
      <br/>
      This property increases the value of M-Modes in wall thickening analysis because erroneous thickenings caused by inclined measurements can be avoided.
      <br/>
      Furthermore, reference points in the image scene can be fixed in the M-Mode display such that the visual interpretation of relative variations can be improved.
      <br/>
      In 3D cineloops the M-Modes can be computed locally at all points in the ventricle wall along M-Mode lines that are perpendicular to the endocard surface.
      <br/>
      These local M-Modes are exploited to assess wall thickening and to utilize these measurements in a color encoding of the endocard surface.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>We claim:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>A method for generating anatomical M-Mode displays in ultrasonic investigation of living biological structures during movement employing an ultrasonic transducer the method comprising the steps of:</claim-text>
      <claim-text>acquiring a time series of ultrasonic images; arranging said time series so as to constitute data sets obtained by multiple ultrasound beams; providing at least one virtual M-Mode line positioned in relationship to said data sets so as not to coincide with any ultrasonic beam direction of said transducer; subjecting said data sets to computer processing on the basis of said at least one virtual M-Mode line, whereby interpolation along said at least one virtual M-Mode line is effected using values from said multiple ultrasound beams;</claim-text>
      <claim-text>and displaying the resulting computed anatomical M-Mode display on a display unit.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. The method according to claim 1, further comprising the step of moving the position and orientation of said at least one virtual M-Mode line in response to rhythmic movement of the biological structure.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. The method according to claim 2, further comprising the step of associating a reference point with said ultrasonic images and fixing a corresponding reference point at a chosen vertical coordinate in the resulting anatomical M-Mode display based upon said reference point.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. The method according to claim 3, employed for investigating the left ventricle wall of the heart, the method further comprising the steps of: computing anatomical M-Modes associated with each position on the left ventricle wall surface in ultrasonic images so as to represent a differential time evolution of the cardiac cycle, and characterizing each of the computed anatomical M-Modes for color encoding at each said position on the left ventricle wall surface.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. The method according to claim 3, further comprising the steps of: computing anatomical M-Modes associated with each position on the left ventricle wall surface in ultrasonic images limited to the difference between two image frames, and characterizing each of the computed anatomical M-Modes for color encoding at each said position on the left ventricle wall surface.</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. The method according to claim 3, further comprising the steps of: computing anatomical M-Modes associated with each position on the left ventricle wall surface in ultrasonic images so as to represent a time interval, and characterizing each of the computed anatomical M-Modes for color encoding at each said position on the left ventricle wall surface.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. The method according to claim 1, employed for investigating the left ventricle wall of the heart, the method further comprising the steps of: computing anatomical M-Modes associated with each position on the left ventricle wall surface in ultrasonic images so as to represent a differential time evolution of the cardiac cycle, and characterizing each of the computed anatomical M-Modes for color encoding at each said position on the left ventricle wall surface.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. The method according to claim 7, further comprising the step of measuring local or global thickening of said left ventricle wall along said at least one virtual M-Mode line and utilizing the result of the measurement for said color encoding.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. The method according to claim 7, further comprising the step of measuring temporal intensity variations along said at least one virtual M-Mode line and utilizing the result of the measurement for said color encoding.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. The method according to claim 7, further including the step of determining the direction of said at least one virtual M-Mode line as the direction determined in the distance transform from an arbitrary position to the closest position on the left ventricle wall.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. The method according to claim 1, further comprising the steps of: computing anatomical M-Modes associated with each position on the left ventricle wall surface in ultrasonic images limited to the difference between two image frames, and characterizing each of the computed anatomical M-Modes for color encoding at each said position on the left ventricle wall surface.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. The method according to claim 1, further comprising the steps of: computing anatomical M-Modes associated with each position on the left ventricle wall surface in ultrasonic images so as to represent a time interval, and characterizing each of the computed anatomical M-Modes for color encoding at each said position on the left ventricle wall surface.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. The method according to claim 12, further comprising the step of measuring local or global thickening of said left ventricle wall along said at least one virtual M-Mode line and utilizing the result of the measurement for said color encoding.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. The method according to claim 12, further comprising the step of measuring temporal intensity variations along said at least one virtual M-Mode line and utilizing the result of the measurement for said color encoding.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. The method according to claim 1, further comprising the step of subjecting the result of said computer processing with interpolation to image processing for edge enhancement, thus producing said resulting computed anatomical M-Mode display.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. The method according to claim 1, wherein the step of acquiring a time series of ultrasonic images occurs after a desired virtual M-Mode line has been defined, such that only the ultrasound data necessary to generate the said virtual M-Mode line are acquired, thereby increasing the time-resolution of said time series and hence the said computed anatomical M-Mode display.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. The method according to claim 1, further comprising the step of moving the position and orientation of said at least one virtual M-Mode line in response to rhythmic movement of the biological structure.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. The method according to claim 1, further comprising the step of associating a reference point with said ultrasonic images and fixing a corresponding reference point at a chosen vertical coordinate in the resulting anatomical M-Mode display based upon said reference point.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. The method according to claim 1, wherein said time series of ultrasonic images is three dimensional.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. An ultrasound imaging apparatus comprising: a memory to store ultrasonic information associated with a set of ultrasound beams;</claim-text>
      <claim-text>and a computer processing device, coupled to said memory, said processing device to generate a virtual M-mode line that is distinct from said ultrasound beams, and to generate image data based on said M-Mode line.</claim-text>
    </claim>
    <claim num="21">
      <claim-text>21. The apparatus of claim 20, wherein said virtual M-mode line is non-coincident with said set of ultrasound beams.</claim-text>
    </claim>
    <claim num="22">
      <claim-text>22. The apparatus of claim 21, further comprising: a transducer, coupled to said memory, to provide said ultrasonic information associated with said set of ultrasound beams.</claim-text>
    </claim>
    <claim num="23">
      <claim-text>23. The apparatus of claim 21, further comprising: a display, coupled to said processing device, to display an image based on said image data.</claim-text>
    </claim>
    <claim num="24">
      <claim-text>24. The apparatus of claim 23, wherein said image includes color encoded information, based on a predetermined variable.</claim-text>
    </claim>
    <claim num="25">
      <claim-text>25. The apparatus of claim 24, wherein said predetermined variable depends on temporal variation along said virtual M-mode line.</claim-text>
    </claim>
    <claim num="26">
      <claim-text>26. The apparatus of claim 24, wherein said predetermined variable depends on a thickness of an anatomical structure.</claim-text>
    </claim>
    <claim num="27">
      <claim-text>27. The apparatus of claim 26, wherein said structure comprises an anatomical structure having motion.</claim-text>
    </claim>
    <claim num="28">
      <claim-text>28. The apparatus of claim 21, wherein said ultrasonic information comprises a time series of ultrasonic information.</claim-text>
    </claim>
    <claim num="29">
      <claim-text>29. The apparatus of claim 21, wherein said processing device is operable to vary at least one of a position and an orientation of said virtual M-mode line.</claim-text>
    </claim>
    <claim num="30">
      <claim-text>30. The apparatus of claim 29, wherein said processing device is further operable to vary at least one of said position and said orientation of said virtual M-mode line based on motion of a structure indicated by said ultrasonic information.</claim-text>
    </claim>
    <claim num="31">
      <claim-text>31. A system for providing ultrasound imaging, said system comprising: a first means for providing ultrasonic information based on a set of ultrasound beams;</claim-text>
      <claim-text>and a second means for generating image data based at least in part on a virtual M-mode line means which is distinct from said ultrasound beams.</claim-text>
    </claim>
    <claim num="32">
      <claim-text>32. The system of claim 31, wherein: said first means includes a transducer means for generating said set of ultrasound beams upon which said ultrasonic information is based;</claim-text>
      <claim-text>and said M-mode line which is non-coincident with said set of ultrasound beams.</claim-text>
    </claim>
    <claim num="33">
      <claim-text>33. The system of claim 31, further comprising: a display means for displaying an image associated with said image data.</claim-text>
    </claim>
    <claim num="34">
      <claim-text>34. The system of claim 33, wherein said image includes color encoded information, based on a predetermined variable.</claim-text>
    </claim>
    <claim num="35">
      <claim-text>35. The system of claim 34, wherein said predetermined variable depends on temporal variation with respect to said virtual reference means.</claim-text>
    </claim>
    <claim num="36">
      <claim-text>36. The system of claim 34, wherein said predetermined variable depends on a thickness of an anatomical structure.</claim-text>
    </claim>
    <claim num="37">
      <claim-text>37. The system of claim 31, wherein said ultrasonic information comprises a time series of ultrasonic information.</claim-text>
    </claim>
    <claim num="38">
      <claim-text>38. The system of claim 31, wherein said second means comprises means for varying at least one of a position and an orientation of said virtual M-mode line means.</claim-text>
    </claim>
    <claim num="39">
      <claim-text>39. The system of claim 38, wherein said second means provides for varying at least one of said position and said orientation of said virtual M-mode line means based on motion of a structure indicated by said ultrasonic information.</claim-text>
    </claim>
    <claim num="40">
      <claim-text>40. A method for use in an ultrasound imaging system, said method comprising: storing ultrasonic data associated with a set of ultrasonic beams;</claim-text>
      <claim-text>and generating a virtual M-mode line to generate image data based on said ultrasonic data, wherein said virtual M-mode line is distinct from said set of ultrasonic beams.</claim-text>
    </claim>
    <claim num="41">
      <claim-text>41. The method of claim 40, further comprising: displaying an image based on an interpolation of said ultrasonic data along said reference.</claim-text>
    </claim>
    <claim num="42">
      <claim-text>42. The method of claim 41, further comprising: color encoding said image based on a predetermined criteria.</claim-text>
    </claim>
    <claim num="43">
      <claim-text>43. The method of claim 42, wherein said predetermined criteria is associated with a temporal intensity variation with respect to said virtual reference, which comprises a virtual M-mode line.</claim-text>
    </claim>
    <claim num="44">
      <claim-text>44. The method of claim 42, wherein said predetermined criteria is associated with thickening of an anatomical structure.</claim-text>
    </claim>
    <claim num="45">
      <claim-text>45. The method of claim 40, wherein said virtual M-mode line non-coincident with said set of ultrasound beams.</claim-text>
    </claim>
    <claim num="46">
      <claim-text>46. The method of claim 40, further comprising: acquiring a time series of ultrasonic information;</claim-text>
      <claim-text>and arranging said time series of ultrasonic information to generate said ultrasonic data, which represents data sets obtained by said set of ultrasonic beams.</claim-text>
    </claim>
    <claim num="47">
      <claim-text>47. The method of claim 46, wherein said time series of ultrasonic information is three-dimensional (3D).</claim-text>
    </claim>
    <claim num="48">
      <claim-text>48. The method of claim 40, further comprising: moving at least one of a position and orientation of said virtual M-mode line.</claim-text>
    </claim>
    <claim num="49">
      <claim-text>49. The method of claim 48, wherein moving said at least one of said position and orientation of said virtual M-mode line depends on movement of an object represented by said ultrasonic data.</claim-text>
    </claim>
    <claim num="50">
      <claim-text>50. The method of claim 40, further comprising: performing edge enhancement image processing upon said ultrasonic data;</claim-text>
      <claim-text>and displaying an image based on said edge enhanced ultrasonic data, said image representing an interpolation of said ultrasonic data along said virtual M-mode line.</claim-text>
    </claim>
  </claims>
</questel-patent-document>