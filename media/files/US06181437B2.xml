<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06181437B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06181437</doc-number>
        <kind>B2</kind>
        <date>20010130</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6181437</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference is-representative="YES" family-id="26504201" extended-family-id="21258133">
      <document-id>
        <country>US</country>
        <doc-number>08891942</doc-number>
        <kind>A</kind>
        <date>19970714</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1997US-08891942</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>21801387</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>JP</country>
        <doc-number>18719196</doc-number>
        <kind>A</kind>
        <date>19960717</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1996JP-0187191</doc-number>
      </priority-claim>
      <priority-claim kind="national" sequence="2">
        <country>JP</country>
        <doc-number>24469496</doc-number>
        <kind>A</kind>
        <date>19960917</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="2">
        <doc-number>1996JP-0244694</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010130</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G06K   9/46        20060101A I20070721RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>9</main-group>
        <subgroup>46</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20070721</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G06K   9/56        20060101A I20070721RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>9</main-group>
        <subgroup>56</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20070721</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>G06T   5/00        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>5</main-group>
        <subgroup>00</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>358001900</text>
        <class>358</class>
        <subclass>001900</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>382194000</text>
        <class>382</class>
        <subclass>194000</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>382269000</text>
        <class>382</class>
        <subclass>269000</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>382271000</text>
        <class>382</class>
        <subclass>271000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G06K-009/46A1</text>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>009</main-group>
        <subgroup>46A1</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>G06K-009/56</text>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>9</main-group>
        <subgroup>56</subgroup>
      </classification-ecla>
      <classification-ecla sequence="3">
        <text>G06T-007/00S2</text>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>007</main-group>
        <subgroup>00S2</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06K-009/4609</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>9</main-group>
        <subgroup>4609</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170105</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06K-009/56</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>K</subclass>
        <main-group>9</main-group>
        <subgroup>56</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170105</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20170101</date>
        </classification-scheme>
        <classification-symbol>G06T-007/12</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>7</main-group>
        <subgroup>12</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170102</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-2207/20192</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>2207</main-group>
        <subgroup>20192</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20170105</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>S06T-207/20192</classification-symbol>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>30</number-of-claims>
    <exemplary-claim>24</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>19</number-of-drawing-sheets>
      <number-of-figures>42</number-of-figures>
      <image-key data-format="questel">US6181437</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Image processing apparatus capable of producing images without jaggies at edges</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>AOYAMA CHIAKI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5835614</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5835614</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="2">
          <text>UEDA NAOFUMI, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5351315</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5351315</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="3">
          <text>MURATA KAZUYUKI</text>
          <document-id>
            <country>US</country>
            <doc-number>5450208</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5450208</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="applicant">
        <patcit num="4">
          <text>RICOH KK</text>
          <document-id>
            <country>JP</country>
            <doc-number>H07193717</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>JP07193717</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Minolta Co., Ltd.</orgname>
            <address>
              <address-1>Osaka, JP</address-1>
              <city>Osaka</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>MINOLTA</orgname>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Sawada, Kenichi</name>
            <address>
              <address-1>Toyohashi, JP</address-1>
              <city>Toyohashi</city>
              <country>JP</country>
            </address>
          </addressbook>
          <nationality>
            <country>JP</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <orgname>Sidley &amp; Austin</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Rogers, Scott</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      Image data for continuous three pixels delayed by one pixel from each other is input in row and column directions from an image input portion into a scanning window.
      <br/>
      A predetermined image pattern is stored in a count value comparison table for detecting a target pixel on an image contour, and a determining portion performs determination relating to the predetermined image pattern and the input image data.
      <br/>
      Based on the result of determination by the determining portion, an intensity converter portion performs conversion of intensity data such that the target pixel becomes black when the target pixel is present on the image contour, and that the target pixel becomes white in other cases.
      <br/>
      As a result, an image processing apparatus can output a smooth contour image without jaggies regardless of an input image intensity.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">Field of the Invention</p>
    <p num="2">The present invention relates to an image processing apparatus, and in particular to an image correction processing apparatus which corrects intensities at edges of a multilevel thin line image for producing an image without jaggies at edges caused by multilevel-to-binary conversion.</p>
    <heading>DESCRIPTION OF THE BACKGROUND ART</heading>
    <p num="3">Description of the Related Art</p>
    <p num="4">
      Generally, in image output apparatuses such as a copying machine, a facsimile and a printer, image data processing is performed for preparing output data by converting multilevel image data, which is supplied from a reading device or the like, into binary data.
      <br/>
      Various types of binary output methods have been proposed for achieving a higher image quality.
      <br/>
      However, any of them cannot perform multilevel-to-binary conversion without a problem that jaggies at edges or interruptions occur at characters or images formed of thin lines or the like, and therefore sharpness is impaired.
      <br/>
      In the prior art, a high-frequency enhancing filter such as a Laplacian filter has been used for reproducing sharp images.
      <br/>
      Also, a degree of enhancing an intensity of edge is controlled to prevent the interruptions and jaggies.
    </p>
    <p num="5">
      In a conventional image output device, a contrast of an edge is enhanced by enhancing the edge so as to increase the gradient of intensity change between a character and a background.
      <br/>
      However, edge enhancement by a Laplacian filter has the characteristic that an amplification rate increases with an increase in frequency of image data to be processed, so that the enhancement is strongly performed on line images and isolated points.
      <br/>
      Therefore, when a line image is read by a general image reading device using a photoelectric conversion element such as a CCD, the line image itself can be read at a high resolution owing to the edge enhancement processing.
      <br/>
      However, an isolated point and low-intensity image located near the line image are also enhanced, so that jaggies occurs at the line image when multilevel-to-binary conversion is performed.
      <br/>
      If an edge detecting level is lowered for preventing jaggies, even a weak image slant portion other than the line image is determined as an edge, resulting in increase in image noises.
    </p>
    <p num="6">
      FIGS. 21A and 21B are diagrams showing distributions of an intensity of an image edge before and after edge enhancement in the prior art.
      <br/>
      The change in intensity of the edge-enhanced image, which is determined in the edge line or longitudinal direction and shown in FIG. 21B, is larger than that before edge-enhancement shown in FIG. 21A. As a result, conspicuous jaggies appear at line images after the multilevel-to-binary conversion.
    </p>
    <p num="7">
      Further, according to a method in which intensity change is extracted by differentiation with a Laplacian filter, an interior of an image cannot be detected because a change in intensity is not present at the interior, although an edge of the image can be detected.
      <br/>
      As a result, scanning for each pixel is performed independently of surrounding pixels according to the method using the Laplacian filter, so that two-dimensional (planar) characteristics of the image cannot be acquired.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="8">Accordingly, it is an object of the invention to provide an image processing apparatus which can output a smooth contour image without jaggies independently of an intensity of an input image.</p>
    <p num="9">Another object of the invention is to provide an image processing apparatus which can output a contour image of a high quality.</p>
    <p num="10">Still another object of the invention is to provide an image processing apparatus which can produce an image without jaggies caused by multilevel-to-binary conversion.</p>
    <p num="11">Yet another object of the invention is to provide an image processing apparatus in which jaggies at a line image are surely prevented.</p>
    <p num="12">A further object of the invention is to provide an image processing apparatus which can remove isolated points.</p>
    <p num="13">
      For achieving the above objects, the invention provides an image processing apparatus including the following components.
      <br/>
      The image processing apparatus according to the invention includes: an edge determining device for determining whether a predetermined target pixel is present at an image edge or not, and an intensity converter for converting an intensity of the target pixel into a predetermined intensity based on the result of the determination.
    </p>
    <p num="14">
      When the target pixel is not present at the edge of the image, an edge portion of the image portion and an image interior other than the edge are detected independently of each other for converting the target pixel into a pixel of a predetermined intensity.
      <br/>
      When the edge is located at the image interior, the intensity is converted into that of the pixel of the predetermined intensity representing the image interior.
      <br/>
      Since the conversion of the intensity is performed taking surrounding pixels around each pixel into consideration, the two-dimensional characteristics of the image are acquired.
      <br/>
      Independently of the intensity of the input image, a smooth contour image without jaggies can be output.
    </p>
    <p num="15">According to another aspect, an image processing apparatus includes: an input device for inputting image data; an image data take-in device for taking in the input data in row and column directions; a counting device for counting the numbers of predetermined pixels in the taken data individually in rows and columns; a count value setting device for setting predetermined count values for the row and the column; a count value comparator for comparing the result of counting by the counting device with the set value of the count value setting device; and a converter for performing conversion of pixel data in the rows and columns based on the result of comparison by the count value comparator.</p>
    <p num="16">
      In the image processing device, the input image data is continuously taken into a scanning window in the row and column directions, and the number of the pixels having intensities in a predetermined range are counted in the row and column directions.
      <br/>
      Then, a comparison is made with a preset count value table for determining whether a predetermined target pixel is on an image edge.
      <br/>
      Conversion of the input image data is performed in accordance with the result of the comparison.
      <br/>
      Since conversion of the intensity of the input image data is performed depending on whether the target pixel is on the image edge or not, the contour image having a high quality can be output.
    </p>
    <p num="17">According to still another aspect of the invention, an image processing apparatus includes: an edge determining device for determining whether a predetermined target pixel is present on an image edge of a line image or not; and an intensity converter for converting an intensity of the target pixel into a predetermined intensity based on the result of determination.</p>
    <p num="18">
      Since the intensity for the target pixel is converted into the predetermined intensity value when it is determined that the edge of the line image contains the target pixel, the edge intensity can be uniform.
      <br/>
      As a result, it is possible to produce an image without jaggies at its edge caused by multilevel-to-binary conversion.
    </p>
    <p num="19">According to a further aspect of the invention, an image processing apparatus includes: a scanning window for inputting image data containing a target pixel in row and column directions; an image data take-in device for taking the image data into a scanning window in the row and column directions; a counting device for counting the numbers of predetermined pixels in the rows and the columns of the taken data; a line image determining device for determining, based on the result of counting, whether the pixel data in the scanning window forms a line image or not; and a converter for converting intensity data of the pixel data of the target pixel into a predetermined intensity based on the result of the determination by the line image determining device.</p>
    <p num="20">
      According to the apparatus of the above aspect, the successively received image data is taken into the scanning window in a matrix form.
      <br/>
      In the row and column directions, the number of the pixels of the predetermined intensity value are counted per line.
      <br/>
      Based on the count value, it is determined whether a line image is formed at the image edge or not.
      <br/>
      When it is determined that the line image is formed, the intensity of the target pixel is converted into the predetermined intensity value.
      <br/>
      Thus, the scanning window having a matrix form is used for determining whether the line image is formed or not.
      <br/>
      Therefore, the determination of the line image can be performed surely.
      <br/>
      If the line image is formed, the target pixel intensity is converted into the predetermined intensity value, so that the edge intensity can be uniform.
      <br/>
      As a result, jaggies at the line image can be surely prevented.
    </p>
    <p num="21">The apparatus of the above aspect may include an average intensity value calculating device for calculating an average intensity value from intensity values of the pixels forming the line image in the scanning window, in which case the intensity value converter uses the average intensity value as the predetermined intensity value.</p>
    <p num="22">According to a further aspect of the invention, an image processing apparatus includes: a scanning window for inputting pixel data containing a target pixel in row and column directions; an image data take-in device for taking the pixel data into a scanning window in the row and column directions; a counting device for counting the number of predetermined pixels in the rows and the columns of the taken data; a line image determining device for determining, based on the result of counting, whether the pixel data in the scanning window forms a line image or not; an isolated pixel determining device for determining whether the target pixel is an isolated pixel or not; and a converter for converting intensity data of the image data of the target pixel into a predetermined line image intensity when the target pixel is contained in the line image according to the result of the determination by the line image determining device, and converting the intensity data of the image data of the target pixel into a predetermined isolated point intensity when the target pixel is the isolated point according to the result of the determination by the isolated point pixel determining device.</p>
    <p num="23">The foregoing and other objects, features, aspects and advantages of the present invention will become more apparent from the following detailed description of the present invention when taken in conjunction with the accompanying drawings.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="24">
      FIGS. 1A and 1B are diagrams showing intensity distributions of line images read by an image reading device and subjected to edge enhancement processing such as an MTF (Modulation Transfer Function);
      <br/>
      FIG. 2 is a block diagram showing a major portion of an image processing apparatus of a first embodiment;
      <br/>
      FIG. 3 shows a scanning window;
      <br/>
      FIG. 4 shows image data taken into the scanning window;
      <br/>
      FIG. 5 shows a line image to be detected;
      <br/>
      FIGS. 6A to 6E show examples of line images in the scanning window;
      <br/>
      FIGS. 7A to 7C show examples of line images in the scanning window;
      <br/>
      FIG. 8 is a flowchart showing the contents of line image detection processing;
      <br/>
      FIGS. 9A and 9B show examples of line images in the scanning window;
      <br/>
      FIG. 10 is a block diagram showing a major portion of an average intensity value calculating circuit;
      <br/>
      FIG. 11 is a flowchart showing the contents of average intensity calculation processing;
      <br/>
      FIG. 12 is a block diagram showing a major portion of an image processing apparatus of a second embodiment;
      <br/>
      FIG. 13 is a flowchart showing an operation of the image processing apparatus of the second embodiment;
      <br/>
      FIGS. 14A and 14B are diagrams showing isolated pixels neighboring to a line image;
      <br/>
      FIG. 15 is a flowchart showing the contents of isolated point detection processing;
      <br/>
      FIGS. 16A and 16B show examples of pixels in the scanning window during the isolated point detection processing;
      <br/>
      FIG. 17 shows an example of a pixel in the scanning window during the isolated point detection processing;
      <br/>
      FIG. 18 shows a distribution of intensity of an image subjected only to edge enhancement processing;
      <br/>
      FIG. 19 shows a distribution of intensity of an image subjected to image correction processing after the edge enhancement processing;
      <br/>
      FIG. 20 is a diagram showing intensity distributions at an image edge before and after edge enhancement processing;
      <br/>
      FIGS. 21A and 21B are diagrams showing intensity distributions at an image edge before and after edge enhancement processing in the prior art;
      <br/>
      FIG. 22 is a block diagram showing a major portion of an image processing apparatus of a third embodiment of the invention;
      <br/>
      FIG. 23 shows a structure of a scanning window in the third embodiment of the invention;
      <br/>
      FIG. 24 shows a positional relationship between a line image and a scanning window;
      <br/>
      FIG. 25 shows a line image pattern matching with a count value table;
      <br/>
      FIGS. 26A and 26B show line image patterns not matching with the count value table;
      <br/>
      FIG. 27 is a flowchart showing processing of a count value comparator;
      <br/>
      FIG. 28 shows an example in such a case that line images in row and column directions are detected in a scanning window, and a result by count value comparison exhibits a match;
      <br/>
      FIG. 29 shows a positional relationship between a scanning window and a line image; and
      <br/>
      FIG. 30 shows an example of processing of the input image shown in FIG. 28.
    </p>
    <heading>DESCRIPTION OF THE PREFERRED EMBODIMENTS</heading>
    <p num="25">(1) First Embodiment</p>
    <p num="26">
      A first embodiment of the invention will now be described below with reference to the drawings.
      <br/>
      FIG. 1A shows a line image for two pixels, and FIG. 1B shows intensity variation.
      <br/>
      When this image is converted into a binary form with a threshold (Th) as shown in FIG. 18, a change between white and block occurs at pixels of intensities immediately above and below the threshold, so that the binary image has jaggies at the edge.
      <br/>
      Although jaggies at the edge may occur in various forms, the jaggies occur independently of manners of binary conversion such as a threshold fixed binary conversion and an error diffusion method.
    </p>
    <p num="27">
      Intensity correction by the image correction processing apparatus according to the invention will be described below.
      <br/>
      FIG. 2 is a block diagram showing a major portion of an image correction processing apparatus according to the invention.
      <br/>
      Referring to FIG. 2, image correction processing device 10 includes line memories 11 for storing image signals for 5 lines which are delayed by one line from each other, a line image detecting circuit 12 for detecting a line image based on data for 5 lines, an average intensity value calculating circuit 13 for calculating an average value of intensities of a line image portion if the line image is detected, and an intensity converter circuit 14 connected to average intensity value calculating circuit 13 for converting the intensity value of the target pixel into the average intensity value.
    </p>
    <p num="28">
      First, the image signals for five lines, which are delayed by one line from each other, are obtained from the input image signals by the continuously connected five line memories 11.
      <br/>
      These image signals are multilevel image signals which are subjected to edge enhancement by MTF correction or the like.
      <br/>
      From the data for five lines thus obtained, line image detecting circuit 12 detects the line image with a window of 5 * 5 pixels.
    </p>
    <p num="29">
      When the line image is detected, average intensity value calculating circuit 13 calculates the average value of the intensities of the detected line image portion, and intensity converter circuit 14 converts the target pixel intensity value into the average intensity value.
      <br/>
      When the line image is not detected, the conversion of the target pixel intensity value is not performed.
    </p>
    <p num="30">
      Description will now be given on detection of a line image edge by line image detecting circuit 12 shown in FIG. 2 with reference to FIG. 3.
      <br/>
      FIG. 3 shows a scanning window 21 forming line image detecting circuit 12.
      <br/>
      First, image data a(ij) (i, j=1, 2, 3, 4, 5) of 5 * 5 pixels is obtained from the image signals for five lines already subjected to the edge enhancement processing.
      <br/>
      The target pixel is represented by a33.
      <br/>
      Based on the pixel data, an operation is performed to count the numbers of pixel(s) of the intensity in a predetermined range in the row and column directions of the scanning window.
      <br/>
      It is assumed that the count values are represented by n10-n50 and n01-n05.
      <br/>
      This predetermined intensity range is determined to allow counting of the number of pixels at the background level in the input image data.
      <br/>
      If the input image data is, for example, a 256-level data, the ground level range is set to be from 0 to 15 for counting the number of pixels contained in this range.
    </p>
    <p num="31">
      FIG. 4 shows a specific example of image data taken into scanning window 21.
      <br/>
      Referring to FIG. 4, count values n of pixels in the predetermined intensity range (0-15) are shown in a matrix form.
      <br/>
      In order to detect line images from the arrangement of pixels in scanning window 21 based on these count values, this embodiment employs such a setting that only the line, of which counting shows the count value n of 0 or 1, is deemed as a line image and others are deemed as a background.
      <br/>
      According to this setting, the image in FIG. 4 is detected as line images shown in FIG. 5.
      <br/>
      More specifically, hatched portions in FIG. 5 are determined as line images.
    </p>
    <p num="32">
      Description will now be given on a count value comparator circuit 22 included in line image detecting circuit 12.
      <br/>
      Count value comparator circuit 22 makes a comparison between a count value table and actual count values.
      <br/>
      FIGS. 6A to 6E and FIGS. 7A to 7C show examples in which line images are detected in the aforementioned manner.
      <br/>
      Intensity converter circuit 14 at the downstream stage performs conversion of the target pixel intensity values.
      <br/>
      In connection with this, the target pixels must always be contained at edges of line images in order to perform the intensity correction of image edges, which is a purpose of this processing, by pipeline processing.
    </p>
    <p num="33">
      In the cases shown in FIGS. 7A to 7C, line images are detected in scanning window 21, but the target pixels are not present on the line image edges.
      <br/>
      For excluding these cases and thereby performing accurately the intensity conversion, a count value table for comparison which will be described later is prepared.
      <br/>
      Also, the intensity conversion is allowed only when a match occurs between the count value table for comparison and the actual count value.
      <br/>
      According to this count value table, the count value n of 0 or 1 represents B (line image), and the other values represent W (background).
      <br/>
      In the various figures, "*" means that the type (i.e., B or W) is not specified.
      <br/>
      In the example shown in FIG. 6A, therefore, a line image of one line can be detected regardless of whether a line image is present at lines of n10 and n50 (uppermost row in the count value table), because the line of n30 forms the line image, and the lines of n20 and n40 form the background.
    </p>
    <p num="34">The following table 1 represents count value table 22 for comparison.</p>
    <p num="35">
      --             TABLE 1
      <br/>
      --             A             B    C           D    E
      <br/>
      --        Row Direction Count Value Table
      <br/>
      --        n10    *             *    W           *    B
      <br/>
      --        n20    W             W    B           W    B
      <br/>
      --        n30    B             B    B           B    B
      <br/>
      --        n40    W             B    W           B    W
      <br/>
      --        n50    *             W    *           B    *
      <br/>
      --        Column Direction Count Value Table
      <br/>
      --        n01    *             *    W           *    B
      <br/>
      --        n02    W             W    B           W    B
      <br/>
      --        n03    B             B    B           B    B
      <br/>
      --        n04    W             B    W           B    W
      <br/>
      --        n05    *             W    *           B    *
    </p>
    <p num="36">
      FIGS. 6A to 6E show line images in the row direction which are detected because they exhibit a match with count value table 22 for comparison.
      <br/>
      Similar images are also found in the column direction.
      <br/>
      In any case, the target pixel is contained in the edge of the line image.
    </p>
    <p num="37">
      FIG. 8 is a flowchart showing an operation of line image detecting circuit 12 described above.
      <br/>
      Referring to FIG. 8, comparison of the count values for the row direction in scanning window 21 is performed (-11).
      <br/>
      When a match is found (YES at -12), the line, which is detected for calculating the average intensity at the next stage as will be described later, is stored (-13).
      <br/>
      Thereafter, comparison is performed in connection with the column direction (-14), and similar processing is performed (-15 and -16).
      <br/>
      FIGS. 9A and 9B show examples of line images which are detected in the row and column directions as described above.
    </p>
    <p num="38">
      FIG. 10 is a block diagram showing a schematic structure relating to the average intensity value calculating circuit.
      <br/>
      Referring to FIG. 10, the calculation of the average intensity is performed by calculating the average intensity of the line images detected based on the intensity data which are obtained from the line address obtained from the result of line image detection by line image detecting circuit 12 (lines determined as the line image), coordinate values (coordinate values of pixels forming the line images) and the intensity data obtained from scanning window 21.
      <br/>
      The average intensity values are calculated in the row and column directions Nr and Nc independently of each other.
      <br/>
      For the direction in which the line image is not detected, the average intensity value is 0.
      <br/>
      If neither Nr nor Nc are 0 (if line images in both the directions are detected), magnitudes of Nr and Nr are compared, and the larger one is handled as output data to intensity converter circuit 14.
      <br/>
      Owing to this manner, the intensity value in the case where the line images cross each other does not lower, and blurring at the crossing point can be prevented.
    </p>
    <p num="39">
      In the example shown in FIG. 9B, the lines of n20 and n30 are detected as the line images in the row direction as a result of the line image detection, and the line of n03 is detected as the line image in the column direction.
      <br/>
      Nr is obtained from the intensity data for 10 pixels in total forming the lines of n20 and n30.
      <br/>
      Nc is obtained from the intensity data for 5 pixels in total forming the line of n03.
    </p>
    <p num="40">
      FIG. 11 is a flowchart showing an operation of average intensity value calculating circuit 13.
      <br/>
      Referring to FIG. 11, it is determined whether the line image is present in the row direction or not (-21).
      <br/>
      If the line image is present in the row direction, the average intensity in the row direction is calculated as Nr (-22).
      <br/>
      If not, Nr is set to 0 (-23).
      <br/>
      For the column direction, similar detection is performed for calculating the average intensity in the column direction (-24 and -25).
      <br/>
      If not detected in the column direction, Nc is set to 0 (-26).
    </p>
    <p num="41">Then, the intensities in the row and column directions are compared with each other, and a larger intensity data is output (-27--29).</p>
    <p num="42">
      Intensity converter circuit 15 converts the target pixel intensity value to 0 only when the aforementioned average intensity value calculating circuit 13 issues the output data other than 0.
      <br/>
      When average intensity value calculating circuit 13 issues data of 0, conversion of the target pixel intensity value is not performed.
    </p>
    <p num="43">By the intensity correction of the line image edge described above, the intensity values of the edge are changed into a uniform value, so that it is possible to prevent jaggies which may occur due to multilevel-to-binary conversion.</p>
    <p num="44">(2) Second Embodiment</p>
    <p num="45">
      A second embodiment of the invention will be described below.
      <br/>
      In the second embodiment, the image intensity correction processing described in the first embodiment additionally has a function of removing an isolated pixel near a line image.
    </p>
    <p num="46">
      FIG. 12 is a block diagram showing a major portion of an image correction processing apparatus of a second embodiment.
      <br/>
      Referring to FIG. 12, the image correction processing apparatus according to the second embodiment includes line memories 11, line image detecting circuit 12, an isolated point detecting circuit 16, an average intensity value calculating circuit 17 and an intensity converter circuit 18.
      <br/>
      Capturing of the image data, detection of the line images and calculation of the average intensity value are performed in a manner similar to that in the first embodiment.
    </p>
    <p num="47">
      FIG. 13 is a flowchart showing an operation of the image correction processing apparatus of the second embodiment.
      <br/>
      Referring to FIGS. 12 and 13, capturing of the image data, determination of the line image and calculation of the average intensity value are performed (-31--33).
      <br/>
      Only when the output result of average intensity value calculating circuit 17 is 0, an operation for detecting an isolated point is performed (-34 and -35).
      <br/>
      When the isolated point is detected, an intensity value of 0 is issued to intensity converter circuit 18 (-36).
      <br/>
      The isolated pixel in the above and following descriptions is a pixel which neighbors to a line image edge and causes jaggies at the line image as indicated by arrows in FIGS. 14A and 14B.
    </p>
    <p num="48">FIG. 14A is a diagram showing an intensity distribution at an image edge, and FIG. 14B shows actual image data.</p>
    <p num="49">
      Next, a method of determining the isolated pixel will be described below.
      <br/>
      Determination of the isolated pixel is performed similarly to the determination of the line image already described, and more specifically is performed by counting the number of pixels in scanning window 21 and comparing the result with a count value table for detection of isolated points.
      <br/>
      A predetermined intensity range for the counting may be equal to that for line image determination.
      <br/>
      However, in scanning window 21 of a 5 * 5 size, reference is made to 3 * 3 pixels including the target pixel at the center.
      <br/>
      Also, a count value table different from that for image line determination is employed.
      <br/>
      In this embodiment, it is determined that the target pixel is isolated if the comparison result shows a match in either the row or column direction.
    </p>
    <p num="50">
      The following table 2 is a count value table for detection of an isolated point.
      <br/>
      In this count value table, K represents that two pixels having intensities in a predetermined range are present in a center line (n20, n02) at the matrix in the scanning window, and in other words that one pixel is present at the center line as a pixel other than the background.
    </p>
    <p num="51">
      --                             TABLE 2
      <br/>
      --                             A    B
      <br/>
      -- Count Value Table for Detecting Isolated Points in Row Direction
      <br/>
      -- n20                         W    B
      <br/>
      -- n30                         K    K
      <br/>
      -- n40                         B    W
      <br/>
      -- Count Value Table for Detecting Isolated Points
      <br/>
      -- in Column Direction
      <br/>
      -- n02                         W    B
      <br/>
      -- n03                         K    K
      <br/>
      -- n04                         B    W
      <br/>
      -- however,
      <br/>
      --                             n    K
      <br/>
      --                             1    W
      <br/>
      --                             2    B
      <br/>
      --                             3    W
    </p>
    <p num="52">
      FIG. 15 is a flowchart showing contents of processing for detecting isolated points.
      <br/>
      Referring to FIG. 15, comparison of count values is performed in connection with the row direction in scanning window 21 (-41).
      <br/>
      When a match is found (YES at -42), it is checked whether the target pixel is the isolated pixel (-43).
      <br/>
      If the target pixel is the isolated pixel (YES at -44), the intensity value of 0 is issued as output data (-50).
    </p>
    <p num="53">
      After completion of checking in the row direction, similar comparison of the count values is performed in the column direction (-45).
      <br/>
      If a match is found (YES at -46), it is checked whether the target pixel is the isolated pixel or not (-47).
      <br/>
      If the target pixel is the isolated pixel (YES at -48), the intensity value of 0 is issued as output data (-50).
      <br/>
      If not, or if a match with data in the isolated point determining window does not occur in the column direction, the original intensity value is issued (-49).
      <br/>
      A description will be given more specifically in the following.
    </p>
    <p num="54">
      FIGS. 16A, 16B and 17 show examples of pixels in scanning window 21 during processing of detecting isolated points.
      <br/>
      FIGS. 16A and 16B relate to the row direction in the case where a match is found as a result of comparison with the count value table.
      <br/>
      FIG. 17 relates to the case where a match is found as a result of comparison with the count value table similarly to the case shown in FIGS. 16A and 16B, but the target pixel is not the isolated pixel.
      <br/>
      In the processing of determining isolated points, it is checked whether the target pixel is the isolated pixel or not after the comparison of the count values as shown in the flowchart of FIG. 15. More specifically, it is determined whether the intensity value of the target pixel is outside the predetermined intensity range (0-15 in 256-levels) or not.
      <br/>
      If it is outside, it is determined that the target pixel is the isolated pixel, and the intensity value of 0 is issued to intensity converter circuit 18 at the downstream stage.
      <br/>
      If the isolated pixel is not detected, conversion of the intensity is not performed because the original input intensity value is issued.
    </p>
    <p num="55">
      Intensity converter circuit 18 converts the intensity value of the target pixel into the average intensity value issued from average intensity value calculating circuit 17 or the intensity value of 0 issued from isolated point determining circuit 16.
      <br/>
      Intensity converter circuit 18 does not perform conversion when the original input intensity value is issued.
    </p>
    <p num="56">
      FIGS. 18 to 20 show an effect of the invention.
      <br/>
      FIG. 18 shows an intensity distribution of an image subjected only to the edge enhancing processing.
      <br/>
      FIG. 19 shows an image intensity distribution at the edge subjected to the image correction processing according to the invention after the edge enhancement processing.
      <br/>
      FIG. 20 is a diagram showing an intensity distribution at the image edge subjected to the processing according to the invention.
      <br/>
      Referring to FIGS. 18 to 20, the intensity varies slowly in the longitudinal direction of the edge, whereby the effect of the correction processing according to the invention can be confirmed.
    </p>
    <p num="57">(3) Third Embodiment</p>
    <p num="58">
      A third embodiment of the invention will be described below with reference to the drawings.
      <br/>
      FIG. 22 is a block diagram showing a major portion of an image processing apparatus of the third embodiment of the invention.
      <br/>
      Referring to FIG. 22, an image processing apparatus 101 of the third embodiment includes an image signal input portion 111 for obtaining image signals for three lines, which are delayed by one line from each other, from input image signals, a scanning window 112 connected to image signal input portion 111 for holding image data of 3 pixels at a time in the row direction, a count value comparison table 113 connected to scanning window 112 for holding preset count values, a determining portion 114 connected to count value comparison table 113 for determining whether the target pixel is on a contour image or not, and an intensity converter portion 115 for performing conversion of the intensity of the target pixel in accordance with a result of determination.
    </p>
    <p num="59">
      Image signal input portion 111 includes continuously connected two line memories 110, which obtain the image signals for three lines delayed by one line from each other.
      <br/>
      The input image signal may be either a binary signal or a multilevel signal.
      <br/>
      Scanning window 112 is formed of 3 * 3 pixels including the target pixel at the center.
      <br/>
      The number of pixels of intensities, which are within a predetermined intensity ranges in both the row and column directions, is counted.
      <br/>
      Comparison is made between the results of counting in scanning window 112 and the preset count values in count value comparison table 113.
      <br/>
      In determining portion 114, it is determined, based on the comparison with count value comparison table 113, whether the target pixel is on the contour image or not.
      <br/>
      Intensity converter portion 115 performs conversion of the target pixel intensity when it is determined that the target pixel is on the contour image based on the comparison result, and thereby the contour image is obtained.
    </p>
    <p num="60">
      Referring to FIG. 23, detection of the line image will now be described more specifically.
      <br/>
      FIG. 23 specifically shows scanning window 112.
      <br/>
      First, image data a(ij) (i, j=1, 2, 3) of 3 * 3 pixels is obtained from the input image signals for three lines.
      <br/>
      The target pixel is represented by a22.
      <br/>
      Based on the pixel data, an operation is performed to count the number of pixel(s) of the intensity in a predetermined range in the row and column directions or components of scanning window 112.
    </p>
    <p num="61">
      When the input image data is binary, the predetermined intensity is set to 0.
      <br/>
      When it is multilevel data, the predetermined intensity range is set to a range from 0 to 15.
      <br/>
      The counted numbers are set to n10-n30 and n01-n03 as shown in FIG. 23.
    </p>
    <p num="62">
      The above intensity range is determined to allow counting of the number of pixels at the background level in the input image data.
      <br/>
      This count value takes a value from 0 to 3 when scanning window size 112 has a 3 * 3 size.
      <br/>
      The value of 3 represents that the intensities of all the counted pixels in the row or column direction are in the predetermined intensity range (background level).
      <br/>
      The value of 0 represents that the pixel belongs to an image other than the background image.
      <br/>
      The value of 1 represents that two of three pixels belong to an image other than the background.
      <br/>
      The value of 2 represents that one of three pixels belong to an image other than the background.
      <br/>
      In the image processing apparatus of this embodiment, it is determined that the pixel belongs to a line image when the count value is 0 or 1.
      <br/>
      In other words, if the count value is 0 or 1, it is determined that image data represents the line image formed of two or three pixels and includes 0 or 1 pixel at the background level.
      <br/>
      Thereby, the contour image can be efficiently output even if an interruption and/or a jaggy are present on the image edge.
      <br/>
      In the foregoing processing, it is detected whether a line image is present or not at each of three longitudinal lines and three lateral lines in scanning window 112 of the 3 * 3 size.
    </p>
    <p num="63">
      A specific example will be described below with reference to FIG. 24, which is a diagram showing a relationship between a portion of a line (character) image and scanning window 112.
      <br/>
      Although this example shows only a lateral-line (character) image, the same is true with respect to a longitudinal-line image.
      <br/>
      It is assumed that scanning window 112 has relationships a to f in the figure with respect to line images 121 and 122.
    </p>
    <p num="64">
      In the case of relationship a, a line image is not detected in scanning window 112.
      <br/>
      In the cases of b and f, a line image of one line is detected in the row direction.
      <br/>
      In the cases of c and e, two lines in the row direction and three lines in the column direction are detected.
      <br/>
      In the case of d, a line image of three lines is detected in each of the row and column directions.
      <br/>
      In the figures, "*" represents the target pixel.
    </p>
    <p num="65">
      For outputting the contour image by pipeline processing, it is desired that the target pixel is detected on the contour image.
      <br/>
      Therefore, the relationships other than c and f do not satisfy the above desired situation, and therefore must be excluded (in c and f, target pixels are present on image edges).
      <br/>
      Accordingly, the following count value table is prepared, and count values in the scanning window are actually compared with this table for performing extraction only when it is determined, based on a match, that the target pixel is present on the image edge.
      <br/>
      In this count value table 3, B (image) represents the case where the count value n is 0 or 1, and W (background) represents the case where the count value n is 2 or 3.
    </p>
    <p num="66">
      -- TABLE 3
      <br/>
      -- Count Value Table for Detecting Isolated Points
      <br/>
      -- in Row Direction
      <br/>
      -- n10                       n20    n30
      <br/>
      -- W                         B      W
      <br/>
      -- W                         B      B
      <br/>
      -- B                         B      W
      <br/>
      -- Count Value Table for Detecting Isolated Points
      <br/>
      -- in Column Direction
      <br/>
      -- n01                       n02    n03
      <br/>
      -- W                         B      W
      <br/>
      -- W                         B      B
      <br/>
      -- B                         B      W
    </p>
    <p num="67">
      Line image patterns matching with the above count value table are shown at g, h and i in FIG. 25. Although FIG. 25 shows only examples in the row direction, similar patterns can be obtained in the column direction.
      <br/>
      In these examples, the count value n is 0 or 3.
      <br/>
      In the figure, g represents a line image having a width of one pixel, and h and i represent line images having widths of two or more pixels.
      <br/>
      In all the examples, the target pixels are present on edges of the line images.
    </p>
    <p num="68">
      FIGS. 26A and 26B show examples of line image patterns not matching with the count value table.
      <br/>
      In these examples, line images are detected in scanning window 112 but the target pixels are not present on line image edges, so that this processing does not handle these examples as detection of a contour.
    </p>
    <p num="69">
      The above examples have been discussed only in connection with the row direction.
      <br/>
      Actual comparison with the count value table is performed in the row and column directions for determining whether the target pixel is on the image edge or not.
    </p>
    <p num="70">
      FIG. 27 is a flowchart showing steps for comparison of count values.
      <br/>
      Referring to FIG. 27, in the processing for comparison of count values, it is first determined whether a match is found in the row direction or not (step S11).
      <br/>
      If not, it is determined whether a match is found in the column direction or not (step S12).
      <br/>
      If a match is found in neither the row nor column directions, it is determined that the target pixel is not present on the edge (step S13).
      <br/>
      If there is a match in at least one of the row and column directions (YES at steps S11 and/or S12), it is determined that the target pixel is present on the edge (step S14).
    </p>
    <p num="71">
      As shown in FIG. 27, when a match is found in at least one of results of the count value comparison in the row and column direction, it is determined that the target pixel is present on the image edge.
      <br/>
      The order of check of the rows and columns is not restricted.
    </p>
    <p num="72">
      FIGS. 28 and 29 are diagrams showing examples in the case where line images in the row and column directions are detected in scanning window 112 and a match is found from the result of comparison by the count value comparator.
      <br/>
      FIG. 28 shows contents in windows j, k and m at positions of line images 123-126 in FIG. 29, respectively.
    </p>
    <p num="73">
      If determining portion 114 determines from FIGS. 28 and 29 that the target pixels are present on image edges, intensity converter portion 115 converts the target pixel into a black pixel.
      <br/>
      If not, intensity converter portion 115 converts the target pixel into a white pixel.
      <br/>
      The image data thus obtained is shown in FIG. 30. As shown in the figure, black pixels are set only at portions where the target pixels are present on the image edges, and pixels at the other portions are converted into white pixels, so that the edge of image is clearly displayed.
      <br/>
      As a result, a clear contour image can be obtained.
    </p>
    <p num="74">The image processing apparatus according to the invention can be applied not only to a laser printer and a scanner but also to image display for a personal computer and image correction processing in a page memory.</p>
    <p num="75">Although the present invention has been described and illustrated in detail, it is clearly understood that the same is by way of illustration and example only and is not to be taken by way of limitation, the spirit and scope of the present invention being limited only by the terms of the appended claims.</p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>What is claimed is:</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20.</claim-text>
      <claim-text>A method of processing image data comprising the steps of: inputting image data; reading a portion of said image data corresponding to a scanning window, said scanning window including a plurality of pixel data which are arranged in rows and columns; counting the numbers of predetermined pixels in the read image data individually in rows and columns; setting predetermined count values for the rows and the columns; comparing a result of counting by said counting step with the set values of said setting step;</claim-text>
      <claim-text>and performing conversion of pixel data in the rows and columns based on a result of said comparing step.</claim-text>
    </claim>
    <claim num="24">
      <claim-text>24. A method of processing image data comprising: reading image data corresponding to a scanning window, said scanning window including a plurality of pixel data which are arranged in rows and columns; counting numbers of predetermined pixels in the rows and the columns of the read data; determining, based on a result of counting by said counting step, whether the pixel data in the scanning window forms a line image or not;</claim-text>
      <claim-text>and converting intensity data of the pixel data of said target pixel into a predetermined intensity based on a result of said determination by said determining step.</claim-text>
      <claim-text>1. An image processing apparatus comprising:</claim-text>
      <claim-text>an input device for inputting image data; a device for reading a portion of said image data corresponding to a scanning window, said scanning window including a plurality of pixel data which are arranged in rows and columns; a counting device for counting the numbers of predetermined pixels in the read image data individually in rows and columns; a count value setting device for setting predetermined count values for the rows and the columns; a count value comparing device for comparing a result of counting by said counting device with the set values of said count value setting device;</claim-text>
      <claim-text>and a converter for performing conversion of pixel data in the rows and columns based on a result of said comparison by said count value comparing device.</claim-text>
      <claim-text>2. An image processing apparatus according to claim 1, wherein said input device continuously inputs image data, and said device for reading takes in a plurality of input image data in the row and column directions.</claim-text>
      <claim-text>3. An image processing apparatus according to claim 1, wherein said counting device counts the number of the predetermined pixels in a predetermined intensity range.</claim-text>
      <claim-text>4. An image processing apparatus according to claim 1, wherein said count value setting device sets the count values for the rows and columns, respectively, such that the predetermined target pixel is present on an edge of the image forming the image data, and said converting device converts the intensity of the target pixel into a predetermined intensity when a predetermined result of comparison is obtained.</claim-text>
      <claim-text>5. An image processing apparatus according to claim 4, wherein said converting device converts the intensity of the target pixel into an intensity of a black pixel when a predetermined result of comparison is obtained, and converts the intensity of the target pixel into an intensity of a white pixel when the predetermined result of comparison is not obtained.</claim-text>
      <claim-text>6. An image processing apparatus according to claim 5, wherein said input device continuously inputs the image data, and said device for reading takes in a plurality of input image data in the row and column directions.</claim-text>
      <claim-text>7. An image processing apparatus according to claim 6, wherein said counting device counts the number of the predetermined pixels in a predetermined intensity range.</claim-text>
      <claim-text>8. An image processing apparatus comprising: a device for reading image data corresponding to a scanning window, said scanning window including a plurality of pixel data which are arranged in rows and columns; a counting device for counting numbers of predetermined pixels in the rows and the columns of the read data; a line image determining device for determining, based on a result of counting by said counting device, whether the pixel data in the scanning window forms a line image or not;</claim-text>
      <claim-text>and a converter for converting intensity data of the pixel data of said target pixel into a predetermined intensity based on a result of said determination by said line image determining device.</claim-text>
      <claim-text>9. An image processing apparatus according to claim 8, further comprising an average intensity value calculating device for calculating an average intensity value from intensity values of a plurality of pixels forming a line image in the scanning window, wherein said predetermined intensity is said average intensity value.</claim-text>
      <claim-text>10. An image processing apparatus according to claim 8, wherein said line image determining device includes:</claim-text>
      <claim-text>- a count value table for setting predetermined count values for the rows and columns in said scanning window, and - a comparator for comparing a result of counting by said counting device with the predetermined count values in said count value table; - wherein the result of said comparison by said comparator is used to determine whether the pixel data forms a line image or not.</claim-text>
      <claim-text>11. An image processing apparatus according to claim 9, wherein said line image determining device determines, in both the row and column directions, whether the pixel data forms a line image or not, said average intensity value calculating device calculates the average intensity value of each of the line images when said line image determining means determines presence of line images in both the row and column directions, and said converter converts the intensity value of said target pixel into a larger one of the calculated average intensity values.</claim-text>
      <claim-text>12. An image processing apparatus comprising: a device for reading image data corresponding to a scanning window, said scanning window including a plurality of pixel data which are arranged in rows and columns; a counting device for counting a number of predetermined pixels in the rows and the columns of the read image data; a line image determining device for determining, based on a result of counting by said counting device, whether the pixel data in said scanning window forms a line image or not; an isolated pixel determining device for determining whether said target pixel is an isolated pixel or not;</claim-text>
      <claim-text>and a converter for converting intensity data of the image data of the target pixel into a predetermined line image intensity when the target pixel is contained in a line image according to a result of said determination by said line image determining device, and converting the intensity data of the image data of the target pixel into a predetermined isolated point intensity when the target pixel is an isolated point according to a result of said determination by said isolated point pixel determining device.</claim-text>
      <claim-text>13. An image processing apparatus according to claim 12, wherein the intensity data of the image data of the target pixel is converted into a predetermined intensity of a white pixel when the target pixel is the isolated point according to a result of said determination by said isolated point pixel determining device.</claim-text>
      <claim-text>14. An image processing apparatus according to claim 12, further comprising: an average intensity value calculating device for calculating an average intensity value from intensity values of a plurality of pixels forming a line image in the scanning window, wherein said predetermined line image intensity is said average intensity value.</claim-text>
      <claim-text>15. An image processing apparatus according to claim 12, wherein said line image determining device includes: - a count value table for setting predetermined count values for the rows and columns in said scanning window, and - a comparator for comparing a result of counting by said counting device with a predetermined count value in said count value table; - wherein the result of said comparison by said comparator is used to determine whether the pixel data forms a line image or not.</claim-text>
      <claim-text>16. An image processing apparatus according to claim 14, wherein said line image determining device determines, in both the row and column directions, whether the pixel data forms a line image or not, when said line image determining device determines a presence of line images in both the row and column directions, said average intensity value calculating device calculates the average intensity value of each of the line images;</claim-text>
      <claim-text>and said converter converts the intensity value of said target pixel into a larger one of the calculated average intensity values.</claim-text>
      <claim-text>17. An image processing apparatus according to claim 12, wherein said isolated point determining device includes: - a count value table for setting predetermined count values for the rows and columns in said scanning window, and - a comparator for comparing a result of counting by said counting device with the predetermined count value in said count value table; - wherein the result of comparison by said comparator is used to determine whether the target pixel is an isolated point or not.</claim-text>
      <claim-text>18. An image processing apparatus comprising: a device for reading image data corresponding to a scanning window, said scanning window including a plurality of pixel data which are arranged in rows and columns; a counting device for counting, for each of the rows and columns in the scanning window, the numbers of pixel data having a predetermined value; a line image determining device for determining, based on a result of counting by said counting device, whether the pixel data in the scanning window forms a line image or not;</claim-text>
      <claim-text>and a converter for converting intensity data of the pixel data of said target pixel into a predetermined intensity based on a result of said determination by said line image determining device.</claim-text>
      <claim-text>19. An image processing apparatus comprising: a device for reading image data corresponding to a scanning window, said scanning window including a plurality of pixel data which are arranged in rows and columns; a counting device for counting, for each of the rows and columns in the scanning window, the numbers of pixel data having a predetermined value; a line image determining device for determining, based on a result of counting by said counting device, whether the pixel data in said scanning window forms a line image or not; an isolated pixel determining device for determining whether said target pixel is an isolated pixel or not;</claim-text>
      <claim-text>and a converter for converting intensity data of the image data of the target pixel into a predetermined line image intensity when the target pixel is contained in a line image according to a result of said determination by said line image determining device, and converting the intensity data of the image data of the target pixel into a predetermined isolated point intensity when the target pixel is an isolated point according to a result of said determination by said isolated point pixel determining device.</claim-text>
      <claim-text>21. A method of processing image data according to claim 20, wherein said counting step counts the number of the predetermined pixels in a predetermined intensity range.</claim-text>
      <claim-text>22. A method of processing image data according to claim 20, wherein: said setting step sets the count values for the rows and columns, respectively, such that the predetermined target pixel is present on an edge of the image forming the image data, and said converting step converts the intensity of the target pixel into a predetermined intensity when a predetermined result of comparison is obtained.</claim-text>
      <claim-text>23. A method of processing image data according to claim 22, wherein said converting step converts the intensity of the target pixel into an intensity of a black pixel when a predetermined result of comparison is obtained, and converts the intensity of the target pixel into an intensity of a white pixel when the predetermined result of comparison is not obtained.</claim-text>
    </claim>
    <claim num="25">
      <claim-text>25. A method of processing image data according to claim 24, further comprising a step of calculating an average intensity value from intensity values of a plurality of pixels forming a line image in the scanning window, wherein said predetermined intensity is said average intensity value.</claim-text>
    </claim>
    <claim num="26">
      <claim-text>26. A method of processing image data according to claim 25, wherein said determining step determines, in both the row and column directions, whether the pixel data forms a line image or not, said calculating step calculates the average intensity value of each of the line images when said determining step determines the presence of line images in both the row and column directions, and said converting step converts the intensity value of said target pixel into a larger one of the calculated average intensity values.</claim-text>
    </claim>
    <claim num="27">
      <claim-text>27. A method of processing image data comprising: reading image data corresponding to a scanning window, said scanning window including a plurality of pixel data which are arranged in rows and columns; counting a number of predetermined pixels in the rows and the columns of the read image data; determining, based on a result of counting by said counting step, whether the pixel data in said scanning window forms a line image or not; determining whether said target pixel is an isolated pixel or not;</claim-text>
      <claim-text>and converting intensity data of the image data of the target pixel into a predetermined line image intensity when the target pixel is contained in a line image according to a result of said determination by said determining step, and converting the intensity data of the image data of the target pixel into a predetermined isolated point intensity when the target pixel is an isolated point according to a result of said determination by said isolated point pixel determining step.</claim-text>
    </claim>
    <claim num="28">
      <claim-text>28. A method of processing image data according to claim 27, wherein the intensity data of the image data of the target pixel is converted into a predetermined intensity of a white pixel when the target pixel is the isolated point according to a result of said determination by said isolated point pixel determining step.</claim-text>
    </claim>
    <claim num="29">
      <claim-text>29. A method of processing image data according to claim 27, further comprising: a step of calculating, when said target pixel is determined to be present in a line image, an average intensity value from intensity values of a plurality of pixels forming said line image in the scanning window, wherein said predetermined line image intensity is said average intensity value.</claim-text>
    </claim>
    <claim num="30">
      <claim-text>30. A method of processing image data according to claim 29, wherein said line image determining step determines, in both the row and column directions, whether the pixel data forms a line image or not and, when said line image determining step determines a presence of line images in both the row and column directions, said average intensity value calculating step calculates the average intensity value of each of the line images and said converting step converts the intensity value of said target pixel into a larger one of the calculated average intensity values.</claim-text>
    </claim>
  </claims>
</questel-patent-document>