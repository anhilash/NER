<?xml version="1.0" encoding="UTF-8"?>
<questel-patent-document lang="en" date-produced="20180805" produced-by="Questel" schema-version="3.23" file="US06184898B2.xml">
  <bibliographic-data lang="en">
    <publication-reference publ-desc="Granted patent as second publication">
      <document-id>
        <country>US</country>
        <doc-number>06184898</doc-number>
        <kind>B2</kind>
        <date>20010206</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>US6184898</doc-number>
      </document-id>
    </publication-reference>
    <original-publication-kind>B2</original-publication-kind>
    <application-reference family-id="21955654" extended-family-id="42112818">
      <document-id>
        <country>US</country>
        <doc-number>09048642</doc-number>
        <kind>A</kind>
        <date>19980326</date>
      </document-id>
      <document-id data-format="questel">
        <doc-number>1998US-09048642</doc-number>
      </document-id>
      <document-id data-format="questel_Uid">
        <doc-number>43170769</doc-number>
      </document-id>
    </application-reference>
    <language-of-filing>en</language-of-filing>
    <language-of-publication>en</language-of-publication>
    <priority-claims>
      <priority-claim kind="national" sequence="1">
        <country>US</country>
        <doc-number>4864298</doc-number>
        <kind>A</kind>
        <date>19980326</date>
        <priority-active-indicator>Y</priority-active-indicator>
      </priority-claim>
      <priority-claim data-format="questel" sequence="1">
        <doc-number>1998US-09048642</doc-number>
      </priority-claim>
    </priority-claims>
    <dates-of-public-availability>
      <publication-of-grant-date>
        <date>20010206</date>
      </publication-of-grant-date>
    </dates-of-public-availability>
    <classifications-ipcr>
      <classification-ipcr sequence="1">
        <text>G06T  11/20        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>11</main-group>
        <subgroup>20</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="2">
        <text>G01R  13/20        20060101A N20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>01</class>
        <subclass>R</subclass>
        <main-group>13</main-group>
        <subgroup>20</subgroup>
        <classification-value>N</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="3">
        <text>G01R  13/28        20060101A N20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>01</class>
        <subclass>R</subclass>
        <main-group>13</main-group>
        <subgroup>28</subgroup>
        <classification-value>N</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
      <classification-ipcr sequence="4">
        <text>G01R  13/34        20060101A I20051008RMEP</text>
        <ipc-version-indicator>
          <date>20060101</date>
        </ipc-version-indicator>
        <classification-level>A</classification-level>
        <section>G</section>
        <class>01</class>
        <subclass>R</subclass>
        <main-group>13</main-group>
        <subgroup>34</subgroup>
        <classification-value>I</classification-value>
        <generating-office>
          <country>EP</country>
        </generating-office>
        <classification-status>R</classification-status>
        <classification-data-source>M</classification-data-source>
        <action-date>
          <date>20051008</date>
        </action-date>
      </classification-ipcr>
    </classifications-ipcr>
    <classification-national>
      <country>US</country>
      <main-classification>
        <text>345440000</text>
        <class>345</class>
        <subclass>440000</subclass>
      </main-classification>
      <further-classification sequence="1">
        <text>345440200</text>
        <class>345</class>
        <subclass>440200</subclass>
      </further-classification>
      <further-classification sequence="2">
        <text>345589000</text>
        <class>345</class>
        <subclass>589000</subclass>
      </further-classification>
      <further-classification sequence="3">
        <text>345639000</text>
        <class>345</class>
        <subclass>639000</subclass>
      </further-classification>
    </classification-national>
    <classifications-ecla>
      <classification-ecla sequence="1">
        <text>G01R-013/34C</text>
        <section>G</section>
        <class>01</class>
        <subclass>R</subclass>
        <main-group>013</main-group>
        <subgroup>34C</subgroup>
      </classification-ecla>
      <classification-ecla sequence="2">
        <text>G06T-011/20T</text>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>011</main-group>
        <subgroup>20T</subgroup>
      </classification-ecla>
    </classifications-ecla>
    <patent-classifications>
      <patent-classification sequence="1">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G01R-013/345</classification-symbol>
        <section>G</section>
        <class>01</class>
        <subclass>R</subclass>
        <main-group>13</main-group>
        <subgroup>345</subgroup>
        <symbol-position>F</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="2">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G01R-013/206</classification-symbol>
        <section>G</section>
        <class>01</class>
        <subclass>R</subclass>
        <main-group>13</main-group>
        <subgroup>206</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="3">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G01R-013/28</classification-symbol>
        <section>G</section>
        <class>01</class>
        <subclass>R</subclass>
        <main-group>13</main-group>
        <subgroup>28</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>A</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="4">
        <classification-scheme office="EP" scheme="CPC">
          <date>20130101</date>
        </classification-scheme>
        <classification-symbol>G06T-011/206</classification-symbol>
        <section>G</section>
        <class>06</class>
        <subclass>T</subclass>
        <main-group>11</main-group>
        <subgroup>206</subgroup>
        <symbol-position>L</symbol-position>
        <classification-value>I</classification-value>
        <classification-status>B</classification-status>
        <classification-data-source>H</classification-data-source>
        <action-date>
          <date>20130101</date>
        </action-date>
      </patent-classification>
      <patent-classification sequence="5">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>S01R-013/20D</classification-symbol>
      </patent-classification>
      <patent-classification sequence="6">
        <classification-scheme office="EP" scheme="ICO"/>
        <classification-symbol>S01R-013/28</classification-symbol>
      </patent-classification>
    </patent-classifications>
    <number-of-claims>47</number-of-claims>
    <exemplary-claim>1</exemplary-claim>
    <figures>
      <number-of-drawing-sheets>3</number-of-drawing-sheets>
      <number-of-figures>5</number-of-figures>
      <image-key data-format="questel">US6184898</image-key>
    </figures>
    <invention-title format="original" lang="en" id="title_en">Waveform display utilizing frequency-based coloring and navigation</invention-title>
    <references-cited>
      <citation srep-phase="examiner">
        <patcit num="1">
          <text>CHEN JAMES N, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5553235</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5553235</doc-number>
          </document-id>
        </patcit>
      </citation>
      <citation srep-phase="examiner">
        <patcit num="2">
          <text>CHEN JAMES NEWMAN, et al</text>
          <document-id>
            <country>US</country>
            <doc-number>5684945</doc-number>
            <kind>A</kind>
          </document-id>
          <document-id data-format="questel">
            <doc-number>US5684945</doc-number>
          </document-id>
        </patcit>
      </citation>
    </references-cited>
    <parties>
      <applicants>
        <applicant data-format="original" app-type="applicant" sequence="1">
          <addressbook lang="en">
            <orgname>Comparisonics Corporation</orgname>
            <address>
              <address-1>Grass Valley, CA, US</address-1>
              <city>Grass Valley</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
        <applicant data-format="questel" app-type="applicant" sequence="2">
          <addressbook lang="en">
            <orgname>COMPARISONICS</orgname>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </applicant>
      </applicants>
      <inventors>
        <inventor data-format="original" sequence="1">
          <addressbook lang="en">
            <name>Rice, Stephen V.</name>
            <address>
              <address-1>Nevada City, CA, US</address-1>
              <city>Nevada City</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
        <inventor data-format="original" sequence="2">
          <addressbook lang="en">
            <name>Patten, Michael D.</name>
            <address>
              <address-1>Nevada City, CA, US</address-1>
              <city>Nevada City</city>
              <state>CA</state>
              <country>US</country>
            </address>
          </addressbook>
          <nationality>
            <country>US</country>
          </nationality>
        </inventor>
      </inventors>
      <agents>
        <agent sequence="1" rep-type="agent">
          <addressbook lang="en">
            <name>Smith-Hill, John</name>
          </addressbook>
        </agent>
        <agent sequence="2" rep-type="agent">
          <addressbook lang="en">
            <orgname>Smith-Hill and Bedell</orgname>
          </addressbook>
        </agent>
      </agents>
    </parties>
    <examiners>
      <primary-examiner>
        <name>Brier, Jeffery</name>
      </primary-examiner>
    </examiners>
    <lgst-data>
      <lgst-status>EXPIRED</lgst-status>
    </lgst-data>
  </bibliographic-data>
  <abstract format="original" lang="en" id="abstr_en">
    <p id="P-EN-00001" num="00001">
      <br/>
      Time evolution of a signal during a signal epoch is represented by a waveform display in which the foreground pixels in a column of pixels assigned to a time interval within the signal epoch are rendered with a color that depends on frequency-dependent information relating to a time segment that includes the time interval.
    </p>
  </abstract>
  <description format="original" lang="en" id="desc_en">
    <heading>BACKGROUND OF THE INVENTION</heading>
    <p num="1">This invention relates to a waveform display utilizing frequency-based coloring and navigation.</p>
    <p num="2">There are at least three well known representations of a signal:</p>
    <p num="3">
      1.
      <br/>
      The spectrum or frequency domain representation is a two-dimensional graph in which amplitude is plotted versus frequency.
      <br/>
      All points of the graph are normally plotted using the same color.
      <br/>
      Time information is not evident.
    </p>
    <p num="4">2. The spectrogram is a three-dimensional graph in which frequency is plotted versus time and the points of the graph are rendered using colors or shades of gray to convey amplitude information.</p>
    <p num="5">
      3. The waveform display or time domain representation is a two-dimensional graph in which amplitude is plotted versus time.
      <br/>
      All points of the graph are normally plotted using the same color.
      <br/>
      Frequency information is not evident.
    </p>
    <p num="6">
      FIG. 1 shows a portion 10 of a typical waveform display derived from an audio signal, i.e. an electrical signal containing audio frequency components.
      <br/>
      The waveform display shown in FIG. 1 is of the kind that might be presented by a display device having a display area composed of pixels 14 arranged in columns 18.
      <br/>
      For convenience, the pixels 14 are shown in FIG. 1 as having an aspect ratio (height: width) substantially less than one, but in practice the aspect ratio would normally be closer to one.
    </p>
    <p num="7">
      By way of example, the portion 10 of the waveform display represents an audio signal that has been sampled at intervals  TAU  and has been quantized to return the twenty values indicated at the bottom of FIG. 1.
      <br/>
      Each column 18 of pixels is used to display a representation of the evolution of the signal over an interval 5 TAU , so that the twenty sample values are represented by four columns.
      <br/>
      Typically, the background color of the display is white and the amplitude information is plotted by rendering selected pixels 14 with a contrasting foreground color or black.
      <br/>
      The pixels in the column that are rendered with the foreground color (or black) show a line segment connecting the maximum and minimum sample values within the interval represented by the column.
      <br/>
      Thus, in the leftmost column the pixels from -2 to +5 are rendered with the foreground color (or black), represented by solid diagonal shading.
    </p>
    <heading>SUMMARY OF THE INVENTION</heading>
    <p num="8">In accordance with a first aspect of the present invention there is provided an improved method of representing time evolution of a signal during a signal epoch using a rectangular array of pixels in which each column of pixels is assigned to a time interval within the signal epoch, and wherein foreground pixels in a column of pixels form a line segment connecting minimum and maximum amplitude values within the time interval to which the column is assigned, wherein the improvement resides in rendering the foreground pixels in a column with a color that depends on frequency-dependent information relating to a time segment that includes the time interval.</p>
    <p num="9">In accordance with a second aspect of the present invention there is provided an improved method of displaying information regarding a signal of which amplitude and frequency vary with time, in which the signal is used to generate a time domain representation of the amplitude of the signal as a foreground waveform against a background, wherein the improvement resides in varying the color with which the waveform is displayed as a function of frequency-dependent information obtained from the signal.</p>
    <p num="10">In accordance with a third aspect of the present invention there is provided a computer programmed to process a signal that evolves with time during a signal epoch by partitioning the signal epoch into a plurality of consecutive time segments, processing the signal to extract frequency-dependent information that characterizes each time segment, assigning a value to each time segment based on the frequency-dependent information that characterizes the time segment, receiving a user input to select a time segment of the signal, determining whether the value assigned to another time segment matches the value assigned to the user selected time segment, and, if so, providing an output which emphasizes at least one such time segment.</p>
    <p num="11">In accordance with a fourth aspect of the present invention there is provided a method of navigating a signal record, comprising partitioning the signal record into a plurality of consecutive segments, processing the signal to extract frequency-dependent information that characterizes each time segment, assigning a value to each time segment based on the frequency-dependent information that characterizes the time segment, selecting a time segment of the signal, determining whether the value assigned to another time segment matches the value assigned to the user selected time segment, and, if so, emphasizing at least one such time segment.</p>
    <p num="12">In accordance with a fifth aspect of the present invention there is provided a computer programmed to generate a representation of time evolution of a signal during a signal epoch using a rectangular array of pixels in which each column of pixels is assigned to a time interval within the signal epoch, and wherein foreground pixels in a column of pixels form a line segment connecting minimum and maximum amplitude values within the time interval to which the column is assigned, wherein the computer is programmed to render the foreground pixels in a column with a color that depends on frequency-dependent information relating to a time segment that includes the time interval.</p>
    <heading>BRIEF DESCRIPTION OF THE DRAWINGS</heading>
    <p num="13">
      For a better understanding of the invention, and to show how the same may be carried into effect, reference will now be made, by way of example, to the accompanying drawings, in which
      <br/>
      FIG. 1 is a graph illustrating a portion of a waveform display of an audio signal,
      <br/>
      FIG. 2 is a block diagram of an apparatus for processing an acoustic signal to provide an enhanced waveform display,
      <br/>
      FIG. 3 is a diagram illustrating signal processing in the apparatus shown in FIG. 1,
      <br/>
      FIG. 4 is a graph illustrating a portion of an enhanced waveform display, and
      <br/>
      FIG. 5 is a flow chart illustrating a method in accordance with the invention.
    </p>
    <heading>DETAILED DESCRIPTION</heading>
    <p num="14">
      Referring to FIG. 2, a microphone 22 receives an acoustic signal and converts it into an audio frequency analog electrical signal.
      <br/>
      An analog-to-digital converter (ADC) 26 samples the analog audio signal at 44.1 ks/sec and quantizes the samples to generate a digital audio signal composed of a succession of N1 sample values or words.
      <br/>
      The digital audio signal may be acquired from another source, such as playback of a compact disc or by digitizing an analog signal generated on playback of a tape recording.
      <br/>
      In any event, an audio data record in which each word represents the amplitude of the audio signal at a selected sampling time during a signal epoch is generated and is loaded into an acquisition memory 30.
      <br/>
      If, for example, the duration of the signal epoch is 200 seconds, the audio data record will contain 8.82 * 106 words.
    </p>
    <p num="15">
      A display controller 40 generates a video signal for controlling operation of a display device 32 to display pixels organized in a rectangular array composed of H rows and N2 columns.
      <br/>
      The display device 32 is able to display a palette of colors, and each pixel can be painted with any of the colors in the palette.
    </p>
    <p num="16">To render the waveform display of the signal as a bitmapped image on the display device 32, each column of the array of pixels represents a distinct interval of the signal epoch containing C=N1/N2 sample values.</p>
    <p num="17">
      A processor 34 reads the audio data record and generates a pair of minimum and maximum amplitude values for each set of C consecutive sample values, corresponding to one of the N2 intervals of the signal epoch.
      <br/>
      The processor 34 supplies the pairs of minimum and maximum amplitude values to the display controller 40.
      <br/>
      The pairs of maximum and minimum values allow the display controller to generate a video signal specifying the foreground pixels of each column, forming a line segment connecting the minimum and maximum values within the interval represented by the column.
    </p>
    <p num="18">
      The processor 34 partitions the audio data record read from the acquisition memory 30 (FIG. 3, step 100) into N3 consecutive, contiguous, non-overlapping segments, where each segment consists of kC sample values, where k is an integer between 1 and N2.
      <br/>
      Thus, N3 is equal to N2/k, and each segment is represented by a distinct group of k consecutive columns of pixels.
      <br/>
      In this specification, the term "super column" is used to refer to the k columns of pixels associated with a given segment of the data record.
      <br/>
      In this manner, the audio signal epoch is divided into N3 consecutive, contiguous, non-overlapping time segments of equal duration.
      <br/>
      In a typical application, there might be one thousand segments and in the case of the example, each segment represents a signal interval of 0.2 s and contains 8,820 words.
    </p>
    <p num="19">
      The processor 34 analyzes each segment (step 104) to extract frequency-dependent information.
      <br/>
      For example, the processor might execute a Fast Fourier Transform or a Linear Prediction algorithm, in which case each segment of the audio data record is decomposed into multiple frequency components.
      <br/>
      The audio frequency spectrum is divided into several bands and a unique index value is associated with each band.
      <br/>
      For example, the audio spectrum may be divided into six bands and one might associate the index value 1 with the lowest frequency band, 2 with the second lowest frequency band, 3 with the third lowest frequency band, and so on, associating the index value 6 with the highest frequency band.
      <br/>
      The processor 34 determines which frequency band is dominant (step 108A), for example by determining which band contains the frequency components having the greatest amplitude, and assigns an index value P to that segment based on the location of the dominant frequency band in the audio spectrum (step 112A).
      <br/>
      The processor 34 also determines an amplitude variance value V for each segment (step 108B), for example based on the variance of the sample values used to form the segment.
      <br/>
      The data elements P and V for each segment are combined to create a signature (P, V) which contains both frequency information and amplitude variance information and characterizes the segment (step 116).
      <br/>
      The processor loads the signature in a signature memory 38 having N3 separate addressable memory locations (step 120).
    </p>
    <p num="20">
      The display controller 40 reads the signatures from the signature memory 38 and generates a video signal for controlling operation of the display device 32 such that the appearance of the foreground pixels in the ith super column of the display depends on the signature stored at the ith memory location in the signature memory.
      <br/>
      Specifically, the display controller generates the video signal such that the foreground pixels in the ith super column are painted with a color that depends on the element Pi of the signature in the corresponding memory location of the signature memory.
      <br/>
      If red is considered a more active or urgent color than blue and correspondingly higher frequency sounds are considered more active or urgent than lower frequency sounds, it may be appropriate to associate shades of red with higher frequencies and shades of blue with lower frequencies.
      <br/>
      Thus, one might associate the colors red, orange, yellow, green, blue and violet with the index values 6, 5, 4, 3, 2 and 1 respectively.
    </p>
    <p num="21">
      It will therefore be seen that the display device provides an display which is similar to the waveform display shown in FIG. 1 but is enhanced by rendering frequency information evident through variation in the foreground color.
      <br/>
      For example, in the case of the signal whose waveform is shown in FIG. 1, if k were equal to two, so that two columns of pixels form a super column, and the index value 6 were assigned to the segment corresponding to the columns at the left of FIG. 1 and the index value 2 were assigned to the segment corresponding to the columns at the right of FIG. 1, the enhanced display shown in FIG. 4 would be obtained, where the two orientations of diagonal shading represent red and blue respectively.
    </p>
    <p num="22">
      Although the foregoing discussion is directed to all the foreground pixels in each super column being displayed with the same color, it would be possible to display the foreground pixels in a given super column with more than one color.
      <br/>
      By way of example only, a given index value could be assigned to two colors, in which case some of the foreground pixels in the super column may be painted with one color and other foreground pixels in the super column may be painted with another color.
      <br/>
      The two groups of pixels may be interspersed, thus creating a third color, or the two groups of pixels may be discrete and continuous or the group of pixels of one color may be located between two subgroups of pixels of the other color.
      <br/>
      The number of possible ways of utilizing the frequency-dependent information to control the color of the foreground pixels is very great, and no attempt has been made to be exhaustive.
    </p>
    <p num="23">
      A printer 36 is associated with the display device 32 and can provide a printout, e.g. on paper or a transparency medium, of the image shown on the display device 32.
      <br/>
      Thus, an image of only transient importance may be only displayed temporarily on the display device, but if an image is perceived to have enduring significance, it can be printed out using the printer to form a lasting record.
    </p>
    <p num="24">In the event that the display device 32 is able to display only W columns of pixels, where W is less than N2, the user may operate a horizontal scroll bar to bring into view any W consecutive columns of the image.</p>
    <p num="25">
      The signatures stored in the signature memory can also be used to navigate the audio data record.
      <br/>
      Referring to FIG. 5, the user can select (step 200) a particular segment (segment M) of the audio data record by using a cursor to identify a super column of the display while viewing the waveform.
      <br/>
      The processor 34 retrieves the signature for segment M of the audio data record from the signature memory and compares other signatures with the signature for segment M, using both the frequency information and the amplitude variance information, in order to identify signatures that match the signature for segment M within a desired tolerance.
      <br/>
      As shown in FIG. 5, this may be accomplished by setting a variable N equal to M (step 204), reading the signature for segment N+1 from the signature memory (step 208) and comparing it with the signature for segment M (step 212).
      <br/>
      If the two signatures match within the desired tolerance, the processor 34 instructs the display controller to alter the display by emphasizing or drawing attention to the super column corresponding to segment N+1 of the audio data record (step 216), for example by moving the cursor of the display to point to this super column.
      <br/>
      If the signatures do not match, the process determines whether segment N+1 is the last segment, i.e. N+1=N3 (step 220) and, if so, the process terminates.
      <br/>
      Otherwise, the variable is incremented (step 224) and the process returns to step 208.
    </p>
    <p num="26">
      In the process described with reference to FIG. 5, the segments having signatures that match the signature for segment M are located by reading forward from segment M. Alternatively, the matching segments may be located by examining all the signatures from the start of the signature memory or by reading backward from the selected segment, or in another convenient fashion, depending on user commands.
      <br/>
      The signatures may be compared until a selected number of matches have been accumulated, including only a single match, or until all signatures have been compared.
      <br/>
      The user can move the cursor forward or backward from one matching segment to another, for example by pressing direction arrow keys or invoking other standard cursor movement commands.
    </p>
    <p num="27">
      The weight to be accorded to amplitude variance in the matching process can be selected by the user.
      <br/>
      For example, the user may wish to base the matching only on the color component of the signature, in which case no weight would be accorded to amplitude variance.
    </p>
    <p num="28">
      It would also be possible to select a segment of the audio data record by invoking a select command while listening to the acoustic signal concurrently with processing the acoustic signal in the manner described with reference to FIGS. 2 and 3 to generate the signatures, or while listening to a replica of the acoustic signal created by playing back the audio data record stored in the acquisition memory, through a digital-to-analog converter and a loudspeaker.
      <br/>
      In the former case, it may be necessary to wait briefly while the digital audio signal is processed before it will be possible to navigate the audio data record.
    </p>
    <p num="29">The process described with reference to FIG. 5 is not restricted to matching a single segment with other segments, and the user may select a sequence of consecutive segments and have this sequence compared with every other sequence of segments to locate matches.</p>
    <p num="30">Although it is normally preferred that the waveform should be displayed in color, as described with reference to FIGS. 2 and 3, it is not necessary to do so when using the signatures to navigate the audio data record as described with reference to FIG. 5, and in this case the display could be monochrome.</p>
    <p num="31">
      It will be appreciated that the invention is not restricted to the particular embodiment that has been described, and that variations may be made therein without departing from the scope of the invention as defined in the appended claims and equivalents thereof.
      <br/>
      For example, although the foregoing description refers to a method in which the segments are non-overlapping and each corresponds to the same length of time, and the segmentation is accomplished automatically, the segmentation could be performed in response to user input, wholly or in part, and the segments may correspond to time intervals of non-uniform length and intervals that are overlapping.
      <br/>
      Particularly, if the signal remains uniform (within specified limits) in amplitude and frequency for considerable periods of time, a single segment may correspond to a longer time interval than if the signal changes relatively rapidly in amplitude or frequency.
      <br/>
      Further, although the foregoing description is concerned with extracting information regarding the dominant frequency, information regarding subordinate frequencies may also be used to determine the color or colors used to paint a super column.
      <br/>
      Moreover, the functions and arrangement of the blocks shown in FIG. 2 were chosen in order to facilitate discussion of signal flow and the invention is not restricted to use of the specific functional blocks shown in FIG. 2, arranged and connected in the manner shown in FIG. 2.
      <br/>
      For example, although the display controller 40 is shown in FIG. 2 as a distinct block from the processor 34, its function may be performed by the processor 34.
    </p>
  </description>
  <claims format="original" lang="en" id="claim_en">
    <claim num="1">
      <claim-text>We claim:</claim-text>
      <claim-text>1.</claim-text>
      <claim-text>An improved method of representing time evolution of a signal during a signal epoch using a rectangular array of pixels in which each column of pixels is assigned to a time interval within the signal epoch, and wherein foreground pixels in a column of pixels form a line segment connecting smaller and greater amplitude values within the time interval to which the column is assigned, wherein the improvement resides in rendering the foreground pixels in a column with a color that depends on frequency-dependent information relating to a time segment that includes the time interval.</claim-text>
    </claim>
    <claim num="2">
      <claim-text>2. A method according to claim 1, comprising rendering all the foreground pixels in the column with the same color.</claim-text>
    </claim>
    <claim num="3">
      <claim-text>3. A method according to claim 1, comprising rendering the foreground pixels in the column with at least two colors.</claim-text>
    </claim>
    <claim num="4">
      <claim-text>4. A method according to claim 1, wherein the smaller and greater amplitude values are minimum and maximum amplitude values.</claim-text>
    </claim>
    <claim num="5">
      <claim-text>5. A method according to claim 1, comprising:</claim-text>
      <claim-text>(a) partitioning the signal epoch into a plurality of consecutive time segments each of a duration corresponding to at least one column of the display, (b) processing the signal to extract frequency-dependent information relating to each time segment, (c) assigning a color to each time segment based on the frequency-dependent information relating to the time segment, and (d) rendering the foreground pixels of each column in the time segment with the color assigned in step (c).</claim-text>
    </claim>
    <claim num="6">
      <claim-text>6. A method according to claim 5, comprising creating an image on a transient display.</claim-text>
    </claim>
    <claim num="7">
      <claim-text>7. A method according to claim 5, comprising creating an image on a sheet form medium.</claim-text>
    </claim>
    <claim num="8">
      <claim-text>8. A method according to claim 5, wherein the time segments are contiguous.</claim-text>
    </claim>
    <claim num="9">
      <claim-text>9. A method according to claim 5, wherein the time segments are of equal duration.</claim-text>
    </claim>
    <claim num="10">
      <claim-text>10. A method according to claim 5, wherein the time segments are not of equal duration.</claim-text>
    </claim>
    <claim num="11">
      <claim-text>11. A method according to claim 5, wherein the time segments are non-overlapping.</claim-text>
    </claim>
    <claim num="12">
      <claim-text>12. A method according to claim 5, wherein the time segments are overlapping.</claim-text>
    </claim>
    <claim num="13">
      <claim-text>13. A method according to claim 5, comprising partitioning the signal epoch into segments automatically.</claim-text>
    </claim>
    <claim num="14">
      <claim-text>14. A method according to claim 5, comprising partitioning the signal epoch into segments in response to user input.</claim-text>
    </claim>
    <claim num="15">
      <claim-text>15. A method according to claim 5, wherein step (b) comprises extracting frequency-dependent information depending on a dominant frequency in the segment.</claim-text>
    </claim>
    <claim num="16">
      <claim-text>16. A method according to claim 5, wherein step (b) comprises extracting frequency-dependent information depending on a subordinate frequency in the segment.</claim-text>
    </claim>
    <claim num="17">
      <claim-text>17. An improved method of displaying information regarding a signal of which amplitude and frequency vary with time, in which the signal is used to generate a time domain representation of the amplitude of the signal as a foreground waveform against a background, wherein the improvement resides in varying the color with which the waveform is displayed as a function of frequency-dependent information obtained from the signal.</claim-text>
    </claim>
    <claim num="18">
      <claim-text>18. A computer programmed to process a signal that evolves with time during a signal epoch by: (a) partitioning the signal epoch into a plurality of consecutive time segments, (b) processing the signal to extract frequency-dependent information that characterizes each time segment, (c) assigning a value to each time segment based on the frequency-dependent information that characterizes the time segment, (d) receiving a user input to select a time segment of the signal, (e) determining whether the value assigned to another time segment matches the value assigned to the user selected time segment, and, if so, (f) providing an output which emphasizes at least one such time segment.</claim-text>
    </claim>
    <claim num="19">
      <claim-text>19. A computer according to claim 18, wherein step (d) comprises receiving a user input to select a sequence of consecutive time segments and step (e) comprises determining whether the values assigned to another sequence of consecutive time segments match the values assigned to the user selected sequence of time segments.</claim-text>
    </claim>
    <claim num="20">
      <claim-text>20. A computer according to claim 18, including a display device for displaying a monochrome representation of the time evolution of the signal during at least a part of the signal epoch.</claim-text>
    </claim>
    <claim num="21">
      <claim-text>21. A computer according to claim 18, programmed to partition the signal epoch into contiguous time segments.</claim-text>
    </claim>
    <claim num="22">
      <claim-text>22. A computer according to claim 18, programmed to partition the signal epoch into time segments of equal duration.</claim-text>
    </claim>
    <claim num="23">
      <claim-text>23. A computer according to claim 18, programmed to partition the signal epoch into time segments not of equal duration.</claim-text>
    </claim>
    <claim num="24">
      <claim-text>24. A computer according to claim 18, programmed to partition the signal epoch into time segments that are non-overlapping.</claim-text>
    </claim>
    <claim num="25">
      <claim-text>25. A computer according to claim 18, programmed to partition the signal epoch into time segments that are overlapping.</claim-text>
    </claim>
    <claim num="26">
      <claim-text>26. A computer according to claim 18, programmed to partition the signal epoch into segments automatically.</claim-text>
    </claim>
    <claim num="27">
      <claim-text>27. A computer according to claim 18, programmed to partition the signal epoch into segments in response to user input.</claim-text>
    </claim>
    <claim num="28">
      <claim-text>28. A computer according to claim 18, programmed to extract frequency-dependent information depending on a dominant frequency in the segment.</claim-text>
    </claim>
    <claim num="29">
      <claim-text>29. A computer according to claim 18, programmed to extract frequency-dependent information depending on a subordinate frequency in the segment.</claim-text>
    </claim>
    <claim num="30">
      <claim-text>30. A computer according to claim 19, programmed to display a representation of the time evolution of the signal during at least a part of the signal epoch, and wherein step (d) comprises receiving the user input based on the display.</claim-text>
    </claim>
    <claim num="31">
      <claim-text>31. A computer according to claim 30, wherein step (f) includes adjusting the display.</claim-text>
    </claim>
    <claim num="32">
      <claim-text>32. A computer according to claim 30, programmed to associate a color with each value assigned in step (c) and display each time segment using the color associated with the value assigned to the time segment.</claim-text>
    </claim>
    <claim num="33">
      <claim-text>33. A computer according to claim 30, programmed to scroll the display to illustrate said one segment.</claim-text>
    </claim>
    <claim num="34">
      <claim-text>34. A computer according to claim 19, programmed to extract amplitude-dependent information relating to each segment and to create a data structure including the frequency-dependent information and the amplitude-dependent information.</claim-text>
    </claim>
    <claim num="35">
      <claim-text>35. A computer according to claim 34, wherein the amplitude-dependent information is a value of amplitude variance during the segment.</claim-text>
    </claim>
    <claim num="36">
      <claim-text>36. A computer according to claim 34, programmed to assign a value to each time segment based on both the frequency-dependent information and the amplitude-dependent information.</claim-text>
    </claim>
    <claim num="37">
      <claim-text>37. A computer according to claim 19, programmed to display a representation of the time evolution of the signal during at least a part of the signal epoch and to emphasize at least one such segment by moving a cursor to call attention to said segment.</claim-text>
    </claim>
    <claim num="38">
      <claim-text>38. A computer according to claim 37, programmed to displace the cursor to a matching segment in response to a user command.</claim-text>
    </claim>
    <claim num="39">
      <claim-text>39. A computer according to claim 18, programmed to create an image representing time evolution of the signal during the signal epoch using a rectangular array of pixels in which each column of pixels is assigned to a time interval within the signal epoch, and wherein foreground pixels in a column of pixels form a line segment connecting smaller and greater amplitude values within the time interval to which the column is assigned and are rendered with a color that depends on the frequency-dependent information that characterizes the time segment that includes the time interval.</claim-text>
    </claim>
    <claim num="40">
      <claim-text>40. A computer according to claim 39, programmed to render all the foreground pixels in the column with the same color.</claim-text>
    </claim>
    <claim num="41">
      <claim-text>41. A computer according to claim 39, programmed to render the foreground pixels in the column with at least two colors.</claim-text>
    </claim>
    <claim num="42">
      <claim-text>42. A computer according to claim 39, wherein the smaller and greater amplitude values are minimum and maximum amplitude values.</claim-text>
    </claim>
    <claim num="43">
      <claim-text>43. A method of navigating a signal record, comprising: (a) partitioning the signal record into a plurality of consecutive segments, (b) processing the signal record to extract frequency-dependent information that characterizes each time segment, (c) assigning a value to each time segment based on the frequency-dependent information that characterizes the time segment, (d) selecting a time segment of the signal record, (e) determining whether the value assigned to another time segment matches the value assigned to the user selected time segment, and, if so, (f) emphasizing at least one such time segment.</claim-text>
    </claim>
    <claim num="44">
      <claim-text>44. A computer programmed to generate a representation of time evolution of a signal during a signal epoch using a rectangular array of pixels in which each column of pixels is assigned to a time interval within the signal epoch, and wherein foreground pixels in a column of pixels form a line segment connecting smaller and greater amplitude values within the time interval to which the column is assigned, wherein the computer is programmed to render the foreground pixels in a column with a color that depends on frequency-dependent information relating to a time segment that includes the time interval.</claim-text>
    </claim>
    <claim num="45">
      <claim-text>45. A computer according to claim 44, wherein the smaller and greater amplitude values are minimum and maximum amplitude values.</claim-text>
    </claim>
    <claim num="46">
      <claim-text>46. An improved method of analyzing a signal, comprising: (a) processing the signal to extract frequency-dependent information that characterizes a time segment of the signal, (b) assigning a value to the time segment based on the frequency-dependent information that characterizes the time segment, and (c) comparing the value assigned in step (b) with a datum value.</claim-text>
    </claim>
    <claim num="47">
      <claim-text>47. A method according to claim 46, comprising the step of deriving the datum value by: (A) partitioning a signal into a plurality of consecutive time segments, (B) processing the signal of step (A) to extract frequency-dependent information that characterizes each time segment, (C) assigning a value to each time segment based on the frequency-dependent information that characterizes the time segment, (D) selecting a time segment of the signal of step (A), and (E) selecting the value that characterizes the time segment selected in step (D) as the datum value.</claim-text>
    </claim>
  </claims>
</questel-patent-document>